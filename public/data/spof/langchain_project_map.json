{
  "Third-Party Integrations & Connectors": {
    "description": "Offers a vast ecosystem of pre-built integrations with hundreds of external systems. This includes seamless connections to a wide array of language models, vector databases, APIs, and other services, accelerating development and providing platform flexibility.",
    "functions": {
      "Vector Database Connectors": {
        "files": [
          {
            "path": "libs/partners/qdrant/README.md",
            "description": "This file is the README for the `langchain-qdrant` Python package, detailing its purpose as an integration between LangChain and Qdrant, providing installation instructions, and linking to official documentation.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/langchain_qdrant/__init__.py",
            "description": "This `__init__.py` file initializes the `langchain_qdrant` package, providing core components for integrating the Qdrant vector database with LangChain, including vector store functionalities and sparse embeddings.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/langchain_qdrant/fastembed_sparse.py",
            "description": "This file implements the `SparseEmbeddings` interface using the `fastembed` library to generate sparse text embeddings, primarily for integration with Qdrant.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder integration test for the Qdrant LangChain partner library, designed solely to check if the integration test suite compiles correctly without executing any actual tests.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/common.py",
            "description": "This file provides utility functions and fake embedding implementations (dense and sparse) primarily for use in Qdrant integration tests, including checking if a local Qdrant instance is running and asserting document equality.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/fixtures.py",
            "description": "This file provides utility functions (fixtures) for configuring Qdrant test environments, specifically determining Qdrant instance locations and retrieval modes for integration tests.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/test_from_texts.py",
            "description": "This file contains integration tests for the `Qdrant.from_texts` method in the langchain_qdrant library, covering various scenarios like data storage, ID handling, vector configurations, collection reuse, and error conditions.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/qdrant_vector_store/test_mmr.py",
            "description": "This file contains integration tests for the Max Marginal Relevance (MMR) search functionality in the Qdrant vector store, covering various configurations and retrieval modes, including cases where MMR should and should not be supported.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/qdrant_vector_store/test_from_texts.py",
            "description": "This file contains integration tests for the `from_texts` method of the `QdrantVectorStore` in the `langchain_qdrant` library. It verifies text storage, ID handling, named vector functionality, collection reuse, and error conditions related to vector dimensionality, names, and distance metrics.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/async_api/test_add_texts.py",
            "description": "This file contains asynchronous integration tests for the `aadd_texts` method of the `Qdrant` vector store, verifying its functionality in various scenarios including ID management, handling duplicate texts, and named vectors.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/unit_tests/test_standard.py",
            "description": "This file contains a pytest benchmark test to measure the initialization performance of the QdrantVectorStore using mock embeddings and an in-memory database.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/unit_tests/test_imports.py",
            "description": "This file contains a unit test that verifies the `__all__` variable in the `langchain_qdrant` package accurately lists all expected public symbols. It ensures the public API surface matches the intended components.",
            "spof": true
          },
          {
            "path": "libs/partners/chroma/README.md",
            "description": "This README file introduces and provides guidance for the `langchain-chroma` package, which integrates LangChain with Chroma. It includes installation instructions and links to further documentation.",
            "spof": true
          },
          {
            "path": "libs/partners/chroma/langchain_chroma/__init__.py",
            "description": "This file serves as the `__init__.py` for the `langchain_chroma` package, providing LangChain integration for the Chroma vector database. It exposes the `Chroma` vector store class for external use.",
            "spof": true
          },
          {
            "path": "libs/partners/chroma/tests/unit_tests/test_vectorstores.py",
            "description": "This file contains unit tests for the `Chroma` vector store integration, specifically testing its initialization and similarity search functionalities using fake embeddings.",
            "spof": true
          },
          {
            "path": "libs/partners/chroma/tests/unit_tests/test_imports.py",
            "description": "This file contains a unit test to verify that the `langchain_chroma` module's `__all__` variable correctly exposes its intended public symbols. It asserts that only 'Chroma' is listed as part of the module's public API.",
            "spof": true
          },
          {
            "path": "libs/partners/chroma/tests/integration_tests/test_vectorstores.py",
            "description": "This file contains integration tests for the LangChain Chroma vector store. It verifies various functionalities like document ingestion, similarity search, metadata handling, persistence, and filtering with the ChromaDB backend.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 45
          },
          {
            "name": "Anush",
            "percent": 22
          },
          {
            "name": "Eric Pinzur",
            "percent": 8
          }
        ]
      },
      "General-Purpose LLM & Embedding Integrations": {
        "files": [
          {
            "path": "libs/partners/deepseek/README.md",
            "description": "This README file introduces the `langchain-deepseek` package, detailing its purpose as the LangChain integration with DeepSeek, providing installation instructions, and linking to documentation and contribution guidelines.",
            "spof": true
          },
          {
            "path": "libs/partners/deepseek/tests/integration_tests/__init__.py",
            "description": "This file serves as the package initializer for the integration tests of the `langchain_deepseek` package. It primarily defines the `integration_tests` directory as a Python package and provides a high-level summary of its contents.",
            "spof": true
          },
          {
            "path": "libs/partners/deepseek/tests/unit_tests/__init__.py",
            "description": "This `__init__.py` file defines the `unit_tests` directory as a Python package within the `langchain_deepseek` library and provides a docstring describing its purpose.",
            "spof": true
          },
          {
            "path": "libs/partners/deepseek/langchain_deepseek/__init__.py",
            "description": "This is the initialization file for the 'langchain_deepseek' package, serving as its main entry point. It exposes the 'ChatDeepSeek' chat model and defines the package's version.",
            "spof": true
          },
          {
            "path": "libs/partners/deepseek/langchain_deepseek/data/_profiles.py",
            "description": "This file contains auto-generated profiles for Deepseek models, detailing their capabilities and constraints such as token limits and feature support (e.g., tool calling). It is not meant for manual editing.",
            "spof": true
          },
          {
            "path": "libs/partners/deepseek/langchain_deepseek/data/__init__.py",
            "description": "This file, part of the `data` directory, provides model profile data. It indicates that any modifications to this data should be done in `profile_augmentations.toml`.",
            "spof": true
          },
          {
            "path": "libs/partners/README.md",
            "description": "This file serves as a FAQ for Langchain's partner integrations, providing guidance on finding integrations and linking to relevant documentation.",
            "spof": true
          },
          {
            "path": "libs/partners/xai/README.md",
            "description": "This README file introduces the `langchain-xai` Python package, detailing its purpose of integrating xAI APIs with LangChain, providing installation instructions, documentation links, and contribution guidelines.",
            "spof": true
          },
          {
            "path": "libs/partners/xai/langchain_xai/chat_models.py",
            "description": "This file defines the `ChatXAI` class, which serves as a LangChain wrapper for interacting with xAI's Chat Completions API. It provides methods for invoking, streaming, and utilizing advanced features like reasoning and tool/function calling with xAI models.",
            "spof": true
          },
          {
            "path": "libs/partners/xai/tests/integration_tests/test_chat_models.py",
            "description": "This file contains integration tests for the `ChatXAI` chat model, focusing on features like reasoning and web search functionality. It verifies content, additional metadata, and streaming behavior for various model configurations.",
            "spof": false
          },
          {
            "path": "libs/partners/xai/tests/unit_tests/__init__.py",
            "description": "Initializes the unit test environment for the XAI partner library by setting a mock API key. This allows tests to run without requiring a real XAI API key.",
            "spof": true
          },
          {
            "path": "libs/partners/xai/tests/unit_tests/test_imports.py",
            "description": "This file contains unit tests to ensure that the `__all__` variable in the `langchain_xai` package correctly lists all intended public modules and symbols. It verifies the public API surface of the package.",
            "spof": true
          },
          {
            "path": "libs/partners/xai/tests/unit_tests/test_secrets.py",
            "description": "This unit test verifies that the `xai_api_key` is not exposed in the string representation of the `ChatXAI` object, ensuring sensitive information is handled securely.",
            "spof": false
          },
          {
            "path": "libs/partners/xai/tests/unit_tests/test_chat_models_standard.py",
            "description": "This file contains standard unit tests for the `ChatXAI` chat model within the LangChain framework. It uses the `ChatModelUnitTests` base class to ensure the `ChatXAI` implementation adheres to the standard LangChain chat model interface.",
            "spof": false
          },
          {
            "path": "libs/partners/xai/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the `ChatXAI` chat model within the LangChain framework, covering its initialization, parameter handling, error conditions, and message conversion utilities.",
            "spof": false
          },
          {
            "path": "libs/partners/nomic/langchain_nomic/__init__.py",
            "description": "This file serves as the main entry point for the 'langchain_nomic' package, making the NomicEmbeddings class accessible for use within LangChain.",
            "spof": false
          },
          {
            "path": "libs/partners/nomic/langchain_nomic/embeddings.py",
            "description": "This file defines the `NomicEmbeddings` class, which integrates Nomic's text and image embedding models into the LangChain framework. It allows users to generate embeddings for text documents, queries, and images using Nomic's API or local models.",
            "spof": true
          },
          {
            "path": "libs/partners/nomic/tests/__init__.py",
            "description": "This file serves as the initialization file for the Nomic partner integration test suite, indicating the directory contains tests for Nomic.",
            "spof": true
          },
          {
            "path": "libs/partners/nomic/tests/integration_tests/test_embeddings.py",
            "description": "This file contains integration tests for the NomicEmbeddings class within the LangChain Nomic partner library. It verifies the functionality of embedding documents, embedding queries, and ensuring correct dimensionality.",
            "spof": true
          },
          {
            "path": "libs/partners/nomic/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test used to verify the compilation of integration tests for the Nomic partner integration, without executing any actual test logic.",
            "spof": true
          },
          {
            "path": "libs/partners/nomic/tests/integration_tests/__init__.py",
            "description": "This file serves as the package initializer for the integration tests of the Nomic partner integration, indicating the location of these tests.",
            "spof": true
          },
          {
            "path": "libs/partners/nomic/tests/unit_tests/test_embeddings.py",
            "description": "This file contains unit tests for the Nomic embeddings integration within the LangChain framework. Specifically, it tests the initialization of the NomicEmbeddings model.",
            "spof": false
          },
          {
            "path": "libs/partners/nomic/tests/unit_tests/test_standard.py",
            "description": "This file contains unit tests to benchmark the initialization time of the NomicEmbeddings class within the Langchain Nomic partner integration.",
            "spof": true
          },
          {
            "path": "libs/partners/nomic/tests/unit_tests/__init__.py",
            "description": "This file contains unit tests specifically for verifying imports within the Nomic partner integration. It also serves to mark the `unit_tests` directory as a Python package.",
            "spof": true
          },
          {
            "path": "libs/partners/nomic/tests/unit_tests/test_imports.py",
            "description": "This file contains unit tests to verify that the `__all__` variable in the `langchain_nomic` package correctly exposes the intended public classes, such as `NomicEmbeddings`.",
            "spof": true
          },
          {
            "path": "libs/partners/nomic/scripts/check_imports.py",
            "description": "This script checks if a list of given Python files can be imported successfully by attempting to load them as modules. It is used to verify imports within the Nomic partner integration and reports any failures.",
            "spof": false
          },
          {
            "path": "libs/partners/nomic/README.md",
            "description": "This README file provides an overview of the 'langchain-nomic' Python package, detailing its purpose as the LangChain integration with Nomic, along with installation instructions and links to documentation.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/wolframcloud",
            "description": "This directory contains unit test specifications or examples specifically designed for the Wolfram Cloud integration within the LangChain library. Its purpose is to define expected behaviors and functionalities for LangChain's interactions with Wolfram Cloud components during unit testing.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 72
          },
          {
            "name": "ccurme",
            "percent": 13
          },
          {
            "name": "Vadym Barda",
            "percent": 7
          }
        ]
      },
      "Fireworks AI Integration": {
        "files": [
          {
            "path": "libs/partners/fireworks/README.md",
            "description": "This README.md file provides an overview of the `langchain-fireworks` partner package, detailing its purpose (tying Fireworks.ai with LangChain), installation instructions, documentation links, and contribution guidelines.",
            "spof": true
          },
          {
            "path": "libs/partners/fireworks/langchain_fireworks/embeddings.py",
            "description": "This file implements a LangChain integration for Fireworks AI's embedding models, allowing users to generate vector representations of text using Fireworks services. It defines the `FireworksEmbeddings` class, which handles API key management and provides methods for embedding single or multiple text documents.",
            "spof": true
          },
          {
            "path": "libs/partners/fireworks/langchain_fireworks/data/__init__.py",
            "description": "This file contains model profile data and specifies that all edits should be made in 'profile_augmentations.toml'.",
            "spof": true
          },
          {
            "path": "libs/partners/fireworks/langchain_fireworks/data/_profiles.py",
            "description": "This file contains auto-generated profiles for various Fireworks models, detailing their token limits and I/O capabilities. It is generated by a CLI tool and should not be edited manually.",
            "spof": true
          },
          {
            "path": "libs/partners/fireworks/tests/integration_tests/test_embeddings.py",
            "description": "This file contains integration tests for the FireworksEmbeddings class from the langchain_fireworks library. It verifies the functionality of embedding documents and queries using Fireworks' hosted embedding models.",
            "spof": true
          },
          {
            "path": "libs/partners/fireworks/tests/integration_tests/test_chat_models.py",
            "description": "This file contains integration tests for the `ChatFireworks` API wrapper within the LangChain Fireworks partner library. It verifies functionalities such as tool calling, streaming, batch processing, synchronous/asynchronous invocation, and structured output using various schema types.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder pytest integration test. It is used to verify the compilation of integration tests without actually executing any real test logic.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/tests/integration_tests/test_llms.py",
            "description": "This file contains integration tests for the LangChain Fireworks LLM wrapper, verifying its synchronous and asynchronous functionalities like `invoke`, `generate`, `stream`, and `batch` methods.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/tests/unit_tests/test_imports.py",
            "description": "This file contains unit tests to verify that the `__all__` variable in the `langchain_fireworks` package exports the expected public API components. It ensures consistency in what modules and classes are exposed.",
            "spof": true
          },
          {
            "path": "libs/partners/fireworks/tests/unit_tests/test_embeddings.py",
            "description": "This file contains unit tests for the `FireworksEmbeddings` integration, specifically testing the initialization of the embedding model.",
            "spof": true
          },
          {
            "path": "libs/partners/fireworks/tests/unit_tests/test_llms.py",
            "description": "This file contains unit tests for the Fireworks LLM integration within the `langchain_fireworks` library. It primarily tests the handling and masking of API keys, as well as the tracing of model parameters.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/tests/unit_tests/test_standard.py",
            "description": "This file contains unit tests for the `ChatFireworks` LangChain integration, verifying its adherence to the standard chat model interface and specific functionalities like model profile loading.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the `_convert_dict_to_message` function within the `langchain_fireworks.chat_models` module. It verifies the correct conversion of API response dictionaries to `AIMessage` objects, specifically testing the extraction and handling of `reasoning_content`.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "ccurme",
            "percent": 38
          },
          {
            "name": "Mason Daugherty",
            "percent": 37
          },
          {
            "name": "Dragos Bobolea",
            "percent": 10
          }
        ]
      },
      "MistralAI Integration": {
        "files": [
          {
            "path": "libs/partners/mistralai/README.md",
            "description": "This README file provides an overview, installation instructions, documentation links, and contribution guidelines for the `langchain-mistralai` Python package.",
            "spof": true
          },
          {
            "path": "libs/partners/mistralai/langchain_mistralai/chat_models.py",
            "description": "This file defines the LangChain chat model integration for Mistral AI. It handles communication with the Mistral API, including message conversion, retry logic, and streaming responses for chat completions.",
            "spof": false
          },
          {
            "path": "libs/partners/mistralai/langchain_mistralai/__init__.py",
            "description": "This is the `__init__.py` file for the `langchain_mistralai` package, serving as its primary entry point. It makes the `ChatMistralAI` and `MistralAIEmbeddings` components available for use within LangChain.",
            "spof": true
          },
          {
            "path": "libs/partners/mistralai/langchain_mistralai/_compat.py",
            "description": "This file provides compatibility functions to translate content blocks between a standard LangChain format and Mistral AI's specific message content format, registering these translators for the 'mistralai' provider.",
            "spof": true
          },
          {
            "path": "libs/partners/mistralai/langchain_mistralai/data/_profiles.py",
            "description": "This file contains auto-generated profiles for various Mistral AI language models, detailing their specifications and capabilities like token limits and input/output types. It is not meant for manual editing and is generated by a CLI tool.",
            "spof": true
          },
          {
            "path": "libs/partners/mistralai/tests/integration_tests/test_chat_models.py",
            "description": "This file contains integration tests for the `ChatMistralAI` chat model, covering functionalities such as asynchronous streaming, structured output with JSON schemas, retry mechanisms, and the model's reasoning capabilities.",
            "spof": true
          },
          {
            "path": "libs/partners/mistralai/tests/integration_tests/test_standard.py",
            "description": "This file contains integration tests for the `ChatMistralAI` model, ensuring its compatibility and adherence to the standard LangChain chat model interface. It specifically tests functionalities like structured output, although some tests are marked as xfail due to inconsistent behavior from the MistralAI API.",
            "spof": false
          },
          {
            "path": "libs/partners/mistralai/tests/unit_tests/test_imports.py",
            "description": "This file contains a unit test to verify that the publicly exposed symbols (defined in `__all__`) of the `langchain_mistralai` package match the expected list of components.",
            "spof": true
          },
          {
            "path": "libs/partners/mistralai/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the MistralAI Chat API wrapper within the Langchain framework. It verifies initialization, message conversion between Langchain and MistralAI formats, streaming capabilities, and tool call handling.",
            "spof": false
          },
          {
            "path": "libs/partners/mistralai/tests/unit_tests/test_embeddings.py",
            "description": "This file contains unit tests for the `MistralAIEmbeddings` class, specifically verifying its initialization and the handling of model and API key parameters.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 41
          },
          {
            "name": "ccurme",
            "percent": 38
          },
          {
            "name": "Bagatur",
            "percent": 5
          }
        ]
      },
      "Anthropic Integration": {
        "files": [
          {
            "path": "libs/partners/anthropic/README.md",
            "description": "This README.md file introduces the `langchain-anthropic` package, detailing its purpose as the LangChain integration for Anthropic's generative models. It provides installation instructions, documentation links, and information on releases and contributing.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/__init__.py",
            "description": "This file serves as the __init__.py for the langchain_anthropic package, exposing its main components such as AnthropicLLM, ChatAnthropic, and a utility for converting tools for Anthropic models.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/middleware/prompt_caching.py",
            "description": "This file implements a LangChain agent middleware for Anthropic models, enabling prompt caching to optimize API usage. It modifies model requests to include Anthropic's cache control settings based on configurable parameters.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/middleware/__init__.py",
            "description": "This `__init__.py` file serves to aggregate and expose various middleware components designed for use with Anthropic models within the LangChain framework.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/middleware/file_search.py",
            "description": "This module provides a middleware for Anthropic agents to perform file search operations (glob and grep) on virtual files stored in the agent's state or memory. It adds tools for pattern matching file paths and searching file contents using regular expressions.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/data/_profiles.py",
            "description": "This file contains auto-generated profiles and metadata for various Anthropic language models, detailing their capabilities and specifications (e.g., token limits, input/output types) for use within the Langchain framework.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/tests/unit_tests/test_standard.py",
            "description": "This file contains standard unit tests and a performance benchmark for the `ChatAnthropic` model, ensuring it conforms to the LangChain chat model interface and measures its initialization time.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/unit_tests/test_client_utils.py",
            "description": "This file contains unit tests for the utility functions that create synchronous and asynchronous HTTPX clients for the Anthropic API, specifically verifying their behavior with and without proxy configurations.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/tests/unit_tests/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_anthropic` package correctly lists all intended public symbols.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the Langchain Anthropic chat model integration. It verifies the functionality of ChatAnthropic initialization, client caching, proxy support, token limits, model parameters, and output formatting.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/tests/unit_tests/middleware/__init__.py",
            "description": "This file serves as the package initializer for unit tests specifically designed for the Anthropic middleware components within the LangChain library.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/tests/unit_tests/middleware/test_bash.py",
            "description": "This file contains unit tests for the `ClaudeBashToolMiddleware` class, verifying its functionality in creating a 'bash' tool and correctly transforming it into a Claude-specific bash descriptor during model calls.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/unit_tests/middleware/test_prompt_caching.py",
            "description": "This file contains unit tests for the `AnthropicPromptCachingMiddleware`, which manages prompt caching for Anthropic models. It verifies initialization, behavior with unsupported models, and asynchronous operations under various caching conditions.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/integration_tests/test_llms.py",
            "description": "This file contains integration tests for the `AnthropicLLM` class, covering various functionalities such as model parameter handling, synchronous and asynchronous invocation, and streaming with callbacks.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/cassettes",
            "description": "This directory is designated to store 'cassettes,' which are recorded HTTP interactions for tests within the `langchain/libs/partners/anthropic` module. These recordings allow tests to run offline, ensuring speed, consistency, and isolation from external API dependencies. Though currently empty, its purpose is to serve as a fixture storage location for network-dependent tests.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 42
          },
          {
            "name": "ccurme",
            "percent": 17
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 17
          }
        ]
      },
      "API & Configuration Abstraction": {
        "files": [
          {
            "path": "libs/partners/prompty/README.md",
            "description": "This README provides an overview of the `langchain-prompty` package, detailing its purpose as a LangChain integration with Microsoft Prompty, installation instructions, and basic usage examples for loading `.prompty` files.",
            "spof": true
          },
          {
            "path": "libs/partners/prompty/langchain_prompty/utils.py",
            "description": "This file provides utility functions for loading, preparing, and executing 'Prompty' configurations, which define interactions with language models or templating engines. It orchestrates the lifecycle of a Prompty object from file loading to execution.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/langchain/rate_limiters/__init__.py",
            "description": "This file defines the base abstraction and an in-memory implementation for rate limiters within LangChain, used to control the rate of requests to APIs.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/sandboxes.py",
            "description": "This file provides a base class for integration tests for `SandboxProvider` implementations, covering synchronous and asynchronous operations like sandbox creation, listing, deletion, file operations, and command execution.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/tmdb_docs.py",
            "description": "This file contains a multi-line string defining the API documentation for the TMDb movie search endpoint. It details query parameters and response schema for searching movies.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/open_meteo_docs.py",
            "description": "This file contains the API documentation for the Open-Meteo weather API. It details the available endpoints, parameters, and variable definitions.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/news_docs.py",
            "description": "This file contains a detailed documentation string for interacting with the NewsAPI's '/v2/top-headlines' endpoint, outlining request parameters, possible values, and the structure of the API response for news articles.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/podcast_docs.py",
            "description": "This file stores API documentation for a podcast search endpoint provided by ListenNotes. It details the available query parameters and the structure of the API response for searching podcasts or episodes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/__init__.py",
            "description": "This file initializes the API chain module, providing functionality for making API calls and summarizing responses to answer questions.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_functions/openapi.py",
            "description": "This file provides utilities to convert OpenAPI specifications into OpenAI function JSON schemas and enables LangChain to interact with external APIs defined by these specs. It includes functions for formatting URLs, mapping OpenAPI parameters to JSON schema, and a chain for executing API requests.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/scenexplain/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the `scenexplain` API toolkit within `langchain_classic`, indicating the presence and purpose of the SceneXplain API integration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/stackexchange/__init__.py",
            "description": "This file initializes the StackExchange API toolkit within the LangChain Classic library, providing functionality to interact with the StackExchange platform.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/zapier",
            "description": "This directory contains test specifications or examples specifically designed for unit testing the Langchain integration with Zapier. It provides defined scenarios or data structures used to validate the correct functionality of the Zapier component.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/klarna",
            "description": "This directory is intended to contain unit test specifications or examples specifically for Klarna-related functionalities within the LangChain library. It serves as a dedicated location for testing the integration and behavior of Klarna components.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/quickchart",
            "description": "This directory is intended to house example test specifications for the QuickChart integration within LangChain's unit tests. It would contain files defining specific test cases or data related to QuickChart functionality.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/datasette",
            "description": "This directory is designated for unit tests specifically related to Datasette examples or functionalities within the LangChain library. It serves as a placeholder for test specifications demonstrating interaction with Datasette. Currently, it is empty, indicating no such tests have been implemented yet.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/slack",
            "description": "This directory is designated to store test specifications for unit tests specifically concerning Slack integration within the Langchain library. It provides a dedicated location for defining expected behaviors and requirements for Slack-related functionalities. Although currently empty, its purpose is to organize future test specifications for Slack components.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/apis-guru",
            "description": "This directory is designated to contain test specifications specifically for APIs Guru, within the context of Langchain's unit test examples. It serves as a categorized location for defining API-related test cases, although it is currently empty.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/urlbox",
            "description": "This directory contains unit test specifications for example implementations or functionalities related to 'urlbox' within the LangChain library, ensuring their correct behavior.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/mock_servers/robot/server.py",
            "description": "This file implements a mock FastAPI server that simulates a robot's operations and state. It provides various API endpoints to control the robot's movement, retrieve its state, and test specific scenarios like pass phrase validation and prompt injection handling.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Eugene Yurtsev",
            "percent": 68
          },
          {
            "name": "Mason Daugherty",
            "percent": 23
          },
          {
            "name": "Chuyuan Qu",
            "percent": 3
          }
        ]
      },
      "OpenAI & Azure Integration": {
        "files": [
          {
            "path": "libs/partners/openai/README.md",
            "description": "This README provides an overview and instructions for the `langchain-openai` package, detailing its purpose, installation, documentation, and contribution guidelines.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/langchain_openai/embeddings/azure.py",
            "description": "This file provides an integration for Azure OpenAI embedding models within the LangChain framework. It defines the `AzureOpenAIEmbeddings` class, handling configuration, authentication, and client initialization for Azure-specific OpenAI embedding services.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/langchain_openai/embeddings/base.py",
            "description": "This file defines the base class `OpenAIEmbeddings` for integrating OpenAI embedding models within the LangChain framework, handling model configuration, API interaction, and embedding processing.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/langchain_openai/chat_models/__init__.py",
            "description": "This file serves as the main entry point for OpenAI chat models within the `langchain_openai` library, exposing `AzureChatOpenAI` and `ChatOpenAI` classes.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/langchain_openai/chat_models/_client_utils.py",
            "description": "This module provides helper functions for creating and caching `httpx` clients (both sync and async) used by OpenAI API clients, and for resolving API keys. Its primary goal is to optimize client instantiation by reusing `httpx` clients across different instances of ChatOpenAI.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/langchain_openai/chat_models/base.py",
            "description": "This file provides the base implementation for integrating OpenAI chat models within the LangChain framework. It includes utilities for converting messages between LangChain's internal format and OpenAI's API format, supporting features like tool calls and content formatting.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/langchain_openai/middleware/__init__.py",
            "description": "This file serves as the `__init__.py` for the OpenAI middleware package, exposing components related to OpenAI moderation functionality, such as `OpenAIModerationError` and `OpenAIModerationMiddleware`.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/langchain_openai/llms/base.py",
            "description": "This file defines the base class (`BaseOpenAI`) for interacting with OpenAI large language models (LLMs) within the LangChain framework. It provides common parameters, instantiation methods, and functionalities for synchronous and asynchronous invocation and streaming.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/langchain_openai/llms/__init__.py",
            "description": "This `__init__.py` file serves as the entry point for the `langchain_openai.llms` package, exposing the core OpenAI and Azure OpenAI large language model classes. It allows direct import of `OpenAI` and `AzureOpenAI` from the package.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/conftest.py",
            "description": "This file configures VCR (Video Cassette Recorder) for pytest tests, extending the base configuration to redact sensitive headers in recorded requests and responses for integration tests with OpenAI services. It also registers custom VCR persisters and serializers.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/test_token_counts.py",
            "description": "This file contains unit tests for verifying the token counting functionality (`get_num_tokens`) of various OpenAI and ChatOpenAI language models in the `langchain-openai` library, using a specific Chinese text with emojis.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_openai` package correctly lists all expected public imports.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/test_secrets.py",
            "description": "This file contains unit tests for verifying the secure handling of API keys and secret tokens within LangChain's OpenAI and Azure OpenAI integrations. It ensures secrets are properly masked, stored as `SecretStr` objects, and correctly retrieved.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/embeddings/test_azure_standard.py",
            "description": "This file contains unit tests for the standard configuration and initialization of Azure OpenAI Embeddings, ensuring they correctly handle parameters and environment variables.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/embeddings/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_openai.embeddings` module correctly exposes the expected embedding classes, specifically `OpenAIEmbeddings` and `AzureOpenAIEmbeddings`.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/embeddings/test_azure_embeddings.py",
            "description": "This file contains unit tests for the `AzureOpenAIEmbeddings` class, specifically verifying its initialization and configuration with various parameters, including Azure-specific settings.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/embeddings/test_base.py",
            "description": "This file contains unit tests for the `OpenAIEmbeddings` class, covering its initialization, parameter handling, document embedding with custom chunk sizes, and adherence to token limits for large inputs.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/chat_models/test_base.py",
            "description": "This file contains unit tests for the base functionalities of the LangChain OpenAI chat model integration, including model parameter handling, streaming, client caching, model profiles, and message conversion utilities.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/llms/test_imports.py",
            "description": "This unit test file verifies that the `__all__` variable in the `langchain_openai.llms` module correctly lists all expected public classes, ensuring the public API surface is as intended.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/llms/test_base.py",
            "description": "This file contains unit tests for the `OpenAI` LLM class in the `langchain-openai` library, covering its parameter handling, model configuration, tokenization, streaming behavior, and utility functions.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/middleware/test_openai_moderation_middleware.py",
            "description": "This file contains unit tests for the OpenAIModerationMiddleware, verifying its behavior in moderating input and output messages based on OpenAI's moderation results, and testing various exit strategies like erroring, ending, or replacing content.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder pytest integration test. Its purpose is to allow for compilation of integration tests within the OpenAI partner library without executing any actual tests.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/chat_models/test_responses_api.py",
            "description": "This file contains integration tests for the `ChatOpenAI` model's Responses API, verifying its functionality for handling incomplete responses, web search, function calling, and structured output parsing using Pydantic schemas and dictionaries.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/embeddings/test_azure.py",
            "description": "This file contains integration tests for the LangChain Azure OpenAI Embeddings class, verifying its functionality for embedding documents and queries, including async operations, chunking, and handling edge cases.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/embeddings/test_base.py",
            "description": "This file contains integration tests for the `OpenAIEmbeddings` class within LangChain's OpenAI partner library. It verifies the functionality of embedding generation, dimension control, consistency with the raw OpenAI API, and dynamic API key handling.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/moderation.py",
            "description": "This file defines the `OpenAIModerationChain` class, a LangChain component that moderates input text using the OpenAI moderation API to check for policy violations. It supports both synchronous and asynchronous calls and handles different versions of the OpenAI Python client.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_functions/__init__.py",
            "description": "This `__init__.py` file serves as a central hub for exposing various utilities and chain creation functions related to OpenAI function calling within the `langchain_classic` library, including tools for extraction, tagging, QA, and structured output.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/utils/test_openai_functions.py",
            "description": "This file contains unit tests for the `convert_to_openai_function` utility, verifying its ability to correctly transform Pydantic models (including nested ones) into OpenAI function schema definitions.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/chains/openai_functions/test_openapi.py",
            "description": "This file contains integration tests for OpenAI-related functionalities within the LangChain library, specifically testing the OpenAPI chain's ability to interact with an API specification and the instantiation of the OpenAI Moderation Chain.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 47
          },
          {
            "name": "ccurme",
            "percent": 26
          },
          {
            "name": "Bagatur",
            "percent": 5
          }
        ]
      },
      "Groq Integration": {
        "files": [
          {
            "path": "libs/partners/groq/README.md",
            "description": "This README file provides an overview, installation instructions, documentation links, and contribution guidelines for the `langchain-groq` Python library. It serves as the main entry point for users and contributors of the Groq integration with LangChain.",
            "spof": true
          },
          {
            "path": "libs/partners/groq/langchain_groq/version.py",
            "description": "This file dynamically retrieves and sets the package version using `importlib.metadata`, making it available as `__version__`.",
            "spof": true
          },
          {
            "path": "libs/partners/groq/langchain_groq/__init__.py",
            "description": "This `__init__.py` file serves as the main entry point for the `langchain_groq` package, making the `ChatGroq` class and the package version (`__version__`) available for import. It facilitates Groq integration within LangChain.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/langchain_groq/chat_models.py",
            "description": "This file implements the `ChatGroq` class, which serves as a LangChain wrapper for interacting with Groq's large language models API. It provides functionalities for invoking, streaming, asynchronous calls, and tool calling with Groq models.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/langchain_groq/_compat.py",
            "description": "This file provides a utility function to convert `langchain_core` content blocks from a v1 format into a structure compatible with the Groq API. It handles various content types, including text, reasoning, and server tool calls/results, adapting them for Groq-specific requirements.",
            "spof": true
          },
          {
            "path": "libs/partners/groq/langchain_groq/data/_profiles.py",
            "description": "This file contains auto-generated profiles and metadata for various language models, including details like token limits and supported input/output types. It is generated by a CLI tool and derived from the models.dev project.",
            "spof": true
          },
          {
            "path": "libs/partners/groq/tests/integration_tests/test_chat_models.py",
            "description": "This file contains integration tests for the `ChatGroq` chat model, covering its various invocation methods (invoke, stream, batch) and features like streaming and reasoning output.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test function, marked for compilation, to verify that integration tests for the Groq partner library can be compiled without executing any actual test logic.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/tests/unit_tests/test_standard.py",
            "description": "This file contains unit tests for the `ChatGroq` chat model, ensuring its adherence to standard LangChain interface specifications. It uses the `llama-3.1-8b-instant` model for testing.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/tests/unit_tests/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_groq` package exposes the expected public API components.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the Groq Chat API wrapper within the LangChain framework, covering functionalities like message conversion, invocation, error handling, serialization, and usage metadata.",
            "spof": true
          },
          {
            "path": "libs/partners/groq/tests/cassettes",
            "description": "This directory likely stores 'cassettes' or recorded HTTP interactions used for VCR-style testing of the `groq` partner library within Langchain. These cassettes enable deterministic and efficient testing by replaying network requests instead of hitting actual external APIs.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 48
          },
          {
            "name": "Mshari",
            "percent": 19
          },
          {
            "name": "ccurme",
            "percent": 16
          }
        ]
      },
      "Ollama Integration": {
        "files": [
          {
            "path": "libs/partners/groq/scripts/__init__.py",
            "description": "This `__init__.py` file initializes the `scripts` package, stated to contain scripts for Ollama partner integration.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/README.md",
            "description": "This README provides an overview of the `langchain-ollama` package, detailing its purpose as a LangChain integration with Ollama, installation instructions, and links to documentation and contribution guidelines.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/langchain_ollama/llms.py",
            "description": "This file defines the `OllamaLLM` class, which integrates Ollama large language models with the LangChain framework. It provides methods for initializing, configuring, and interacting with Ollama models for text generation, including streaming and asynchronous operations.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/langchain_ollama/_utils.py",
            "description": "Provides utility functions for validating Ollama models and handling URL-based authentication for Ollama client configurations. It includes logic to check model existence, extract basic auth from URLs, and merge authentication headers into client arguments.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/langchain_ollama/_compat.py",
            "description": "This file provides utility functions to convert content blocks from Langchain's v1 format into a compatible format for the Ollama SDK, ensuring interoperability between the two systems.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/langchain_ollama/embeddings.py",
            "description": "This file defines the `OllamaEmbeddings` class, which integrates Ollama embedding models with Langchain. It allows users to generate vector embeddings for single or multiple text inputs, supporting both synchronous and asynchronous operations.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/tests/integration_tests/test_embeddings.py",
            "description": "This file contains integration tests for the Ollama embeddings class within the Langchain framework, specifically verifying its functionality using a specified model.",
            "spof": false
          },
          {
            "path": "libs/partners/ollama/tests/integration_tests/test_llms.py",
            "description": "This file contains integration tests for the `OllamaLLM` class, verifying its synchronous and asynchronous `invoke`, `batch`, and `stream` functionalities, including behavior with and without reasoning enabled.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder integration test designed to facilitate the compilation of integration tests without actually running them.",
            "spof": false
          },
          {
            "path": "libs/partners/ollama/tests/integration_tests/chat_models/test_chat_models_standard.py",
            "description": "This file contains standard integration tests for the `ChatOllama` chat model, configuring its capabilities and marking certain tool-calling tests as expected to fail due to known Ollama issues.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/tests/integration_tests/chat_models/test_chat_models_reasoning.py",
            "description": "This file contains integration tests for the `ChatOllama` class, specifically verifying the behavior of the `reasoning` parameter for a reasoning-capable model (DeepSeek R1). It tests how reasoning content is handled or suppressed during both streaming and invocation based on different `reasoning` settings (True, False, None).",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/tests/integration_tests/chat_models/cassettes/test_chat_models_standard",
            "description": "This directory stores pre-recorded HTTP interaction 'cassettes' for integration tests of standard Ollama chat models. These cassettes are used to replay network requests, ensuring consistent and reproducible test execution without external dependencies. They specifically support the `test_chat_models_standard` suite within the LangChain Ollama partner integration.",
            "spof": false
          },
          {
            "path": "libs/partners/ollama/tests/integration_tests/chat_models/test_chat_models.py",
            "description": "This file contains integration tests for the `ChatOllama` model, validating its initialization, structured output capabilities, tool calling, and streaming functionalities within the LangChain Ollama partner library.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/tests/unit_tests/test_imports.py",
            "description": "This file contains unit tests to verify that the `__all__` variable in the `langchain_ollama` package correctly exposes the expected public components like `OllamaLLM`, `ChatOllama`, and `OllamaEmbeddings`.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/tests/unit_tests/test_auth.py",
            "description": "This file contains unit tests for parsing URL authentication credentials and their integration with Ollama client classes (ChatOllama, OllamaLLM, OllamaEmbeddings) in the LangChain Ollama partner package.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the `ChatOllama` class, covering its functionality for parsing tool call arguments and JSON strings, validating model initialization, and handling various response scenarios from the Ollama API.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 81
          },
          {
            "name": "Isaac Francisco",
            "percent": 3
          },
          {
            "name": "Copilot",
            "percent": 2
          }
        ]
      },
      "Perplexity AI Integration": {
        "files": [
          {
            "path": "libs/partners/perplexity/README.md",
            "description": "This README file introduces the langchain-perplexity package, providing information on its purpose, installation, documentation, and how to contribute. It serves as a guide for users integrating Perplexity with LangChain.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/langchain_perplexity/__init__.py",
            "description": "This `__init__.py` file serves as the main entry point for the `langchain_perplexity` package, exposing its public API components related to Perplexity AI integration, including chat models, retrievers, tools, types, and output parsers for LangChain.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/langchain_perplexity/_utils.py",
            "description": "This utility file is responsible for initializing the Perplexity client by retrieving the API key from various sources (input values or environment variables) and setting up the client instance.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/langchain_perplexity/types.py",
            "description": "This file defines Pydantic data models for various types and configurations used when interacting with the Perplexity API. It includes structures for user location, web search options, and media response overrides.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/langchain_perplexity/chat_models.py",
            "description": "This file implements a LangChain chat model (`ChatPerplexity`) for interacting with Perplexity AI's chat APIs. It allows users to integrate Perplexity's generative models into LangChain applications, supporting features like streaming, structured output, and token usage tracking.",
            "spof": false
          },
          {
            "path": "libs/partners/perplexity/langchain_perplexity/tools.py",
            "description": "This file implements a LangChain tool for performing searches using the Perplexity Search API. It defines the `PerplexitySearchResults` class, which wraps the Perplexity search functionality and returns results in a structured JSON format.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/langchain_perplexity/data/__init__.py",
            "description": "This file contains or refers to model profile data. It specifies that any modifications should be made in 'profile_augmentations.toml' rather than directly in this file.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/integration_tests/test_search_api.py",
            "description": "This file contains integration tests for the Perplexity Search API within the LangChain framework. It verifies the functionality of the `PerplexitySearchRetriever` and `PerplexitySearchResults` components, including basic searches, filtering, and multi-query capabilities.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/integration_tests/test_chat_models.py",
            "description": "This file contains integration tests for the `ChatPerplexity` chat model, verifying its various features such as standard and asynchronous generation, Pro Search, streaming, citations, search control, search filters, and media/metadata handling.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/integration_tests/test_chat_models_standard.py",
            "description": "This file contains integration tests for the LangChain `ChatPerplexity` model, ensuring its compatibility with the standard LangChain chat model interface. It uses the 'sonar' model for testing and includes some xfail tests for specific functionalities.",
            "spof": false
          },
          {
            "path": "libs/partners/perplexity/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder integration test for the Perplexity partner library. It is marked for compilation, allowing test discovery and setup without executing any actual test logic.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/unit_tests/test_imports.py",
            "description": "This file contains a unit test to verify that the '__all__' variable in the 'langchain_perplexity' module correctly lists all expected public imports. It ensures the module's public API surface is as intended.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/unit_tests/test_secrets.py",
            "description": "This file contains a unit test for the `ChatPerplexity` class, specifically verifying that API keys are not exposed in the string representation of the model object. It ensures sensitive information is handled securely.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/unit_tests/test_chat_models_standard.py",
            "description": "This file contains standard unit tests for the `ChatPerplexity` API wrapper, ensuring its functionality and integration with `langchain_core` components.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/unit_tests/test_tools.py",
            "description": "This file contains unit tests for the `PerplexitySearchResults` tool, specifically verifying its `invoke` method correctly processes mocked search results from the Perplexity API.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the `ChatPerplexity` class within the `langchain_perplexity` library, covering its initialization, parameter handling, streaming behavior, and response metadata.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kesku",
            "percent": 54
          },
          {
            "name": "Sydney Runkle",
            "percent": 16
          },
          {
            "name": "Mason Daugherty",
            "percent": 15
          }
        ]
      },
      "Exa Search Integration": {
        "files": [
          {
            "path": "libs/partners/exa/README.md",
            "description": "This `README.md` file introduces the `langchain-exa` package, detailing its purpose as the LangChain integration with Exa. It includes installation instructions and links to the official documentation.",
            "spof": false
          },
          {
            "path": "libs/partners/exa/langchain_exa/tools.py",
            "description": "This file implements LangChain tools for interacting with the Exa Search API, enabling functionality for general search queries and finding similar content based on a URL.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/langchain_exa/_utilities.py",
            "description": "This file provides a utility function `initialize_client` for configuring and initializing the Exa API client, handling API key retrieval from inputs or environment variables and converting it to a secret string.",
            "spof": false
          },
          {
            "path": "libs/partners/exa/langchain_exa/__init__.py",
            "description": "This file serves as the `__init__.py` for the `langchain_exa` package, providing LangChain integrations for the Exa API. It exposes Exa-related tools, retrievers, and content options for use within LangChain applications.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/tests/__init__.py",
            "description": "This `__init__.py` file marks the directory as a Python package for Exa-related tests within the `langchain/libs/partners/exa` module. Its docstring indicates its purpose is to contain Exa tests.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/tests/unit_tests/test_imports.py",
            "description": "This file contains unit tests to verify that the `__all__` variable in the `langchain_exa` package correctly lists all intended public imports. It ensures that the package's public API is as expected.",
            "spof": false
          },
          {
            "path": "libs/partners/exa/tests/unit_tests/test_standard.py",
            "description": "This file contains a unit test to benchmark the initialization time of the ExaSearchRetriever class. It uses pytest-benchmark to measure how long it takes to instantiate the retriever multiple times.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/tests/integration_tests/__init__.py",
            "description": "This is an empty `__init__.py` file, signifying that the `integration_tests` directory for the Exa partner library is a Python package.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test designed to ensure that the integration tests compile successfully without actually executing any real tests. It serves as a compilation check for the integration test suite.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/tests/integration_tests/test_find_similar_tool.py",
            "description": "This file contains integration tests for the Exa find similar tool within the langchain-exa library, verifying its functionality to retrieve similar web content based on a given URL.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/wolframalpha",
            "description": "This directory is intended to contain unit test specifications or examples specifically for the Wolfram Alpha integration within the LangChain library. It serves as a dedicated location for defining how the Wolfram Alpha components should be tested.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/schooldigger",
            "description": "This directory is a placeholder intended to house unit test specifications or example data specifically for the 'schooldigger' component or integration within the Langchain library. Its current emptiness suggests that tests for this particular module are either not yet implemented or are not using this specific directory structure.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/biztoc",
            "description": "This directory is intended to house unit test specifications and examples specifically for the 'biztoc' component within the `langchain` library. Its role is to organize testing resources related to this particular integration or module.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 69
          },
          {
            "name": "Ishan Goswami",
            "percent": 13
          },
          {
            "name": "Copilot",
            "percent": 6
          }
        ]
      },
      "Hugging Face Integration": {
        "files": [
          {
            "path": "libs/partners/huggingface/README.md",
            "description": "This file is the README for the `langchain-huggingface` package, providing an overview of its purpose, installation instructions, documentation links, and contribution guidelines. It details the LangChain integrations for Hugging Face related classes.",
            "spof": true
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/__init__.py",
            "description": "This file serves as the package initializer for the `langchain_huggingface` library, exposing its core components for integrating Hugging Face models (chat, embeddings, and LLMs) within LangChain.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/llms/__init__.py",
            "description": "This file serves as the package initializer for HuggingFace LLMs, exposing `HuggingFaceEndpoint` and `HuggingFacePipeline` for easy import and use within the `langchain_huggingface.llms` module.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/llms/huggingface_endpoint.py",
            "description": "This file implements the `HuggingFaceEndpoint` class, providing an interface to Hugging Face Inference Endpoints for text generation within the LangChain framework. It allows users to interact with various Hugging Face models and custom endpoints for large language model (LLM) tasks.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/llms/huggingface_pipeline.py",
            "description": "This file defines the `HuggingFacePipeline` class, which serves as a LangChain integration for Hugging Face pipeline-based language models. It enables loading and utilizing various Hugging Face models for tasks like text generation, summarization, and translation within the LangChain framework, including support for optimized backends like OpenVINO and IPEX.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/embeddings/huggingface.py",
            "description": "This file defines the `HuggingFaceEmbeddings` class, which integrates Hugging Face's `sentence-transformers` models to generate text embeddings, supporting both standard and Intel IPEX optimized backends.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/utils/import_utils.py",
            "description": "This file provides utility functions to check the availability and specific versions of optional external libraries, such as Optimum, Optimum Intel, IPEX, and OpenVINO, facilitating conditional dependency management.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/tests/integration_tests",
            "description": "This directory contains integration tests for the `langchain_huggingface` library. These tests verify the correct functionality and interaction of the LangChain Hugging Face components with actual Hugging Face services and APIs.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/tests/unit_tests/test_huggingface_pipeline.py",
            "description": "This file contains unit tests for the `HuggingFacePipeline` class, verifying its various initialization methods and behaviors when interacting with Hugging Face models and pipelines.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/tests/integration_tests/test_llms.py",
            "description": "This file contains an integration test for the streaming capabilities of the HuggingFacePipeline LLM, specifically verifying that it can generate and stream text chunks effectively.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/tests/integration_tests/test_chat_models.py",
            "description": "This file contains an integration test for the `ChatHuggingFace` model. It verifies that streaming responses correctly include usage metadata when enabled.",
            "spof": true
          },
          {
            "path": "libs/partners/huggingface/tests/integration_tests/test_embeddings_standard.py",
            "description": "This file contains integration tests for HuggingFace embeddings, specifically testing both `HuggingFaceEmbeddings` and `HuggingFaceEndpointEmbeddings` classes using a standard sentence transformer model.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test used specifically for compiling integration tests to ensure they are syntactically correct without actually executing them.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/tests/integration_tests/test_standard.py",
            "description": "This file contains integration tests for the `ChatHuggingFace` model, specifically using the `HuggingFaceEndpoint`, to verify its adherence to the standard LangChain chat model interface. It includes tests for various features like structured output and tool calling, noting current limitations or specific implementation details.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 48
          },
          {
            "name": "Jofthomas",
            "percent": 10
          },
          {
            "name": "Ella Charlaix",
            "percent": 9
          }
        ]
      },
      "Legacy API & Utility Shims": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/requests.py",
            "description": "This file provides backwards compatibility for deprecated `Requests` classes (`Requests`, `RequestsWrapper`, `TextRequestsWrapper`) by dynamically importing them from `langchain_community.utilities`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/sql_database.py",
            "description": "This file provides backward compatibility for the `SQLDatabase` class, which has been moved to `langchain_community.utilities`. It dynamically imports the class from its new location, likely issuing deprecation warnings upon use.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/serpapi.py",
            "description": "This file provides backwards compatibility for `SerpAPIWrapper`, dynamically re-exporting it from `langchain_community.utilities` while handling potential deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/__init__.py",
            "description": "This file initializes the chat_loaders module, which is responsible for loading chat messages from various communication platforms like Facebook Messenger, Telegram, and WhatsApp. These loaded messages are intended for use in fine-tuning models.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/slack.py",
            "description": "This file provides a compatibility layer or re-export for the `SlackChatLoader` class, which has been moved to `langchain_community.chat_loaders.slack`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/imessage.py",
            "description": "This file facilitates the backward-compatible import of `IMessageChatLoader` by redirecting requests from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/gmail.py",
            "description": "This file acts as a compatibility layer, dynamically importing the `GMailLoader` from `langchain_community` while signaling its deprecation within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/base.py",
            "description": "This file re-exports the `BaseChatLoader` class from `langchain_core.chat_loaders`. It serves as a foundational component for defining chat loader functionalities within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/telegram.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `TelegramChatLoader` from `langchain_community` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/facebook_messenger.py",
            "description": "This file provides backward compatibility by re-exporting Facebook Messenger chat loader classes from `langchain_community` into the `langchain_classic` namespace, slated for future removal.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/utils.py",
            "description": "This file re-exports chat loader utility functions from `langchain_community` to maintain backward compatibility for `langchain_classic`, likely handling deprecation or dynamic imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/whatsapp.py",
            "description": "This file re-exports `WhatsAppChatLoader` from `langchain_community` to maintain compatibility within `langchain_classic`, likely serving as a backward-compatibility shim for deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/arize_callback.py",
            "description": "This file facilitates backward compatibility for the `ArizeCallbackHandler` by dynamically redirecting its import from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/arthur_callback.py",
            "description": "This file serves as a compatibility layer to re-export `ArthurCallbackHandler`, redirecting imports from `langchain_classic` to its new location in `langchain_community` while handling deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/sagemaker_callback.py",
            "description": "This file re-exports the `SageMakerCallbackHandler` class, providing a compatibility layer for its previous location while dynamically importing it from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/mlflow_callback.py",
            "description": "This file acts as a compatibility layer, dynamically providing access to MLflow callback functionalities and related utilities from `langchain_community` within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/streamlit/__init__.py",
            "description": "This file defines a StreamlitCallbackHandler function that integrates LangChain agent's LLM and tool-usage 'thoughts' into a Streamlit application, displaying them within dynamic expanders. It prioritizes using an official Streamlit implementation if available, falling back to a `langchain-community` version otherwise.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/streamlit/mutable_expander.py",
            "description": "This file acts as a compatibility layer, re-exporting `MutableExpander`, `ChildRecord`, and `ChildType` from `langchain_community` for `langchain_classic` to ensure backward compatibility during a migration or refactor.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_requests.py",
            "description": "This file acts as a compatibility layer for `LLMRequestsChain`, dynamically importing it from `langchain_community.chains.llm_requests`. It ensures backward compatibility by redirecting imports for moved or deprecated modules.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/base.py",
            "description": "This file defines a deprecated APIChain class that makes API calls and summarizes their responses using an LLM. It includes utilities for URL parsing and domain restriction for security.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/openapi/response_chain.py",
            "description": "This file handles deprecated imports for OpenAPI response chain components, dynamically redirecting them to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/openapi/requests_chain.py",
            "description": "This file acts as a compatibility layer, re-exporting API-related classes and templates from `langchain_community.chains.openapi.requests_chain` to maintain backwards compatibility or manage deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/openapi/chain.py",
            "description": "This file acts as a deprecation layer, redirecting imports of `OpenAPIEndpointChain` from its old location in `langchain_classic` to its new home in `langchain_community` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/elasticsearch_database/__init__.py",
            "description": "This file serves as the `__init__.py` for the `elasticsearch_database` module, making the `ElasticsearchDatabaseChain` class directly importable from the package.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/neptune_cypher.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting deprecated classes and functions related to Neptune Cypher QA chains from `langchain_community` to maintain backward compatibility during a library refactor or migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/arangodb.py",
            "description": "This file provides a compatibility layer, dynamically redirecting imports of `ArangoGraphQAChain` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/ontotext_graphdb.py",
            "description": "This file acts as a compatibility layer to dynamically import the `OntotextGraphDBQAChain` class, redirecting from a potentially deprecated location to its current home in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/hugegraph.py",
            "description": "This file acts as a compatibility layer or redirector for 'HugeGraphQAChain'. It dynamically imports the class from `langchain_community` while maintaining its availability in the `langchain_classic` package, likely for handling deprecation or module relocation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/nebulagraph.py",
            "description": "This file acts as a compatibility layer or re-exporter for `NebulaGraphQAChain`, dynamically importing it from the `langchain_community` package. It manages the deprecation of `NebulaGraphQAChain` from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/ernie_functions/__init__.py",
            "description": "This file acts as a re-exporter for Ernie-related functions, dynamically importing them from `langchain_community` to maintain compatibility or manage deprecation. It provides a centralized access point for these utilities.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/ernie_functions/base.py",
            "description": "This file facilitates the re-exporting of deprecated Ernie function-related utilities, forwarding imports from `langchain_classic` to their new location in `langchain_community` while handling potential deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/cohere.py",
            "description": "This file provides a backward-compatible or dynamic import mechanism for the `ChatCohere` class, redirecting its import from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/baidu_qianfan_endpoint.py",
            "description": "This file serves as a deprecation shim for `QianfanChatEndpoint`, dynamically importing it from `langchain_community` to maintain backward compatibility for `langchain_classic` users. It provides a transitional mechanism for accessing the moved class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/vertexai.py",
            "description": "This file acts as a compatibility shim, dynamically importing and re-exporting the `ChatVertexAI` class from `langchain_community` to maintain backwards compatibility or manage deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/elasticsearch.py",
            "description": "This file provides backward compatibility for `ElasticsearchEmbeddings`, dynamically importing it from `langchain_community.embeddings` to maintain older references.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/baidu_qianfan_endpoint.py",
            "description": "This file provides backward compatibility for `QianfanEmbeddingsEndpoint`, redirecting its import from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/ollama.py",
            "description": "This file facilitates the dynamic import and re-export of `OllamaEmbeddings` from `langchain_community.embeddings`, likely as part of a deprecation or package restructuring effort.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/dashscope.py",
            "description": "This file acts as a compatibility layer, re-exporting `DashScopeEmbeddings` from `langchain_community.embeddings` to maintain backward compatibility or facilitate a transition from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/octoai_embeddings.py",
            "description": "This file dynamically imports and re-exports the `OctoAIEmbeddings` class, likely to manage a deprecated or relocated module from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/gradient_ai.py",
            "description": "This file manages the deprecated import of `GradientEmbeddings`, redirecting it from `langchain_classic` to its new location in `langchain_community.embeddings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/jina.py",
            "description": "This file acts as a shim to re-export `JinaEmbeddings` by dynamically importing it from `langchain_community.embeddings`, likely managing a deprecated import path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/bedrock.py",
            "description": "This file serves as a compatibility layer or proxy, dynamically importing and re-exporting `BedrockEmbeddings` from `langchain_community.embeddings` to handle module reorganization or deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/cohere.py",
            "description": "This file serves as a compatibility layer, dynamically re-exporting `CohereEmbeddings` from `langchain_community.embeddings` to maintain backward compatibility for older `langchain_classic` imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/ernie.py",
            "description": "This file provides a compatibility layer for the `ErnieEmbeddings` class, dynamically redirecting its import to `langchain_community.embeddings`. It facilitates backward compatibility while indicating the class's new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/aleph_alpha.py",
            "description": "This file acts as a compatibility layer or proxy for Aleph Alpha embedding classes. It dynamically re-exports `AlephAlphaAsymmetricSemanticEmbedding` and `AlephAlphaSymmetricSemanticEmbedding` from `langchain_community.embeddings`, likely to manage deprecation or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/mlflow.py",
            "description": "This file handles the deprecation and dynamic re-export of `MlflowEmbeddings` from `langchain_community.embeddings`, facilitating backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/openai.py",
            "description": "This file provides backward compatibility for `OpenAIEmbeddings` by dynamically importing it from `langchain_community.embeddings`. It acts as a redirect for a deprecated import, ensuring older code continues to function while pointing to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/huggingface_hub.py",
            "description": "This file acts as a compatibility shim, re-exporting `HuggingFaceHubEmbeddings` from `langchain_community.embeddings`. It uses a dynamic importer to handle deprecated import paths and ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/xinference.py",
            "description": "This file serves as a compatibility shim to dynamically import `XinferenceEmbeddings`, redirecting it from its old location to `langchain_community.embeddings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/vertexai.py",
            "description": "This file acts as a compatibility layer, dynamically importing `VertexAIEmbeddings` from `langchain_community.embeddings` to handle a package relocation and ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/voyageai.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `VoyageEmbeddings` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/llm_rails.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `LLMRailsEmbeddings` from `langchain_community.embeddings`. It facilitates a migration path or provides backward compatibility for the `LLMRailsEmbeddings` class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/self_hosted_hugging_face.py",
            "description": "This file acts as a re-exporting module, dynamically importing and exposing self-hosted Hugging Face embedding classes from `langchain_community.embeddings` to maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/edenai.py",
            "description": "This file acts as a compatibility layer to re-export the `EdenAiEmbeddings` class, indicating its migration from `langchain_classic` to `langchain_community.embeddings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/google_palm.py",
            "description": "This file serves as a compatibility layer, dynamically redirecting imports for `GooglePalmEmbeddings` from `langchain_classic` to its new location in `langchain_community.embeddings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/adapters/openai.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting OpenAI-related classes and functions that have been moved to `langchain_community.adapters.openai`. It allows `langchain_classic` to access these components, likely facilitating a migration or maintaining backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/neo4j_graph.py",
            "description": "This file manages the deprecated import of 'Neo4jGraph', redirecting it from 'langchain_classic' to 'langchain_community' using a dynamic importer mechanism.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/rdf_graph.py",
            "description": "This file acts as a compatibility layer, redirecting imports of 'RdfGraph' from 'langchain_classic' to its new location in 'langchain_community.graphs'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/networkx_graph.py",
            "description": "This file handles deprecated imports for NetworkX graph functionalities, redirecting them from `langchain_classic` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/falkordb_graph.py",
            "description": "This file acts as a compatibility layer for `FalkorDBGraph`, dynamically importing it from `langchain_community.graphs` to manage module migration and deprecation. It allows continued access to `FalkorDBGraph` while it transitions to a new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/hugegraph.py",
            "description": "This file acts as a compatibility layer or deprecation shim for `HugeGraph`, redirecting imports from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/__init__.py",
            "description": "This `__init__.py` file serves as the package entry point for graph database integrations, dynamically re-exporting various graph-related classes from `langchain_community.graphs`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/arangodb_graph.py",
            "description": "This file serves as a shim for backward compatibility, dynamically redirecting imports of `ArangoGraph` and `get_arangodb_client` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/nebula_graph.py",
            "description": "This file manages the deprecated import of 'NebulaGraph', providing backward compatibility by dynamically redirecting requests for it to 'langchain_community.graphs'. It facilitates the transition of components from 'langchain_classic' to 'langchain_community'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/memgraph_graph.py",
            "description": "This file dynamically re-exports the `MemgraphGraph` class from `langchain_community.graphs`, serving as a compatibility layer or deprecation handler for its classic counterpart.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/kuzu_graph.py",
            "description": "This file provides backward compatibility for the KuzuGraph class, dynamically importing it from `langchain_community.graphs` when accessed via `langchain_classic`. It uses a dynamic import mechanism to manage deprecated locations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/graph_store.py",
            "description": "This file acts as a deprecation proxy for `GraphStore`, dynamically importing it from `langchain_community.graphs.graph_store`. It ensures backward compatibility for users while directing them to the new module location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/neptune_graph.py",
            "description": "This file provides backward-compatible access to the `NeptuneGraph` class, dynamically importing it from `langchain_community.graphs`. It serves as a re-export mechanism for managing module deprecation or relocation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/baseten.py",
            "description": "This file acts as a re-export or redirection for the `Baseten` LLM class, ensuring compatibility by dynamically importing it from `langchain_community.llms`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/beam.py",
            "description": "This file acts as a compatibility layer or proxy, dynamically importing the `Beam` LLM from `langchain_community.llms` into the `langchain_classic` package. It manages potential deprecation or relocation of the `Beam` class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/gigachat.py",
            "description": "This file acts as a compatibility layer for the `GigaChat` LLM, dynamically importing it from `langchain_community.llms` to handle potential deprecation or migration within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/forefrontai.py",
            "description": "This file acts as a compatibility layer, providing dynamic import resolution for the `ForefrontAI` LLM class. It redirects imports from `langchain_classic.llms` to its new location in `langchain_community.llms`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/bananadev.py",
            "description": "This file serves as a compatibility layer, dynamically redirecting imports for the `Banana` LLM class from `langchain_classic.llms` to its new location in `langchain_community.llms`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/databricks.py",
            "description": "This file serves as a compatibility layer, dynamically redirecting imports of the `Databricks` LLM class to its new location in `langchain_community.llms` while managing deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/javelin_ai_gateway.py",
            "description": "This file serves as a compatibility layer, dynamically importing and redirecting usage of `JavelinAIGateway` and `Params` from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/google_palm.py",
            "description": "This file provides backward compatibility for the `GooglePalm` LLM class. It dynamically redirects imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/yandex.py",
            "description": "This file manages the deprecation and dynamic import of the `YandexGPT` class, redirecting it from `langchain_classic` to `langchain_community` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/clarifai.py",
            "description": "This file acts as a re-export or compatibility layer for the Clarifai LLM. It allows `Clarifai` to be imported from `langchain_classic.llms` while dynamically redirecting the actual import to `langchain_community.llms`, likely to handle deprecation or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/mlflow.py",
            "description": "This file re-exports the `Mlflow` LLM class from `langchain_community.llms`. It provides a dynamic import mechanism to maintain backward compatibility and handle deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/fireworks.py",
            "description": "This file acts as a compatibility shim, redirecting imports of the `Fireworks` LLM from `langchain_classic` to its new location in `langchain_community.llms`. It uses dynamic import logic to maintain backward compatibility for users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/minimax.py",
            "description": "This file manages a deprecated import for the `Minimax` LLM, redirecting requests from `langchain_classic` to `langchain_community.llms`. It ensures backward compatibility by dynamically handling the module transition.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/deepsparse.py",
            "description": "This file serves as a compatibility layer, dynamically importing the `DeepSparse` LLM from `langchain_community.llms`. It facilitates access to `DeepSparse` while handling potential deprecation or relocation from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/vertexai.py",
            "description": "This file acts as a compatibility layer, re-exporting `VertexAI` and `VertexAIModelGarden` classes that have been moved to `langchain_community.llms`. It uses a dynamic importer to handle these re-exports and manage deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/nlpcloud.py",
            "description": "This file provides backward compatibility for the `NLPCloud` LLM, which has been moved to the `langchain_community` package. It dynamically redirects imports from `langchain_classic` to the new location while managing deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/predictionguard.py",
            "description": "This file provides a compatibility layer for the `PredictionGuard` LLM, dynamically importing it from `langchain_community.llms` to support changes in the module structure or handle deprecations. It re-exports `PredictionGuard` for use within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/replicate.py",
            "description": "This file serves as a compatibility layer for the Replicate LLM, dynamically importing it from `langchain_community.llms` and managing deprecation for `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/titan_takeoff_pro.py",
            "description": "This file provides backward compatibility for the 'TitanTakeoffPro' class by dynamically redirecting its import from 'langchain_classic' to 'langchain_community.llms'. It acts as a shim for deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/volcengine_maas.py",
            "description": "This file acts as a compatibility layer for `langchain_classic`, dynamically importing `VolcEngineMaasBase` and `VolcEngineMaasLLM` from `langchain_community`. It helps manage the migration of these components to the `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/vllm.py",
            "description": "This file serves as a compatibility layer or re-export mechanism for the `VLLM` and `VLLMOpenAI` classes. It dynamically imports these classes from `langchain_community.llms` for backward compatibility or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/airbyte.py",
            "description": "This file acts as an import proxy for various Airbyte document loader classes, dynamically importing them from `langchain_community.document_loaders` and handling potential deprecation for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/iugu.py",
            "description": "This file provides a compatibility layer for `IuguLoader`, enabling it to be imported from `langchain_classic` while its actual implementation resides in `langchain_community`. It manages the deprecation and redirect of the `IuguLoader` class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/trello.py",
            "description": "This file re-exports the `TrelloLoader` class, serving as a compatibility layer while indicating its relocation from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/xata.py",
            "description": "This file provides backward compatibility for `XataChatMessageHistory`, dynamically re-exporting it from `langchain_community.chat_message_histories`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/openai.py",
            "description": "This file re-exports the `is_openai_v1` utility function, dynamically importing it from `langchain_community.utils.openai`. It primarily manages the deprecation and transition of this function to a new module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/storage/redis.py",
            "description": "This file acts as a re-exporter for 'RedisStore' from 'langchain_community.storage', likely to manage deprecation or consolidate import logic for this component within the classic LangChain library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/storage/upstash_redis.py",
            "description": "This file acts as a compatibility layer to dynamically import and re-export deprecated `UpstashRedisStore` and `UpstashRedisByteStore` classes. It ensures backward compatibility by redirecting imports to `langchain_community.storage`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/deeplake.py",
            "description": "This file facilitates dynamic and deprecated imports for DeepLake-related query constructor components, ensuring backward compatibility. It acts as an importer shim for `DeepLakeTranslator` and `can_cast_to_float`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/supabase.py",
            "description": "This file manages the dynamic import and deprecation handling for the `SupabaseVectorTranslator` class, redirecting imports from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/myscale.py",
            "description": "This file provides backward compatibility for the `MyScaleTranslator` class, dynamically redirecting its import from `langchain_classic` to `langchain_community`. It serves as a deprecation handler for this specific class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/tencentvectordb.py",
            "description": "This file acts as a shim to provide backward compatibility for `TencentVectorDBTranslator`, dynamically importing it from `langchain_community` while residing in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/pinecone.py",
            "description": "This file provides backward compatibility for the `PineconeTranslator` class, allowing it to be accessed from `langchain_classic` while it is actually imported from `langchain_community`. It uses dynamic import lookup to manage this transition.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/vectara.py",
            "description": "This file acts as a shim for deprecated Vectara-related components, dynamically importing `VectaraTranslator` and `process_value` from `langchain_community` while maintaining backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ifttt.py",
            "description": "This file manages the deprecated import path for the 'IFTTTWebhook' tool, allowing it to be accessed from 'langchain_community.tools' while maintaining backward compatibility. It uses a dynamic import mechanism to achieve this.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/yahoo_finance_news.py",
            "description": "This file provides backward compatibility for `YahooFinanceNewsTool` by dynamically importing it from `langchain_community.tools` while allowing it to be referenced from its old `langchain_classic` location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/arxiv/__init__.py",
            "description": "This file is the `__init__.py` for the Arxiv API toolkit within the `langchain` library. It serves as the package initializer and indicates that the directory contains components for interacting with the Arxiv API.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/azure_cognitive_services/form_recognizer.py",
            "description": "This file provides a compatibility layer for the `AzureCogsFormRecognizerTool`, dynamically redirecting imports from its old location in `langchain_classic` to its new home in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/azure_cognitive_services/__init__.py",
            "description": "This file serves as an `__init__.py` for Azure Cognitive Services tools, making them discoverable and dynamically imported from `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/azure_cognitive_services/text_analytics_health.py",
            "description": "This file provides a compatibility layer for `AzureCogsTextAnalyticsHealthTool`. It dynamically imports the tool from `langchain_community.tools`, allowing deprecated imports from `langchain_classic` to continue functioning by redirecting to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/azure_cognitive_services/image_analysis.py",
            "description": "This file serves as a compatibility layer to re-export the `AzureCogsImageAnalysisTool`, which has been moved to `langchain_community.tools`, ensuring backward compatibility and dynamic lookup with potential deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/amadeus/closest_airport.py",
            "description": "This file provides backward-compatible imports for Amadeus closest airport tools, redirecting them from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/amadeus/__init__.py",
            "description": "This file serves as an import proxy for Amadeus tools, redirecting imports from `langchain_classic` to their new location in `langchain_community`. It dynamically re-exports `AmadeusClosestAirport` and `AmadeusFlightSearch`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/amadeus/base.py",
            "description": "This file provides backward compatibility for the `AmadeusBaseTool` by dynamically importing it from `langchain_community`, handling deprecated import paths. It acts as a redirection layer for the tool.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/dataforseo_api_search/__init__.py",
            "description": "This file acts as a compatibility layer and dynamic importer for DataForSeo API tools, redirecting imports to `langchain_community` while maintaining a consistent API within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/dataforseo_api_search/tool.py",
            "description": "This file dynamically imports and re-exports DataForSeo API search tools from `langchain_community` for use within `langchain_classic`. It serves as a compatibility layer or deprecation handler for these components.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/clickup/tool.py",
            "description": "This file dynamically imports and re-exports the `ClickupAction` tool from `langchain_community`, likely serving as a compatibility layer or handling a deprecation for its original location in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/edenai/audio_text_to_speech.py",
            "description": "This file acts as a compatibility layer or stub for `EdenAiTextToSpeechTool`, dynamically importing it from `langchain_community.tools` and handling deprecated lookups.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/edenai/__init__.py",
            "description": "This file serves as an entry point for Edenai tools within the `langchain_classic` package, dynamically importing them from `langchain_community.tools`. It manages the availability of various Edenai-related tools like image processing, object detection, and text manipulation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/edenai/image_explicitcontent.py",
            "description": "This file provides a dynamic import mechanism for `EdenAiExplicitImageTool`, likely to manage its deprecation or consolidate import logic. It allows accessing the tool from `langchain_classic` while it originates from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/edenai/ocr_invoiceparser.py",
            "description": "This file provides backward compatibility for the `EdenAiParsingInvoiceTool`, dynamically importing it from `langchain_community.tools` if it's referenced from this deprecated location within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/edenai/text_moderation.py",
            "description": "This file acts as a compatibility layer for `EdenAiTextModerationTool`, dynamically importing it from `langchain_community.tools`. It facilitates package reorganization and deprecation management for this specific tool.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ainetwork/app.py",
            "description": "This file manages dynamic imports for AINetwork tools, specifically handling deprecated module paths for `AINAppOps`, `AppOperationType`, and `AppSchema` by redirecting them to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gmail/search.py",
            "description": "This file manages deprecated imports for Gmail search-related tools, dynamically redirecting them to their new locations in `langchain_community` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gmail/create_draft.py",
            "description": "This file facilitates the dynamic import of `CreateDraftSchema` and `GmailCreateDraft` from `langchain_community.tools`, handling deprecated import paths. It acts as a transitional shim for these specific Gmail-related tools.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gmail/get_message.py",
            "description": "This file acts as a compatibility layer, dynamically importing and exposing `GmailGetMessage` and `SearchArgsSchema` from `langchain_community` to manage deprecation and maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gmail/__init__.py",
            "description": "This file provides a dynamic import mechanism for various Gmail-related tools, acting as a compatibility layer or a proxy for tools located in `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gitlab/tool.py",
            "description": "This file facilitates backward compatibility by re-exporting the `GitLabAction` tool, which has been moved to the `langchain_community` package. It uses a dynamic importer to handle deprecated access to this tool.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_serper/tool.py",
            "description": "This file acts as a compatibility layer for Google Serper tools within `langchain_classic`. It dynamically imports `GoogleSerperRun` and `GoogleSerperResults` from `langchain_community.tools` and handles potential deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_cloud/texttospeech.py",
            "description": "This file acts as a compatibility layer, dynamically importing the `GoogleCloudTextToSpeechTool` from `langchain_community.tools` to handle moved or deprecated imports. It ensures older code referencing this tool can still function by redirecting the import.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_cloud/__init__.py",
            "description": "This file serves as the `__init__.py` for Google Cloud tools within the `langchain_classic` library, primarily managing the dynamic import and deprecation handling of tools like `GoogleCloudTextToSpeechTool`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/jira/tool.py",
            "description": "This module provides backward compatibility for deprecated Jira tools by dynamically redirecting access to their new locations in `langchain_community.tools`. It ensures older code continues to function while signaling deprecation to developers.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/jira/__init__.py",
            "description": "Initializes the 'jira' subpackage within LangChain Classic's tools, likely making Jira-related functionalities or tools discoverable.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_finance/tool.py",
            "description": "This file acts as a compatibility layer to handle deprecated imports for `GoogleFinanceQueryRun`, dynamically re-exporting it from `langchain_community.tools.google_finance.tool`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/eleven_labs/__init__.py",
            "description": "This file acts as an `__init__.py` for Eleven Labs tools, primarily serving as a dynamic importer to re-export `ElevenLabsText2SpeechTool` from `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/eleven_labs/models.py",
            "description": "This file serves as a deprecation handler, providing backward compatibility for the `ElevenLabsModel` by redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_jobs/tool.py",
            "description": "This file acts as a compatibility layer, providing a deprecated import for `GoogleJobsQueryRun`. It redirects references from `langchain_classic` to its new location within `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/nuclia/tool.py",
            "description": "This file re-exports `NUASchema` and `NucliaUnderstandingAPI` from `langchain_community` for backward compatibility within `langchain_classic`. It uses a dynamic importer to manage these possibly deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/multion/close_session.py",
            "description": "This file manages deprecated imports for Multion session closing tools, redirecting calls from `langchain_classic` to the `langchain_community` package for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/powerbi/__init__.py",
            "description": "This file provides tools designed for interacting with a PowerBI dataset.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/powerbi/tool.py",
            "description": "This file acts as a proxy or entry point for PowerBI tools, dynamically importing them from `langchain_community.tools`. It uses a dynamic import mechanism, possibly to manage deprecated imports or module reorganization.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/__init__.py",
            "description": "This file serves as an `__init__.py` for browser-related tools, handling dynamic imports and managing the deprecation of these tools by redirecting them to `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/office365/send_message.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `O365SendMessage` and `SendMessageSchema` from `langchain_community.tools` to maintain backward compatibility for older import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/office365/base.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting the `O365BaseTool` from `langchain_community` to maintain backward compatibility within `langchain_classic`. It uses an importer to handle deprecated lookups, guiding users to the new location of the Office 365 base tool.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/office365/send_event.py",
            "description": "This file provides backward compatibility for `O365SendEvent` and `SendEventSchema` by dynamically importing them from their new location in `langchain_community.tools.office365.send_event`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/office365/events_search.py",
            "description": "This file acts as a compatibility layer for Office 365 event search tools, dynamically importing them from `langchain_community`. It handles deprecated imports to ensure a smooth transition from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/steam/__init__.py",
            "description": "Initializes the 'steam' tool package, providing an API toolkit for interacting with Steam services.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/steam/tool.py",
            "description": "This file acts as a proxy for `SteamWebAPIQueryRun`, enabling dynamic import and handling potential deprecation by redirecting to `langchain_community.tools`. It allows `SteamWebAPIQueryRun` to be accessed from the current package while sourcing it from an external or community module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/metaphor_search/tool.py",
            "description": "This file acts as an import proxy, making the `MetaphorSearchResults` class available from `langchain_community.tools` within the current module. It primarily handles dynamic imports, likely for deprecation or migration purposes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/wikipedia/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the Wikipedia API toolkit within LangChain, making its functionalities available for import.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/searchapi/__init__.py",
            "description": "This `__init__.py` file provides tools for interacting with the SearchApi.io Google SERP API, dynamically importing `SearchAPIResults` and `SearchAPIRun` from `langchain_community.tools` while handling deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/searchapi/tool.py",
            "description": "This file provides a compatibility layer for deprecated SearchAPI tools, dynamically redirecting imports of 'SearchAPIRun' and 'SearchAPIResults' to their new location in 'langchain_community.tools'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/stackexchange/tool.py",
            "description": "This file provides a compatibility layer for the `StackExchangeTool`, dynamically importing it from `langchain_community.tools`. It ensures backward compatibility and proper import resolution for `StackExchangeTool` after its relocation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/slack/schedule_message.py",
            "description": "This file serves as a compatibility layer to re-export `ScheduleMessageSchema` and `SlackScheduleMessage` from `langchain_community`, dynamically handling imports and potential deprecation. It allows older codebases to continue referencing these tools from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/slack/base.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `SlackBaseTool` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/slack/get_message.py",
            "description": "This file provides backward compatibility for `SlackGetMessage` and `SlackGetMessageSchema` by dynamically importing them from `langchain_community.tools` when accessed from the `langchain_classic` package. It acts as a redirector for deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/slack/__init__.py",
            "description": "This `__init__.py` file serves as an entry point for Slack tools within `langchain_classic`, dynamically re-exporting them from `langchain_community.tools` for compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/slack/send_message.py",
            "description": "This file acts as a deprecation shim, dynamically re-exporting `SendMessageSchema` and `SlackSendMessage` classes which have been moved to the `langchain_community` package. It provides backward compatibility for existing `langchain_classic` imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/slack/get_channel.py",
            "description": "This file serves as a compatibility shim, redirecting imports of `SlackGetChannel` from `langchain_classic` to its new location in `langchain_community`. It manages deprecated imports to provide backward compatibility during library restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/openweathermap/tool.py",
            "description": "This file acts as a compatibility layer or stub, dynamically importing and re-exporting the `OpenWeatherMapQueryRun` tool from `langchain_community.tools` to handle potential deprecations or refactoring in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/zapier/tool.py",
            "description": "This module provides backward compatibility for deprecated Zapier tools by dynamically redirecting old import paths to their new locations in `langchain_community.tools`. It ensures that applications using older references continue to function.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/zapier/__init__.py",
            "description": "This file serves as a re-export mechanism for Zapier tools, `ZapierNLARunAction` and `ZapierNLAListActions`, managing their dynamic import and indicating their relocation to `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/openapi/utils/openapi_utils.py",
            "description": "This file provides utility functions for parsing OpenAPI specifications, primarily by re-exporting deprecated classes and functions from `langchain_community` for backwards compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/clickup.py",
            "description": "This file provides a compatibility layer for deprecated ClickUp utility classes, dynamically importing them from `langchain_community.utilities.clickup` while handling deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/brave_search.py",
            "description": "This file provides a dynamic import mechanism for `BraveSearchWrapper`, ensuring backward compatibility by redirecting imports from `langchain_classic` to its new location in `langchain_community.utilities`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/apify.py",
            "description": "This file acts as an import shim, dynamically exposing `ApifyWrapper` from `langchain_community.utilities`. It manages potential deprecation warnings and handles optional imports for this utility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/alpha_vantage.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `AlphaVantageAPIWrapper` from `langchain_community` to maintain backward compatibility for `langchain_classic` imports. It facilitates the migration of the utility to a new package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/jira.py",
            "description": "This file provides a compatibility layer for importing 'JiraAPIWrapper', dynamically redirecting imports from the classic langchain package to its new location in 'langchain_community.utilities'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/graphql.py",
            "description": "This file dynamically imports and re-exports `GraphQLAPIWrapper` from `langchain_community.utilities`, primarily to manage deprecated imports and maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/google_scholar.py",
            "description": "This file provides a dynamic import mechanism for `GoogleScholarAPIWrapper`, forwarding it from `langchain_classic` to its new location in `langchain_community.utilities` to manage deprecated imports gracefully.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/portkey.py",
            "description": "This file provides a compatibility layer for dynamically importing the `Portkey` utility. It handles deprecated import paths by redirecting requests for `Portkey` to `langchain_community.utilities`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/golden_query.py",
            "description": "This file manages dynamic imports and deprecation warnings for `GoldenQueryAPIWrapper`, redirecting it to `langchain_community.utilities`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/arxiv.py",
            "description": "This file provides a dynamic import mechanism for `ArxivAPIWrapper`, redirecting imports from `langchain_classic` to `langchain_community.utilities` for compatibility or deprecation handling.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/awslambda.py",
            "description": "This file manages the backward-compatible import of `LambdaWrapper`, dynamically redirecting it from `langchain_classic` to its new location in `langchain_community` to handle deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/python.py",
            "description": "This file provides backwards compatibility for the 'PythonREPL' utility, redirecting imports to 'langchain_community.utilities.python' as the original code has been removed.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/scenexplain.py",
            "description": "This file facilitates dynamic imports and manages the deprecation or relocation of the `SceneXplainAPIWrapper` from `langchain_classic` to `langchain_community`, ensuring backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/github.py",
            "description": "This file provides a compatibility layer for `GitHubAPIWrapper`, dynamically importing it from `langchain_community.utilities.github`. It handles deprecated imports, redirecting usage from `langchain_classic` to the updated community package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/google_jobs.py",
            "description": "This file acts as a compatibility layer or proxy for dynamically importing the `GoogleJobsAPIWrapper` from `langchain_community.utilities`, likely managing a deprecation or migration strategy.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/google_trends.py",
            "description": "This file serves as a deprecation layer for `GoogleTrendsAPIWrapper`, redirecting its import from `langchain_classic` to `langchain_community.utilities`. It uses a dynamic importer to handle these legacy imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/google_lens.py",
            "description": "This file provides a compatibility layer for the `GoogleLensAPIWrapper`, dynamically importing it from `langchain_community.utilities` to support deprecation handling and migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/twilio.py",
            "description": "This file provides backward compatibility for the `TwilioAPIWrapper` class by dynamically importing it from `langchain_community.utilities`, handling deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/google_serper.py",
            "description": "This file acts as a compatibility layer or proxy, dynamically importing `GoogleSerperAPIWrapper` from `langchain_community.utilities`. It helps manage deprecated imports and provides a unified access point for this utility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/bing_search.py",
            "description": "This file serves as a re-export and compatibility layer for `BingSearchAPIWrapper`, dynamically importing it from `langchain_community.utilities`. It manages deprecated imports to maintain backward compatibility for `langchain_classic` users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/google_finance.py",
            "description": "This file dynamically re-exports the `GoogleFinanceAPIWrapper` from `langchain_community.utilities` to maintain backward compatibility within the `langchain_classic` package. It uses a dynamic import mechanism to handle potential deprecation or relocation of the utility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/nasa.py",
            "description": "This file provides backward compatibility for importing `NasaAPIWrapper`, dynamically re-exporting it from its new location in `langchain_community.utilities`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/max_compute.py",
            "description": "This file provides backward compatibility for `MaxComputeAPIWrapper`, dynamically redirecting its import from `langchain_classic` to `langchain_community.utilities`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/powerbi.py",
            "description": "This file acts as a compatibility layer for the `PowerBIDataset` utility. It dynamically imports `PowerBIDataset` from `langchain_community.utilities`, managing deprecated import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/google_places_api.py",
            "description": "This file provides a compatibility layer for the GooglePlacesAPIWrapper, enabling dynamic import and handling deprecation by redirecting imports from 'langchain_classic' to 'langchain_community'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/spark_sql.py",
            "description": "This file acts as a re-export mechanism for the `SparkSQL` utility class, dynamically importing it from `langchain_community.utilities` to manage module restructuring or maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/__init__.py",
            "description": "This `__init__.py` file serves as the entry point for the utilities package, exposing a collection of integrations with third-party systems and packages. It primarily re-exports these utilities from `langchain_community.utilities` while handling dynamic imports and deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/metaphor_search.py",
            "description": "This file acts as a compatibility layer within `langchain_classic`, re-exporting `MetaphorSearchAPIWrapper` from `langchain_community.utilities`. It enables dynamic import and handles potential deprecation of the module's original location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/reddit_search.py",
            "description": "This file serves as a compatibility layer, providing dynamic import redirection for `RedditSearchAPIWrapper`. It handles deprecation by pointing to the class's new location within `langchain_community.utilities.reddit_search`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/openapi.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `HTTPVerb` and `OpenAPISpec` from `langchain_community`. It uses a dynamic importer to handle potential deprecations and maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/duckduckgo_search.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `DuckDuckGoSearchAPIWrapper` from `langchain_classic` to its new location in `langchain_community.utilities`. It manages deprecated imports to ensure backward compatibility during package restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/dataforseo_api_search.py",
            "description": "This file provides a compatibility layer for `DataForSeoAPIWrapper`, dynamically redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/searchapi.py",
            "description": "This file provides a compatibility layer for `SearchApiAPIWrapper`, dynamically importing it from `langchain_community.utilities`. It handles deprecated imports to ensure backward compatibility and guide users to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/openweathermap.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting the `OpenWeatherMapAPIWrapper` class from `langchain_community.utilities`. It manages imports for backward compatibility, specifically for the OpenWeatherMap utility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/searx_search.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `SearxResults` and `SearxSearchWrapper` which have been moved to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/stackexchange.py",
            "description": "This file manages deprecated imports, specifically redirecting `StackExchangeAPIWrapper` from `langchain_classic` to `langchain_community` using dynamic attribute lookup for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/gitlab.py",
            "description": "This file acts as a re-exporter for `GitLabAPIWrapper`, redirecting imports from `langchain_classic` to its new location in `langchain_community`. It facilitates backward compatibility and manages deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/pubmed.py",
            "description": "This file acts as a compatibility shim or re-exporter for the `PubMedAPIWrapper` class. It dynamically imports and exposes `PubMedAPIWrapper` from `langchain_community.utilities` to maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/sql_database.py",
            "description": "This file acts as a compatibility layer, dynamically importing `SQLDatabase` and `truncate_word` from `langchain_community` to handle deprecated imports and ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/tavily_search.py",
            "description": "This file acts as a deprecation layer for `TavilySearchAPIWrapper`, dynamically forwarding imports from `langchain_classic` to its new location in `langchain_community` to ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/serpapi.py",
            "description": "This file acts as a compatibility layer or shim, dynamically forwarding imports of `SerpAPIWrapper` and `HiddenPrints` from `langchain_classic.utilities.serpapi` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/steam.py",
            "description": "This file provides a compatibility layer for accessing the `SteamWebAPIWrapper`, facilitating its import from `langchain_community.utilities` while maintaining backward compatibility for older `langchain_classic` references.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/google_search.py",
            "description": "This file re-exports `GoogleSearchAPIWrapper` from `langchain_community.utilities` to maintain backward compatibility. It uses a dynamic import mechanism to handle the relocation of this class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/wolfram_alpha.py",
            "description": "This file provides a compatibility layer to re-export the `WolframAlphaAPIWrapper` class. It handles dynamic imports and deprecation lookup, redirecting references to the class from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/vertexai.py",
            "description": "This file serves as a shim to re-export utilities related to Vertex AI that have been moved to the `langchain_community` package, providing backward compatibility for `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/merriam_webster.py",
            "description": "This file provides backward compatibility for the `MerriamWebsterAPIWrapper` class. It dynamically imports the class from `langchain_community.utilities`, managing deprecated import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/zapier.py",
            "description": "This file serves as a deprecation layer for the `ZapierNLAWrapper` class, redirecting imports from `langchain_classic` to `langchain_community` to maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/wikipedia.py",
            "description": "This file acts as an import shim, providing backward compatibility for `WikipediaAPIWrapper` by dynamically redirecting its import from `langchain_community.utilities`. It uses a dynamic importer to handle deprecated module paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/bageldb.py",
            "description": "This file provides backward compatibility for the `Bagel` vector store by dynamically redirecting its import from a deprecated `langchain_classic` path to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/hologres.py",
            "description": "This file acts as a compatibility layer, providing a dynamic import for the `Hologres` vector store, redirecting to its new location in `langchain_community.vectorstores`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/deeplake.py",
            "description": "This file provides a compatibility layer for the `DeepLake` vector store, dynamically importing it from `langchain_community.vectorstores` to handle potential deprecation or package restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/epsilla.py",
            "description": "This file acts as a compatibility layer for the Epsilla vector store, redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/mongodb_atlas.py",
            "description": "This file re-exports the `MongoDBAtlasVectorSearch` class from `langchain_community.vectorstores`, serving as a compatibility layer or deprecated module redirection within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/momento_vector_index.py",
            "description": "This file handles the deprecation and re-exporting of the `MomentoVectorIndex` class, redirecting users to its new location in `langchain_community.vectorstores`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/lancedb.py",
            "description": "This file serves as a shim for backward compatibility, redirecting the deprecated import of the LanceDB vector store from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/astradb.py",
            "description": "This file acts as a compatibility layer for the `AstraDB` vector store, dynamically re-exporting it from `langchain_community.vectorstores`. It handles deprecated imports to ensure backward compatibility during a refactoring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/chroma.py",
            "description": "This file serves as a compatibility layer or re-export mechanism, redirecting the import of the `Chroma` vector store from `langchain_classic` to its new location in `langchain_community.vectorstores`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/dingo.py",
            "description": "This file provides backward compatibility for the `Dingo` vector store by re-exporting it from `langchain_community.vectorstores` and handling potential deprecation within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/cassandra.py",
            "description": "This file acts as a compatibility layer or re-export mechanism for the 'Cassandra' vector store, dynamically importing it from 'langchain_community.vectorstores'. It likely handles deprecated imports to ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/baiducloud_vector_search.py",
            "description": "This file manages the deprecation and redirects imports of the `BESVectorStore` class from `langchain_classic` to its new location in `langchain_community.vectorstores`, ensuring backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/supabase.py",
            "description": "This file acts as a compatibility layer, enabling dynamic import and handling deprecation of `SupabaseVectorStore` by redirecting its import from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/vectara.py",
            "description": "This file acts as a compatibility layer or shim for the `Vectara` vectorstore and `VectaraRetriever` classes. It dynamically imports them from `langchain_community` while managing deprecated imports within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/awadb.py",
            "description": "This file acts as a compatibility layer for the `AwaDB` vector store. It dynamically imports `AwaDB` from `langchain_community.vectorstores`, facilitating backward compatibility or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/pgvector.py",
            "description": "This file provides a compatibility layer for `langchain_classic` users, dynamically redirecting imports of `DistanceStrategy` and `PGVector` to their new locations within `langchain_community.vectorstores.pgvector`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/tiledb.py",
            "description": "This file dynamically imports and re-exports the `TileDB` vectorstore from `langchain_community`, serving as a compatibility or deprecation handling layer within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/elasticsearch.py",
            "description": "This file acts as a compatibility layer, redirecting imports of Elasticsearch-related classes from `langchain_classic` to their new locations within `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/nucliadb.py",
            "description": "This file acts as a compatibility layer, re-exporting the `NucliaDB` vector store from `langchain_community` to maintain backward compatibility for `langchain_classic` imports. It facilitates dynamic lookup and deprecation handling for `NucliaDB`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/azuresearch.py",
            "description": "This file provides a compatibility layer for AzureSearch vector store components, dynamically redirecting deprecated imports from `langchain_classic` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/myscale.py",
            "description": "This file acts as a deprecation shim for MyScale vector store components, dynamically importing them from `langchain_community` while maintaining access through the `langchain_classic` namespace.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/milvus.py",
            "description": "This file acts as a deprecation shim, redirecting imports of the `Milvus` vector store from `langchain_classic` to its new location in `langchain_community.vectorstores`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/meilisearch.py",
            "description": "This file acts as a deprecation shim for the Meilisearch vector store, forwarding imports from `langchain_classic.vectorstores` to its new location in `langchain_community.vectorstores`. It ensures backward compatibility during refactoring by dynamically resolving the import.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/weaviate.py",
            "description": "This file manages the backward-compatible import of the `Weaviate` vector store, redirecting it from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/dashvector.py",
            "description": "This file dynamically re-exports the `DashVector` class from `langchain_community.vectorstores`, serving as a compatibility layer for `langchain_classic` users. It allows `DashVector` to be accessed from the older `langchain_classic` path while its canonical location is now in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/pgvecto_rs.py",
            "description": "This file serves as a deprecation shim, dynamically importing the `PGVecto_rs` class from `langchain_community.vectorstores` while maintaining backward compatibility for older `langchain_classic` imports. It facilitates the migration of the `PGVecto_rs` vector store to the community package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/tair.py",
            "description": "This file acts as an import redirector for the `Tair` vector store, allowing it to be imported from `langchain_classic.vectorstores` while actually sourcing it from `langchain_community.vectorstores`. It facilitates a deprecation or migration strategy for the `Tair` class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/vald.py",
            "description": "This file acts as a re-exporter for the `Vald` vector store class, redirecting imports from `langchain_classic` to `langchain_community.vectorstores`. It facilitates backward compatibility during package restructuring by dynamically handling deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/typesense.py",
            "description": "This file serves as a deprecated redirect for the Typesense vector store, pointing imports from `langchain_classic` to its new location in `langchain_community`. It uses dynamic attribute lookup to manage this migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/yellowbrick.py",
            "description": "This file acts as a compatibility layer or deprecation shim for the `Yellowbrick` vector store. It dynamically imports `Yellowbrick` from `langchain_community.vectorstores` for backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/scann.py",
            "description": "This file acts as a compatibility layer for the ScaNN vector store, redirecting imports from `langchain_classic` to its new location in `langchain_community.vectorstores`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/semadb.py",
            "description": "This file provides a compatibility layer for the `SemaDB` vector store, dynamically importing it from `langchain_community.vectorstores`. It facilitates handling deprecated imports, allowing `SemaDB` to be accessed from `langchain_classic` while it resides in the community package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/redis/filters.py",
            "description": "This file manages the deprecation and re-exporting of Redis filter-related components from the `langchain_classic` package, redirecting imports to `langchain_community.vectorstores.redis.filters` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/redis/__init__.py",
            "description": "This file acts as a compatibility layer, re-exporting Redis vector store components that have moved from `langchain_classic` to `langchain_community` while managing potential deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/docarray/hnsw.py",
            "description": "This file acts as a compatibility layer for `DocArrayHnswSearch`, dynamically importing it from `langchain_community.vectorstores` when accessed through `langchain_classic`. It facilitates a smooth transition for deprecated modules by redirecting imports.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 95
          },
          {
            "name": "Christophe Bornet",
            "percent": 4
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 2
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 447,
      "spofCount": 109
    },
    "busFactor": 5,
    "authorCount": 30
  },
  "Data Indexing & Retrieval (RAG)": {
    "description": "Enables applications to connect with private data sources and provide external knowledge to language models. This module includes tools for loading, transforming, splitting, storing, and retrieving documents, forming the backbone of Retrieval-Augmented Generation (RAG) systems.",
    "functions": {
      "Vector Store & Docstore Integrations": {
        "files": [
          {
            "path": "libs/partners/qdrant/langchain_qdrant/qdrant.py",
            "description": "This file implements the `QdrantVectorStore` class, providing an integration between LangChain and Qdrant. It allows for storing, retrieving, and searching documents using dense, sparse, or hybrid embedding retrieval modes within a Qdrant collection.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/langchain_qdrant/vectorstores.py",
            "description": "This file implements the Qdrant vector store for LangChain, providing functionality to store and retrieve document embeddings in a Qdrant collection. It includes methods for adding texts, performing similarity searches, and handling both synchronous and asynchronous operations.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/test_from_existing_collection.py",
            "description": "Integration test for the `Qdrant.from_existing_collection` method, ensuring it correctly reuses and adds to an existing Qdrant collection.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/test_embedding_interface.py",
            "description": "This file contains integration tests for the `Qdrant` vector store in `langchain_qdrant`. It verifies that `Qdrant` correctly accepts different embedding interfaces (either `embeddings` or `embedding_function`) and raises a `ValueError` when conflicting or missing embedding methods are provided.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/conftest.py",
            "description": "This file defines a pytest teardown hook (`pytest_runtest_teardown`) responsible for cleaning up Qdrant collections after each integration test.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/test_add_texts.py",
            "description": "This file contains integration tests for the `add_texts` and `add_documents` methods of the `langchain_qdrant.Qdrant` vector store. It verifies various functionalities such as extending existing collections, returning IDs, handling duplicated texts, storing provided IDs, and managing named vectors.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/test_max_marginal_relevance.py",
            "description": "This file contains integration tests for the `max_marginal_relevance_search` method of the Langchain Qdrant vector store. It verifies its functionality under various configurations, including different batch sizes, content/metadata keys, vector names, and filtering options.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/test_similarity_search.py",
            "description": "This file contains integration tests for the Qdrant vector store's similarity search functionalities, covering various search methods, filtering options, and parameter configurations.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/fastembed/test_fastembed_sparse.py",
            "description": "This file contains integration tests for the `FastEmbedSparse` class in `langchain_qdrant`, specifically verifying the functionality of sparse embedding models for both query and document embedding.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/qdrant_vector_store/test_from_existing.py",
            "description": "This file contains integration tests for the `QdrantVectorStore.from_existing_collection` method. It verifies that an existing Qdrant collection is correctly reused when initializing the vector store.",
            "spof": true
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/qdrant_vector_store/test_add_texts.py",
            "description": "This file contains integration tests for the `add_texts` and `add_documents` methods of the `QdrantVectorStore` class. It verifies functionalities like extending collections, returning unique IDs, handling duplicated texts, and using specified IDs when adding data.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/qdrant_vector_store/test_search.py",
            "description": "This file contains integration tests for the QdrantVectorStore's search functionalities, including similarity search, relevance search, and various filtering options.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/async_api/test_max_marginal_relevance.py",
            "description": "This file contains an asynchronous integration test for the Qdrant vector store's maximum marginal relevance (MMR) search functionality. It verifies that the `amax_marginal_relevance_search` method works correctly with various configurations and parameters.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/async_api/test_from_texts.py",
            "description": "This file contains integration tests for the `afrom_texts` asynchronous method of the `langchain_qdrant` vector store. It verifies various functionalities, including storing duplicated texts, handling IDs, named vectors, collection reuse, and error scenarios related to configuration mismatches.",
            "spof": false
          },
          {
            "path": "libs/partners/qdrant/tests/integration_tests/async_api/test_similarity_search.py",
            "description": "This file contains integration tests for the asynchronous similarity search functionalities of the Langchain Qdrant vector store. It covers various search methods, including text and vector-based searches, and tests different configurations, filtering options, and relevance score thresholds.",
            "spof": false
          },
          {
            "path": "libs/partners/chroma/langchain_chroma/vectorstores.py",
            "description": "This module defines the Chroma vector store integration for LangChain, enabling document storage, retrieval, and similarity search functionalities using ChromaDB. It includes the `Chroma` class and helper functions for similarity calculations.",
            "spof": false
          },
          {
            "path": "libs/partners/chroma/tests/unit_tests/test_standard.py",
            "description": "This file contains unit and integration tests for the `Chroma` vector store, including a performance benchmark for its initialization time. It sets up an empty Chroma instance using a pytest fixture for testing purposes.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/vectorstores/in_memory.py",
            "description": "This file implements an in-memory vector store, `InMemoryVectorStore`, which stores documents and their embeddings in a dictionary. It provides methods for adding, deleting, and searching documents based on vector similarity, including support for asynchronous operations and filtering.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/vectorstores/utils.py",
            "description": "This file provides internal utility functions for vector store implementations, including cosine similarity calculation and Maximal Marginal Relevance (MMR) for selecting diverse embeddings. It's intended for private use within the `langchain_core` library.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/vectorstores/test_in_memory.py",
            "description": "This file contains unit and integration tests for the InMemoryVectorStore class, verifying its functionality for operations such as similarity search, adding/updating documents, filtering, and persistence, including both synchronous and asynchronous methods.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/vectorstores/test_utils.py",
            "description": "This file contains unit tests for the `_cosine_similarity` function found in `langchain_core.vectorstores.utils`. It thoroughly tests various scenarios, including basic calculations, edge cases, different input types, and numerical stability.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/vectorstores.py",
            "description": "This file provides a base class (`VectorStoreIntegrationTests`) for standardized integration testing of `VectorStore` implementations. It includes common test cases for functionalities like adding, deleting, and searching documents, ensuring consistent behavior across different vector store integrations.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/tests/unit_tests/test_in_memory_vectorstore.py",
            "description": "This file contains unit and integration tests for the `InMemoryVectorStore` class, including a specific test case for scenarios where the `get_by_ids` method is not implemented.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/docstore/arbitrary_fn.py",
            "description": "This file facilitates the dynamic import and deprecation handling of `DocstoreFn`, redirecting it from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/docstore/__init__.py",
            "description": "This `__init__.py` file defines the `docstore` package, serving as a gateway to various document store implementations like `DocstoreFn`, `InMemoryDocstore`, and `Wikipedia`. It uses dynamic import mechanisms to expose these classes, including handling deprecation warnings.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/docstore/base.py",
            "description": "This file acts as a compatibility layer for `Docstore` and `AddableMixin`, redirecting imports from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/docstore/in_memory.py",
            "description": "This file acts as a deprecation shim, dynamically redirecting imports of `InMemoryDocstore` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/vectorstore.py",
            "description": "This file defines utilities for creating and interacting with vector store indexes. It includes classes for wrapping vector stores to facilitate querying and for creating vector stores from documents or loaders.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/storage/encoder_backed.py",
            "description": "This file defines an `EncoderBackedStore` class that wraps an underlying storage system, providing transparent encoding and decoding of keys and values using user-defined functions. It allows storing arbitrary Python objects by converting them to string keys and byte values for the wrapped store.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/storage/_lc_store.py",
            "description": "This file provides utility functions to create typed key-value stores for LangChain serializable objects or specifically Document objects, by wrapping a low-level byte store and handling serialization/deserialization to/from bytes.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/storage/__init__.py",
            "description": "This file provides implementations of various key-value stores and storage helpers, primarily designed to support caching within LangChain. It exposes in-memory, file-system, and encoder-backed stores, and handles dynamic imports for community-provided Redis-based stores.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/vespa_retriever.py",
            "description": "This file acts as a compatibility layer, re-exporting the `VespaRetriever` class from `langchain_community` for use within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/azure_ai_search.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `AzureAISearchRetriever` and `AzureCognitiveSearchRetriever` classes that have been moved to `langchain_community.retrievers`. It handles these imports and facilitates deprecation warnings for users still referencing them from this location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/google_vertex_ai_search.py",
            "description": "This file acts as a compatibility layer, re-exporting Google Vertex AI Search and Enterprise Search retriever classes that have been moved to `langchain_community.retrievers`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/zilliz.py",
            "description": "This file serves as a compatibility layer within `langchain_classic` to dynamically import `ZillizRetriever` classes from `langchain_community`, handling deprecated import paths and potential typos.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/milvus.py",
            "description": "This file acts as a compatibility layer for `MilvusRetriever` (and its typo `MilvusRetreiver`), dynamically importing them from `langchain_community` while likely handling deprecation notices. It ensures older references to these classes within `langchain_classic` are correctly resolved.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/analyticdb.py",
            "description": "This file acts as a compatibility layer or re-export module for the 'AnalyticDB' vector store, dynamically importing it from 'langchain_community.vectorstores'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/faiss.py",
            "description": "This file acts as a re-exporter or shim for the `FAISS` vector store, dynamically importing it from `langchain_community.vectorstores` for compatibility or deprecation handling within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/elastic_vector_search.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `ElasticKnnSearch` and `ElasticVectorSearch` classes from `langchain_community.vectorstores`. It uses a deprecated lookup mechanism to manage these imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/annoy.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting the `Annoy` vector store class from `langchain_community.vectorstores` while handling potential deprecation for `langchain_classic` usage.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/neo4j_vector.py",
            "description": "This file provides backward compatibility for `Neo4jVector` and `SearchType` by dynamically importing them from the `langchain_community` package, managing deprecated imports and ensuring a smooth transition.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/alibabacloud_opensearch.py",
            "description": "This file serves as a re-exporter for `AlibabaCloudOpenSearch` and `AlibabaCloudOpenSearchSettings` classes. It dynamically imports these components from `langchain_community.vectorstores` to provide backward compatibility for users referencing them through `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/pgembedding.py",
            "description": "This file acts as a compatibility layer or re-exporter for `PGEmbedding` and related classes, redirecting imports from `langchain_classic` to their new location in `langchain_community.vectorstores`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/azure_cosmos_db.py",
            "description": "This file acts as a compatibility layer for `langchain_classic`, redirecting imports of `AzureCosmosDBVectorSearch` and `CosmosDBSimilarityType` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/atlas.py",
            "description": "This file manages the deprecated import of `AtlasDB`, dynamically re-exporting it from `langchain_classic` while indicating its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/xata.py",
            "description": "This file provides a compatibility layer for the `XataVectorStore` by dynamically importing it from `langchain_community`, primarily for handling deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/matching_engine.py",
            "description": "This file serves as a compatibility layer for the `MatchingEngine` vector store, dynamically importing it from `langchain_community.vectorstores`. It manages deprecated imports and ensures existing code referencing `MatchingEngine` continues to function.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/sqlitevss.py",
            "description": "This file acts as a compatibility layer or shim, dynamically re-exporting the `SQLiteVSS` class from `langchain_community.vectorstores` for backwards compatibility. It uses an importer mechanism to manage deprecated imports, ensuring that `SQLiteVSS` is available via `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/pinecone.py",
            "description": "This file serves as a compatibility layer for the Pinecone vector store, dynamically importing it from `langchain_community.vectorstores` and managing deprecation warnings for `langchain_classic` users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/databricks_vector_search.py",
            "description": "This file acts as a compatibility shim, dynamically importing the `DatabricksVectorSearch` class from `langchain_community.vectorstores` to maintain backward compatibility for older `langchain_classic` references. It uses a dynamic importer to handle deprecated module paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/hippo.py",
            "description": "This file provides backward compatibility for the `Hippo` vector store, dynamically redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/clickhouse.py",
            "description": "This file acts as a compatibility layer or proxy, dynamically importing `Clickhouse` and `ClickhouseSettings` from `langchain_community.vectorstores`. It facilitates access to these classes while potentially handling deprecation warnings for their usage within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/rocksetdb.py",
            "description": "This file re-exports the `Rockset` vector store class from `langchain_community.vectorstores`, handling dynamic lookup and deprecation for compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/sklearn.py",
            "description": "This file acts as a compatibility layer, redirecting imports for `SKLearnVectorStore` and related components from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/qdrant.py",
            "description": "This file provides backward compatibility for `langchain_classic` by dynamically re-exporting `Qdrant` and `QdrantException` classes from `langchain_community` using a deprecated import mechanism.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/clarifai.py",
            "description": "This file acts as a compatibility layer, re-exporting the `Clarifai` vector store class which has been moved to `langchain_community`. It uses a dynamic importer to handle deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/zep.py",
            "description": "This file provides backward compatibility for `ZepVectorStore` and `CollectionConfig` by dynamically importing them from the `langchain_community` package, managing deprecated imports from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/tencentvectordb.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `TencentVectorDB`, `ConnectionParams`, and `IndexParams` from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/timescalevector.py",
            "description": "This file acts as a compatibility layer, re-exporting the `TimescaleVector` class, which has been moved to `langchain_community.vectorstores`. It uses dynamic import logic to manage deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/starrocks.py",
            "description": "This file re-exports the `StarRocks` vector store and its settings from `langchain_community`, providing a compatibility layer and handling potential deprecations for `langchain_classic` users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/vearch.py",
            "description": "This file serves as a shim or re-exporter for the `Vearch` vector store class, redirecting its import from `langchain_community.vectorstores` for backward compatibility or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/opensearch_vector_search.py",
            "description": "This file dynamically re-exports the `OpenSearchVectorSearch` class, likely for backward compatibility or deprecation handling, redirecting imports from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/marqo.py",
            "description": "This file acts as a compatibility layer, re-exporting the `Marqo` vector store class from `langchain_community` to maintain backward compatibility within `langchain_classic` while handling potential deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/vespa.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for the `VespaStore` class which has been moved to `langchain_community.vectorstores`. It ensures backward compatibility for users still importing `VespaStore` from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/singlestoredb.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting the `SingleStoreDB` vectorstore from `langchain_community.vectorstores`. It handles potential deprecation or migration of the `SingleStoreDB` class to a new location within the LangChain ecosystem.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/usearch.py",
            "description": "This file provides backward compatibility for importing the `USearch` vector store, dynamically redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/utils.py",
            "description": "This file serves as a shim for backward compatibility, re-exporting utility functions and classes from 'langchain_community.vectorstores.utils' into 'langchain_classic.vectorstores' and handling deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/zilliz.py",
            "description": "This file serves as an import proxy for the `Zilliz` vector store, enabling dynamic lookup and handling potential relocation or deprecation warnings by re-exporting it from `langchain_community.vectorstores`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/redis/base.py",
            "description": "This file acts as a compatibility layer, dynamically importing and exposing Redis-related vector store components from `langchain_community`. It manages deprecated imports by redirecting calls to their new locations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/redis/schema.py",
            "description": "This file serves as a compatibility layer, dynamically re-exporting classes and functions from `langchain_community.vectorstores.redis.schema`. It allows `langchain_classic` to access these components, likely for managing deprecation or package restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/docarray/in_memory.py",
            "description": "This file acts as a compatibility layer, dynamically redirecting imports for `DocArrayInMemorySearch` from `langchain_classic` to `langchain_community` to manage deprecations or refactoring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/docarray/__init__.py",
            "description": "This file acts as a compatibility layer for DocArray-based vector stores, dynamically importing `DocArrayHnswSearch` and `DocArrayInMemorySearch` from `langchain_community.vectorstores` to manage deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/docarray/base.py",
            "description": "This file manages the deprecation and re-export of the `DocArrayIndex` class, allowing it to be imported from `langchain_classic` while it is actually located in `langchain_community` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/vectorstores/test_public_api.py",
            "description": "This file tests the public API of the `langchain_classic.vectorstores` package. It ensures that the exposed classes and functions match a predefined list, helping to detect accidental API changes or regressions.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/storage/test_imports.py",
            "description": "This file contains a unit test to verify that the `langchain_classic.storage` module's `__all__` attribute correctly lists all expected public exports.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/storage/test_lc_store.py",
            "description": "This file contains unit tests for `_lc_store.py`, specifically verifying the creation and basic functionality of `lc_store` and `kv_docstore` using a `LocalFileStore`.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/storage/test_filesystem.py",
            "description": "This file contains unit tests for the `LocalFileStore` class, which manages key-value storage using the local file system. It verifies core functionalities like setting, getting, deleting, iterating keys, handling file permissions, and managing invalid or forbidden key paths.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 57
          },
          {
            "name": "Anush",
            "percent": 12
          },
          {
            "name": "Christophe Bornet",
            "percent": 6
          }
        ]
      },
      "Document Combination & Re-ranking": {
        "files": [
          {
            "path": "libs/partners/qdrant/langchain_qdrant/_utils.py",
            "description": "This file provides utility functions for calculating cosine similarity between matrices and implementing maximal marginal relevance (MMR) for selecting diverse embeddings, often used in information retrieval contexts.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/documents/compressor.py",
            "description": "This file defines the abstract base class `BaseDocumentCompressor`, which serves as an interface for post-processing and compressing retrieved documents based on a given query.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/retrieval.py",
            "description": "This file defines the `create_retrieval_chain` function, which constructs a LangChain Expression Language (LCEL) Runnable for retrieval augmented generation (RAG). It combines a retriever (to fetch relevant documents) with a document combining chain (to process those documents and generate an answer).",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/combine_documents/stuff.py",
            "description": "This file defines a method and a deprecated class for combining multiple documents into a single string by 'stuffing' them into a language model's context. It prepares documents for use in prompt templates by formatting and concatenating them.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/combine_documents/__init__.py",
            "description": "This file serves as the __init__.py for the combine_documents package, exposing utilities for combining documents, including functions for reducing/collapsing documents and creating document combination chains.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/combine_documents/refine.py",
            "description": "This file defines the `RefineDocumentsChain` class, which combines multiple documents by iteratively refining an initial output. It first processes an initial document and then refines the result by incorporating subsequent documents one by one.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/combine_documents/reduce.py",
            "description": "This file implements the `ReduceDocumentsChain`, which combines multiple documents by recursively reducing them into smaller groups until they can be combined into a final output, often due to token limits. It provides functions for splitting and collapsing documents as part of this process.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/combine_documents/map_rerank.py",
            "description": "This file defines the `MapRerankDocumentsChain` class, a deprecated LangChain component that combines documents by mapping an LLM chain over them and then reranking the results based on a score to select the best answer.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/qa_with_sources/vector_db.py",
            "description": "This file defines a deprecated chain for performing question-answering with sources by querying a vector database. It includes logic for retrieving documents, reducing them based on token limits, and integrates with other QA components.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/retrieval_qa/base.py",
            "description": "This file defines deprecated classes for performing question-answering by retrieving information from a vector database or an index. It provides the base structure for these retrieval-augmented generation (RAG) chains.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/__init__.py",
            "description": "This file serves as the `__init__.py` for the `document_transformers` package, dynamically exposing various document transformer classes, many of which are imported from `langchain_community` and handle potential deprecations.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/embeddings_redundant_filter.py",
            "description": "This file acts as a compatibility layer or shim for `langchain_classic`, dynamically importing document transformer utilities related to embeddings filtering from the `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/long_context_reorder.py",
            "description": "This file acts as a compatibility layer for the `LongContextReorder` class. It facilitates importing the class from `langchain_classic` by redirecting to its new location in `langchain_community.document_transformers`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/doctran_text_qa.py",
            "description": "This file dynamically re-exports `DoctranQATransformer` from `langchain_community.document_transformers`. It acts as a transitional shim to maintain compatibility while the class's location has moved.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/prompts/entity_summarization.py",
            "description": "This file defines a PromptTemplate for an AI assistant to summarize entities. It provides instructions for updating an entity's summary based on the last line of conversation, focusing on new, relevant facts.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/contextual_compression.py",
            "description": "This file defines a retriever that first fetches documents using a base retriever and then compresses them contextually based on the query using a document compressor.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/base.py",
            "description": "This file defines the `DocumentCompressorPipeline` class, which chains together multiple document transformers or compressors to process and refine a list of documents sequentially. It provides methods for both synchronous and asynchronous document compression.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/cross_encoder.py",
            "description": "This file defines the abstract base class `BaseCrossEncoder`, serving as an interface for models that score the similarity between pairs of texts. It specifies the `score` method which concrete cross-encoder implementations must provide.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/cross_encoder_rerank.py",
            "description": "This file defines the `CrossEncoderReranker` class, a document compressor that uses a CrossEncoder model to rerank and select the most relevant documents based on a given query.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/chain_extract_prompt.py",
            "description": "This file defines a prompt template used to extract relevant parts of a given context, verbatim, based on a specific question. It is intended for document compression or retrieval-augmented generation tasks.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/cohere_rerank.py",
            "description": "This file defines a `CohereRerank` document compressor that uses the Cohere Rerank API to reorder and filter documents based on relevance to a given query. It is marked as deprecated, with an alternative import suggested in `langchain_cohere`.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/chain_filter.py",
            "description": "This file defines a document compressor (`LLMChainFilter`) that uses a Large Language Model (LLM) chain to filter out documents that are not relevant to a given query. It provides methods to synchronously and asynchronously compress (filter) a sequence of documents.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/chain_extract.py",
            "description": "This file defines the `LLMChainExtractor` class, a document compressor that uses an LLM chain to extract relevant parts from documents based on a given query. It provides methods for synchronously and asynchronously compressing documents.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/chain_filter_prompt.py",
            "description": "This file defines a prompt template used to determine if a given document context is relevant to a specific question. It is designed for use within a document compression or filtering chain in a retrieval system.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/listwise_rerank.py",
            "description": "This file defines a document compressor, `LLMListwiseRerank`, that uses a language model to re-rank a list of documents based on their relevance to a given query, selecting the top-k most relevant documents.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/__init__.py",
            "description": "This `__init__.py` file exposes various document compressor classes directly from the `langchain_classic.retrievers.document_compressors` package. It also includes dynamic import logic for compressors like `FlashrankRerank` from the `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/embeddings_filter.py",
            "description": "This file defines the `EmbeddingsFilter` class, a document compressor that filters and returns relevant documents based on their embedding similarity to a given query. It allows filtering by a fixed number of top documents or a similarity threshold.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/document_compressors/flashrank_rerank.py",
            "description": "This file facilitates the deprecation and migration of `FlashrankRerank` by re-exporting it from `langchain_community.document_compressors.flashrank_rerank`. It dynamically handles imports to ensure backward compatibility while pointing to the new module location.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_combine_documents.py",
            "description": "This file contains unit tests for functionality related to combining documents within the LangChain framework. It covers testing document splitting, collapsing documents with and without metadata, and formatting documents using prompts.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/document_transformers/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `document_transformers` module correctly lists all expected public components, ensuring the module's public API is as intended.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/document_compressors/test_chain_extract.py",
            "description": "This file contains unit tests for the `LLMChainExtractor` class, which is used to compress documents by extracting relevant information using an LLM. It includes tests for both synchronous and asynchronous document compression.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/document_compressors/test_listwise_rerank.py",
            "description": "This file contains unit tests for the `LLMListwiseRerank` document compressor, specifically testing its initialization method using an OpenAI LLM.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/document_compressors/test_chain_filter.py",
            "description": "This file contains unit tests for the `LLMChainFilter` document compressor. It verifies both synchronous and asynchronous filtering of documents based on a query, using a mock language model to simulate relevance judgments.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/retrievers/document_compressors/test_cohere_reranker.py",
            "description": "This file contains an integration test for the Cohere Rerank document compressor, specifically checking its initialization. It ensures the `CohereRerank` class can be instantiated correctly.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/integration_tests/retrievers/document_compressors/test_listwise_rerank.py",
            "description": "This file contains an integration test for the `LLMListwiseRerank` document compressor. It verifies that the compressor correctly re-ranks and selects the top documents based on a query using an OpenAI LLM.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 89
          },
          {
            "name": "Christophe Bornet",
            "percent": 3
          },
          {
            "name": "ccurme",
            "percent": 3
          }
        ]
      },
      "Core RAG Abstractions & Data Models": {
        "files": [
          {
            "path": "libs/partners/qdrant/langchain_qdrant/sparse_embeddings.py",
            "description": "This file defines the `SparseVector` Pydantic model and the `SparseEmbeddings` abstract base class. It provides an interface for sparse embedding models to be used with Qdrant, including abstract methods for embedding documents and queries, along with asynchronous implementations.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/document_loaders/__init__.py",
            "description": "This `__init__.py` file serves as the public API for the `langchain_core.document_loaders` package, dynamically exposing various document loader components like `BaseLoader`, `BlobLoader`, and `LangSmithLoader`.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/document_loaders/blob_loaders.py",
            "description": "This file defines the abstract base class `BlobLoader` for lazy loading of raw data (blobs) from storage systems, aiming to decouple content loading from parsing. It also re-exports `Blob` and `PathLike` for compatibility.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/document_loaders/base.py",
            "description": "This file defines abstract interfaces for document loaders (`BaseLoader`) and blob parsers (`BaseBlobParser`), providing a standardized way to load and process data into `Document` objects, with an emphasis on lazy loading for memory efficiency.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/documents/transformers.py",
            "description": "This file defines the `BaseDocumentTransformer` abstract base class, providing an interface for transforming sequences of `Document` objects, with both synchronous and asynchronous methods.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/documents/__init__.py",
            "description": "This `__init__.py` file serves as the entry point for the LangChain documents module, facilitating dynamic imports and exposing core abstractions for data retrieval and processing workflows such as `Document`, `BaseDocumentCompressor`, and `BaseDocumentTransformer`.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/documents/base.py",
            "description": "This file defines core abstractions (`BaseMedia`, `Blob`, `Document`) for handling data within LangChain's data retrieval and processing workflows. These classes are designed for use in document loaders, vector stores, and RAG systems, distinguishing them from LLM chat message content.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/retrievers.py",
            "description": "This file defines the abstract base class `BaseRetriever` for document retrieval systems within LangChain. It establishes the interface for classes that retrieve `Document` objects given a text query, supporting both synchronous and asynchronous invocation patterns.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/structured_query.py",
            "description": "This file defines the internal representation (data models) for a structured query language, including operators, comparators, and filter directives. It also provides an abstract base class for a visitor pattern to translate these structured queries into other forms.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/vectorstores/__init__.py",
            "description": "This file serves as the `__init__.py` for the `vectorstores` package, providing lazy loading for core vector store components like `VectorStore` and `InMemoryVectorStore` from its submodules. It reduces import time and manages potential circular dependencies by dynamically importing these classes upon first access.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/vectorstores/base.py",
            "description": "This file defines the abstract base class for `VectorStore` in Langchain, outlining the common interface for storing embedded data and performing vector search operations. It establishes standard methods for adding, retrieving, and deleting documents to be implemented by concrete vector store integrations.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/documents/test_document.py",
            "description": "This file contains unit tests for the `Document` class within the `langchain_core` library, specifically verifying its initialization with various `page_content`, `metadata`, and `id` arguments.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/documents/test_imports.py",
            "description": "This file contains a unit test to verify that the '__all__' variable in the 'langchain_core.documents' module correctly exports the expected public classes and modules, ensuring API consistency.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/documents/test_str.py",
            "description": "This file contains unit tests for the `__str__` and `__repr__` methods of the `Document` class in `langchain_core`, ensuring they produce the expected string representations.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/document_loaders/test_base.py",
            "description": "This file contains unit tests for the base classes `BaseBlobParser` and `BaseLoader` within the Langchain document loaders module, verifying their default implementations and expected behaviors for parsing and loading documents.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/vectorstores/test_vectorstore.py",
            "description": "This file contains unit tests for the base VectorStore abstraction, verifying that default implementations correctly delegate calls to specific overridden methods (add_texts or add_documents) in subclasses.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/base.py",
            "description": "This file defines the abstract base class `TextSplitter`, which provides a standardized interface for splitting text into smaller chunks. It also includes methods for creating text splitters that use tokenizers like Hugging Face or Tiktoken for length calculation.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/retrievers.py",
            "description": "This file defines a base class and standard integration tests for Langchain retriever implementations, ensuring they function correctly and adhere to common interface expectations like handling 'k' parameters and returning Document objects.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/tests/unit_tests/test_basic_retriever.py",
            "description": "This file defines a basic `ParrotRetriever` class that repeats the input query and implements integration tests for it using `RetrieversIntegrationTests`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/docstore/document.py",
            "description": "This file re-exports the `Document` class from `langchain_core.documents`. It serves to make the `Document` class accessible from `langchain_classic.docstore`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/graphs/graph_document.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting graph-related classes like `Node`, `Relationship`, and `GraphDocument` from `langchain_community.graphs.graph_document` for backward compatibility or deprecation handling.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/base.py",
            "description": "This file re-exports base classes (`BaseBlobParser`, `BaseLoader`) for document loading from the `langchain_core` library, making them accessible within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/blob_loaders/schema.py",
            "description": "This file acts as a compatibility layer or re-export mechanism for `Blob` and `BlobLoader` classes. It dynamically imports and exposes these components, with built-in support for handling future deprecations by redirecting to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/document.py",
            "description": "This file re-exports core document classes, BaseDocumentTransformer and Document, from 'langchain_core.documents' for use within the 'langchain_classic' schema. It primarily serves as an import consolidation or compatibility layer.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/vectorstore.py",
            "description": "This file re-exports core vector store components (VST, VectorStore, VectorStoreRetriever) from `langchain_core.vectorstores`, likely for backward compatibility or to maintain a consistent import path within the classic LangChain library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/retriever.py",
            "description": "This file re-exports the `BaseRetriever` class from `langchain_core` to make it accessible within the `langchain_classic` schema, ensuring compatibility and consistent import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/storage.py",
            "description": "This file re-exports fundamental storage interfaces and type variables (BaseStore, K, V) from `langchain_core.stores`, serving as a compatibility layer within the `langchain_classic` schema.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/zep.py",
            "description": "This file provides backward compatibility for Zep-related classes (ZepRetriever, SearchScope, SearchType) by dynamically importing them from their new location in `langchain_community`, managing deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/docarray.py",
            "description": "This file acts as a compatibility layer, redirecting imports for `DocArrayRetriever` and `SearchType` from `langchain_classic` to their new locations in `langchain_community`. It facilitates a smooth transition by handling deprecated imports dynamically.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/base.py",
            "description": "This file serves as a re-exporting module for base VectorStore classes from `langchain_core`, making them accessible within the `langchain_classic` vectorstores package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/__init__.py",
            "description": "This file defines the base `VectorStore` concept and acts as a central entry point for importing a wide range of vector store implementations, managing their availability and handling deprecation.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/embeddings/test_caching.py",
            "description": "This file contains unit tests for the `CacheBackedEmbeddings` class, verifying its caching functionality for document and query embeddings, including asynchronous operations, batch processing, and different key encoding mechanisms.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/document_loaders/test_base.py",
            "description": "This file contains unit tests for the `BaseBlobParser` class, verifying that its eager parsing method (`parse`) correctly utilizes the lazy parsing method (`lazy_parse`) by default.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/document_loaders/blob_loaders/test_public_api.py",
            "description": "This file contains a unit test to verify the public API of the blob loaders module, ensuring that the exposed classes and functions match an expected list.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_retriever.py",
            "description": "This file contains unit tests for the `retriever` schema module, specifically verifying the `__all__` variable to ensure correct exports.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_vectorstore.py",
            "description": "This file contains unit tests for the `__all__` variable in the `vectorstore` schema module. It verifies that the module correctly exports the expected public API elements.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_document.py",
            "description": "This unit test verifies that the `__all__` variable in the `langchain_classic.schema.document` module correctly lists all public symbols intended for export.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `langchain_classic.retrievers` module correctly exposes all expected retriever classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/parrot_retriever.py",
            "description": "This file defines a `FakeParrotRetriever` class, a test utility that mimics a retriever by returning the input query as a single document. It's used for testing purposes where the exact content of the retrieved document needs to match the query.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/docstore/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `docstore` module from `langchain_classic` correctly exposes the intended public API elements. It ensures that only specified classes and functions are part of the module's public interface.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 54
          },
          {
            "name": "Christophe Bornet",
            "percent": 25
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 9
          }
        ]
      },
      "Advanced Retrieval & Query Transformation": {
        "files": [
          {
            "path": "libs/partners/perplexity/langchain_perplexity/retrievers.py",
            "description": "This file defines a LangChain retriever, `PerplexitySearchRetriever`, which integrates with the Perplexity Search API to fetch relevant documents based on a given query and configurable search parameters.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/unit_tests/test_retrievers.py",
            "description": "This file contains unit tests for the `PerplexitySearchRetriever` class, verifying its initialization and its ability to retrieve relevant documents by mocking the Perplexity API.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/langchain_exa/retrievers.py",
            "description": "This file implements a LangChain retriever that utilizes the Exa Search API to fetch search results and convert them into LangChain Document objects. It allows configuring various search parameters like domain filtering, date ranges, and content options.",
            "spof": false
          },
          {
            "path": "libs/partners/exa/tests/integration_tests/test_search_tool.py",
            "description": "This file contains integration tests for the Exa search tool within the LangChain framework, verifying its basic search functionality and advanced features like result limiting, summarization, and text content options.",
            "spof": false
          },
          {
            "path": "libs/partners/exa/tests/integration_tests/test_retriever.py",
            "description": "This file contains integration tests for the `ExaSearchRetriever` class, verifying its basic functionality, highlight extraction, and advanced configuration options like `k`, `text_contents_options`, `summary`, and `type`.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/example_selectors/test_similarity.py",
            "description": "This file contains unit tests for the `SemanticSimilarityExampleSelector` and `MaxMarginalRelevanceExampleSelector` classes. It uses a `DummyVectorStore` implementation to test various functionalities like adding examples, selecting examples, and initializing selectors from examples, including their asynchronous versions.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/history_aware_retriever.py",
            "description": "This file defines a function to create a history-aware retriever chain, which adapts its retrieval query based on whether chat history is provided, either directly using user input or rephrasing it with an LLM.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/elasticsearch_database/base.py",
            "description": "This file defines the `ElasticsearchDatabaseChain` class, which facilitates interaction with an Elasticsearch database. It uses language models to generate Elasticsearch queries and formulate answers based on the search results.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/cypher_utils.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `CypherQueryCorrector` and `Schema` from `langchain_community.chains.graph_qa.cypher_utils` for backward compatibility. It manages deprecated imports to ensure smooth transitions for users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/flare/__init__.py",
            "description": "This file initializes the FLARE chain implementation within the classic LangChain library. It is explicitly noted as being adapted from an external GitHub repository (jzbjyb/FLARE).",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/flare/base.py",
            "description": "This file implements the FlareChain, an active retrieval augmented generation (RAG) chain that iteratively generates responses by identifying low-confidence spans, generating questions, and retrieving relevant context. It aims to improve response quality by dynamically incorporating retrieved information during the generation process.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/hyde/base.py",
            "description": "This file implements the Hypothetical Document Embedder (HyDE) technique, which generates a hypothetical document for a given query using an LLM and then embeds that document to represent the query. It combines an LLM chain with a base embedding model to improve query embedding.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/hyde/__init__.py",
            "description": "Initializes the Hypothetical Document Embeddings (HyDE) module within LangChain, which is based on the research described in the linked arXiv paper.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/query_constructor/ir.py",
            "description": "This file serves as an internal re-export point for core structured query language components (e.g., Comparators, Operations, StructuredQuery) from `langchain_core` within the `langchain_classic` library. It makes these elements accessible under a unified module path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/query_constructor/schema.py",
            "description": "This file defines the `AttributeInfo` Pydantic model, which describes the name, description, and type of an attribute used within the LangChain query constructor chain. It serves as a schema for representing metadata about data source attributes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/query_constructor/parser.py",
            "description": "This file defines a grammar and a transformer using the Lark library to parse a query string into a structured query representation for LangChain. It converts the parsed query into `FilterDirective`, `Comparison`, or `Operation` objects, handling various data types and validating comparators and operators.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/openai_functions.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for deprecated `OpenAIMetadataTagger` and `create_metadata_tagger` functions from `langchain_community` when accessed from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/prompts/entity_extraction.py",
            "description": "This file defines a `PromptTemplate` used for extracting proper nouns and entities from the last line of a conversation. It provides a template instructing an AI to identify capitalized words, names, and places, returning them as a comma-separated list.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/prompts/knowledge_triplet_extraction.py",
            "description": "This file defines a `PromptTemplate` for extracting knowledge triples (subject, predicate, object) from text. It includes a detailed template with examples to guide the extraction process.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/embedchain.py",
            "description": "This file acts as a compatibility layer or proxy for `EmbedchainRetriever`, dynamically importing it from `langchain_community.retrievers` to manage its relocation and ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/chaindesk.py",
            "description": "This file acts as a compatibility layer or proxy for `ChaindeskRetriever`. It dynamically imports the retriever from `langchain_community.retrievers`, likely to handle deprecated imports or maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/pinecone_hybrid_search.py",
            "description": "This file handles the deprecated import of 'PineconeHybridSearchRetriever', dynamically re-exporting it from 'langchain_community.retrievers' for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/ensemble.py",
            "description": "This file defines an `EnsembleRetriever` class that combines results from multiple retrievers using a weighted Reciprocal Rank Fusion algorithm to produce a single, reranked list of documents.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/merger_retriever.py",
            "description": "This file defines a `MergerRetriever` class that combines the results from multiple `BaseRetriever` instances into a single list of documents, supporting both synchronous and asynchronous operations.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/re_phraser.py",
            "description": "This file defines a retriever that re-phrases user queries using a language model before passing them to an underlying retriever to fetch relevant documents. It aims to improve document retrieval by generating more optimal queries for vectorstores.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/bedrock.py",
            "description": "This file provides backward compatibility for Bedrock-related retriever classes and configurations by dynamically importing them from `langchain_community` after they were moved from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/tavily_search_api.py",
            "description": "This file manages the deprecated import of `TavilySearchAPIRetriever` and `SearchDepth` by dynamically redirecting their imports from `langchain_classic` to `langchain_community` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/arcee.py",
            "description": "This file acts as a deprecated entry point for `ArceeRetriever`, redirecting imports from `langchain_classic` to `langchain_community` for backward compatibility. It dynamically handles the import of `ArceeRetriever` from its new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/google_cloud_documentai_warehouse.py",
            "description": "This file acts as a compatibility layer or redirector, dynamically importing the `GoogleDocumentAIWarehouseRetriever` from `langchain_community.retrievers`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/time_weighted_retriever.py",
            "description": "This file defines the `TimeWeightedVectorStoreRetriever`, a LangChain retriever that combines vector embedding similarity with document recency (time-weighted decay) to prioritize relevant and recently accessed information.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/multi_vector.py",
            "description": "This file implements the `MultiVectorRetriever` which retrieves documents by first searching over smaller sub-documents in a vector store and then fetching the corresponding larger, original parent documents from a document store. It supports various search types like similarity, MMR, and similarity with score threshold.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/bm25.py",
            "description": "This file acts as a compatibility layer, re-exporting `BM25Retriever` and `default_preprocessing_func` from `langchain_community.retrievers.bm25` for backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/databerry.py",
            "description": "This file serves as a deprecation shim and re-exporter for `DataberryRetriever`, redirecting its import from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/parent_document_retriever.py",
            "description": "This file implements the ParentDocumentRetriever, a specialized retriever that indexes small document chunks for accurate embeddings but retrieves larger 'parent' documents to maintain context. It extends MultiVectorRetriever and manages the splitting, storage, and retrieval of documents based on this strategy.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/cohere_rag_retriever.py",
            "description": "This file acts as a compatibility layer, re-exporting the `CohereRagRetriever` class from `langchain_community.retrievers` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/multi_query.py",
            "description": "This file defines the `MultiQueryRetriever` class, which improves document retrieval by using a language model to generate multiple diverse queries from an initial user question, then retrieves and de-duplicates documents from an underlying retriever for all generated queries.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/tfidf.py",
            "description": "This file provides a dynamic import mechanism for `TFIDFRetriever`, allowing it to be accessed from `langchain_classic` while redirecting to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/web_research.py",
            "description": "This file acts as an import proxy, re-exporting classes like `WebResearchRetriever`, `QuestionListOutputParser`, and `SearchQueries` from `langchain_community.retrievers.web_research` to maintain backward compatibility or facilitate migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/metal.py",
            "description": "This file acts as a compatibility layer for `MetalRetriever`, dynamically importing it from `langchain_community.retrievers` to handle moved or deprecated imports within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/__init__.py",
            "description": "This file serves as the `__init__.py` for the retrievers module, consolidating and exporting various retriever implementations (both classic and community-based). It uses dynamic importing and a deprecation lookup to manage access to a wide range of retriever classes.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/knn.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `KNNRetriever` from `langchain_community.retrievers`. It manages the relocation of `KNNRetriever` while maintaining backward compatibility for older imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/llama_index.py",
            "description": "This file acts as a compatibility layer, dynamically importing `LlamaIndexRetriever` and `LlamaIndexGraphRetriever` from `langchain_community.retrievers`. It ensures that older references within `langchain_classic` are correctly resolved to their new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/you.py",
            "description": "This file provides a compatibility layer for the 'YouRetriever' class, dynamically re-exporting it from 'langchain_community.retrievers' while maintaining backward compatibility for older 'langchain_classic' imports. It uses a dynamic import mechanism to handle deprecation and module reorganization.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/chatgpt_plugin_retriever.py",
            "description": "This file re-exports the `ChatGPTPluginRetriever` from `langchain_community.retrievers`, likely serving as a backward compatibility or deprecation shim for module restructuring. It dynamically imports the retriever from its new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/weaviate_hybrid_search.py",
            "description": "This file facilitates the dynamic import and re-export of `WeaviateHybridSearchRetriever` from `langchain_community.retrievers` to maintain backward compatibility. It acts as an import shim, handling potential deprecations or moves of the retriever class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/kendra.py",
            "description": "This file acts as a compatibility layer or re-exporter for Amazon Kendra-related components. It dynamically imports these components from `langchain_community` to maintain backward compatibility or manage deprecations within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/svm.py",
            "description": "This file acts as a compatibility layer for `SVMRetriever`, redirecting imports from `langchain_classic` to its new location in `langchain_community.retrievers`. It ensures backward compatibility by dynamically handling attribute lookups.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/pupmed.py",
            "description": "This file acts as a compatibility layer, providing dynamic import forwarding for 'PubMedRetriever' from 'langchain_classic' to its new location in 'langchain_community.retrievers'. It handles deprecated imports by redirecting calls.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/kay.py",
            "description": "This file serves as a re-export or compatibility layer for the `KayAiRetriever`. It dynamically imports `KayAiRetriever` from `langchain_community.retrievers`, likely managing a migration or deprecation of its original location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/elastic_search_bm25.py",
            "description": "This file provides backward compatibility for the ElasticSearchBM25Retriever, dynamically importing it from 'langchain_community.retrievers' as it has been moved from 'langchain_classic'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/remote_retriever.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `RemoteLangChainRetriever` from `langchain_community.retrievers` to handle deprecation and ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/dingo.py",
            "description": "This file provides a dynamic import mechanism for `DingoDBTranslator`, facilitating backward compatibility and handling potential deprecation by importing it from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/mongodb_atlas.py",
            "description": "This file acts as a compatibility layer or proxy, dynamically importing the `MongoDBAtlasTranslator` class from `langchain_community.query_constructors.mongodb_atlas` to handle potential module relocations or deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/opensearch.py",
            "description": "This file provides backward compatibility for the `OpenSearchTranslator` by dynamically importing it from `langchain_community`, handling a deprecated import path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/milvus.py",
            "description": "This file dynamically re-exports `MilvusTranslator` and `process_value` from `langchain_community.query_constructors.milvus`. It serves as a compatibility layer for deprecated imports within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/weaviate.py",
            "description": "This file provides a compatibility layer for the `WeaviateTranslator` class, dynamically importing it from `langchain_community` into the `langchain_classic` package, likely for deprecation management.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/databricks_vector_search.py",
            "description": "This file re-exports the `DatabricksVectorSearchTranslator` from `langchain_community`, likely serving as a compatibility layer or a temporary redirect within the `langchain_classic` package during a refactoring process.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/astradb.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting the `AstraDBTranslator` class from `langchain_community` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/elasticsearch.py",
            "description": "This file dynamically imports and re-exports the `ElasticsearchTranslator` class from `langchain_community.query_constructors.elasticsearch`. It serves as a bridge or re-exporter for this class, handling dynamic lookups and potential deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/pgvector.py",
            "description": "This file serves as a compatibility layer or re-exporter for the `PGVectorTranslator` class, dynamically importing it from `langchain_community.query_constructors.pgvector`. It helps manage deprecated imports and optional dependencies.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/redis.py",
            "description": "This file manages the dynamic import and deprecation handling for `RedisTranslator`, re-exporting it from `langchain_community.query_constructors.redis`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/timescalevector.py",
            "description": "This file manages the deprecation and dynamic import of the `TimescaleVectorTranslator` class, redirecting it to its new location in `langchain_community.query_constructors.timescalevector`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/dashvector.py",
            "description": "This file provides a compatibility layer for `DashvectorTranslator`, dynamically importing it from `langchain_community.query_constructors.dashvector` to support older references within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/qdrant.py",
            "description": "This file provides a compatibility layer for the `QdrantTranslator` class, allowing it to be dynamically imported from `langchain_community.query_constructors.qdrant` for backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/base.py",
            "description": "This file defines the `SelfQueryRetriever`, which uses an LLM to generate structured queries from natural language. It also includes utility functions to automatically select the correct query translator for various vector store implementations, enabling the retriever to execute these structured queries against different vector store backends.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/self_query/chroma.py",
            "description": "This file provides a backward-compatible import mechanism for 'ChromaTranslator', dynamically redirecting its import from 'langchain_classic' to its new location in 'langchain_community' while handling potential deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/retriever.py",
            "description": "This file re-exports retriever-related tool creation and description rendering functions from `langchain_core.tools`. It serves to make these utilities accessible within the `langchain_classic` tools module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/vectorstores/llm_rails.py",
            "description": "This file acts as a compatibility layer, providing dynamic import and deprecation handling for the `LLMRails` and `LLMRailsRetriever` classes, which have been moved to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_hyde.py",
            "description": "This file contains unit tests for the HypotheticalDocumentEmbedder (HyDE) chain. It uses mock implementations for LLM and Embeddings to test the `from_llm` method with different prompt configurations.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_retrieval.py",
            "description": "This file contains unit tests for the `create_retrieval_chain` function. It verifies the chain's ability to integrate with a language model and a retriever, process inputs, and produce expected outputs.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_conversation_retrieval.py",
            "description": "This file contains unit tests for the `ConversationalRetrievalChain` in LangChain. It tests the chain's behavior with and without retrieved documents, and verifies the handling of responses when no documents are found, both asynchronously and synchronously.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/query_constructor/test_parser.py",
            "description": "This file contains unit tests for the structured query parser used in LangChain's query constructor. It verifies the parser's ability to handle various query structures, data types, and error conditions.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/test_multi_vector.py",
            "description": "This file contains unit tests for the MultiVectorRetriever class, including tests for its initialization, synchronous and asynchronous retrieval, and similarity search with score thresholds. It uses a mock in-memory vector store for testing purposes.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/test_parent_document.py",
            "description": "This file contains unit tests for the `ParentDocumentRetriever` from `langchain_classic`. It includes a mock in-memory vector store to test its initialization and basic document retrieval functionality.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/sequential_retriever.py",
            "description": "This file defines a `SequentialRetriever` class for unit testing purposes. It's a mock retriever designed to return a predefined sequence of documents in a sequential manner upon each retrieval call.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/test_time_weighted_retriever.py",
            "description": "This file contains unit tests for the `TimeWeightedVectorStoreRetriever` class, including its synchronous and asynchronous methods. It uses a mocked vector store to verify the retriever's functionality.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/test_ensemble.py",
            "description": "This file contains unit tests for the `EnsembleRetriever` class, verifying its document merging and ranking behavior in different scenarios, including when an `id_key` is specified.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/test_multi_query.py",
            "description": "This file contains unit tests for components of the `multi_query` retriever in `langchain_classic`. It specifically tests the `_unique_documents` utility function for deduplicating Document objects and the `LineListOutputParser` for parsing multiline strings.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/retrievers/self_query/test_base.py",
            "description": "This file contains unit tests for the `SelfQueryRetriever` component in LangChain. It uses mock LLM and vector store implementations, along with a custom query translator, to verify the retriever's ability to process and apply structured queries both synchronously and asynchronously.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 46
          },
          {
            "name": "Christophe Bornet",
            "percent": 18
          },
          {
            "name": "Kesku",
            "percent": 14
          }
        ]
      },
      "Indexing Orchestration & Record Management": {
        "files": [
          {
            "path": "libs/core/langchain_core/indexing/in_memory.py",
            "description": "This file implements an in-memory document index (`InMemoryDocumentIndex`) for the `langchain_core` library. It provides functionalities to store, retrieve, update, and delete documents, along with a basic search mechanism.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/indexing/api.py",
            "description": "This module provides core logic and utilities for indexing documents into vector stores. It handles document hashing, batching, and managing document additions, updates, and deletions within an indexing system.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/indexing/__init__.py",
            "description": "This file provides core utilities and helper logic for efficiently indexing data into vector stores, preventing duplication and unnecessary overwrites. It exposes key indexing components and functions from submodules.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/indexing/base.py",
            "description": "This file defines the abstract base classes for managing document records within LangChain's indexing API. It includes the `RecordManager` interface, which tracks indexed documents and their timestamps to optimize indexing operations, along with an in-memory implementation for testing purposes.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/indexing/test_in_memory_indexer.py",
            "description": "This file contains unit and integration tests for the `InMemoryDocumentIndex` class, covering both synchronous and asynchronous operations like upserting documents and invoking the index for retrieval.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/indexing/test_in_memory_record_manager.py",
            "description": "This file contains unit tests for the `InMemoryRecordManager` class, including synchronous and asynchronous methods for updating, listing, checking existence, and deleting records. It verifies the functionality of the in-memory record management system, including timestamp and group-based filtering.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/indexing/test_public_api.py",
            "description": "This file contains unit tests for the public API of the `langchain_core.indexing` module. It verifies that the `__all__` variable is correctly defined and lists the expected public members, helping to catch breaking changes.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/indexing/test_hashed_document.py",
            "description": "This file contains unit tests for the `_get_document_with_hash` function, ensuring that document hashing is deterministic, correctly applies different algorithms, and supports custom key encoders.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/indexing/test_indexing.py",
            "description": "This file contains unit tests for the indexing functionality of LangChain Core. It verifies the behavior of synchronous and asynchronous indexing operations, including adding, updating, skipping, and deleting documents from a vector store and record manager.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/indexer.py",
            "description": "This file contains a test suite for checking implementations of the `DocumentIndex` abstraction. It defines standard tests to ensure correct read-write behavior for document indexing.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/graph.py",
            "description": "This file facilitates dynamic imports for graph-related classes, specifically `GraphIndexCreator` and `NetworkxEntityGraph`, redirecting them from `langchain_classic` to `langchain_community` while managing potential deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/_api.py",
            "description": "This file re-exports private indexing utility functions (`_abatch`, `_batch`, `_HashedDocument`) from `langchain_core` for internal use, primarily to maintain compatibility during a migration without altering existing unit tests.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/__init__.py",
            "description": "This file serves as the __init__.py for the indexes module, exposing core indexing functionalities, record management, and vectorstore/graph index creation. Its purpose is to manage content indexing, prevent duplication, and support various data transformation and storage strategies.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/_sql_record_manager.py",
            "description": "This file implements a record management layer using SQLAlchemy, designed to track upserted records and their update times in a database. It supports both synchronous and asynchronous operations with SQL engines like SQLite and PostgreSQL.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/indexes/prompts/__init__.py",
            "description": "This file provides prompts relevant for constructing indexes, though it is marked for deprecation and will be removed in a future version.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/indexes/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_classic.indexes` module correctly lists all its public members.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/indexes/test_api.py",
            "description": "This file contains a unit test to verify the public API surface of the `langchain_classic.indexes` module, ensuring that its `__all__` variable lists the expected components to catch obvious breaking changes.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/indexes/test_indexing.py",
            "description": "This file contains unit tests for LangChain's document indexing functionality, covering both synchronous and asynchronous indexing. It uses mock components like `ToyLoader` and `InMemoryVectorStore` to test scenarios such as adding, skipping, and deleting documents during indexing.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 33
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 22
          },
          {
            "name": "Christophe Bornet",
            "percent": 19
          }
        ]
      },
      "Text Splitting": {
        "files": [
          {
            "path": "libs/text-splitters/langchain_text_splitters/konlpy.py",
            "description": "This file defines the `KonlpyTextSplitter` class, which is a text splitter designed for Korean language processing using the Konlpy library. It splits text into sentences using Konlpy's Kkma tagger.",
            "spof": true
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/sentence_transformers.py",
            "description": "This file implements a text splitter using a Sentence Transformer model's tokenizer to divide text into token-based chunks. It manages token limits, overlaps, and counts for efficient text processing.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/nltk.py",
            "description": "This file defines a text splitter class, `NLTKTextSplitter`, that utilizes the NLTK library for splitting text into sentences or other segments based on NLTK's tokenization capabilities.",
            "spof": true
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/jsx.py",
            "description": "This file defines a text splitter tailored for JavaScript framework code (like React JSX, Vue, and Svelte), which intelligently splits code into chunks by identifying and using custom component tags and JavaScript syntax elements as separators.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/__init__.py",
            "description": "This is the package's initialization file, exposing various text splitter classes and related utilities from its submodules for easy access at the package level.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/spacy.py",
            "description": "This file implements a text splitter using the SpaCy library, specifically designed to segment text into sentences or other linguistic units. It provides a `SpacyTextSplitter` class that leverages SpaCy's pipeline capabilities for text division.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/python.py",
            "description": "This file defines a text splitter, `PythonCodeTextSplitter`, specifically designed to split Python code files based on Python syntax for more effective text processing.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/latex.py",
            "description": "This file defines the `LatexTextSplitter` class, which extends `RecursiveCharacterTextSplitter` to specifically split text content formatted in LaTeX.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/markdown.py",
            "description": "This file provides classes for splitting Markdown text. It includes `MarkdownTextSplitter` for general Markdown-aware splitting and `MarkdownHeaderTextSplitter` for splitting based on specific, user-defined Markdown headers, supporting custom patterns and metadata extraction.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/json.py",
            "description": "This file defines a `RecursiveJsonSplitter` class responsible for splitting JSON data into smaller, structured chunks while preserving its hierarchical integrity. It supports configurable chunk sizes and can output chunks as dictionaries, JSON strings, or `Document` objects.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/html.py",
            "description": "This file implements an HTML text splitter that extracts content from HTML documents and organizes it into structured `Document` objects based on specified header tags. It can process HTML from strings, URLs, or files, enriching the output documents with hierarchical metadata.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/character.py",
            "description": "This file provides text splitting utilities, including `CharacterTextSplitter` for basic splitting and `RecursiveCharacterTextSplitter` for more intelligent, hierarchical splitting with support for language-specific separators.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/langchain_text_splitters/xsl",
            "description": "This empty directory is located within the `langchain_text_splitters` library. Its name suggests it might have been intended to contain XSLT-related files or logic for processing XML-based text, although no such components are currently present.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/README.md",
            "description": "This README.md file introduces the LangChain Text Splitters library, which provides utilities for splitting various text documents into chunks. It includes installation instructions, documentation links, and contribution guidelines.",
            "spof": true
          },
          {
            "path": "libs/text-splitters/tests/unit_tests/test_text_splitters.py",
            "description": "This file contains unit tests for various text splitting functionalities within the LangChain library, primarily focusing on `CharacterTextSplitter` and `RecursiveCharacterTextSplitter`.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/tests/unit_tests/test_html_security.py",
            "description": "This file contains unit tests to ensure the security of the `HTMLSectionSplitter` against various XML External Entity (XXE) attacks. It verifies that the HTML splitter safely processes input by blocking external entities, network access, and DTD processing.",
            "spof": true
          },
          {
            "path": "libs/text-splitters/tests/integration_tests/test_nlp_text_splitters.py",
            "description": "This file contains integration tests for text splitting functionalities using NLTK and SpaCy sentence splitters, covering various configurations, argument validation, and features like start index addition.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/tests/integration_tests/test_text_splitter.py",
            "description": "This file contains integration tests for various text splitter implementations, including those using HuggingFace tokenizers, LangChain's TokenTextSplitter, and Sentence Transformers. It verifies their functionality, such as token counting and text splitting with and without overlap.",
            "spof": true
          },
          {
            "path": "libs/text-splitters/tests/test_data",
            "description": "This directory is intended to store test data for the `text-splitters` library tests. Although currently empty, its purpose is to provide specific input files or content for testing various text splitting functionalities.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/text_splitter.py",
            "description": "This file serves as a compatibility layer, re-exporting various text splitter classes and related utilities from the `langchain_text_splitters` library. It is kept for backwards compatibility with older import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/language/javascript.py",
            "description": "This file acts as a deprecation shim for `JavaScriptSegmenter`, redirecting imports from `langchain_classic` to its new location in `langchain_community`. It facilitates backward compatibility while guiding users to the updated import path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/language/python.py",
            "description": "This file provides backward-compatible access to the `PythonSegmenter` class. It dynamically imports `PythonSegmenter` from `langchain_community` to handle a deprecated module relocation.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Christophe Bornet",
            "percent": 30
          },
          {
            "name": "Mason Daugherty",
            "percent": 21
          },
          {
            "name": "Ahmed Tammaa",
            "percent": 9
          }
        ]
      },
      "Document Loading & Parsing": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/docstore/wikipedia.py",
            "description": "This file provides backward compatibility for the 'Wikipedia' class, redirecting imports from 'langchain_classic' to 'langchain_community'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/doctran_text_translate.py",
            "description": "This file provides backward compatibility for `DoctranTextTranslator`, dynamically redirecting imports from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/beautiful_soup_transformer.py",
            "description": "This file acts as a compatibility layer, providing dynamic import for the `BeautifulSoupTransformer` class which has been moved to `langchain_community.document_transformers`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/doctran_text_extract.py",
            "description": "This file provides backward compatibility for the `DoctranPropertyExtractor` class, redirecting its import from `langchain_classic` to its new location in `langchain_community.document_transformers`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/nuclia_text_transform.py",
            "description": "This file provides a compatibility layer within `langchain_classic` to dynamically import the `NucliaTextTransformer` class. It redirects imports of `NucliaTextTransformer` to its new location in `langchain_community.document_transformers`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/html2text.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for `Html2TextTransformer` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/xsl",
            "description": "This directory was likely intended to house document transformers leveraging XSL (eXtensible Stylesheet Language). Its role would involve applying XSL transformations to documents within the `langchain_classic` framework. The directory's emptiness suggests this specific functionality may be unimplemented or deprecated.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/__init__.py",
            "description": "This file serves as the main entry point for LangChain's document loaders, consolidating imports for a wide variety of loader classes from 'langchain_community' and handling deprecation for backwards compatibility.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/baiducloud_bos_directory.py",
            "description": "This file acts as an import shim, redirecting the deprecated `BaiduBOSDirectoryLoader` from `langchain_classic` to its new location in `langchain_community` to maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/apify_dataset.py",
            "description": "This file acts as a compatibility layer for `ApifyDatasetLoader`, dynamically importing it from `langchain_community.document_loaders` while potentially handling deprecation for its previous location in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/base_o365.py",
            "description": "This file serves as a compatibility layer, dynamically re-exporting the `O365BaseLoader` class which has been relocated to `langchain_community`, to ensure backward compatibility and manage deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/baiducloud_bos_file.py",
            "description": "This file manages the dynamic import and deprecation of `BaiduBOSFileLoader`, redirecting it to its new location within the `langchain_community` package. It ensures backward compatibility while migrating modules.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/airbyte_json.py",
            "description": "This file acts as a compatibility layer or stub for `AirbyteJSONLoader`, dynamically importing it from `langchain_community.document_loaders` to manage deprecation or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/bilibili.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting the `BiliBiliLoader` from `langchain_community.document_loaders` to maintain backward compatibility or manage deprecation within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/bigquery.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `BigQueryLoader` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/blockchain.py",
            "description": "This file acts as a compatibility layer for deprecated blockchain document loader components. It dynamically redirects imports of `BlockchainType` and `BlockchainDocumentLoader` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/college_confidential.py",
            "description": "This file serves as an import proxy for `CollegeConfidentialLoader`, dynamically redirecting its import from `langchain_community.document_loaders` to maintain backward compatibility or manage module transitions. It handles potential deprecations by centralizing import logic.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/assemblyai.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for deprecated AssemblyAI-related document loaders and types from `langchain_classic` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/acreom.py",
            "description": "This file acts as a compatibility shim, dynamically importing the `AcreomLoader` from `langchain_community.document_loaders` when requested from `langchain_classic`. It facilitates a smooth transition for moved components, managing deprecation through dynamic lookup.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/bibtex.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `BibtexLoader` from `langchain_community.document_loaders`. It manages deprecation of the old import path for `BibtexLoader`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/async_html.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting the `AsyncHtmlLoader` from `langchain_community.document_loaders` for backward compatibility within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/azure_blob_storage_file.py",
            "description": "This file acts as a compatibility layer, re-exporting `AzureBlobStorageFileLoader` from `langchain_community.document_loaders` to maintain a consistent import path or manage deprecation for the classic LangChain package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/cube_semantic.py",
            "description": "This file serves as a compatibility layer for the `CubeSemanticLoader` class, dynamically importing it from `langchain_community.document_loaders` to handle deprecation and module relocation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/blackboard.py",
            "description": "This file acts as a compatibility shim, dynamically importing and re-exporting the `BlackboardLoader` from the `langchain_community.document_loaders` package. It helps manage deprecation warnings for the moved class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/arcgis_loader.py",
            "description": "This file facilitates the dynamic and deprecated import of 'ArcGISLoader', redirecting it from 'langchain_classic' to its current location in 'langchain_community.document_loaders'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/azlyrics.py",
            "description": "This file acts as a deprecation shim, redirecting imports of `AZLyricsLoader` from `langchain_classic` to its new location in `langchain_community.document_loaders`. It ensures backward compatibility for older codebases.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/arxiv.py",
            "description": "This file acts as a compatibility layer for `ArxivLoader`, dynamically redirecting its import from `langchain_classic` to `langchain_community.document_loaders`. It ensures backward compatibility while managing the migration of the loader's location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/airtable.py",
            "description": "This file provides a compatibility layer for the `AirtableLoader` class, dynamically redirecting imports from `langchain_classic` to its new location within `langchain_community.document_loaders` to handle deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/brave_search.py",
            "description": "This file acts as a backward compatibility shim, dynamically importing the `BraveSearchLoader` from `langchain_community` to maintain old import paths. It facilitates deprecation and migration of the loader to a new package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/azure_ai_data.py",
            "description": "This file acts as a compatibility layer for `AzureAIDataLoader`, redirecting imports from `langchain_classic` to its new location in `langchain_community` while managing deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/facebook_chat.py",
            "description": "This file provides backward compatibility for `FacebookChatLoader` and `concatenate_rows` by dynamically redirecting their imports from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/git.py",
            "description": "This file dynamically re-exports the `GitLoader` class from `langchain_community.document_loaders`, likely serving as a compatibility layer or for internal package restructuring within LangChain Classic.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/chatgpt.py",
            "description": "This file provides a compatibility layer for `langchain_classic`, dynamically handling imports for `ChatGPTLoader` and `concatenate_rows` which have been moved to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/gcs_directory.py",
            "description": "This file provides dynamic import functionality for `GCSDirectoryLoader`, likely serving as a compatibility layer or deprecation handler for its relocation to `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/epub.py",
            "description": "This file provides a compatibility layer for `UnstructuredEPubLoader`, dynamically importing it from `langchain_community.document_loaders`. It facilitates a consistent import path within `langchain_classic` by re-exporting the loader.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/excel.py",
            "description": "This file acts as a compatibility layer or proxy, dynamically re-exporting `UnstructuredExcelLoader` from `langchain_community.document_loaders` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/dropbox.py",
            "description": "This file provides a backward-compatible import mechanism for `DropboxLoader`, dynamically redirecting its import from `langchain_classic` to `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/dataframe.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `BaseDataFrameLoader` and `DataFrameLoader` from `langchain_classic` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/geodataframe.py",
            "description": "This file manages the deprecated import of `GeoDataFrameLoader` by redirecting it from `langchain_classic` to its new location in `langchain_community`. It acts as a shim for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/google_speech_to_text.py",
            "description": "This file acts as a re-exporter for `GoogleSpeechToTextLoader`, dynamically loading it from `langchain_community.document_loaders` to maintain backward compatibility or manage module transitions within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/fauna.py",
            "description": "This file manages the import of `FaunaLoader`, handling its deprecation by dynamically redirecting its import from `langchain_classic` to `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/etherscan.py",
            "description": "This file acts as a deprecation shim, redirecting the import of `EtherscanLoader` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/figma.py",
            "description": "This file serves as a compatibility layer for `FigmaFileLoader`, dynamically redirecting imports from `langchain_classic` to `langchain_community` to handle deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/email.py",
            "description": "This file acts as a compatibility layer, providing dynamic import access to document loaders (OutlookMessageLoader, UnstructuredEmailLoader) that have been moved to the `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/html_bs.py",
            "description": "This file dynamically imports `BSHTMLLoader` from `langchain_community.document_loaders`, likely for compatibility or deprecation handling within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/azure_blob_storage_container.py",
            "description": "This file serves as a deprecation shim for `AzureBlobStorageContainerLoader`. It dynamically imports the loader from its new location in `langchain_community` while maintaining compatibility for existing imports from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/modern_treasury.py",
            "description": "This file acts as a re-exporter for `ModernTreasuryLoader`, dynamically importing it from `langchain_community.document_loaders` and handling potential deprecation through a centralized importer mechanism.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/diffbot.py",
            "description": "This file acts as a compatibility layer, providing dynamic import of `DiffbotLoader` from `langchain_community.document_loaders` for modules still referencing it from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/couchbase.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting the `CouchbaseLoader` from `langchain_community` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/browserless.py",
            "description": "This file acts as a compatibility layer for `BrowserlessLoader`, dynamically importing it from `langchain_community.document_loaders` to handle deprecated or refactored module paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/image.py",
            "description": "This file acts as a compatibility layer, redirecting imports of 'UnstructuredImageLoader' from 'langchain_classic' to 'langchain_community' to manage deprecated modules gracefully.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/image_captions.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `ImageCaptionLoader` from `langchain_community.document_loaders`. It manages imports and handles potential deprecation warnings for this specific class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/evernote.py",
            "description": "This file acts as a compatibility layer, allowing `EverNoteLoader` to be imported from `langchain_classic` while redirecting the actual import to `langchain_community.document_loaders`. It facilitates a smooth transition for deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/discord.py",
            "description": "This file acts as a compatibility layer to dynamically import the `DiscordChatLoader` class, likely redirecting it from an older `langchain_classic` location to `langchain_community.document_loaders`. It helps manage deprecated imports and provides a seamless transition for users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/gutenberg.py",
            "description": "This file acts as a deprecation shim, redirecting imports of `GutenbergLoader` from `langchain_classic` to its new location in `langchain_community.document_loaders`. It ensures backward compatibility while signaling the module's migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/notion.py",
            "description": "This file provides a compatibility layer for the `NotionDirectoryLoader`, dynamically importing it from `langchain_community.document_loaders` to handle potential deprecated lookups. It ensures backward compatibility for users still referencing the loader through `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/csv_loader.py",
            "description": "This file acts as a compatibility layer for `CSVLoader` and `UnstructuredCSVLoader`, dynamically importing them from `langchain_community.document_loaders`. It ensures backward compatibility for older code referencing these classes within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/html.py",
            "description": "This file serves as a compatibility layer, dynamically redirecting the import of `UnstructuredHTMLLoader` from `langchain_classic` to its new location in `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/googledrive.py",
            "description": "This file acts as a compatibility layer, providing access to the `GoogleDriveLoader` from `langchain_community.document_loaders` for modules within `langchain_classic`. It handles dynamic import resolution, likely for deprecation or refactoring purposes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/helpers.py",
            "description": "This file serves as a redirection layer for deprecated imports, specifically for `FileEncoding` and `detect_file_encodings`. It dynamically forwards calls to these utilities from the `langchain_classic` package to their new location in `langchain_community.document_loaders.helpers`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/mongodb.py",
            "description": "This file acts as a compatibility layer to dynamically import and re-export the `MongodbLoader` from `langchain_community.document_loaders` for backward compatibility or package restructuring purposes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/gcs_file.py",
            "description": "This file re-exports the `GCSFileLoader` class from `langchain_community.document_loaders`, providing a compatibility layer and managing potential deprecation for its import.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/merge.py",
            "description": "This file acts as a compatibility layer, providing dynamic import functionality for `MergedDataLoader` by redirecting its import from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/lakefs.py",
            "description": "This file acts as a compatibility layer for LakeFS document loaders and client classes, redirecting imports from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/open_city_data.py",
            "description": "This file manages the deprecated import of `OpenCityDataLoader`, redirecting it to its new location in `langchain_community.document_loaders` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/mastodon.py",
            "description": "This file acts as an import shim for `MastodonTootsLoader`, dynamically redirecting imports from `langchain_classic` to `langchain_community.document_loaders` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/imsdb.py",
            "description": "This file provides backward compatibility for `IMSDbLoader` by re-exporting it from `langchain_community.document_loaders`, handling deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/gitbook.py",
            "description": "This file provides a backward-compatible import mechanism for `GitbookLoader`, dynamically loading it from the `langchain_community` package. It helps manage the migration of `GitbookLoader` to a new location while maintaining existing imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/github.py",
            "description": "This file manages deprecated imports for GitHub-related document loaders, redirecting references from `langchain_classic` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/concurrent.py",
            "description": "This file dynamically re-exports the `ConcurrentLoader` class from `langchain_community.document_loaders`. It handles deprecation warnings and ensures backward compatibility for older imports of this class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/chromium.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `AsyncChromiumLoader` from `langchain_community.document_loaders` for backward compatibility or module restructuring. It uses a `__getattr__` hook to import the class on demand.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/duckdb_loader.py",
            "description": "This file acts as a re-exporter or shim for the `DuckDBLoader` class, allowing it to be imported from `langchain_classic` while its actual implementation is in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/max_compute.py",
            "description": "This file acts as a compatibility layer or proxy for the `MaxComputeLoader`, redirecting its import from `langchain_classic` to its new location in `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/quip.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `QuipLoader` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/conllu.py",
            "description": "This file acts as a compatibility layer for the `CoNLLULoader`, dynamically redirecting imports from `langchain_classic` to its current location in `langchain_community.document_loaders`. It ensures backward compatibility by handling deprecated module lookups.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/pubmed.py",
            "description": "This file acts as a re-exporter for `PubMedLoader`, redirecting its import from `langchain_classic` to `langchain_community` using a dynamic attribute lookup mechanism. It manages deprecated imports to ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/readthedocs.py",
            "description": "This file provides backward compatibility for `ReadTheDocsLoader` by dynamically importing it from `langchain_community.document_loaders`. It acts as a transitional shim for components moved from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/hn.py",
            "description": "This file provides backward compatibility for the `HNLoader` by dynamically importing it from `langchain_community.document_loaders`. It acts as a redirect for users still referencing `HNLoader` from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/psychic.py",
            "description": "This file provides a compatibility layer for the `PsychicLoader`, dynamically importing it from `langchain_community.document_loaders` for backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/hugging_face_dataset.py",
            "description": "This file serves as a shim for `HuggingFaceDatasetLoader`, dynamically importing it from `langchain_community.document_loaders`. It manages the deprecation and re-export of this specific document loader from the classic `langchain` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/recursive_url_loader.py",
            "description": "This file provides backward compatibility for `RecursiveUrlLoader`, dynamically importing it from its new location in `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/roam.py",
            "description": "This file manages the import of `RoamLoader`, re-exporting it from `langchain_community.document_loaders` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/python.py",
            "description": "This file acts as a deprecation layer and re-exporter for `PythonLoader`, redirecting imports from the classic `langchain` package to `langchain_community.document_loaders.python`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/confluence.py",
            "description": "This file acts as a compatibility layer, re-exporting `ConfluenceLoader` and `ContentFormat` from `langchain_community` while also handling their deprecation from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/rtf.py",
            "description": "This file provides a compatibility layer for `UnstructuredRTFLoader`, dynamically importing it from `langchain_community.document_loaders` to manage deprecated imports within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/ifixit.py",
            "description": "This file provides a compatibility layer for the `IFixitLoader` class, dynamically importing it from `langchain_community.document_loaders` for backward compatibility. It acts as a redirector for deprecated module paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/mhtml.py",
            "description": "This file acts as a deprecation shim, dynamically importing the `MHTMLLoader` class from `langchain_community.document_loaders` to provide backward compatibility for its moved location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/nuclia.py",
            "description": "This file provides a deprecation layer for `NucliaLoader`, dynamically importing it from `langchain_community` for backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/json_loader.py",
            "description": "This file acts as a compatibility layer or proxy, dynamically importing `JSONLoader` from `langchain_community.document_loaders`. It ensures backward compatibility and manages the deprecation of `JSONLoader` in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/mediawikidump.py",
            "description": "This file acts as a compatibility layer for the `MWDumpLoader` class. It dynamically imports `MWDumpLoader` from `langchain_community.document_loaders` to support deprecated imports within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/web_base.py",
            "description": "This file acts as a compatibility layer, dynamically importing `WebBaseLoader` from `langchain_community.document_loaders` to handle deprecated import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/notiondb.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for the `NotionDBLoader` class from `langchain_classic` to `langchain_community` while issuing deprecation warnings. It facilitates a smooth transition for users while consolidating import logic.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/notebook.py",
            "description": "This file serves as a compatibility layer for notebook-related document loaders and utilities. It dynamically imports these components from `langchain_community` to support deprecated `langchain_classic` import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/obsidian.py",
            "description": "This file serves as a compatibility layer for `ObsidianLoader`, dynamically importing it from `langchain_community.document_loaders` when accessed through `langchain_classic`. It handles potential deprecation or relocation of the `ObsidianLoader`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/directory.py",
            "description": "This file serves as a compatibility layer, dynamically re-exporting the `DirectoryLoader` class from `langchain_community.document_loaders` to maintain backward compatibility for `langchain_classic` users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/joplin.py",
            "description": "This file acts as a deprecation shim, allowing `JoplinLoader` to be imported from `langchain_classic` while dynamically loading it from its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/srt.py",
            "description": "This file dynamically imports the `SRTLoader` class from `langchain_community.document_loaders`, serving as a redirector or compatibility layer within the `langchain_classic` package. It manages the import of a component that has likely been moved or deprecated, ensuring older references still function by pointing to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/org_mode.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `UnstructuredOrgModeLoader` from `langchain_community.document_loaders` to handle module reorganization or deprecation warnings. It provides a mechanism for dynamic attribute lookup for this loader.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/obs_file.py",
            "description": "This file provides backward compatibility for `OBSFileLoader` by dynamically importing it from `langchain_community.document_loaders`, its new location. It acts as a proxy to handle deprecated imports and ensure smooth transitions for users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/slack_directory.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting the `SlackDirectoryLoader` from `langchain_community.document_loaders` to ensure consistent access during module refactoring or deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/onenote.py",
            "description": "This file acts as a compatibility shim, dynamically re-exporting the `OneNoteLoader` class from `langchain_community` while managing deprecation for its former location in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/obs_directory.py",
            "description": "This file serves as a shim for the deprecated `OBSDirectoryLoader`, re-exporting it from `langchain_community.document_loaders`. It uses a dynamic import mechanism to provide backward compatibility while guiding users to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/tomarkdown.py",
            "description": "This file acts as a compatibility layer or deprecation shim for `ToMarkdownLoader`. It dynamically imports `ToMarkdownLoader` from `langchain_community.document_loaders`, redirecting older references to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/markdown.py",
            "description": "This file acts as a compatibility layer for `UnstructuredMarkdownLoader`. It dynamically imports the loader from `langchain_community.document_loaders`, primarily to manage a deprecated import path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/docusaurus.py",
            "description": "This file acts as a compatibility layer, re-exporting the `DocusaurusLoader` from `langchain_community.document_loaders`. It dynamically handles imports, likely managing a deprecated or moved location for this loader within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/rocksetdb.py",
            "description": "This file acts as a compatibility layer or proxy for `RocksetLoader`, dynamically importing it from `langchain_community.document_loaders` to manage module re-organization or provide backward compatibility within LangChain Classic.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/powerpoint.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `UnstructuredPowerPointLoader` from `langchain_community.document_loaders` to maintain backward compatibility for users of `langchain_classic`. It handles the relocation of the loader by providing a deprecated lookup mechanism.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/onedrive_file.py",
            "description": "This file acts as a transitional module for `OneDriveFileLoader`, dynamically re-exporting it from `langchain_community.document_loaders` while handling potential deprecation warnings. It helps manage module reorganization and optional dependencies.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/onedrive.py",
            "description": "This file acts as a compatibility layer or re-exporter for the `OneDriveLoader` class, dynamically importing it from `langchain_community.document_loaders`. It manages the deprecation and relocation of `OneDriveLoader` from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/telegram.py",
            "description": "This file serves as a compatibility layer, dynamically re-exporting Telegram document loaders and related utilities that have been moved to the `langchain_community` package. It handles dynamic imports and potentially deprecation for these components.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/snowflake_loader.py",
            "description": "This file acts as a compatibility layer, dynamically importing and redirecting the `SnowflakeLoader` class from its deprecated location within `langchain_classic` to `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/odt.py",
            "description": "This file serves as a redirection and compatibility layer for the `UnstructuredODTLoader` class. It re-exports `UnstructuredODTLoader` from `langchain_classic` while internally sourcing it from `langchain_community.document_loaders`, likely to manage module deprecation or migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/pdf.py",
            "description": "This file serves as a compatibility layer for PDF document loaders in `langchain_classic`, dynamically importing them from `langchain_community` where they have been moved. It provides a mechanism for handling deprecated imports and ensuring backward compatibility for users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/rss.py",
            "description": "This file acts as a compatibility layer for `RSSFeedLoader`, dynamically importing it from `langchain_community.document_loaders` to handle deprecated or moved imports within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/s3_file.py",
            "description": "This file acts as a re-exporter for `S3FileLoader`, dynamically loading it from `langchain_community.document_loaders` to maintain backward compatibility within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/url_playwright.py",
            "description": "This file acts as a compatibility layer for deprecated Playwright-related document loader classes, redirecting imports from `langchain_classic` to their new locations in `langchain_community`. It ensures backward compatibility by dynamically looking up attributes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/toml.py",
            "description": "This file provides a compatibility layer for the `TomlLoader` by dynamically importing it from `langchain_community.document_loaders`, managing deprecated references.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/spreedly.py",
            "description": "This file facilitates the dynamic lookup and re-exporting of `SpreedlyLoader`, which has been moved to `langchain_community.document_loaders`. It acts as a compatibility layer for deprecated imports within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/news.py",
            "description": "This file serves as a compatibility layer, dynamically importing and exposing `NewsURLLoader` from `langchain_community.document_loaders`. It manages deprecation and ensures backward compatibility for the `NewsURLLoader` module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/weather.py",
            "description": "This file acts as a re-exporter and compatibility layer for `WeatherDataLoader`, dynamically importing it from `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/tsv.py",
            "description": "This file acts as a compatibility layer or redirector for the 'UnstructuredTSVLoader' class, dynamically importing it from 'langchain_community.document_loaders'. It ensures that older references to this class within 'langchain_classic' are correctly resolved to its new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/tencent_cos_file.py",
            "description": "This file acts as a re-exporter for `TencentCOSFileLoader`, dynamically redirecting imports from `langchain_classic` to `langchain_community` while handling deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/docugami.py",
            "description": "This file acts as a compatibility layer, dynamically importing the `DocugamiLoader` from `langchain_community.document_loaders`. It ensures backward compatibility by redirecting imports of `DocugamiLoader` to its new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/s3_directory.py",
            "description": "This file serves as a compatibility layer for the `S3DirectoryLoader` class, dynamically redirecting imports from `langchain_classic` to its new location in `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/pyspark_dataframe.py",
            "description": "This file re-exports the `PySparkDataFrameLoader` class, acting as a compatibility layer or deprecation handler. It redirects imports from `langchain_classic` to the `langchain_community` package where the class is now located.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/sharepoint.py",
            "description": "This file serves as a compatibility layer, re-exporting the `SharePointLoader` from `langchain_community.document_loaders` to maintain backward compatibility within the `langchain_classic` package. It uses dynamic import mechanisms to manage deprecated references.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/rst.py",
            "description": "This file dynamically re-exports the `UnstructuredRSTLoader` from `langchain_community.document_loaders`, likely for backward compatibility or to manage deprecation of its original location within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/twitter.py",
            "description": "This file acts as a deprecation shim, redirecting imports of 'TwitterTweetLoader' from 'langchain_classic' to 'langchain_community.document_loaders'. It ensures backward compatibility while signaling the move of the loader to a new package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/stripe.py",
            "description": "This file provides a compatibility layer within `langchain_classic`, dynamically re-exporting `StripeLoader` from `langchain_community.document_loaders`. It facilitates a smooth transition for imports by handling the relocation of the `StripeLoader` class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/tensorflow_datasets.py",
            "description": "This file provides a compatibility layer for the `TensorflowDatasetLoader`, dynamically redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/text.py",
            "description": "This file provides backward compatibility for the 'TextLoader' class, which has been moved to 'langchain_community.document_loaders'. It dynamically imports 'TextLoader' from its new location, likely with deprecation handling.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/reddit.py",
            "description": "This file serves as a compatibility layer or redirect for the `RedditPostsLoader`. It dynamically imports `RedditPostsLoader` from `langchain_community.document_loaders`, likely to manage deprecated imports and guide users to the updated location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/xml.py",
            "description": "This file acts as a compatibility layer for `UnstructuredXMLLoader`, dynamically importing it from `langchain_community.document_loaders` to manage deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/larksuite.py",
            "description": "This file acts as a re-export module, providing backward compatibility for the `LarkSuiteDocLoader` class. It dynamically imports `LarkSuiteDocLoader` from `langchain_community.document_loaders` when accessed, likely issuing a deprecation warning.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/unstructured.py",
            "description": "This file acts as a compatibility layer for Unstructured document loaders, dynamically redirecting deprecated imports from `langchain_classic` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/wikipedia.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `WikipediaLoader` from `langchain_community.document_loaders` to ensure backward compatibility during migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/url_selenium.py",
            "description": "This file provides a compatibility layer for `SeleniumURLLoader`, redirecting imports from `langchain_classic` to its new location in `langchain_community.document_loaders`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/whatsapp_chat.py",
            "description": "This file acts as a compatibility layer or proxy for deprecated imports, redirecting `WhatsAppChatLoader` and `concatenate_rows` from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/url.py",
            "description": "This file re-exports the `UnstructuredURLLoader` class, dynamically importing it from `langchain_community.document_loaders`. It facilitates a smooth transition for users while the module is being deprecated or moved from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/xorbits.py",
            "description": "This file provides a compatibility layer or re-export mechanism for the `XorbitsLoader` from `langchain_community.document_loaders` for the `langchain_classic` library. It dynamically looks up and imports `XorbitsLoader`, potentially handling deprecation or lazy loading.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/tencent_cos_directory.py",
            "description": "This file acts as a compatibility layer, redirecting imports for `TencentCOSDirectoryLoader` to its new location in `langchain_community.document_loaders`. It ensures backward compatibility and handles dynamic imports for this moved class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/rspace.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `RSpaceLoader` from `langchain_community`. It facilitates a soft deprecation of `RSpaceLoader` within `langchain_classic`, pointing to its new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/polars_dataframe.py",
            "description": "This file dynamically imports and re-exports `PolarsDataFrameLoader` from `langchain_community.document_loaders`. It acts as a compatibility layer, providing access to the loader while indicating its deprecated location within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/word_document.py",
            "description": "This file provides dynamic import forwarding for Word document loaders, specifically `Docx2txtLoader` and `UnstructuredWordDocumentLoader`. It handles the transition of these loaders from `langchain_classic` to `langchain_community` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/txt.py",
            "description": "This file acts as a compatibility shim, dynamically re-exporting the `TextParser` class from `langchain_community` to maintain backward compatibility for older `langchain_classic` imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/audio.py",
            "description": "This file acts as a shim, dynamically importing deprecated audio parser classes like `OpenAIWhisperParser` and `YandexSTTParser` from the `langchain_community` package to maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/msword.py",
            "description": "This file serves as a compatibility layer or deprecation shim for `MsWordParser`. It dynamically imports the `MsWordParser` from `langchain_community` when accessed from `langchain_classic` to manage package restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/grobid.py",
            "description": "This file acts as a compatibility layer, re-exporting `GrobidParser` and `ServerUnavailableException` from `langchain_community` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/docai.py",
            "description": "This file provides backward compatibility for `DocAIParser` and `DocAIParsingResults` by dynamically importing them from `langchain_community`. It acts as a forwarding mechanism for these moved classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/__init__.py",
            "description": "This file serves as the package's entry point for document parsers, dynamically exposing various parser classes from `langchain_community` while managing potential deprecations and lazy loading.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/registry.py",
            "description": "This file serves as a compatibility layer for `langchain_classic`, dynamically importing the `get_parser` function from `langchain_community`. It manages deprecated imports to ensure smooth transitions for code that might still reference the older `langchain_classic` path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/pdf.py",
            "description": "This file acts as a compatibility layer or deprecation handler, re-exporting various PDF parser classes and utilities from 'langchain_community' to maintain backward compatibility for 'langchain_classic'. It dynamically handles imports and likely issues deprecation warnings when these moved components are accessed.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/language/code_segmenter.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for the `CodeSegmenter` class from `langchain_community` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/language/cobol.py",
            "description": "This file acts as a compatibility layer and re-exporter for the `CobolSegmenter` class, which has been moved to `langchain_community`. It dynamically looks up and provides access to the class while handling deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/language/language_parser.py",
            "description": "This file serves as a compatibility layer or shim for the `LanguageParser` class, redirecting imports from `langchain_classic` to `langchain_community`. It likely handles deprecation warnings for the moved class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/language/__init__.py",
            "description": "This file dynamically re-exports the `LanguageParser` class, serving as a compatibility layer to manage its import, possibly from a deprecated location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/html/bs4.py",
            "description": "This file serves as a shim or re-exporter for `BS4HTMLParser`, dynamically importing it from `langchain_community.document_loaders.parsers.html.bs4`. It facilitates backward compatibility or manages package transitions by making the class available from the current package while it physically resides in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/parsers/html/__init__.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `BS4HTMLParser` from `langchain_community` to maintain backward compatibility within the `langchain_classic` namespace. It uses an importer mechanism to manage potential module migrations or deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/blob_loaders/file_system.py",
            "description": "This file acts as a compatibility layer or proxy, dynamically importing and re-exporting `FileSystemBlobLoader` from `langchain_community.document_loaders` to maintain backward compatibility for classic `langchain` modules.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_loaders/blob_loaders/__init__.py",
            "description": "This `__init__.py` file manages the dynamic import and deprecation of Blob and BlobLoader related classes, routing them from `langchain_core` to `langchain_community` for backward compatibility. It acts as an entry point for blob loaders within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/arxiv.py",
            "description": "This file acts as a compatibility layer, dynamically importing and redirecting the `ArxivRetriever` class from `langchain_community.retrievers`. It enables access to the retriever through an older import path, likely for deprecation management.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/pubmed.py",
            "description": "This file manages the deprecated import of `PubMedRetriever`, dynamically redirecting it from `langchain_classic` to `langchain_community.retrievers`. It ensures backward compatibility while guiding users towards the updated module location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/retrievers/wikipedia.py",
            "description": "This file acts as an import shim for `WikipediaRetriever`, dynamically redirecting its import from `langchain_classic` to `langchain_community.retrievers` to handle deprecation or refactoring.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/document_loaders/test_imports.py",
            "description": "This file contains a unit test that verifies the `__all__` attribute of the `langchain.document_loaders` module exposes all expected document loader classes.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/document_loaders/parsers/test_public_api.py",
            "description": "This file contains unit tests to verify the public API of the document loader parsers in the `langchain_classic` library. It ensures that the `__all__` variable correctly exposes the expected set of parser classes, preventing unintended breaking changes.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Bagatur",
            "percent": 42
          },
          {
            "name": "Mason Daugherty",
            "percent": 42
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 15
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 436,
      "spofCount": 70
    },
    "busFactor": 4,
    "authorCount": 25
  },
  "Infrastructure": {
    "description": "",
    "functions": {
      "Build & Configuration": {
        "files": [
          {
            "path": "libs/partners/qdrant/scripts/check_imports.py",
            "description": "This script checks if a list of specified Python files can be imported successfully. It loads each file as a module and reports any import errors, exiting with a non-zero status if any file fails.",
            "spof": false
          },
          {
            "path": "libs/partners/chroma/scripts/check_imports.py",
            "description": "This script checks if a given list of Python files can be imported successfully as modules. It prints out any files that fail to import along with their tracebacks.",
            "spof": false
          },
          {
            "path": "libs/partners/chroma/tests/integration_tests/test_compile.py",
            "description": "This file serves as a placeholder for compiling integration tests without executing any actual test logic. It ensures that the test compilation process for `langchain/libs/partners/chroma` integration tests can complete successfully.",
            "spof": false
          },
          {
            "path": "libs/partners/deepseek/tests/__init__.py",
            "description": "This file serves as the initialization file for the `langchain_deepseek` package's test suite, indicating that the directory contains tests and potentially defining top-level test configurations or documentation.",
            "spof": true
          },
          {
            "path": "libs/partners/deepseek/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test used solely for compiling integration tests, ensuring they can be built without executing any actual tests.",
            "spof": false
          },
          {
            "path": "libs/partners/deepseek/scripts/check_imports.py",
            "description": "This script checks if a list of given Python files can be successfully imported as modules. It exits with a non-zero status if any file fails to import, printing the filename and traceback for each failure.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/scripts/check_imports.py",
            "description": "This script checks if a list of Python files provided as command-line arguments can be successfully imported as modules. It reports any import failures with their tracebacks and exits with a non-zero status if any file fails to load.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/langchain_fireworks/version.py",
            "description": "This file dynamically retrieves and exposes the version number for the 'langchain_fireworks' package. It uses `importlib.metadata` to get the version, defaulting to an empty string if metadata is not found.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/scripts/check_imports.py",
            "description": "A Python script designed to check for import errors in specified Python files by attempting to load them as modules. It takes file paths as command-line arguments and reports any import failures.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/conftest.py",
            "description": "This conftest.py file configures the `VCR` library for pytest tests, redacting sensitive headers from HTTP requests and responses before recording. It also registers custom VCR persisters and serializers.",
            "spof": false
          },
          {
            "path": "libs/partners/prompty/scripts/check_imports.py",
            "description": "This script checks if a list of Python files, provided as command-line arguments, can be successfully imported as modules. It exits with an error code if any file fails to import, printing the traceback for debugging purposes.",
            "spof": false
          },
          {
            "path": "libs/partners/prompty/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test used specifically for compiling integration tests within the 'prompty' library, without actually executing any functional tests.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/scripts/check_imports.py",
            "description": "This script checks for import errors in specified Python files by attempting to dynamically load them as modules. It prints the file path and traceback for any files that fail to import, exiting with a non-zero status if any errors are found.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/scripts/check_imports.py",
            "description": "This script checks if a list of specified Python files can be successfully imported as modules. It exits with a non-zero status code if any import fails.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/tests/conftest.py",
            "description": "This file configures VCR (cassette library for HTTP interactions) for pytest tests. It sets up custom request/response header redaction, uses a `yaml.gz` serializer, and registers custom persisters and serializers for VCR.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/scripts/check_imports.py",
            "description": "This script checks if a list of specified Python files can be imported without raising any exceptions. It iterates through the files provided as command-line arguments and attempts to load each as a module, reporting any import failures.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/scripts/check_imports.py",
            "description": "This script checks if a given list of Python files can be successfully imported as modules. It loads each file using SourceFileLoader and reports any import errors.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/scripts/check_imports.py",
            "description": "This script checks if a list of specified Python files can be successfully imported as modules. It exits with a non-zero status code if any file fails to import, indicating an issue with the module's syntax or dependencies.",
            "spof": false
          },
          {
            "path": "libs/partners/xai/scripts/check_imports.py",
            "description": "This script checks if a list of specified Python files can be imported without errors. It attempts to load each file using `SourceFileLoader` and reports any import failures.",
            "spof": false
          },
          {
            "path": "libs/partners/ollama/tests/__init__.py",
            "description": "This file provides instructions and requirements for running integration tests, specifically listing the Ollama models needed for testing.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/scripts/check_imports.py",
            "description": "This script attempts to load multiple Python files specified as command-line arguments. It checks for importability and prints error details for any file that fails to load, exiting with a non-zero status if any errors occur.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/globals.py",
            "description": "This file defines global settings for the LangChain framework, including verbose mode, debug mode, and an LLM cache. It provides controlled access to these settings via dedicated getter and setter functions.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/version.py",
            "description": "This file defines the version number for the langchain-core library. It serves as a central place to store and retrieve the package's current version.",
            "spof": false
          },
          {
            "path": "libs/core/scripts/check_version.py",
            "description": "This script checks for version consistency between the `version` field in `pyproject.toml` and the `VERSION` variable in `langchain_core/version.py`. It is intended as a pre-commit hook to prevent version mismatches.",
            "spof": true
          },
          {
            "path": "libs/core/scripts/check_imports.py",
            "description": "This script checks if a list of specified Python files can be successfully imported as modules. It takes file paths as command-line arguments and reports any import failures along with their tracebacks.",
            "spof": false
          },
          {
            "path": "libs/core/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder integration test used to compile other integration tests without actually executing any functional test logic. It ensures the integration test suite can be built successfully.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/scripts/check_imports.py",
            "description": "This script checks if a list of Python files provided as command-line arguments can be successfully imported as modules. It exits with a non-zero status if any import fails.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/tests/unit_tests/conftest.py",
            "description": "This file configures pytest, adding custom command-line options like `--only-extended` and `--only-core`, and implementing a `requires` marker to conditionally skip or fail tests based on package availability and test classification.",
            "spof": false
          },
          {
            "path": "libs/text-splitters/tests/integration_tests/test_compile.py",
            "description": "This file provides a placeholder test specifically designed to ensure the compilation of integration tests without actually executing them. It helps verify that the integration test suite builds successfully.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/scripts/check_version.py",
            "description": "This script checks for version consistency between `pyproject.toml` and `langchain/__init__.py` to prevent mismatches, intended for use as a pre-commit hook.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/scripts/check_imports.py",
            "description": "This script verifies that a list of Python files can be imported by the interpreter without errors. It prints the filename and traceback for any files that fail to load, and exits with a non-zero status if any failures occur.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/langchain/__init__.py",
            "description": "This file serves as the main entry point for the LangChain library, defining its package initialization and current version.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/README.md",
            "description": "This README provides an overview of the LangChain Python library, detailing its purpose for building LLM applications, installation instructions, key features, and links to documentation and contribution guidelines.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/test_imports.py",
            "description": "This file contains unit tests to verify that all modules and their public attributes within the `langchain` library can be successfully imported, ensuring the integrity of the public API.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/test_version.py",
            "description": "This file contains a unit test to ensure that the package version defined in `langchain/__init__.py` consistently matches the version specified in `pyproject.toml`.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/test_pytest_config.py",
            "description": "This file contains a unit test for the 'pytest-socket' plugin, demonstrating that network requests are blocked as expected during testing. It verifies the plugin's functionality by asserting a `SocketBlockedError` when attempting an external HTTP request.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/test_dependencies.py",
            "description": "This unit test file checks for accidental introductions of new, non-optional dependencies in the project. It ensures that the core dependencies specified in `pyproject.toml` match an expected, predefined set.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/conftest.py",
            "description": "This file provides pytest configuration for unit tests, including fixtures for HTTP interaction recording (BlockBuster, VCR) with sensitive data redaction. It also adds custom command-line options and dynamically skips tests based on required package availability or specified test categories.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test designed to ensure the integration test suite compiles correctly without executing any actual test logic. It is likely used in a build or CI process to validate compilation.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/tests/integration_tests/conftest.py",
            "description": "This file is a pytest configuration file that loads environment variables, defines fixtures for integration test directories, and sets up paths for VCR.py cassettes to manage network request recordings for tests.",
            "spof": true
          },
          {
            "path": "libs/model-profiles/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test used specifically for compiling integration tests within the model-profiles library, without executing actual tests.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/langchain_tests/conftest.py",
            "description": "This `conftest.py` file configures Pytest for testing within the LangChain standard tests, primarily by defining custom serialization and persistence for VCR (Video Cassette Recorder) to handle HTTP request/response recording using gzipped YAML. It also provides common VCR configurations and fixtures for tests.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/utils/__init__.py",
            "description": "This file serves as the package initializer for the `utils` module within `langchain_tests`, intended to contain various utility functions for Langchain testing.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/scripts/check_imports.py",
            "description": "This script checks if a list of provided Python files can be successfully imported as modules. It iterates through each file, attempting to load it, and reports any import failures.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/tests/integration_tests/test_compile.py",
            "description": "This file is a placeholder integration test used to verify that the test suite compiles correctly without running any actual test logic. It ensures the integrity of the integration test environment or build process.",
            "spof": true
          },
          {
            "path": "libs/langchain/README.md",
            "description": "This README provides an overview and installation instructions for the `langchain-classic` Python package, which contains legacy, re-exported, and deprecated components of LangChain, advising users to generally prefer the main `langchain` package.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/python.py",
            "description": "This file provides backwards compatibility by dynamically redirecting imports for deprecated modules, such as PythonREPL, to their new locations in the `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/base.py",
            "description": "This file provides a compatibility layer for the `GraphQAChain` class, which has been moved to `langchain_community`. It dynamically redirects imports to the new location while handling deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_bash/__init__.py",
            "description": "This file serves as a deprecation notice for the `llm_bash` module, informing users that it has been moved to `langchain-experimental` and providing instructions for its new location and installation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/document_transformers/google_translate.py",
            "description": "This file serves as a deprecation shim, redirecting imports of `GoogleTranslateTransformer` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/minimax.py",
            "description": "This file provides backward compatibility for the `MiniMaxEmbeddings` class, redirecting its import from `langchain_classic` to `langchain_community` using a dynamic importer.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/data.py",
            "description": "This file defines common test data, specifically paths to various PDF files, used for integration tests within the Langchain library.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/test_dependencies.py",
            "description": "This file contains unit tests to prevent the accidental introduction of new non-optional dependencies into the project and to manage dependencies within the test group. It ensures that only approved dependencies are part of the core and test requirements.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/test_pytest_config.py",
            "description": "This unit test verifies that the `pytest_socket` plugin correctly blocks network connections during tests, expecting a `SocketBlockedError` when an HTTP request is attempted.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/__init__.py",
            "description": "This file serves as the package initializer for unit tests and contains a utility function to assert that all exposed attributes within a module are importable.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/conftest.py",
            "description": "This file configures pytest for unit tests, enabling custom command-line options for filtering tests (e.g., core, extended, community) and dynamically skipping tests based on external package dependencies using a 'requires' marker.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/test_imports.py",
            "description": "This file contains unit tests to verify that all modules within the 'langchain' package can be imported correctly and their public APIs are accessible. It also includes a test to prevent new deprecated imports from the 'langchain_community' package.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/_api/test_importing.py",
            "description": "This file contains unit tests for the `create_importer` utility, verifying its functionality in importing modules from various paths, including non-deprecated, deprecated, and fallback configurations.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test designed to allow compilation of integration tests without executing any actual test logic. It's used for compilation purposes within the test suite.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/conftest.py",
            "description": "This file configures the testing environment for LangChain integration tests. It loads environment variables, defines project and test directory paths, and provides pytest fixtures for test directories and VCR.py cassette paths.",
            "spof": true
          },
          {
            "path": "libs/README.md",
            "description": "This README provides an overview of the LangChain monorepo structure, detailing the core packages within the `libs/` directory and explaining the organization of integration packages, including those directly maintained and those in separate repositories.",
            "spof": true
          },
          {
            "path": ".devcontainer/README.md",
            "description": "This README.md file explains how to use a development container for the project, detailing setup instructions for GitHub Codespaces and VS Code Dev Containers, along with useful tips.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 30
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 25
          },
          {
            "name": "Christophe Bornet",
            "percent": 17
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 62,
      "spofCount": 24
    },
    "busFactor": 5,
    "authorCount": 20
  },
  "Model Abstraction Layer": {
    "description": "Provides a standardized interface for interacting with a wide variety of language models from different providers. This allows developers to easily switch between models (e.g., from OpenAI to Anthropic) with minimal code changes, promoting flexibility and avoiding vendor lock-in.",
    "functions": {
      "Model Testing and Validation": {
        "files": [
          {
            "path": "libs/partners/chroma/tests/integration_tests/fake_embeddings.py",
            "description": "This file defines several fake embedding classes (`FakeEmbeddings`, `ConsistentFakeEmbeddings`, `AngularTwoDimensionalEmbeddings`) that implement the `Embeddings` interface for testing purposes. These classes provide predictable or artificial embedding vectors to facilitate integration and unit tests without relying on real embedding models.",
            "spof": false
          },
          {
            "path": "libs/partners/deepseek/tests/integration_tests/test_chat_models.py",
            "description": "This file contains integration tests for the `ChatDeepSeek` chat model within the LangChain framework, verifying its core functionalities, JSON mode support, and features like reasoning content and streaming.",
            "spof": false
          },
          {
            "path": "libs/partners/deepseek/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the `ChatDeepSeek` chat model, covering its integration, message parsing (including 'reasoning_content'), streaming chunk conversion, and request payload generation for tools. It also includes tests for strict mode functionality.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/tests/integration_tests/test_standard.py",
            "description": "This file contains integration tests for the `ChatFireworks` LangChain model, ensuring it adheres to the standard LangChain chat model interface specifications. It configures a specific Fireworks model for testing and includes overridden test behaviors.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/tests/unit_tests/test_embeddings_standard.py",
            "description": "This file contains unit tests for the `FireworksEmbeddings` class, ensuring it conforms to the standard LangChain embeddings interface. It extends `EmbeddingsUnitTests` to validate the implementation.",
            "spof": false
          },
          {
            "path": "libs/partners/mistralai/tests/integration_tests/test_embeddings.py",
            "description": "This file contains integration tests for the MistralAIEmbeddings class, covering synchronous and asynchronous embedding of documents and queries, as well as error handling scenarios.",
            "spof": true
          },
          {
            "path": "libs/partners/mistralai/tests/integration_tests/test_compile.py",
            "description": "This file serves as a placeholder for compiling integration tests within the MistralAI Langchain partner library, specifically designed to check compilation without executing actual tests.",
            "spof": false
          },
          {
            "path": "libs/partners/mistralai/tests/unit_tests/test_standard.py",
            "description": "This file contains standard LangChain interface unit tests for the ChatMistralAI class. It ensures that the Mistral AI chat model implementation adheres to the expected LangChain chat model API.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test function, marked for compilation, used to ensure integration tests can be built without actual execution.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/integration_tests/test_standard.py",
            "description": "This file contains integration tests for the `ChatAnthropic` model, verifying its adherence to the standard LangChain interface and its support for features like image inputs, PDF inputs, and native structured outputs.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/integration_tests/test_chat_models.py",
            "description": "This file contains integration tests for the `ChatAnthropic` chat model within the LangChain framework, covering functionalities like streaming, asynchronous operations, batch processing, tool usage, and usage metadata.",
            "spof": false
          },
          {
            "path": "libs/partners/prompty/tests/unit_tests/fake_chat_model.py",
            "description": "This file defines a `FakeEchoPromptChatModel` class, which is a mock chat model designed for testing purposes within the Langchain framework. It simulates a chat model by echoing input messages or returning a fixed fake response.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/embeddings/test_base_standard.py",
            "description": "This file contains unit tests for the OpenAIEmbeddings class, ensuring it adheres to the standard LangChain Embeddings interface. It also tests the initialization of OpenAIEmbeddings using various environment variables.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/chat_models/test_base_standard.py",
            "description": "This file contains unit tests for the `ChatOpenAI` model, ensuring it conforms to the standard LangChain chat model interface and correctly handles initialization parameters from environment variables.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/chat_models/test_responses_standard.py",
            "description": "This file contains standard unit tests for the `ChatOpenAI` model within the LangChain framework, specifically validating its responses and adherence to the `BaseChatModel` interface, likely using a mocked responses API.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/chat_models/test_imports.py",
            "description": "This unit test file verifies that the `__all__` list in the `langchain_openai.chat_models` module correctly exports the expected ChatOpenAI and AzureChatOpenAI classes, ensuring the public API surface is as intended.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/chat_models/test_responses_stream.py",
            "description": "This file defines a mock stream of OpenAI response events, including reasoning and text delta events. It is used as a test fixture for unit testing streaming capabilities of LangChain's OpenAI chat models.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/chat_models/test_azure.py",
            "description": "This file contains unit tests for the `AzureChatOpenAI` class, verifying its initialization, configuration, and request payload generation for various parameters and API behaviors, including the Azure Responses API.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/chat_models/test_azure_standard.py",
            "description": "This file contains unit tests for the `AzureChatOpenAI` class, ensuring its adherence to the standard LangChain chat model interface. It includes specific configurations for Azure and handles known limitations, such as tool choice support.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/chat_models/test_base.py",
            "description": "This file contains integration tests for the `ChatOpenAI` chat model in LangChain, covering its core functionalities, streaming, API key handling, and various configuration options.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/chat_models/test_azure.py",
            "description": "This file contains integration tests for the AzureChatOpenAI wrapper, covering various functionalities like generation, streaming, batching, and JSON mode.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/chat_models/test_azure_standard.py",
            "description": "This file contains integration tests for the AzureChatOpenAI model within the LangChain framework. It validates the model's standard interface, responses API usage, and legacy model compatibility through a series of parameterized tests.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/chat_models/test_base_standard.py",
            "description": "This file contains integration tests for the `ChatOpenAI` model, ensuring it conforms to the standard LangChain chat model interface. It verifies support for various features such as image, JSON, PDF, and audio inputs, as well as usage metadata details and VCR tests.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/chat_models/test_responses_standard.py",
            "description": "This file contains integration tests for the LangChain ChatOpenAI model, specifically focusing on its interaction with the OpenAI Responses API. It verifies functionality related to various input types, including text, URLs, and PDFs, as well as features like reasoning and caching.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/embeddings/test_base_standard.py",
            "description": "This file contains integration tests for the `OpenAIEmbeddings` class, ensuring it adheres to the standard LangChain embeddings interface and functionality.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/llms/test_azure.py",
            "description": "This file contains integration tests for the `AzureOpenAI` LLM wrapper, verifying its various functionalities including invocation, streaming, batching, and callback handling. It is currently marked to be skipped due to the retirement of relevant Azure OpenAI models.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/integration_tests/llms/test_base.py",
            "description": "This file contains integration and unit tests for the OpenAI LLM class in Langchain, covering various functionalities like streaming, batching, invocation, error handling, and callback mechanisms.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/tests/integration_tests/test_standard.py",
            "description": "Integration tests for the `ChatGroq` model, verifying its adherence to the standard LangChain interface, including tool calling and structured output capabilities.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/tests/unit_tests/test_chat_models.py",
            "description": "This file contains unit tests for the `ChatHuggingFace` class, verifying its message conversion, prompt formatting, tool binding, and parameter inheritance from the `HuggingFaceEndpoint` LLM.",
            "spof": false
          },
          {
            "path": "libs/partners/xai/tests/integration_tests/test_chat_models_standard.py",
            "description": "This file contains integration tests for the `ChatXAI` chat model within the LangChain framework, ensuring it adheres to standard LangChain interface functionalities. It includes specific tests for features like stop sequences.",
            "spof": false
          },
          {
            "path": "libs/partners/xai/tests/integration_tests/test_compile.py",
            "description": "This file contains a placeholder test marked for compilation, used to verify that integration tests can be compiled without actually running them. It serves to check for syntax errors or missing dependencies in the integration test suite.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/tests/unit_tests/test_embeddings.py",
            "description": "This file contains unit tests for the OllamaEmbeddings class, verifying its initialization, model validation logic, and correct passing of configuration options like `num_gpu` and `temperature` to the underlying Ollama client during embedding operations.",
            "spof": false
          },
          {
            "path": "libs/partners/ollama/tests/unit_tests/test_llms.py",
            "description": "This file contains unit tests for the `OllamaLLM` class within the `langchain_ollama` library. It verifies the initialization, parameter handling, model validation, and reasoning aggregation features of the Ollama LLM wrapper.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/language_models/fake.py",
            "description": "This file provides fake LLM implementations, `FakeListLLM` and `FakeStreamingListLLM`, designed specifically for testing purposes within the LangChain core library.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/language_models/fake_chat_models.py",
            "description": "This file provides fake chat model implementations for testing purposes, offering different behaviors like cycling through responses, simulating delays, and raising errors during streaming to facilitate robust testing of LangChain components.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/embeddings/fake.py",
            "description": "This module provides fake embedding models, `FakeEmbeddings` and `DeterministicFakeEmbedding`, designed exclusively for unit testing purposes. These models generate embedding vectors for testing without relying on actual embedding model computations.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/test_pydantic_serde.py",
            "description": "This file contains unit tests for pydantic serialization and deserialization (SerDe) of various `langchain_core` message types. It specifically verifies that Union discrimination works correctly when validating `AnyMessage` models from dumped dictionaries.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/stubs.py",
            "description": "This file provides utility classes and helper functions for unit testing `langchain_core` models. It defines a custom `AnyStr` class and functions to create models with an ID field that can match any string, circumventing a Pydantic issue in test comparisons.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/test_pydantic_imports.py",
            "description": "This file contains unit tests for the `langchain_core` library, specifically verifying that all Pydantic models exposed by its modules are correctly initialized and marked as complete.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/test_messages.py",
            "description": "This file contains unit tests for the `langchain_core.messages` module, focusing primarily on the instantiation and concatenation logic of various message chunk types (e.g., AIMessageChunk, ChatMessageChunk). It verifies the merging behavior of content, additional arguments, tool calls, usage metadata, and message IDs during chunk concatenation.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/language_models/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_core.language_models` matches an expected list of public exports, ensuring API consistency.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/language_models/chat_models/test_base.py",
            "description": "This file contains unit tests for the base functionalities of chat models, including batching, streaming (sync and async), and error handling, within the `langchain_core` library.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/language_models/chat_models/test_rate_limiting.py",
            "description": "This file contains unit tests for the `InMemoryRateLimiter` integration with `GenericFakeChatModel`, verifying its behavior across various invocation methods (invoke, batch, stream), and its interaction with caching and serialization.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/language_models/llms/test_base.py",
            "description": "This file contains unit tests for the core functionalities of Langchain's base LLM classes, covering batch processing, streaming, error handling with callbacks, and tracing parameter extraction.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/embeddings/test_deterministic_embedding.py",
            "description": "This file contains unit tests for the `DeterministicFakeEmbedding` class. It verifies that the fake embedding model consistently returns the same embedding vector for identical text inputs, ensuring its deterministic behavior.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/test_imports.py",
            "description": "Tests the `__all__` export of the `langchain_core.messages` module. It verifies that the publicly exposed names match an expected list.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/test_utils.py",
            "description": "This file contains unit tests for message utility functions such as `merge_message_runs`, `filter_messages`, and `trim_messages` within the `langchain_core.messages.utils` module.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/messages/test_ai.py",
            "description": "This file contains unit tests for `AIMessage` and `AIMessageChunk` classes, covering their serialization/deserialization, handling of tool calls and various content blocks, and the aggregation/manipulation of token usage metadata.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/block_translators/test_registration.py",
            "description": "This test file verifies that all block translators implemented within the `langchain_core.messages.block_translators` package are properly registered in `PROVIDER_TRANSLATORS`.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/block_translators/test_groq.py",
            "description": "This file contains unit tests for the Groq message block translator within `langchain_core`. It verifies the correct translation of various AI message components, such as text, reasoning, tool calls, and executed tools, into a standardized block format.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/block_translators/test_openai.py",
            "description": "This file contains unit tests for the `openai` block translator, verifying its ability to convert various message content blocks (like reasoning, function calls, text, images, and files) to and from a format compatible with OpenAI's message structure, including handling message chunks.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/block_translators/test_bedrock.py",
            "description": "This file contains unit tests for converting Bedrock-specific message formats (AIMessage, AIMessageChunk, HumanMessage) into LangChain's 'v1' content block representation, ensuring proper handling of various content types including text, tool calls, citations, and document types.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/block_translators/test_langchain_v0.py",
            "description": "This file contains unit tests for the `_convert_legacy_v0_content_block_to_v1` function, which converts legacy (v0) content block formats used in LangChain messages to the newer v1 format. It verifies correct translation of various content types and the handling of extra metadata.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/block_translators/test_bedrock_converse.py",
            "description": "This file contains unit tests for message block translators, verifying the correct conversion of messages and message chunks from the Bedrock Converse API format into LangChain's internal `ContentBlock` representation.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/messages/block_translators/test_anthropic.py",
            "description": "This file contains unit tests for converting Anthropic-specific message formats (both full messages and streaming chunks) into a standardized LangChain V1 ContentBlock format. It verifies the correct translation of various content types, including tool calls, server tool calls, annotations, and non-standard blocks.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/fake/test_fake_chat_model.py",
            "description": "This file contains unit tests for various fake chat model implementations (e.g., GenericFakeChatModel, ParrotFakeChatModel, FakeListChatModel) within the LangChain library. It verifies their functionality, including synchronous/asynchronous invocation, streaming, batch processing, and callback handling.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/embeddings/test_imports.py",
            "description": "This file contains a unit test to verify that the `langchain.embeddings` module exports the expected public symbols as defined in its `__all__` attribute.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/embeddings/test_base.py",
            "description": "This file contains unit tests for the base embedding utility functions in Langchain, including parsing model strings, inferring model and provider information, and validating supported provider configurations.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/chat_models/test_chat_models.py",
            "description": "This file contains unit tests for the `init_chat_model` function and related utilities within the `langchain.chat_models` module. It verifies correct model initialization, provider inference, and the configurable behavior of chat models.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/tests/integration_tests/chat_models/test_base.py",
            "description": "This file contains integration tests for `init_chat_model` and the base chat model functionality in LangChain. It verifies the initialization, configuration, and core features like tool calling and structured output for chat models.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/tests/integration_tests/embeddings/test_base.py",
            "description": "This file contains integration tests for initializing and using various embedding models from different providers (e.g., OpenAI, Google Vertex AI, Bedrock, Cohere). It verifies that embedding models can be correctly instantiated and produce valid embeddings.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/embeddings.py",
            "description": "This file provides a base class for integration tests of embedding models, defining common tests for embedding single queries and lists of documents, both synchronously and asynchronously. Subclasses are expected to specify the embedding model and its initialization parameters.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/chat_models.py",
            "description": "This file contains integration tests for chat models within the Langchain framework. It defines a base class `ChatModelIntegrationTests` that other test classes can extend to test their specific chat model implementations, providing properties for model class, parameters, and supported features like tool calling or structured output.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/tests/unit_tests/test_custom_chat_model.py",
            "description": "This file contains unit and integration tests for a custom chat model named `ChatParrotLink`, ensuring its compatibility with the standard LangChain chat model interfaces. It specifically tests basic functionality and notes expected failures for features like tool calling that are not yet implemented in `ChatParrotLink`.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/tests/unit_tests/test_embeddings.py",
            "description": "This file contains unit and integration tests for the `DeterministicFakeEmbedding` class, ensuring its proper functionality and adherence to the `Embeddings` interface within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/tests/unit_tests/custom_chat_model.py",
            "description": "This file defines `ChatParrotLink`, an example custom LangChain chat model that echoes a specified number of characters from its input, demonstrating how to implement and stream custom chat model logic within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/test_schema.py",
            "description": "This file contains unit tests for the serialization and deserialization of various LangChain core schema objects, such as messages, documents, agents, and outputs, using Pydantic.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/embeddings/test_base.py",
            "description": "This file contains unit tests for the base embeddings module, specifically testing functions related to parsing and inferring model and provider strings, and validating supported embedding providers.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/embeddings/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `langchain_classic.embeddings` module correctly exposes a predefined list of embedding classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chat_models/test_imports.py",
            "description": "This file contains a unit test to verify that the `langchain_classic.chat_models` module correctly exposes all expected chat model classes through its `__all__` attribute, ensuring proper import functionality.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chat_models/test_base.py",
            "description": "This file contains unit tests for the `init_chat_model` function within the LangChain framework. It verifies model initialization, dependency handling, and the configurable behavior of chat models with and without default parameters across various providers.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/llms/test_base.py",
            "description": "This file contains unit tests for the base LLM (Large Language Model) functionality, including verification of module exports and comprehensive testing of the caching mechanism.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/llms/test_imports.py",
            "description": "This file contains a unit test to verify that all expected Large Language Model (LLM) classes are correctly imported and exposed by the `langchain_classic.llms` module. It asserts that the module's `__all__` attribute matches a predefined list of LLM class names.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/llms/test_fake_chat_model.py",
            "description": "This file contains unit tests for the `GenericFakeChatModel`, verifying the functionality of its `invoke`, `ainvoke`, `stream`, `astream_log` methods, and its integration with callback handlers.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/llms/fake_chat_model.py",
            "description": "This file provides `FakeChatModel` and `GenericFakeChatModel` classes, which are fake implementations of chat models used for testing. They simulate chat responses and support testing of streaming and callback functionalities within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_embeddings.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_classic.schema.embeddings` correctly exposes only the `Embeddings` class, ensuring proper module exports.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_language_model.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_classic.schema.language_model` correctly exports all expected symbols, ensuring proper module public interface definition.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_classic.schema` correctly exposes the intended public API, ensuring all expected components are discoverable.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_messages.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_classic.schema.messages` correctly exposes all expected message classes and utility functions.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_exceptions.py",
            "description": "This unit test file verifies that the `langchain_classic.schema.exceptions` module's `__all__` variable correctly exposes only the `LangChainException`.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/load/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable of the `langchain_classic.load` module correctly exposes the expected public symbols, such as `dumpd`, `dumps`, `load`, and `loads`.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/integration_tests/test_schema.py",
            "description": "This file contains integration tests for the `_get_token_ids_default_method` function, verifying its tokenization functionality, particularly with the GPT-2 tokenizer. It checks consistency, empty input, multiple tokens, and special characters.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/examples/non-utf8-encoding.py",
            "description": "This file is an example integration test designed to verify how the LangChain library handles non-UTF-8 encodings, specifically using iso-8859-5.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/examples/default-encoding.py",
            "description": "This file is an integration test example for LangChain, designed to verify default encoding handling. It tests the system's ability to process non-ASCII characters, such as emojis, within string literals.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/embeddings/test_base.py",
            "description": "This file contains integration tests for the `init_embeddings` function, verifying that it can correctly initialize and use embedding models from different providers (e.g., OpenAI, Google, Bedrock, Cohere) to embed text queries.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/integration_tests/chat_models/test_base.py",
            "description": "This file contains integration tests for the `langchain_classic.chat_models.init_chat_model` function, verifying its ability to initialize chat models, chain them with tools and configurations, and adhere to standard chat model integration test requirements.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 51
          },
          {
            "name": "ccurme",
            "percent": 18
          },
          {
            "name": "Weichen Zhao",
            "percent": 6
          }
        ]
      },
      "Provider-Specific Model Integrations": {
        "files": [
          {
            "path": "libs/partners/deepseek/langchain_deepseek/chat_models.py",
            "description": "This file implements the LangChain integration for DeepSeek's chat models, extending BaseChatOpenAI to interact with the DeepSeek API. It handles model configuration, API calls, tool usage, and structured output for DeepSeek models within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/langchain_fireworks/__init__.py",
            "description": "This `__init__.py` file serves as the main entry point for the `langchain_fireworks` package, exposing key components for Fireworks AI integration with LangChain, such as chat models, embeddings, and the LLM class.",
            "spof": false
          },
          {
            "path": "libs/partners/fireworks/langchain_fireworks/llms.py",
            "description": "This file provides a LangChain wrapper for interacting with Fireworks AI's Completion API, enabling text generation with various configurable parameters. It handles API authentication, request formatting, and both synchronous and asynchronous calls to the Fireworks API.",
            "spof": true
          },
          {
            "path": "libs/partners/fireworks/langchain_fireworks/chat_models.py",
            "description": "This file defines a wrapper for Fireworks chat models, integrating them with the LangChain framework. It includes utilities for converting messages between LangChain's internal formats and the Fireworks API's expected formats.",
            "spof": true
          },
          {
            "path": "libs/partners/mistralai/langchain_mistralai/embeddings.py",
            "description": "This file implements the `MistralAIEmbeddings` class, integrating MistralAI's embedding models into Langchain. It provides methods for embedding single or multiple texts, handling API communication, batching, and retries.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/llms.py",
            "description": "This file provides a legacy wrapper for Anthropic's text completion LLMs within the LangChain framework. It includes common configurations and methods for interacting with the Anthropic API, although its primary class `AnthropicLLM` is marked as deprecated.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/_client_utils.py",
            "description": "This module provides helper functions for creating and caching httpx clients used by Anthropic API clients, reducing resource overhead. It includes both synchronous and asynchronous client wrappers with caching logic.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/chat_models.py",
            "description": "This file implements Anthropic chat models for LangChain, providing utilities for message formatting, tool integration, and adapting LangChain's messaging and tool definitions to Anthropic's API requirements.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/langchain_openai/__init__.py",
            "description": "This file serves as the main package initializer for `langchain_openai`, exposing key classes for OpenAI chat models, LLMs, embeddings, and custom tools, making them directly accessible from the package root.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/langchain_openai/embeddings/__init__.py",
            "description": "This file serves as the `__init__.py` for the `embeddings` module within `langchain_openai`, making `AzureOpenAIEmbeddings` and `OpenAIEmbeddings` classes directly accessible when importing from `langchain_openai.embeddings`.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/langchain_openai/chat_models/azure.py",
            "description": "This file implements the `AzureChatOpenAI` class, providing an integration for Azure OpenAI chat models within the LangChain framework. It acts as a wrapper to interact with Azure's OpenAI services for tasks like chat completions, streaming, tool calling, and structured output.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/langchain_openai/llms/azure.py",
            "description": "This file defines the `AzureOpenAI` class, which implements an Azure-specific large language model (LLM) for the LangChain framework, distinguishing it from chat models. It handles authentication and configuration for Azure OpenAI services.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/embeddings/__init__.py",
            "description": "This initialization file exposes HuggingFace embedding classes, specifically `HuggingFaceEmbeddings` and `HuggingFaceEndpointEmbeddings`, making them directly importable from the `embeddings` package.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/embeddings/huggingface_endpoint.py",
            "description": "This file implements the `HuggingFaceEndpointEmbeddings` class for LangChain, enabling the generation of text embeddings using Hugging Face's Inference API or a specified provider for various models. It provides both synchronous and asynchronous methods for embedding documents and queries.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/chat_models/__init__.py",
            "description": "This file serves as the package initializer for `langchain_huggingface.chat_models`, exposing the `ChatHuggingFace` class and related Text Generation Inference (TGI) message structures.",
            "spof": false
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/chat_models/huggingface.py",
            "description": "This file implements a LangChain chat model wrapper for Hugging Face, handling the conversion of messages and tool calls between LangChain's format and Hugging Face's API format.",
            "spof": false
          },
          {
            "path": "libs/partners/xai/langchain_xai/__init__.py",
            "description": "This file serves as the main entry point for the `langchain_xai` package, exposing the `ChatXAI` class for integrating xAI chat models with LangChain.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/langchain_ollama/chat_models.py",
            "description": "This file implements the LangChain integration for Ollama chat models, providing classes and utilities to convert messages between LangChain and Ollama formats and handle the communication flow.",
            "spof": true
          },
          {
            "path": "libs/partners/ollama/langchain_ollama/__init__.py",
            "description": "This file serves as the `__init__.py` for the `langchain_ollama` package, providing core classes like `ChatOllama`, `OllamaEmbeddings`, and `OllamaLLM` for integrating LangChain with the Ollama service.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 76
          },
          {
            "name": "ccurme",
            "percent": 8
          },
          {
            "name": "Bagatur",
            "percent": 3
          }
        ]
      },
      "Message and Content Standardization": {
        "files": [
          {
            "path": "libs/partners/fireworks/langchain_fireworks/_compat.py",
            "description": "This file provides a utility function to convert `AIMessage` objects between different output formats. It specifically converts a 'v1' message format to a 'Chat Completions' format by processing and potentially stripping certain content blocks.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/_compat.py",
            "description": "This file provides compatibility functions to convert LangChain V1 content and annotation formats into Anthropic's native message and citation formats, enabling integration with the Anthropic API.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/language_models/_utils.py",
            "description": "This file provides utility functions for parsing and normalizing message content blocks, particularly focusing on converting OpenAI Chat Completions multimodal data and older LangChain v0 formats into the LangChain v1 standard. It ensures consistent handling of image, audio, and file data within messages.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/prompt_values.py",
            "description": "This file defines abstract and concrete classes for `PromptValue` objects, which represent different types of input (text, chat messages, images) for language model prompts, allowing them to be converted into string or message formats.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/human.py",
            "description": "This file defines `HumanMessage` and `HumanMessageChunk` classes, representing user messages and their streamed chunks within the LangChain framework. These classes are used to pass content from a user to a language model.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/base.py",
            "description": "This file defines the `BaseMessage` abstract base class, which serves as the foundation for all message types in LangChain. It handles various content formats, serialization, and provides utility for accessing message text content with backward compatibility.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/__init__.py",
            "description": "This file serves as the `__init__.py` for the `langchain_core.messages` package, consolidating and exporting various message types, content blocks, and utility functions for use in prompts and chat conversations.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/system.py",
            "description": "This file defines the `SystemMessage` class and its `SystemMessageChunk` variant, which are used to prime AI behavior by providing initial instructions or context to a model.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/ai.py",
            "description": "This file defines the `AIMessage` class, representing a message generated by an AI model. It includes structures for tool calls, invalid tool calls, and detailed token usage metadata within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/content.py",
            "description": "This file defines standardized, multimodal content blocks (e.g., text, citations, tool calls) for Large Language Model (LLM) I/O. It provides a unified, provider-agnostic format to facilitate interactions with different LLM APIs, supporting extensibility and provider-specific metadata.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/utils.py",
            "description": "This module provides utility functions for working with different LangChain message types, including serialization, deserialization, filtering, and formatting messages into string or XML representations.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/block_translators/google_vertexai.py",
            "description": "This file registers content block translators for Google VertexAI, leveraging existing translation logic from Google Generative AI, to handle specific content types within the system.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/block_translators/groq.py",
            "description": "This file provides functions to translate Groq-specific message content and message chunks into a standardized `langchain_core` content block format. It handles various content types, including tool calls, tool results, and text, and registers these translators for integration within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/block_translators/__init__.py",
            "description": "This file manages the registration and retrieval of content block translators for various AI model providers. It allows provider-specific message content to be converted into a standardized `ContentBlock` format for `AIMessage` and `AIMessageChunk` objects.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/block_translators/bedrock_converse.py",
            "description": "This file contains functions to translate and adapt content blocks from the Amazon Bedrock Converse format into LangChain Core's standard content block format.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/block_translators/langchain_v0.py",
            "description": "This file provides functions to convert multimodal content blocks (images, audio, files) from the legacy LangChain v0 format to the current LangChain v1 content block format. It handles various source types like URL, base64, and ID, while preserving unrecognized keys as 'extras'.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/block_translators/openai.py",
            "description": "This file provides utility functions for converting content blocks (e.g., images, files, audio, tool calls) between LangChain's internal 'v1' format and the formats expected by OpenAI's Chat Completions and Responses APIs.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/block_translators/anthropic.py",
            "description": "This file provides utilities to convert content blocks and messages from Anthropic's format into LangChain's standard v1 content block format, handling various types including text, files, images, and tool calls.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/block_translators/bedrock.py",
            "description": "This file provides functions to translate message content and message chunks from Bedrock's format into LangChain's standard content block format, including handling tool calls. It registers these translators for use within the LangChain core.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/langchain/messages/__init__.py",
            "description": "This file serves as the `__init__.py` for the `langchain.messages` package, re-exporting core message types and content block types from `langchain_core.messages`. It provides a centralized access point for various message roles (human, AI, system) and content formats (text, image, audio) used within the LangChain framework.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 69
          },
          {
            "name": "Christophe Bornet",
            "percent": 11
          },
          {
            "name": "Weichen Zhao",
            "percent": 4
          }
        ]
      },
      "Model Profile Registry": {
        "files": [
          {
            "path": "libs/partners/mistralai/langchain_mistralai/data/__init__.py",
            "description": "This file initializes the 'data' package within the 'langchain_mistralai' library, specifically for model profile data. It indicates that all edits should be directed to 'profile_augmentations.toml'.",
            "spof": true
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/data/__init__.py",
            "description": "This file contains model profile data for the `langchain_anthropic` library. It specifies that all modifications should be made in `profile_augmentations.toml`.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/langchain_openai/data/__init__.py",
            "description": "This file contains model profile data and indicates that all modifications should be made in `profile_augmentations.toml`.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/langchain_openai/data/_profiles.py",
            "description": "This file contains auto-generated profiles for various AI models, detailing their specifications and capabilities. It is generated by the `langchain-profiles` CLI tool based on data from the `models.dev` project.",
            "spof": true
          },
          {
            "path": "libs/partners/groq/langchain_groq/data/__init__.py",
            "description": "This file serves as an entry point for the `data` package within `langchain_groq`, specifically for model profile data. It indicates that all modifications should be made in the `profile_augmentations.toml` file.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/langchain_perplexity/data/_profiles.py",
            "description": "This file contains auto-generated model profiles for LangChain, defining capabilities and token limits for various Perplexity AI 'sonar' models. It is automatically generated by a CLI tool and should not be edited manually.",
            "spof": true
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/data/_profiles.py",
            "description": "This auto-generated file defines profiles for various large language models, including their token limits and capabilities like tool calling or media inputs/outputs. It serves as a central registry for model metadata within the LangChain framework.",
            "spof": true
          },
          {
            "path": "libs/partners/huggingface/langchain_huggingface/data/__init__.py",
            "description": "This file initializes the 'data' package within the 'langchain_huggingface' library. It is designed to hold model profile data, with all modifications explicitly directed to 'profile_augmentations.toml'.",
            "spof": true
          },
          {
            "path": "libs/partners/xai/langchain_xai/data/__init__.py",
            "description": "This file is intended to hold model profile data. It explicitly states that all edits should be made in 'profile_augmentations.toml'.",
            "spof": true
          },
          {
            "path": "libs/partners/xai/langchain_xai/data/_profiles.py",
            "description": "This file contains auto-generated model profiles for various Grok language models, defining their capabilities and limitations (e.g., token limits, input/output modalities). It is generated by the `langchain-profiles` CLI tool and should not be edited manually.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/language_models/model_profile.py",
            "description": "This file defines the `ModelProfile` TypedDict, which specifies the capabilities and constraints of language models, including input/output types, token limits, and feature support like tool calling and structured output. It also defines `ModelProfileRegistry` for mapping model identifiers to their profiles.",
            "spof": true
          },
          {
            "path": "libs/model-profiles/README.md",
            "description": "This README describes the `langchain-model-profiles` CLI tool, which is used for fetching and updating model capability data from `models.dev` to maintain LangChain model profiles in integration packages.",
            "spof": true
          },
          {
            "path": "libs/model-profiles/langchain_model_profiles/cli.py",
            "description": "This CLI tool refreshes model profile data for LangChain from models.dev. It downloads model information, merges it with local augmentations defined in `profile_augmentations.toml`, and generates a `profiles.py` file containing the consolidated model profiles.",
            "spof": true
          },
          {
            "path": "libs/model-profiles/tests/unit_tests/test_cli.py",
            "description": "This file contains unit tests for the `refresh` command-line interface (CLI) function within the `langchain_model_profiles` package. It verifies that the CLI correctly generates model profile files, handles augmentations, and manages various error conditions.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "ccurme",
            "percent": 97
          },
          {
            "name": "Mason Daugherty",
            "percent": 2
          },
          {
            "name": "Kesku",
            "percent": 1
          }
        ]
      },
      "Backward Compatibility Layer": {
        "files": [
          {
            "path": "libs/partners/openai/langchain_openai/chat_models/_compat.py",
            "description": "This module provides utility functions for converting between different `AIMessage` output formats (v0 and responses/v1) used by `ChatOpenAI` to ensure backward compatibility.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/base_language.py",
            "description": "This deprecated module exists solely for backward compatibility, re-exporting the `BaseLanguageModel` class from `langchain_core`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/anyscale.py",
            "description": "This file serves as a compatibility layer, providing a dynamic import redirect for the `ChatAnyscale` class from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/javelin_ai_gateway.py",
            "description": "This file provides a compatibility layer for `ChatJavelinAIGateway` and `ChatParams`, redirecting their imports from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/mlflow.py",
            "description": "This file acts as a compatibility layer, providing a deprecated import path for `ChatMlflow` which has been moved to `langchain_community`. It dynamically re-exports the class while handling potential deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/fireworks.py",
            "description": "This file serves as a compatibility layer, redirecting imports of `ChatFireworks` from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/jinachat.py",
            "description": "This file re-exports the `JinaChat` class from `langchain_community` to maintain backward compatibility, dynamically handling its import and managing deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/human.py",
            "description": "This file facilitates dynamic imports for `HumanInputChatModel`, acting as a compatibility layer to redirect its import from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/azureml_endpoint.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `AzureMLChatOnlineEndpoint` and `LlamaContentFormatter` from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/volcengine_maas.py",
            "description": "This file manages the deprecation of VolcEngineMaasChat and convert_dict_to_message by redirecting imports from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/ollama.py",
            "description": "This file acts as a re-export or compatibility layer for `ChatOllama`, dynamically importing it from `langchain_community.chat_models.ollama`. It is likely used to manage module reorganization or maintain backward compatibility within the `langchain` project.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/ernie.py",
            "description": "This file acts as a compatibility shim, dynamically importing the `ErnieBotChat` class from `langchain_community` while maintaining its presence in `langchain_classic` for backward compatibility during deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/azure_openai.py",
            "description": "This file re-exports `AzureChatOpenAI` from `langchain_community.chat_models.azure_openai` for `langchain_classic`, acting as a compatibility or deprecation layer.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/bedrock.py",
            "description": "This file provides backward compatibility for `BedrockChat` and `ChatPromptAdapter` by re-exporting them from `langchain_community.chat_models.bedrock` using a dynamic importer.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/__init__.py",
            "description": "This file serves as the `langchain_classic.chat_models` package's entry point, defining and re-exporting various chat model classes. It primarily handles the deprecation of importing chat models directly from `langchain` by dynamically redirecting imports to `langchain_community` and issuing a warning.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/baichuan.py",
            "description": "This file acts as a compatibility layer or redirector, dynamically importing the `ChatBaichuan` class from the `langchain_community` package. It helps manage module restructuring and provides a consistent access point within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/fake.py",
            "description": "This file provides backward compatibility for `FakeListChatModel` and `FakeMessagesListChatModel` by re-exporting them from `langchain_community.chat_models.fake`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/mlflow_ai_gateway.py",
            "description": "This file provides backward compatibility for `ChatMLflowAIGateway` and `ChatParams` by dynamically re-exporting them from `langchain_community` while being part of `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/databricks.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for the `ChatDatabricks` class which has been moved to `langchain_community`. It ensures backward compatibility while facilitating the migration of the module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/anthropic.py",
            "description": "This file serves as a compatibility layer for deprecated imports of `ChatAnthropic` and related functions, redirecting them from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/minimax.py",
            "description": "This file facilitates backward compatibility by dynamically redirecting imports of the `MiniMaxChat` class from `langchain_classic` to its new location in `langchain_community`, ensuring older code continues to function while pointing to the updated package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/promptlayer_openai.py",
            "description": "This file serves as a compatibility layer, providing dynamic lookup and handling for the `PromptLayerChatOpenAI` class, which has been moved to `langchain_community` and is considered deprecated in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/everlyai.py",
            "description": "This file serves as a compatibility layer, dynamically importing `ChatEverlyAI` from `langchain_community.chat_models.everlyai`. It manages the deprecation of `ChatEverlyAI` in its current location by redirecting imports to the new module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/meta.py",
            "description": "This file manages deprecated imports for chat models, dynamically redirecting calls to `convert_messages_to_prompt_llama` from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/pai_eas_endpoint.py",
            "description": "This file provides backward compatibility for the `PaiEasChatEndpoint` class by dynamically redirecting its import from `langchain_classic` to `langchain_community`, likely issuing a deprecation warning in the process.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/litellm.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting ChatLiteLLM and ChatLiteLLMException from `langchain_community` for `langchain_classic` users. It facilitates migration by providing a deprecation shim for these classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/openai.py",
            "description": "This file acts as a re-export shim for the `ChatOpenAI` class, dynamically importing it from `langchain_community` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/google_palm.py",
            "description": "This file provides a compatibility layer for `ChatGooglePalm` and `ChatGooglePalmError`, dynamically importing them from `langchain_community` to maintain backward compatibility for `langchain_classic` users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/hunyuan.py",
            "description": "This file acts as a deprecation shim, dynamically re-exporting `ChatHunyuan` from `langchain_community.chat_models.hunyuan` to maintain backward compatibility for `langchain_classic` users. It helps manage the transition of imports to new locations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/yandex.py",
            "description": "This file re-exports `ChatYandexGPT` from `langchain_community` into `langchain_classic` using a dynamic import mechanism. It facilitates backward compatibility or handles deprecation by redirecting imports to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/tongyi.py",
            "description": "This file re-exports the `ChatTongyi` class from `langchain_community` to maintain backward compatibility for `langchain_classic` users. It uses a dynamic import mechanism to handle deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/konko.py",
            "description": "This file acts as a compatibility layer for the `ChatKonko` class, dynamically redirecting imports from `langchain_classic` to its new location in `langchain_community` due to deprecation. It ensures backward compatibility for existing code.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/gigachat.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting the `GigaChat` class which has been moved to `langchain_community`. It uses an import helper to maintain backward compatibility for users still referencing `GigaChat` from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/azure_openai.py",
            "description": "This file facilitates backward compatibility for the `AzureOpenAIEmbeddings` class, dynamically importing it from `langchain_community.embeddings` to handle deprecated references. It serves as a redirector to ensure older codebases continue to function after module reorganization.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/awa.py",
            "description": "This file serves as a compatibility layer or re-export mechanism for `AwaEmbeddings`, dynamically importing it from `langchain_community.embeddings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/bookend.py",
            "description": "This file acts as a compatibility layer or re-exporter for the `BookendEmbeddings` class. It dynamically imports `BookendEmbeddings` from `langchain_community.embeddings`, likely to manage deprecation or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/__init__.py",
            "description": "This file serves as a central entry point for various embedding models, dynamically importing them from `langchain_community.embeddings` for backward compatibility. It allows users to access different embedding implementations through a unified interface.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/cloudflare_workersai.py",
            "description": "This file acts as a compatibility layer for `CloudflareWorkersAIEmbeddings`, dynamically importing it from `langchain_community`. It helps manage deprecated imports by redirecting to the updated module location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/clarifai.py",
            "description": "This file facilitates the dynamic and deprecated import of `ClarifaiEmbeddings` from `langchain_community.embeddings`, ensuring compatibility and guiding users to the new location of the class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/huggingface.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting HuggingFace embedding classes from `langchain_community.embeddings` to maintain backward compatibility or simplify imports. It handles the lookup and import of these potentially deprecated classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/gpt4all.py",
            "description": "This file acts as a compatibility layer or proxy for `GPT4AllEmbeddings`, dynamically importing it from `langchain_community.embeddings` to handle potential deprecations or refactors.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/deepinfra.py",
            "description": "This file acts as a compatibility layer or proxy for `DeepInfraEmbeddings`, dynamically importing it from `langchain_community.embeddings` when accessed from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/johnsnowlabs.py",
            "description": "This file facilitates backward compatibility for the `JohnSnowLabsEmbeddings` class, which has been moved from `langchain_classic` to `langchain_community`. It dynamically imports the class from its new location while providing a deprecated lookup mechanism.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/infinity.py",
            "description": "This file serves as a compatibility layer, re-exporting `InfinityEmbeddings` and `TinyAsyncOpenAIInfinityEmbeddingClient` from `langchain_community` while managing potential deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/nlpcloud.py",
            "description": "This file provides backward compatibility for `NLPCloudEmbeddings` by redirecting its import from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/embaas.py",
            "description": "This file acts as a compatibility layer for the `EmbaasEmbeddings` class. It enables dynamic lookup and redirects imports from `langchain_classic` to `langchain_community`, facilitating migration and providing backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/sagemaker_endpoint.py",
            "description": "This file provides a compatibility layer for deprecated imports of `EmbeddingsContentHandler` and `SagemakerEndpointEmbeddings`, dynamically redirecting them to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/databricks.py",
            "description": "This file provides backward compatibility for the `DatabricksEmbeddings` class, redirecting imports from `langchain_classic` to its new location in `langchain_community.embeddings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/self_hosted.py",
            "description": "This file dynamically imports and re-exports the `SelfHostedEmbeddings` class, likely for deprecation handling or to consolidate access from `langchain_community.embeddings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/localai.py",
            "description": "This file provides backward compatibility for `LocalAIEmbeddings` by dynamically redirecting its import from `langchain_classic` to `langchain_community`. It uses a deprecated lookup mechanism to manage this transition.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/fastembed.py",
            "description": "This file acts as a redirector for the `FastEmbedEmbeddings` class, ensuring that imports from `langchain_classic` are dynamically resolved to their new location in `langchain_community.embeddings`. It facilitates a soft deprecation and migration path for users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/javelin_ai_gateway.py",
            "description": "This file provides backward compatibility for `JavelinAIGatewayEmbeddings` by dynamically importing it from `langchain_community.embeddings`, while signaling its deprecation in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/fake.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `FakeEmbeddings` and `DeterministicFakeEmbedding` from `langchain_classic` to their new location in `langchain_community.embeddings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/mosaicml.py",
            "description": "This file re-exports `MosaicMLInstructorEmbeddings` from `langchain_community.embeddings`, acting as an import shim to maintain backward compatibility while the class has been moved to a different package. It handles dynamic imports and potential deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/mlflow_gateway.py",
            "description": "This file serves as a compatibility layer for `MlflowAIGatewayEmbeddings`, dynamically importing it from its new location in `langchain_community.embeddings` to maintain backward compatibility for users. It uses a deprecated lookup mechanism to redirect imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/modelscope_hub.py",
            "description": "This file acts as a compatibility layer for `ModelScopeEmbeddings`, dynamically redirecting imports from `langchain_classic` to `langchain_community`. It facilitates handling deprecated imports by ensuring backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/tensorflow_hub.py",
            "description": "This file provides backward compatibility for `TensorflowHubEmbeddings` by dynamically importing it from `langchain_community.embeddings`, indicating its relocation from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/sentence_transformer.py",
            "description": "This file acts as a compatibility layer, dynamically importing and exposing `SentenceTransformerEmbeddings` from `langchain_community.embeddings`. It is likely used for handling module deprecation or migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/spacy_embeddings.py",
            "description": "This file serves as a compatibility layer for `SpacyEmbeddings`, dynamically importing it from `langchain_community.embeddings`. It facilitates smooth transitions for users during module restructuring or deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/llamacpp.py",
            "description": "This file acts as a compatibility layer and redirect for the `LlamaCppEmbeddings` class, which has been moved to `langchain_community.embeddings`. It dynamically imports the class from its new location to maintain backward compatibility and handle deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/base.py",
            "description": "This module provides backward-compatible exports of core language model classes (LLM, BaseLLM, BaseLanguageModel) to ensure stable imports for older LangChain versions.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/aleph_alpha.py",
            "description": "This file acts as a compatibility layer, redirecting imports of the `AlephAlpha` LLM class from `langchain_classic` to its new location in `langchain_community.llms`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/aviary.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting the `Aviary` LLM class from `langchain_community.llms` to handle deprecation or migration within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/gpt4all.py",
            "description": "This file provides a mechanism to dynamically import `GPT4All` from `langchain_community.llms`, primarily handling deprecated import paths. It acts as a transitional module for accessing the `GPT4All` class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/bittensor.py",
            "description": "This file acts as a compatibility layer or stub, redirecting imports for the `NIBittensorLLM` class from `langchain_classic` to its new location in `langchain_community.llms`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/amazon_api_gateway.py",
            "description": "This file acts as a compatibility layer, dynamically importing the `AmazonAPIGateway` class from `langchain_community.llms`. It is designed to handle deprecated imports and ensure existing code continues to function by redirecting to the new module location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/edenai.py",
            "description": "This file provides backward compatibility for importing the `EdenAI` LLM, dynamically re-exporting it from `langchain_community.llms`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/anthropic.py",
            "description": "This file acts as a redirection module for the Anthropic LLM, handling deprecated imports from `langchain_classic` by dynamically pointing to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/__init__.py",
            "description": "This file serves as the `__init__.py` for the LLMs package, providing access to a wide array of Large Language Model (LLM) implementations from various providers, primarily through lazy imports from `langchain_community`.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/llms/gooseai.py",
            "description": "This file provides a compatibility layer for the `GooseAI` LLM, dynamically redirecting imports from `langchain_classic` to its new location in `langchain_community.llms` to handle deprecated paths. It ensures that older codebases using the classic import path can still access the `GooseAI` class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/huggingface_pipeline.py",
            "description": "This file re-exports the `HuggingFacePipeline` class from `langchain_community` for backward compatibility, allowing it to be accessed via `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/bedrock.py",
            "description": "This file acts as an import shim for Bedrock LLM classes, dynamically redirecting deprecated imports from `langchain_classic` to `langchain_community`. It ensures backward compatibility during package restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/gradient_ai.py",
            "description": "This file acts as a compatibility layer, providing dynamic import and deprecation warnings for `GradientLLM` and `TrainResult` which have been moved to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/chatglm.py",
            "description": "This file acts as a compatibility layer, re-exporting the `ChatGLM` class from `langchain_community.llms` to maintain backward compatibility for older `langchain-classic` imports. It facilitates a smooth transition for users migrating to the newer `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/azureml_endpoint.py",
            "description": "This file acts as a compatibility layer, providing dynamic import resolution for Azure ML Endpoint-related classes that have been moved to the `langchain_community` package, thereby handling deprecation and ensuring backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/mosaicml.py",
            "description": "This file acts as a shim for the `MosaicML` LLM class, redirecting imports from `langchain_classic` to its new location in `langchain_community.llms`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/ctransformers.py",
            "description": "This file acts as a compatibility shim for the `CTransformers` class, re-exporting it from `langchain_community.llms`. It enables continued functionality for older imports from `langchain_classic` while guiding users to the new module location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/ctranslate2.py",
            "description": "This file acts as a redirection or compatibility layer for the `CTranslate2` LLM, dynamically importing it from `langchain_community.llms`. It facilitates module reorganization and handles potential deprecation warnings for `langchain_classic` users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/arcee.py",
            "description": "This file serves as a shim for handling deprecated imports, specifically redirecting the `Arcee` LLM class from `langchain_classic` to its new location in `langchain_community.llms` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/modal.py",
            "description": "This file acts as a re-exporter for the `Modal` LLM class, dynamically importing it from `langchain_community.llms` to manage deprecated imports or consolidate module paths within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/cloudflare_workersai.py",
            "description": "This file provides a deprecated re-export of the `CloudflareWorkersAI` class, redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/cerebriumai.py",
            "description": "This file serves as a deprecation handler, redirecting imports of 'CerebriumAI' from 'langchain_classic' to its new location in 'langchain_community.llms'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/anyscale.py",
            "description": "This file acts as a compatibility layer for the `Anyscale` LLM integration, redirecting imports from `langchain_classic.llms` to its new location in `langchain_community.llms` to handle deprecation or refactoring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/baidu_qianfan_endpoint.py",
            "description": "This file acts as a deprecation handler, dynamically redirecting imports for `QianfanLLMEndpoint` from `langchain_classic` to its new location within `langchain_community`. It ensures backward compatibility while prompting users towards the updated module structure.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/openllm.py",
            "description": "This file serves as a shim for backward compatibility, dynamically re-exporting the `OpenLLM` class from `langchain_community.llms` to maintain consistent import paths during a refactoring or deprecation period.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/fake.py",
            "description": "This file provides backward compatibility for `FakeListLLM` and `FakeStreamingListLLM` by dynamically redirecting deprecated imports to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/human.py",
            "description": "This file acts as a compatibility layer, re-exporting `HumanInputLLM` from the `langchain_community.llms` package to maintain backward compatibility for modules still referencing it from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/huggingface_endpoint.py",
            "description": "This file re-exports the `HuggingFaceEndpoint` class, redirecting imports from `langchain_classic` to `langchain_community.llms`. It acts as a compatibility layer for module migration within the LangChain library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/rwkv.py",
            "description": "This file acts as a compatibility layer or re-exporter for the `RWKV` LLM class, dynamically importing it from `langchain_community.llms` into the `langchain_classic` namespace, likely to manage deprecations or refactoring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/loading.py",
            "description": "This file manages deprecated LLM loading functions, `load_llm` and `load_llm_from_config`, by dynamically redirecting their imports to the `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/cohere.py",
            "description": "This file acts as a compatibility layer to dynamically re-export the `Cohere` LLM class from `langchain_community.llms`, likely to support older imports or facilitate module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/openai.py",
            "description": "This file acts as a compatibility layer, re-exporting OpenAI-related LLM classes that have been moved to `langchain_community`. It dynamically looks up deprecated imports to maintain backward compatibility and guide users to the new module locations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/predibase.py",
            "description": "This file acts as a compatibility layer for the `Predibase` LLM, redirecting its import from `langchain_classic.llms` to `langchain_community.llms` to handle deprecation or relocation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/deepinfra.py",
            "description": "This file provides a compatibility shim for the `DeepInfra` LLM, dynamically importing it from `langchain_community.llms`. It ensures backward compatibility while redirecting users to the updated module location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/huggingface_hub.py",
            "description": "This file serves as a compatibility layer to re-export the `HuggingFaceHub` LLM class. It dynamically imports `HuggingFaceHub` from `langchain_community.llms`, likely managing module relocation or deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/octoai_endpoint.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting the `OctoAIEndpoint` class from its new location in `langchain_community.llms`. It manages deprecated imports to ensure backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/ai21.py",
            "description": "This file serves as a redirection or deprecation shim for AI21-related classes. It dynamically imports `AI21` and `AI21PenaltyData` from `langchain_community` when accessed from `langchain_classic`, facilitating a smooth transition for users during library restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/pai_eas_endpoint.py",
            "description": "This file serves as a shim for backward compatibility, redirecting imports of 'PaiEasEndpoint' from its old location to 'langchain_community.llms'. It dynamically handles deprecated imports to ensure functionality while guiding users to the new module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/ollama.py",
            "description": "This file acts as a compatibility layer, re-exporting the `Ollama` LLM class from `langchain_community.llms` to maintain backward compatibility for `langchain_classic` users. It dynamically handles imports and deprecation for the `Ollama` class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/manifest.py",
            "description": "This file provides a compatibility layer for the `ManifestWrapper` LLM, allowing it to be dynamically imported from its new location in `langchain_community.llms` while maintaining backward compatibility for older references. It handles deprecated imports by redirecting them.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/sagemaker_endpoint.py",
            "description": "This file serves as a compatibility layer, redirecting imports of `SagemakerEndpoint` and `LLMContentHandler` from `langchain_classic` to their new locations within `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/symblai_nebula.py",
            "description": "This file provides a deprecation layer for the `Nebula` LLM, dynamically importing it from `langchain_community.llms` while maintaining compatibility for `langchain_classic` users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/together.py",
            "description": "This file acts as a compatibility layer, re-exporting the `Together` LLM class from `langchain_community.llms` for `langchain_classic` users, likely to manage deprecation or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/koboldai.py",
            "description": "This file acts as a compatibility layer or redirect for the `KoboldApiLLM` class. It enables importing `KoboldApiLLM` from its former location in `langchain_classic.llms` while transparently fetching it from `langchain_community.llms`, managing deprecation and package reorganization.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/petals.py",
            "description": "This file facilitates the re-export of the `Petals` LLM from `langchain_community.llms`, managing its import and handling potential deprecation or migration within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/openlm.py",
            "description": "This file acts as a compatibility layer for the `OpenLM` LLM, dynamically importing it from `langchain_community.llms` to facilitate deprecation handling within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/stochasticai.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting the `StochasticAI` class from `langchain_community.llms`. It allows older code that expects `StochasticAI` in `langchain_classic` to function correctly by redirecting the import.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/xinference.py",
            "description": "This file provides a compatibility layer for the `Xinference` LLM, dynamically importing it from `langchain_community.llms` and managing its deprecation in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/writer.py",
            "description": "This file facilitates the dynamic import of the `Writer` class, primarily handling its deprecation and redirection from `langchain_classic` to `langchain_community.llms`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/promptlayer_openai.py",
            "description": "This file serves as a compatibility layer for PromptLayer OpenAI classes, dynamically redirecting imports from `langchain_classic.llms` to `langchain_community.llms` to support deprecation and migration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/self_hosted.py",
            "description": "This file acts as a re-exporter and shim for the `SelfHostedPipeline` class, dynamically redirecting its import from `langchain_community.llms`. It manages deprecated imports and ensures backward compatibility for users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/utils.py",
            "description": "This file facilitates the dynamic import and deprecation handling for `enforce_stop_tokens`, redirecting its usage from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/tongyi.py",
            "description": "This file acts as a deprecation shim for the `Tongyi` LLM, redirecting imports from `langchain_classic.llms` to `langchain_community.llms`. It facilitates a smooth transition while maintaining backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/watsonxllm.py",
            "description": "This file acts as a compatibility shim, dynamically re-exporting the `WatsonxLLM` class from `langchain_community.llms`. Its purpose is to handle deprecated imports from `langchain_classic` by redirecting them to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/self_hosted_hugging_face.py",
            "description": "This file serves as a redirector for `SelfHostedHuggingFaceLLM`, handling deprecated imports by dynamically forwarding them to the `langchain_community` package where the class now resides.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/llamacpp.py",
            "description": "This file acts as a shim, dynamically re-exporting the `LlamaCpp` class from `langchain_community.llms` to maintain backward compatibility or facilitate a module migration. It uses a custom importer to handle this redirection and potential deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/opaqueprompts.py",
            "description": "This file acts as a compatibility layer to dynamically import and expose the `OpaquePrompts` class from `langchain_community.llms`. It facilitates handling deprecated imports by redirecting requests from its old `langchain_classic` location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/pipelineai.py",
            "description": "This file provides a compatibility layer for the `PipelineAI` class within the `langchain_classic` framework. It dynamically imports `PipelineAI` from `langchain_community.llms`, primarily to handle deprecated imports and manage module transitions.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/mlflow_ai_gateway.py",
            "description": "This file acts as a compatibility layer or shim for the `MlflowAIGateway` class. It dynamically imports `MlflowAIGateway` from `langchain_community.llms`, likely managing deprecated access patterns from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/titan_takeoff.py",
            "description": "This file acts as a shim or redirector for the `TitanTakeoff` LLM class, dynamically importing it from `langchain_community.llms`. It ensures backward compatibility and handles the relocation of `TitanTakeoff` within the LangChain library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/embeddings.py",
            "description": "This file re-exports the `Embeddings` class from `langchain_core.embeddings`. It likely maintains API compatibility or organization within the `langchain_classic` module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/messages.py",
            "description": "This file re-exports message-related classes and utility functions from `langchain_core.messages`, primarily for backward compatibility within the `langchain_classic` module structure. It aggregates various message types like `AIMessage`, `HumanMessage`, and `SystemMessage`, along with serialization utilities.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/language_model.py",
            "description": "This file serves as a re-exporting point for core language model abstractions, types, and utility functions from `langchain_core` into the `langchain_classic` module. It makes fundamental language model components accessible from this package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/anthropic.py",
            "description": "This file acts as a compatibility layer, re-exporting Anthropic utility functions from `langchain_community` while managing deprecation for `langchain_classic`.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 72
          },
          {
            "name": "ccurme",
            "percent": 24
          },
          {
            "name": "Christophe Bornet",
            "percent": 4
          }
        ]
      },
      "Core Model Abstractions and Factories": {
        "files": [
          {
            "path": "libs/core/langchain_core/language_models/chat_models.py",
            "description": "This file defines the abstract base class `BaseChatModel` and provides related utilities for implementing and interacting with conversational AI chat models within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/language_models/__init__.py",
            "description": "This file defines and manages the core language model abstractions within LangChain, including both chat models and traditional LLMs, along with their associated classes and utilities. It uses dynamic imports to make these components accessible.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/language_models/llms.py",
            "description": "This file defines the base interface for traditional Large Language Models (LLMs) in LangChain, along with utility functions for caching and retry mechanisms for LLM calls.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/language_models/base.py",
            "description": "This file defines the abstract base classes and interfaces for language models within the LangChain framework. It establishes the common structure for interacting with various language models, including input/output types, generation methods, caching, and callback integration.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/load/__init__.py",
            "description": "This `__init__.py` file serves as the main entry point for the `langchain_core.load` package, aggregating and exposing various serialization and deserialization utilities such as `dumpd`, `dumps`, `load`, and `loads`, along with core classes like `Serializable`.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/embeddings/embeddings.py",
            "description": "This file defines the abstract base class `Embeddings`, providing a standard interface for text embedding models, including methods for embedding documents and queries synchronously and asynchronously.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/embeddings/__init__.py",
            "description": "This file serves as the `__init__.py` for the `langchain_core.embeddings` package, dynamically exporting core embedding-related classes like `Embeddings` and `FakeEmbeddings` from its submodules.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/langchain/embeddings/base.py",
            "description": "This file provides factory functions to initialize embedding models from various providers (e.g., OpenAI, Cohere, HuggingFace) by dynamically importing the necessary classes based on a model string or explicit provider.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/langchain/embeddings/__init__.py",
            "description": "This file serves as the `__init__.py` for the `langchain.embeddings` package, providing core embeddings models and functionalities. It imports and exports the base `Embeddings` class and an initialization function for embeddings.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/langchain/chat_models/__init__.py",
            "description": "This file serves as the entry point for the `langchain.chat_models` package, making core chat model components like `BaseChatModel` and the `init_chat_model` utility directly available for import.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/langchain/chat_models/base.py",
            "description": "This file provides a unified interface and factory functions for initializing and managing chat models from various providers within the LangChain framework. It abstracts away provider-specific import and instantiation details.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_models/base.py",
            "description": "This file provides a unified interface, `init_chat_model`, for initializing chat models from various supported providers, allowing for both fixed and dynamically configurable model instances within LangChain.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/embeddings/base.py",
            "description": "This file provides a unified interface for initializing various embedding models from different providers. It acts as a dispatcher, dynamically importing and configuring the correct embedding class based on the given model name and provider.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/schema/__init__.py",
            "description": "This file serves as the `__init__.py` for the `schema` package, aggregating and re-exporting core LangChain base classes, interfaces, and utility functions related to messages, agents, caches, documents, and output parsing for unified access.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 51
          },
          {
            "name": "Christophe Bornet",
            "percent": 19
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 12
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 277,
      "spofCount": 75
    },
    "busFactor": 4,
    "authorCount": 22
  },
  "Utility": {
    "description": "",
    "functions": {
      "General Utility": {
        "files": [
          {
            "path": "libs/partners/mistralai/scripts/check_imports.py",
            "description": "This script checks if a list of given Python files can be imported successfully as modules. It iterates through the files provided as command-line arguments, attempting to load each one, and reports any import errors along with their tracebacks.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/_import_utils.py",
            "description": "This file provides a utility function, `import_attr`, for dynamically importing attributes from specified modules or packages. It is designed to be used in custom `__getattr__` methods, typically within `__init__.py` files, to facilitate lazy or dynamic loading of submodules and their contents.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/_api/__init__.py",
            "description": "This file serves as an internal API gateway for developer-facing utilities within LangChain Core, specifically managing beta features, deprecation warnings, and path-related helpers. It uses dynamic imports to lazily load these internal API components from submodules.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/_api/beta_decorator.py",
            "description": "This module provides helper functions and a decorator (`@beta`) for marking parts of the LangChain API as being in beta, issuing warnings upon their use, and managing these beta warnings.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/_api/internal.py",
            "description": "This file provides a utility function `is_caller_internal` to determine if a calling function originates from an internal `langchain` module by inspecting the call stack.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/_api/deprecation.py",
            "description": "This module provides internal helper functions and decorators for managing and issuing deprecation warnings within the LangChain API.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/_api/path.py",
            "description": "This file provides utility functions for converting file paths into relative paths or Python-style import paths within the package structure.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/sys_info.py",
            "description": "This file provides a utility function `print_sys_info` to output detailed system information, including OS, Python version, and versions of installed LangChain-related packages and their sub-dependencies, for debugging purposes.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/stores.py",
            "description": "This module defines abstract interfaces for key-value stores (`BaseStore`) and provides concrete in-memory implementations (`InMemoryStore`, `InMemoryByteStore`), primarily to support caching mechanisms.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/rate_limiters.py",
            "description": "This file defines an abstract base class for rate limiters and provides an in-memory, thread-safe implementation using a token bucket algorithm, supporting both synchronous and asynchronous acquisition.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/utils/json_schema.py",
            "description": "Provides utility functions for JSON Schema, primarily for resolving and inlining '$ref' references within a schema object, including handling circular and mixed references.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/usage.py",
            "description": "This file provides a utility function for recursively combining two dictionaries by applying a specified integer operation to their corresponding integer values. It supports nested dictionaries for this operation.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/image.py",
            "description": "This file provides utilities for image processing, specifically indicating that functions like `encode_image` and `image_to_data_url` have been removed for security reasons to prevent potential misuse.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/uuid.py",
            "description": "This module provides utility functions for generating UUIDv7s, which are monotonic and time-ordered UUIDs suitable for tracing and similar operations. It primarily exports a `uuid7` function that can generate these IDs from a nanosecond timestamp or the current time.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/utils/__init__.py",
            "description": "This file serves as the __init__.py for the langchain_core.utils package, providing a central point to access various utility functions dynamically imported from submodules. It exposes a set of core utility functions while deferring their actual import until they are first used, optimizing startup performance.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/mustache.py",
            "description": "This file provides functionality for parsing and rendering Mustache templates, adapted from the 'chevron' library. It tokenizes templates, handles delimiters, manages scopes for data lookup, and includes HTML escaping utilities.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/aiter.py",
            "description": "This file provides utilities for working with asynchronous iterators and generators, including an async version of `itertools.tee` for splitting an async iterable into multiple independent async iterators, and an `aclosing` context manager.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/strings.py",
            "description": "This file provides various utility functions for string manipulation, including converting different data types to strings, formatting iterables, and sanitizing strings for PostgreSQL compatibility.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/json.py",
            "description": "This file provides utilities for robust JSON parsing, especially for handling partial or malformed JSON strings, extracting JSON from markdown, and escaping special characters within JSON values. It is designed to be more tolerant of LLM output formats.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/html.py",
            "description": "This file provides utility functions for parsing HTML content, specifically for extracting and processing links. It includes functionalities to find all links in an HTML string, convert them to absolute paths, and filter them based on various criteria like excluding external links or specific prefixes/suffixes.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/_merge.py",
            "description": "This file provides utility functions for merging Python dictionaries and lists. It includes specific logic for handling `None` values, different data types, and merging nested structures like dictionaries within lists based on an 'index' key.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/input.py",
            "description": "This file provides utility functions for coloring and bolding text using ANSI escape codes, and for printing formatted text to standard output or a file.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/iter.py",
            "description": "This file provides utility functions and classes for working with iterators, including a custom `Tee` implementation for splitting an iterator into multiple independent iterators, and a function for batching iterable items.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/utils/utils.py",
            "description": "This file contains generic utility functions for common tasks such as argument validation, error handling, dynamic module imports, package version checking, and Pydantic model introspection.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/pydantic.py",
            "description": "This file provides utility functions for working with Pydantic models, offering compatibility layers and helper methods for both Pydantic v1 and v2, including version detection, model introspection, and dynamic model creation.",
            "spof": false
          },
          {
            "path": "libs/core/README.md",
            "description": "This README provides an overview of LangChain Core, outlining its purpose as the base abstractions for the LangChain ecosystem, its benefits, installation instructions, and links to documentation and contribution guidelines.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/test_globals.py",
            "description": "This file contains unit tests for the global debug flag functionality within `langchain_core`, verifying that the debug state can be correctly set and retrieved.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/test_sys_info.py",
            "description": "This file contains a unit test for the `print_sys_info` function from `langchain_core`. It verifies that calling `print_sys_info` executes without raising any exceptions.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/pydantic_utils.py",
            "description": "This file provides utility functions for normalizing and standardizing JSON schemas generated from Pydantic models, addressing version differences and common schema inconsistencies.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/_api/test_imports.py",
            "description": "This file is a unit test that verifies the `__all__` variable in the `langchain_core._api` module exposes the expected set of public API elements. It ensures that the module's public interface matches a predefined list.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/_api/test_path.py",
            "description": "This file contains unit tests for the `langchain_core._api.path.as_import_path` utility function, verifying its ability to convert file system paths into Python-style import paths relative to a given root directory.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/_api/test_beta_decorator.py",
            "description": "This file contains unit tests for the `beta` decorator and `warn_beta` function, ensuring they correctly issue warnings and modify docstrings for beta-marked functions, methods, properties, and classes. It covers synchronous, asynchronous, class, and static members, as well as property setters and deleters.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/_api/test_deprecation.py",
            "description": "This file contains unit tests for the deprecation utility functions and decorators (`warn_deprecated`, `deprecated`) provided by the `langchain_core._api.deprecation` module. It verifies that deprecation warnings are issued correctly for various Python constructs like functions, methods, properties, and classes.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/rate_limiters/test_in_memory_rate_limiter.py",
            "description": "This file contains unit tests for the `InMemoryRateLimiter` class, verifying its synchronous and asynchronous rate limiting mechanisms, token acquisition, and max bucket size handling.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/load/test_serializable.py",
            "description": "This file contains unit tests for the `Serializable` class and related serialization/deserialization utilities (`dumpd`, `dumps`, `load`, `loads`) in `langchain_core.load`, covering various scenarios like secret handling, Pydantic models, and formatting options.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_rm_titles.py",
            "description": "This file contains unit tests for the `_rm_titles` utility function, ensuring it correctly removes 'title' fields from JSON schemas while preserving other properties.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_formatting.py",
            "description": "This file contains unit tests for the `StrictFormatter` class and the `formatter` singleton from `langchain_core.utils.formatting`. It verifies the correct behavior of string formatting, including strict handling of keyword arguments and validation of input variables.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_uuid_utils.py",
            "description": "This file contains unit tests for the `uuid7` utility function, verifying its correct timestamp generation and monotonic increase over successive calls.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_aiter.py",
            "description": "This file contains unit tests for the `abatch_iterate` utility, which batches items from an asynchronous iterable into lists of a specified size.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_iter.py",
            "description": "This file contains unit tests for the `batch_iterate` utility function, which groups elements from an iterable into batches of a specified size. It includes parameterized tests to verify correct batching behavior for various input sizes and iterables.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_html.py",
            "description": "This file contains unit tests for utility functions that extract and process links from HTML content. It specifically tests `find_all_links` and `extract_sub_links` for various link formats and filtering conditions.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_core.utils` correctly lists all expected public imports. It ensures the module's public API surface is as intended.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_usage.py",
            "description": "This file contains unit tests for the `_dict_int_op` utility function, which performs element-wise operations on dictionaries containing integer values, potentially nested.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_json_schema.py",
            "description": "This file contains unit tests for the `dereference_refs` utility function, which resolves internal JSON schema references (e.g., '$ref'). It covers various scenarios including nested, cyclical, and list-indexed references, ensuring the utility correctly expands schema definitions.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_strings.py",
            "description": "This file contains unit tests for various string utility functions, including sanitization for PostgreSQL, converting lists to comma-separated strings, and stringifying different data structures.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_utils.py",
            "description": "This file contains unit tests for various utility functions within the `langchain_core` library, including package version checking, dictionary merging, guarded imports, environment variable handling, and Pydantic model field introspection.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_pydantic.py",
            "description": "This file contains unit tests for custom Pydantic utilities and decorators, including `pre_init`, `is_basemodel_subclass`, `is_basemodel_instance`, `create_model_v2`, and `get_fields` within the `langchain_core.utils.pydantic` module.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/stores/test_in_memory.py",
            "description": "This file contains unit tests for the `InMemoryStore` class, covering its synchronous and asynchronous key-value store operations such as get, set, delete, and key enumeration.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/dependencies",
            "description": "This directory contains unit tests specifically designed to verify the correct handling and resolution of dependencies within the core library. It ensures that the dependency management mechanisms function as expected under various scenarios.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/utils/pydantic.py",
            "description": "This file provides utilities for working with Pydantic models, specifically to determine the installed Pydantic major version.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/input.py",
            "description": "This file is a deprecated module within the 'langchain_classic' library, serving to re-export input utility functions from 'langchain_core.utils.input' for backwards compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/__init__.py",
            "description": "This `__init__.py` file serves as a backward compatibility layer for the LangChain library, dynamically importing and issuing warnings for classes that have been moved to new locations within `langchain_classic`, `langchain_community`, or `langchain_core`.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/_api/module_import.py",
            "description": "This file provides a utility function `create_importer` that generates a dynamic import function. Its primary purpose is to help manage deprecated imports by redirecting them to new module locations and issuing deprecation warnings, facilitating transitions for users.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/_api/path.py",
            "description": "This file re-exports path utility functions `as_import_path` and `get_relative_path` from `langchain_core` to make them available within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/_api/__init__.py",
            "description": "This file serves as an internal API utility module for LangChain developers. It provides helper functions primarily for managing deprecation warnings and facilitating module imports within the LangChain framework.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/kuzu.py",
            "description": "This file provides backward compatibility by dynamically re-exporting Kuzu graph QA chain components and utilities that have been moved to the `langchain_community` package. It ensures that older imports from `langchain_classic` are redirected to their new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/load/load.py",
            "description": "This file serves as a re-export of `Reviver`, `load`, and `loads` utilities from `langchain_core.load.load`, providing access to core loading functionalities within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/load/serializable.py",
            "description": "This file re-exports core serialization utilities from `langchain_core.load.serializable`, serving as an aggregation point or compatibility layer for the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/load/dump.py",
            "description": "This file re-exports dumping utilities (default, dumpd, dumps) from `langchain_core.load.dump`, likely serving as a compatibility layer or module alias within the classic LangChain library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/load/__init__.py",
            "description": "This file serves as the `__init__.py` for the `load` module, aggregating and re-exporting serialization (`dumps`, `dumpd`) and deserialization (`loads`, `load`) utilities from `langchain_core` for convenience.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/exceptions.py",
            "description": "This file re-exports the `LangChainException` from `langchain_core` to make it accessible within the `langchain_classic.schema` module. It serves as a compatibility or organizational layer for exceptions.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/pydantic.py",
            "description": "This file provides a utility function to retrieve the major version of the Pydantic library being used.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/json_schema.py",
            "description": "This file re-exports utility functions from `langchain_core.utils.json_schema` that are used for dereferencing JSON schema references, maintaining compatibility within the 'langchain_classic' module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/strings.py",
            "description": "This file re-exports string utility functions such as `comma_list`, `stringify_dict`, and `stringify_value` from `langchain_core.utils.strings`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/formatting.py",
            "description": "This file re-exports the `StrictFormatter` class from `langchain_core.utils.formatting`, making it accessible within the `langchain_classic` package for utility functions.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/utils.py",
            "description": "This file re-exports a collection of utility functions from `langchain_core.utils.utils`, making them accessible within the `langchain_classic` module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/ernie_functions.py",
            "description": "This file serves as a compatibility layer for `ernie_functions` utilities, dynamically redirecting deprecated imports from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/html.py",
            "description": "This file re-exports HTML utility functions and constants for link extraction and parsing, primarily from `langchain_core`. It serves as an organizational module or compatibility layer within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/math.py",
            "description": "This file acts as a compatibility layer or proxy, dynamically re-exporting math utility functions like `cosine_similarity` and `cosine_similarity_top_k` from `langchain_community.utils.math`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/aiter.py",
            "description": "This file re-exports asynchronous iterator utility classes and functions (NoLock, Tee, py_anext) from `langchain_core.utils.aiter` for use within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/input.py",
            "description": "This file re-exports utility functions for text formatting and console output, such as bolding, coloring, and printing text, from the `langchain_core` library. It serves as a compatibility layer or central access point for these input/output utilities within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/iter.py",
            "description": "This file re-exports iteration utility functions such as `NoLock`, `Tee`, `batch_iterate`, and `tee_peer` from the `langchain_core` library. It serves to make these core utilities accessible within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/__init__.py",
            "description": "This file serves as the `__init__.py` for the `utils` module, re-exporting a collection of general utility functions from `langchain_core` and dynamically importing additional utilities like `cosine_similarity` from `langchain_community`.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/storage/in_memory.py",
            "description": "This file provides simple, non-thread-safe in-memory store implementations (using dictionaries) primarily for unit testing purposes, without any eviction policy. It exports `InMemoryBaseStore`, `InMemoryByteStore`, and `InMemoryStore`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/storage/exceptions.py",
            "description": "This file re-exports the `InvalidKeyException` from `langchain_core.stores`, making it directly accessible within the `langchain_classic.storage` module for consistent exception handling.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/storage/file_system.py",
            "description": "This file implements a `ByteStore` interface using the local file system, allowing byte data to be stored, retrieved, and managed as files within a specified root directory. It provides methods for reading, writing, deleting, and listing keys (file paths) with optional permission handling and access time updates.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/asyncio.py",
            "description": "This file provides a compatibility shim for the `asyncio.timeout` function, ensuring it's available across different Python versions by importing from `async_timeout` for older versions and `asyncio` for newer ones.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/bibtex.py",
            "description": "This file dynamically imports `BibtexparserWrapper` from `langchain_community.utilities`, acting as a compatibility layer for accessing this utility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/redis.py",
            "description": "This file acts as a compatibility layer or proxy, re-exporting Redis utility functions (`TokenEscaper`, `check_redis_module_exist`, `get_client`) from `langchain_community.utilities.redis` for use within the `langchain_classic` package, likely to manage deprecation or module reorganization.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/requests.py",
            "description": "This file acts as a compatibility layer, providing dynamic import resolution for `Requests` and `RequestsWrapper` which have been moved to `langchain_community.utilities`. It uses a deprecated lookup mechanism to ensure backward compatibility for these utilities.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/tensorflow_datasets.py",
            "description": "This file manages the dynamic import and re-export of the `TensorflowDatasets` utility, providing backward compatibility as it has moved to `langchain_community.utilities`. It uses a deprecation lookup to handle the old import path gracefully.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/test_utils.py",
            "description": "This file contains unit tests for the `check_package_version` utility function, ensuring it correctly verifies installed package versions against specified criteria and raises errors when conditions are not met.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/test_formatting.py",
            "description": "This file contains unit tests for the `formatter` utility, verifying its ability to correctly format strings with keyword arguments and handle incorrect argument usage.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_storage.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_classic.schema.storage` module correctly exports expected components like `BaseStore`, `K`, and `V`.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/load/test_dump.py",
            "description": "This file contains unit tests for the `dumps` function and `Serializable` class within `langchain_core.load`. It verifies the correct serialization of `Serializable` objects, including handling of secrets, attributes, inheritance, and Pydantic field aliases.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/utilities/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `langchain_classic.utilities` module correctly lists all expected public utility classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/utils/test_iter.py",
            "description": "This file contains unit tests for the `batch_iterate` utility function, which groups elements from an iterable into batches of a specified size. It ensures the function correctly handles various input sizes and iterables, including empty ones.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/utils/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `utils` module correctly lists all its intended public imports and exports.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/examples/hello_world.js",
            "description": "This JavaScript file defines a simple 'HelloWorld' class and demonstrates its usage by creating an instance and calling its 'sayHello' method. It serves as a basic 'Hello World' example.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/examples/hello_world.py",
            "description": "This file is a basic Python script that prints 'Hello World!', serving as a minimal example or integration test.",
            "spof": false
          },
          {
            "path": "libs/langchain/scripts/check_imports.py",
            "description": "This script verifies that a list of Python files can be loaded by the interpreter without errors. It serves as a quick pre-check before running more extensive tests, printing problematic filenames and their tracebacks if imports fail.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 31
          },
          {
            "name": "Christophe Bornet",
            "percent": 23
          },
          {
            "name": "ccurme",
            "percent": 9
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 91,
      "spofCount": 19
    },
    "busFactor": 4,
    "authorCount": 18
  },
  "Agent & Tool Framework": {
    "description": "Empowers language models to go beyond text generation by giving them access to tools. This module allows developers to create autonomous agents that can interact with external systems, perform actions, and solve complex problems by reasoning and executing tasks.",
    "functions": {
      "LLM-Specific Tool Marshalling": {
        "files": [
          {
            "path": "libs/partners/anthropic/langchain_anthropic/experimental.py",
            "description": "This file provides experimental utilities for generating system prompts with tool definitions and parsing tool calls from XML responses for Anthropic chat models.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/middleware/anthropic_tools.py",
            "description": "This module implements client-side middleware for Anthropic's text editor and memory tools, managing virtual file systems and injecting tool definitions into model calls. It provides functionalities like file creation, viewing, modification, and deletion within an agent's state.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/langchain_anthropic/middleware/bash.py",
            "description": "This file implements a middleware for Langchain agents that integrates Anthropic's native bash tool. It reconfigures the bash tool's descriptor to use an Anthropic-specific type within model requests.",
            "spof": false
          },
          {
            "path": "libs/partners/anthropic/tests/unit_tests/middleware/test_anthropic_tools.py",
            "description": "This file contains unit tests for the Anthropic text editor and memory tool middleware, verifying functionality for file operations, path validation, and security.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/langchain_openai/tools/__init__.py",
            "description": "This file initializes the `tools` package for OpenAI integrations within `langchain_openai`, making the `custom_tool` available for import.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/function_calling.py",
            "description": "This file provides utility methods for converting Python functions, Pydantic models, and TypedDicts into JSON schema representations compatible with OpenAI's function-calling API, primarily for generating tool specifications.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/utils/test_function_calling.py",
            "description": "This file contains unit tests for the utility functions related to function calling in LangChain, specifically `convert_to_openai_function`. It defines various fixtures representing different callable and schema types (Pydantic models, functions, TypedDicts, LangChain tools/runnables) and verifies their correct conversion to the OpenAI function calling schema.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_tools/__init__.py",
            "description": "This file acts as an `__init__.py` for the `openai_tools` chains, exposing the `create_extraction_chain_pydantic` function. It enables the creation of data extraction chains leveraging OpenAI tools and Pydantic models.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_functions/base.py",
            "description": "This file provides legacy methods for creating LangChain chains that utilize OpenAI's function-calling APIs, enabling both general function execution and structured output extraction. These methods are deprecated in favor of newer implementations.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_functions/utils.py",
            "description": "This file provides utility functions for processing JSON schemas, including resolving references and formatting them. It also contains a function to generate LLM (Large Language Model) keyword arguments for enabling function calling based on a given function definition.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utils/openai_functions.py",
            "description": "This file re-exports utility classes and functions from `langchain_core.utils.function_calling` that are used for defining and converting Pydantic models into OpenAI function and tool specifications.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/render.py",
            "description": "This module provides different methods for rendering and formatting tools to be used with LLMs, including converting them to OpenAI function and tool specifications, and generating text descriptions.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/convert_to_openai.py",
            "description": "This file re-exports a function for converting tools to OpenAI function format, primarily for backwards compatibility within the LangChain classic library.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/runnables/test_openai_functions.py",
            "description": "This file contains unit tests for the `OpenAIFunctionsRouter` in LangChain, demonstrating how it processes and dispatches function calls returned by a simulated OpenAI model within a runnable chain.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Eugene Yurtsev",
            "percent": 34
          },
          {
            "name": "Sydney Runkle",
            "percent": 20
          },
          {
            "name": "Mason Daugherty",
            "percent": 19
          }
        ]
      },
      "Agent Support Services and Middleware": {
        "files": [
          {
            "path": "libs/partners/anthropic/tests/unit_tests/middleware/test_file_search.py",
            "description": "This file contains unit tests for the `StateFileSearchMiddleware` class, verifying its initialization and the functionality of its glob and grep search methods across various scenarios and output modes.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/langchain_openai/middleware/openai_moderation.py",
            "description": "This file implements an agent middleware that uses OpenAI's moderation endpoint to check for harmful content in agent interactions. It can moderate user inputs, model outputs, and tool results, with configurable handling for flagged content.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/tests/unit_tests/test_in_memory_sandbox_provider.py",
            "description": "This file defines an in-memory implementation of a sandbox backend and provider, and then uses it to run standard integration tests for the sandbox provider interface.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/streaming_aiter_final_only.py",
            "description": "This file defines an asynchronous callback handler that streams only the final output of an agent, specifically after a designated 'final answer' prefix has been detected in the token stream.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/natbot/__init__.py",
            "description": "Initializes the natbot chain, which implements a GPT-3 driven browser, drawing heavy influence from the nat/natbot project.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/natbot/base.py",
            "description": "This file implements the `NatBotChain`, an LLM-driven browser chain that determines the next browser command based on an objective, current URL, and browser content. It is marked as deprecated and will be moved to `langchain_community`.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/natbot/crawler.py",
            "description": "This file defines a `Crawler` class that uses Playwright to navigate and interact with web pages. It can perform actions like clicking, typing, scrolling, and extracting information about elements visible in the viewport.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/interaction/__init__.py",
            "description": "This file contains tools designed for interacting with the user within the LangChain classic framework.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/merriam_webster/__init__.py",
            "description": "Initializes the Merriam-Webster API toolkit, providing tools for interacting with the Merriam-Webster API within LangChain.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/sql_database/__init__.py",
            "description": "This file provides tools for interacting with a SQL database within the LangChain framework.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Eugene Yurtsev",
            "percent": 48
          },
          {
            "name": "Nuno Campos",
            "percent": 37
          },
          {
            "name": "Sydney Runkle",
            "percent": 9
          }
        ]
      },
      "Tool Definition and Execution Core": {
        "files": [
          {
            "path": "libs/partners/openai/langchain_openai/tools/custom_tool.py",
            "description": "This file defines a `custom_tool` decorator that facilitates the creation of custom OpenAI tools capable of handling freeform string inputs, optionally with a specified grammar format. It wraps user-defined functions to integrate them as custom tools within the LangChain framework for use with OpenAI models.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/test_tools.py",
            "description": "This file contains unit tests for the `custom_tool` decorator, verifying its functionality, asynchronous behavior, tool schema generation, and integration with `ChatOpenAI` for handling custom tool calls and messages.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/messages/function.py",
            "description": "This file defines the `FunctionMessage` and `FunctionMessageChunk` classes, which represent the result of executing a tool or function and their chunked variants, respectively, for use within the LangChain core messaging system.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/tool.py",
            "description": "This file defines data structures for representing tool calls made by AI models and the corresponding tool messages (results) returned from tool executions within the LangChain framework. It includes types for both complete calls/messages and their streaming chunks.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/tools/render.py",
            "description": "This file provides utility functions for rendering a list of `BaseTool` objects into plain text descriptions, including their names, descriptions, arguments, and function signatures.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tools/convert.py",
            "description": "This file provides utilities to convert Python functions and LangChain Runnables into LangChain `BaseTool` instances. It supports various configurations including automatic schema inference and docstring parsing for tool creation.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tools/structured.py",
            "description": "This file defines the `StructuredTool` class, an extensible tool that can operate on various inputs. It supports creating tools from Python functions (sync and async) with automatic schema inference and handles their execution and callback management.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tools/simple.py",
            "description": "This file defines the `Tool` class in LangChain Core, which wraps a Python function or coroutine for synchronous or asynchronous execution as a tool. It handles argument passing, callback management, and provides compatibility with single-input tools.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tools/__init__.py",
            "description": "This file serves as the main entry point for the `langchain_core.tools` package, aggregating and exposing various tool-related classes and utilities from its submodules. It uses dynamic imports for lazy loading of these components.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tools/retriever.py",
            "description": "This file provides a utility function (`create_retriever_tool`) to wrap a LangChain retriever instance into a `StructuredTool`, enabling its use within agents for document retrieval and formatting.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tools/base.py",
            "description": "This file defines base classes and utilities for LangChain tools. It provides functionalities to create Pydantic schemas for tool arguments from Python function signatures and docstrings.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/test_tools.py",
            "description": "This file contains unit tests for the base tool implementations and related functionalities within the `langchain_core` library, including schema validation, argument parsing, and the `@tool` decorator.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/langchain/tools/__init__.py",
            "description": "This file serves as the main entry point for the `langchain.tools` package, exposing core tool definitions, exceptions, and runtime components for convenient access. It aggregates tool-related functionalities from various submodules.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/tests/unit_tests/tools/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `langchain.tools` module exposes the expected set of public members. It ensures the module's public API remains consistent.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/tools.py",
            "description": "This file contains integration tests for LangChain tools, specifically verifying that their 'invoke' and 'ainvoke' methods correctly handle 'ToolCall' objects and raw dictionaries as input, and produce output conforming to the expected schema.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/unit_tests/tools.py",
            "description": "This file defines base classes for unit testing LangChain tools, providing a standardized framework for testing tool initialization, environment variable handling, and adherence to schema requirements.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/tests/unit_tests/test_basic_tool.py",
            "description": "This file defines example tool classes, `ParrotMultiplyTool` and `ParrotMultiplyArtifactTool`, and provides corresponding unit and integration tests for them, demonstrating how to test tools within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/tests/unit_tests/test_decorated_tool.py",
            "description": "This file defines a sample `parrot_multiply_tool` using the `@tool` decorator and includes both unit and integration tests for its functionality, inheriting from standard test base classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/base.py",
            "description": "This file serves as an aggregation point, re-exporting core tool-related classes and functions from `langchain_core.tools` for use within the `langchain_classic` library. It makes fundamental tool components like `BaseTool`, `StructuredTool`, and the `tool` decorator easily accessible.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/graphql/__init__.py",
            "description": "Provides tools for interacting with a GraphQL API.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/github/__init__.py",
            "description": "This file serves as the package initializer for the GitHub tool within the Langchain Classic library. It likely aggregates or makes available other modules related to interacting with GitHub.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gitlab/__init__.py",
            "description": "This `__init__.py` file serves to initialize the GitLab tools module within the `langchain_classic` library, making various GitLab-related functionalities accessible as tools.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/json/__init__.py",
            "description": "This file initializes the JSON tools module within the Langchain framework. It provides functionalities for interacting with JSON files.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/pubmed/__init__.py",
            "description": "This file serves as the initialization point for the PubMed API toolkit within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/spark_sql/__init__.py",
            "description": "This file contains tools designed for interacting with Spark SQL databases, as indicated by its docstring and file path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/sleep/__init__.py",
            "description": "This file initializes the 'sleep' tool for LangChain, which likely provides functionality to pause execution for a specified duration.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/vectorstore/__init__.py",
            "description": "This file provides a simple tool wrapper for `VectorDBQA` chains, making them accessible as tools within the `langchain_classic` vectorstore module.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/tools/test_base.py",
            "description": "This file contains unit tests for the `langchain_classic.tools.base` module. It verifies that the `__all__` variable in that module correctly lists all intended public exports.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/tools/test_render.py",
            "description": "This file contains unit tests for the `render_text_description` and `render_text_description_and_args` functions, which format tool descriptions for display. It defines example tools and asserts that their rendered output matches expected string formats.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/calculator",
            "description": "This directory is intended to contain unit test specifications or examples specifically for a 'calculator' component or functionality within the LangChain library. It serves as a dedicated location for tests related to calculator operations.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/speak",
            "description": "This directory is intended to house test specifications or fixtures for unit tests related to a 'speak' functionality within the LangChain library. Its name suggests it would define how this specific feature should behave or be tested. While currently empty, it serves as a dedicated location for test-related resources for this particular component.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 30
          },
          {
            "name": "Christophe Bornet",
            "percent": 19
          },
          {
            "name": "Sydney Runkle",
            "percent": 11
          }
        ]
      },
      "Tool Compatibility and Deprecation Management": {
        "files": [
          {
            "path": "libs/langchain_v1/langchain/tools/tool_node.py",
            "description": "This file re-exports various classes related to tool calls and runtime from `langgraph.prebuilt`, primarily for backward compatibility within the `langchain_v1` ecosystem.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/_api/deprecation.py",
            "description": "This file re-exports deprecation utilities from `langchain_core` and defines a specific deprecation warning for LangChain agents, advising migration to LangGraph.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/plugin.py",
            "description": "This file facilitates backward compatibility by dynamically importing deprecated plugin-related tools and configurations from `langchain_community` into the `langchain_classic` namespace.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/__init__.py",
            "description": "This file serves as the primary entry point for importing various tools within the LangChain classic library. It manages tool imports, including handling deprecations and redirects to `langchain_community` or `langchain_experimental` for certain tools.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/arxiv/tool.py",
            "description": "This file provides a compatibility layer for Arxiv-related tools, dynamically re-exporting `ArxivInput` and `ArxivQueryRun` from `langchain_community`. It facilitates handling deprecated imports by redirecting calls to their new locations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/azure_cognitive_services/text2speech.py",
            "description": "This file facilitates the dynamic import and re-export of the `AzureCogsText2SpeechTool` from `langchain_community.tools`, handling potential deprecation for backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/azure_cognitive_services/speech2text.py",
            "description": "This file serves as a re-exporter or compatibility layer for the `AzureCogsSpeech2TextTool`, dynamically importing it from `langchain_community.tools` while handling potential deprecation or relocation of the class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/bing_search/__init__.py",
            "description": "This file initializes the Bing Search API toolkit, providing dynamic imports for `BingSearchResults` and `BingSearchRun` from `langchain_community.tools` and handling potential deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/bing_search/tool.py",
            "description": "This file manages the dynamic import and deprecation of Bing Search related tools, redirecting imports like `BingSearchRun` and `BingSearchResults` to their new location in `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/file_management/write.py",
            "description": "This file provides backward compatibility for deprecated imports of `WriteFileInput` and `WriteFileTool` by dynamically loading them from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/file_management/copy.py",
            "description": "This file acts as a compatibility layer, re-exporting `CopyFileTool` and `FileCopyInput` from `langchain_community.tools` to maintain backward compatibility for `langchain_classic` users. It dynamically imports these attributes to handle deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/file_management/__init__.py",
            "description": "This `__init__.py` file serves as a re-exporting module for file management tools, providing a mechanism for dynamic lookup and handling deprecated imports from `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/file_management/delete.py",
            "description": "This file provides a compatibility layer for deprecated `DeleteFileTool` and `FileDeleteInput` classes, dynamically redirecting imports to their new locations within the `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/file_management/list_dir.py",
            "description": "This file manages the deprecation and re-export of `DirectoryListingInput` and `ListDirectoryTool` from `langchain_classic` to `langchain_community`, providing backward compatibility through dynamic attribute lookup.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/file_management/file_search.py",
            "description": "This file provides a compatibility layer for `FileSearchTool` and `FileSearchInput`, dynamically importing them from `langchain_community.tools` to maintain backward compatibility for `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/file_management/read.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `ReadFileInput` and `ReadFileTool` from `langchain_community`. It helps manage deprecated imports, allowing older code to continue importing these tools from their previous location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/file_management/move.py",
            "description": "This file dynamically re-exports `FileMoveInput` and `MoveFileTool` from `langchain_community.tools`, serving as a compatibility layer for deprecated imports within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/amadeus/flight_search.py",
            "description": "This file acts as a compatibility layer, dynamically importing `AmadeusFlightSearch` and `FlightSearchSchema` from `langchain_community.tools.amadeus.flight_search` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/brave_search/tool.py",
            "description": "This file acts as a compatibility layer for the 'BraveSearch' tool. It dynamically re-exports 'BraveSearch' from 'langchain_community.tools', likely to manage deprecated imports within the 'langchain_classic' package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/graphql/tool.py",
            "description": "This file provides a compatibility layer for `BaseGraphQLTool`, dynamically importing it from `langchain_community.tools` when accessed through `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/edenai/audio_speech_to_text.py",
            "description": "This file handles the dynamic lookup and redirection of the `EdenAiSpeechToTextTool` class from `langchain_classic` to its new location in `langchain_community.tools`, primarily for managing deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/edenai/ocr_identityparser.py",
            "description": "This file dynamically imports and re-exports `EdenAiParsingIDTool`, likely to manage deprecated imports or facilitate a migration from an older `langchain_classic` structure to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/edenai/edenai_base_tool.py",
            "description": "This file acts as a compatibility layer, dynamically importing the `EdenaiTool` from `langchain_community.tools` when accessed through `langchain_classic`. It handles deprecation and consolidates import logic for the Edenai tool.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/bearly/tool.py",
            "description": "This file serves as a compatibility layer, dynamically re-exporting the `BearlyInterpreterTool` and its related argument types from `langchain_community` to maintain backward compatibility for users of `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ainetwork/value.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for deprecated `AINValueOps` and `ValueSchema` classes from `langchain_classic` to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ainetwork/rule.py",
            "description": "This file provides backward compatibility for `AINRuleOps` and `RuleSchema` by dynamically importing them from `langchain_community` when accessed from `langchain_classic`, facilitating a smooth transition during library refactoring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ainetwork/owner.py",
            "description": "This file serves as a compatibility layer, dynamically redirecting imports for `AINOwnerOps` and `RuleSchema` from `langchain_classic` to their new locations in `langchain_community` to handle deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ainetwork/base.py",
            "description": "This file acts as a compatibility layer, re-exporting `AINBaseTool` and `OperationType` from `langchain_community` to maintain backward compatibility for `langchain_classic` consumers. It uses a dynamic import mechanism to handle deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ainetwork/transfer.py",
            "description": "This file serves as a re-export mechanism for the `AINTransfer` tool and `TransferSchema` from the `langchain_community` package. It uses dynamic attribute lookup to provide backward compatibility for imports that might still expect these objects within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_places/__init__.py",
            "description": "This file manages the dynamic import and deprecation of the GooglePlacesTool, redirecting it from 'langchain_classic' to 'langchain_community'.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_places/tool.py",
            "description": "This file serves as a compatibility layer, dynamically re-exporting `GooglePlacesSchema` and `GooglePlacesTool` from `langchain_community` to maintain backward compatibility for `langchain_classic` users. It handles deprecated imports by redirecting them to their new locations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/github/tool.py",
            "description": "This file provides a compatibility layer for the `GitHubAction` tool, allowing it to be dynamically imported from its new location in `langchain_community` while maintaining references from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gmail/get_thread.py",
            "description": "This file acts as a compatibility layer, providing dynamic lookup and forwarding for deprecated `GmailGetThread` and `GetThreadSchema` imports to their new locations in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gmail/send_message.py",
            "description": "This file provides a compatibility layer for deprecated Gmail tool classes, dynamically importing `GmailSendMessage` and `SendMessageSchema` from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/gmail/base.py",
            "description": "This file acts as a re-exporter or shim for `GmailBaseTool`, redirecting imports from `langchain_classic` to `langchain_community`. It facilitates backward compatibility and module migration by dynamically looking up and importing the tool from its new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_serper/__init__.py",
            "description": "This file serves as the `__init__.py` for the `google_serper` tool in `langchain_classic`, facilitating dynamic import and handling deprecation of `GoogleSerperResults` and `GoogleSerperRun` from `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_lens/tool.py",
            "description": "This file provides backward compatibility for `GoogleLensQueryRun` by dynamically importing it from `langchain_community`, managing deprecation for moved modules.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_lens/__init__.py",
            "description": "This file serves as the entry point for the Google Lens API Toolkit within `langchain_classic`, primarily managing the dynamic and deprecated import of `GoogleLensQueryRun` from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/e2b_data_analysis/tool.py",
            "description": "This file acts as a compatibility layer, providing dynamic import redirection for `E2BDataAnalysisTool` and related classes, moving them from `langchain_classic` to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_finance/__init__.py",
            "description": "This file serves as the `__init__.py` for the Google Finance API toolkit within `langchain_classic`. It handles dynamic and deprecated imports, specifically redirecting the `GoogleFinanceQueryRun` class to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/eleven_labs/text2speech.py",
            "description": "This file manages the import and deprecation of the `ElevenLabsText2SpeechTool`, re-exporting it from its new location in `langchain_community.tools` while maintaining compatibility for older references. It acts as a transitional shim for the tool's relocation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/interaction/tool.py",
            "description": "This file acts as an import proxy for `StdInInquireTool`, dynamically importing it from `langchain_community.tools`. It facilitates compatibility and manages the transition of this tool to a different package, handling potential deprecation lookups.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/json/tool.py",
            "description": "This file acts as a compatibility layer, providing dynamic access to deprecated JSON tools by forwarding their imports to their new locations within the `langchain_community.tools` namespace, ensuring backward compatibility for legacy code.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/golden_query/__init__.py",
            "description": "This `__init__.py` file serves as an import shim for the `GoldenQueryRun` tool, dynamically re-exporting it while indicating its migration or deprecation to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/golden_query/tool.py",
            "description": "This file acts as a compatibility layer, dynamically forwarding requests for the `GoldenQueryRun` class from its deprecated location within `langchain_classic` to its new home in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ddg_search/tool.py",
            "description": "This file acts as a compatibility layer for DuckDuckGo search tools, dynamically redirecting imports from their classic location to the `langchain_community` package. It ensures backward compatibility for users accessing these tools.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/ddg_search/__init__.py",
            "description": "This file serves as the entry point for the DuckDuckGo Search API toolkit within `langchain_classic`. It dynamically imports and re-exports the `DuckDuckGoSearchRun` tool, managing potential deprecations or relocations from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/merriam_webster/tool.py",
            "description": "This file provides a compatibility layer for `MerriamWebsterQueryRun`, dynamically importing it from `langchain_community.tools` to handle deprecated import paths. It ensures that older references to the tool still function by redirecting to its new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_scholar/tool.py",
            "description": "This file manages the deprecation of the `GoogleScholarQueryRun` tool, redirecting imports from `langchain_classic` to its new location within `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_scholar/__init__.py",
            "description": "This file serves as a transitional module for the Google Scholar API Toolkit, re-exporting `GoogleScholarQueryRun` from `langchain_community` and managing deprecation for its old location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_jobs/__init__.py",
            "description": "This `__init__.py` file serves as a dynamic importer for Google Jobs API tools within the `langchain_classic` package, primarily re-exporting `GoogleJobsQueryRun` from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/human/tool.py",
            "description": "This file defines the 'HumanInputRun' tool within the classic LangChain framework. It dynamically imports this tool from 'langchain_community.tools', likely for compatibility or deprecation handling purposes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/human/__init__.py",
            "description": "This file provides a dynamic import mechanism for the `HumanInputRun` tool, which is used for asking for human input. It acts as a compatibility layer, routing the import of `HumanInputRun` from `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/nuclia/__init__.py",
            "description": "This file manages the dynamic import and deprecation of the `NucliaUnderstandingAPI` tool, redirecting its lookup to `langchain_community` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/multion/create_session.py",
            "description": "This file manages deprecated imports for Multion tools, redirecting `CreateSessionSchema` and `MultionCreateSession` from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/multion/__init__.py",
            "description": "This file serves as the `__init__.py` for Multion tools in `langchain_classic`, facilitating the dynamic import and handling of deprecation for Multion tool classes that have been moved to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/multion/update_session.py",
            "description": "This file provides a compatibility layer for `MultionUpdateSession` and `UpdateSessionSchema`, re-exporting them from their new location in `langchain_community` to maintain backward compatibility for older `langchain_classic` imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/pubmed/tool.py",
            "description": "This file acts as a compatibility layer or proxy, enabling dynamic import of the `PubmedQueryRun` tool from `langchain_community.tools` into the `langchain_classic` package, likely handling deprecation or restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/base.py",
            "description": "This file acts as a compatibility layer, re-exporting `BaseBrowserTool` from `langchain_community` to maintain backward compatibility for `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/get_elements.py",
            "description": "This file facilitates dynamic and deprecated imports for `GetElementsTool` and `GetElementsToolInput` from `langchain_community` within the `langchain_classic` package. It acts as a transitional layer to handle renamed or moved modules.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/current_page.py",
            "description": "This file provides a transitional module for the 'CurrentWebPageTool', dynamically importing it from 'langchain_community.tools' to handle deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/navigate.py",
            "description": "This file acts as a compatibility layer for `NavigateTool` and `NavigateToolInput`. It handles deprecated imports, redirecting them from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/extract_text.py",
            "description": "This file provides a dynamic import mechanism for the `ExtractTextTool`, handling its deprecation and redirection to `langchain_community.tools` for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/click.py",
            "description": "This file acts as a compatibility layer, re-exporting `ClickTool` and `ClickToolInput` from `langchain_community.tools.playwright.click` for use within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/extract_hyperlinks.py",
            "description": "This file serves as a compatibility layer within `langchain_classic`, dynamically importing `ExtractHyperlinksTool` and `ExtractHyperlinksToolInput` from `langchain_community` to manage deprecated or moved modules. It uses `__getattr__` to redirect imports to their new locations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/playwright/navigate_back.py",
            "description": "This file acts as a re-export mechanism for the `NavigateBackTool`, dynamically importing it from `langchain_community.tools`. It facilitates backward compatibility and manages potential deprecation warnings for the tool within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/python/__init__.py",
            "description": "This file acts as a deprecation notice and migration guide for the Python tool, indicating it has moved to `langchain_experimental` and providing instructions for updating imports.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_trends/__init__.py",
            "description": "This `__init__.py` file dynamically imports the `GoogleTrendsQueryRun` tool from `langchain_community`, providing access to Google Trends API functionality within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_trends/tool.py",
            "description": "This file provides a backward-compatible import mechanism for the `GoogleTrendsQueryRun` class, redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_search/__init__.py",
            "description": "This file serves as the `__init__.py` for the Google Search tools, dynamically importing `GoogleSearchRun` and `GoogleSearchResults` from `langchain_community.tools` and managing potential deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/google_search/tool.py",
            "description": "This file serves as a compatibility layer or proxy for Google Search tools, allowing `GoogleSearchResults` and `GoogleSearchRun` to be accessed from this module while dynamically importing them from `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/scenexplain/tool.py",
            "description": "This file acts as a compatibility shim, dynamically importing and re-exporting `SceneXplainInput` and `SceneXplainTool` from `langchain_community`. It ensures backward compatibility for users still referencing these tools from the `langchain_classic` namespace.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/office365/messages_search.py",
            "description": "This file acts as a compatibility layer for Office 365 email search tools, dynamically importing them from `langchain_community` to maintain backward compatibility for `langchain_classic` users. It re-exports `O365SearchEmails` and `SearchEmailsInput`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/office365/create_draft_message.py",
            "description": "This file provides a compatibility layer for Office365 draft message creation tools, dynamically re-exporting `CreateDraftMessageSchema` and `O365CreateDraftMessage` from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/office365/__init__.py",
            "description": "This file serves as a facade for Office 365 tools, dynamically importing them from 'langchain_community.tools' to maintain backward compatibility or manage module deprecations within the 'langchain_classic' package. It exposes O365 email and event management functionalities.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/spark_sql/tool.py",
            "description": "This file provides a compatibility layer for Spark SQL tools, dynamically re-exporting them from 'langchain_community.tools' to maintain backward compatibility for 'langchain_classic' users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/sql_database/tool.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting SQL database tools from the `langchain_community` package, likely handling deprecated imports or consolidating them.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/metaphor_search/__init__.py",
            "description": "This file dynamically imports and exposes 'MetaphorSearchResults' from the `langchain_community.tools` package, handling potential deprecation or package transitions. It acts as an entry point for the Metaphor Search API toolkit within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/shell/__init__.py",
            "description": "This file re-exports the `ShellTool` from `langchain_community.tools`, acting as a compatibility layer or deprecation handler for its usage within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/shell/tool.py",
            "description": "This file acts as a compatibility layer for `ShellInput` and `ShellTool`, dynamically importing them from `langchain_community` to maintain backward compatibility for deprecated references in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/memorize/tool.py",
            "description": "This file acts as a compatibility layer, dynamically importing `Memorize` and `TrainableLLM` from `langchain_community` into `langchain_classic`. It handles deprecated imports, ensuring backward compatibility while redirecting to the updated module location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/sleep/tool.py",
            "description": "This file provides a compatibility layer for `SleepInput` and `SleepTool`, dynamically re-exporting them from `langchain_community` to maintain backward compatibility during a module refactor or deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/requests/__init__.py",
            "description": "This file serves as the package initializer for the 'requests' tools module within LangChain Classic, containing utilities for making API requests.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/requests/tool.py",
            "description": "This file serves as a compatibility layer for `requests` tools, dynamically importing them from `langchain_community.tools` to manage deprecation or migration while maintaining a consistent import path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/vectorstore/tool.py",
            "description": "This file dynamically re-exports `VectorStoreQATool` and `VectorStoreQAWithSourcesTool` from `langchain_community.tools`, primarily to handle deprecated imports and maintain backward compatibility during package restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/wikipedia/tool.py",
            "description": "This file provides backward compatibility for the `WikipediaQueryRun` tool, redirecting its import from `langchain_classic` to `langchain_community.tools`. It uses a dynamic importer to handle deprecated module paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/reddit_search/tool.py",
            "description": "This file acts as a compatibility layer to dynamically import and re-export `RedditSearchRun` and `RedditSearchSchema` from the `langchain_community.tools` package, handling potential deprecations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/nasa/tool.py",
            "description": "This file manages the dynamic import and deprecation of the `NasaAction` class, redirecting it from `langchain_classic` to its new location in `langchain_community.tools`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/openweathermap/__init__.py",
            "description": "This file provides an entry point for the OpenWeatherMap API toolkit, dynamically importing `OpenWeatherMapQueryRun` and managing attribute lookups, including handling deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/wolfram_alpha/tool.py",
            "description": "This file dynamically imports `WolframAlphaQueryRun` from `langchain_community.tools`, serving as a compatibility layer for tools moved from `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/wolfram_alpha/__init__.py",
            "description": "This file acts as an `__init__.py` for the Wolfram Alpha API toolkit, primarily managing dynamic imports. It uses a deprecation lookup to redirect `WolframAlphaQueryRun` to `langchain_community.tools`, facilitating backward compatibility during package restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/searx_search/tool.py",
            "description": "This file acts as a deprecation handler for Searx search tools, dynamically importing `SearxSearchRun` and `SearxSearchResults` from `langchain_community.tools`. It provides backward compatibility by redirecting older references to their new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/tavily_search/tool.py",
            "description": "This file provides backward compatibility for Tavily search tool imports, redirecting them from `langchain_classic` to `langchain_community` where they have been moved. It uses a dynamic importer to handle deprecated module paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/tavily_search/__init__.py",
            "description": "This file serves as a compatibility layer for the Tavily Search API tools, dynamically importing `TavilyAnswer` and `TavilySearchResults` from `langchain_community` while managing deprecated import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/openapi/utils/api_models.py",
            "description": "This file facilitates the re-exporting of deprecated API model and utility imports from `langchain_community` to maintain backward compatibility during a refactoring or migration process. It acts as an import proxy for various OpenAPI related models and constants.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/tools/test_imports.py",
            "description": "This file contains a unit test to verify that the `langchain_classic.tools` module correctly exposes all expected tool names in its `__all__` attribute, and no others. It ensures API consistency for the tools module.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Sydney Runkle",
            "percent": 63
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 32
          },
          {
            "name": "Mason Daugherty",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 151,
      "spofCount": 18
    },
    "busFactor": 4,
    "authorCount": 10
  },
  "Observability & Evaluation (LangSmith)": {
    "description": "Delivers a comprehensive suite of tools for debugging, testing, evaluating, and monitoring LLM applications. Integrated with LangSmith, it provides deep visibility into application performance, helping developers build more reliable and effective AI systems.",
    "functions": {
      "Test Utilities and Mock Implementations": {
        "files": [
          {
            "path": "libs/partners/anthropic/tests/unit_tests/_utils.py",
            "description": "This file defines fake callback handlers designed for testing purposes, allowing developers to track and verify interactions within LangChain components like LLMs, chains, and tools.",
            "spof": true
          },
          {
            "path": "libs/partners/prompty/tests/unit_tests/fake_callback_handler.py",
            "description": "This file defines fake synchronous and asynchronous callback handlers for Langchain components. These handlers are used for testing purposes to track and count various events (e.g., LLM calls, chain runs, tool invocations) during application execution.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/fake/callbacks.py",
            "description": "This file defines fake callback handlers for testing purposes, allowing tracking and counting of various callback events for synchronous and asynchronous operations.",
            "spof": false
          },
          {
            "path": "libs/partners/openai/tests/cassettes",
            "description": "This directory is designated for storing VCR 'cassettes' used in the OpenAI partner library's tests. These cassettes capture and replay HTTP interactions, enabling efficient and reliable testing of the OpenAI integration without requiring live API calls. Its current empty state suggests that no test recordings have been generated or committed yet.",
            "spof": false
          },
          {
            "path": "libs/partners/groq/tests/unit_tests/fake/callbacks.py",
            "description": "This file defines fake callback handlers (synchronous and asynchronous) used for testing purposes within the Langchain framework. These handlers track and count various events like LLM calls, chain runs, tool invocations, and errors, allowing for verification of callback behavior in unit tests.",
            "spof": true
          },
          {
            "path": "libs/partners/perplexity/tests/unit_tests/__init__.py",
            "description": "This file initializes the unit test environment by setting a dummy API key for Perplexity, enabling tests to run without requiring a valid key.",
            "spof": true
          },
          {
            "path": "libs/partners/exa/tests/unit_tests/__init__.py",
            "description": "This `__init__.py` file marks the `unit_tests` directory as a Python package. Its docstring indicates that it contains unit tests for the `langchain_exa` package.",
            "spof": true
          },
          {
            "path": "libs/core/tests/benchmarks/test_async_callbacks.py",
            "description": "This file contains benchmarks for evaluating the performance of asynchronous callback handlers when streaming output from a language model within a synchronous test context. It defines a custom async handler that introduces a small delay for each new token.",
            "spof": false
          },
          {
            "path": "libs/core/tests/benchmarks/test_imports.py",
            "description": "This file contains benchmarks for measuring the import time of various classes and functions from the `langchain_core` library using `pytest-benchmark`. It executes each import statement in a separate subprocess to accurately gauge its loading performance.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/test_imports.py",
            "description": "This file contains unit tests to ensure that all modules within the `langchain_core` library can be imported successfully, including checking their publicly exposed members (`__all__`), both directly and in isolated subprocesses.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/conftest.py",
            "description": "This file configures the pytest testing environment, providing fixtures for blocking specific function calls, ensuring deterministic UUIDs, and implementing hooks for filtering and skipping tests based on custom command-line options and required package installations.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/callbacks/test_dispatch_custom_event.py",
            "description": "This file contains unit tests for the custom event dispatching mechanism in LangChain's callback system, covering both synchronous and asynchronous event handling within runnables.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/callbacks/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_core.callbacks` correctly exports all expected public callback-related components.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/language_models/chat_models/test_benchmark.py",
            "description": "This file contains a unit test that benchmarks the performance of the `GenericFakeChatModel` by invoking it many times and asserting that the operations complete within a specified time limit.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/tracers/test_async_base_tracer.py",
            "description": "This file contains unit tests for the `AsyncBaseTracer` class, verifying its asynchronous tracing capabilities across various run types like LLM, Chat Model, Chain, Tool, and nested runs.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/tracers/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_core.tracers` correctly exposes all intended public modules and classes.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/tracers/test_automatic_metadata.py",
            "description": "This file contains unit tests for the `_TracerCore` class, specifically verifying that it correctly counts and stores the number of tool calls found in LLM responses (AIMessages within LLMResults) as part of the run metadata.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/examples",
            "description": "This directory is intended to store example data, configurations, or small code snippets that are utilized by the unit tests for the `core` library. These examples help validate the functionality of the `core` components under various conditions.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/fake/callbacks.py",
            "description": "This file defines fake callback handlers (synchronous and asynchronous) used for testing purposes within the LangChain framework. These handlers track and count various events like starts, ends, errors, and specific interactions with LLMs, chains, tools, agents, and retrievers.",
            "spof": false
          },
          {
            "path": "libs/langchain_v1/tests/__init__.py",
            "description": "This `__init__.py` file marks the directory as a Python package and serves as a placeholder for the package's tests.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/tests/integration_tests/__init__.py",
            "description": "This `__init__.py` file marks the `integration_tests` directory as a Python package. Its docstring clarifies that this directory contains all integration tests, which are defined as tests that interact with external APIs.",
            "spof": true
          },
          {
            "path": "libs/langchain_v1/tests/cassettes",
            "description": "This directory is intended to store VCR (Video Cassette Recorder) cassettes, which are used to record and replay HTTP interactions for tests within the `langchain_v1` library. These cassettes help ensure test reliability and speed by mocking external API calls. Although currently empty, it serves as the designated location for such test data.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/__init__.py",
            "description": "Provides base test classes for standard testing within the LangChain framework. It serves as a foundational component for integrating and running standardized tests.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/base.py",
            "description": "This file defines a base class `BaseStandardTests` that enforces consistency for standard test implementations. It ensures that subclasses do not accidentally delete or override standard test methods without explicit `xfail` markers.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/__init__.py",
            "description": "This file initializes the `integration_tests` package, configuring pytest for its submodules and exposing various integration test suites for LangChain components. It serves as a central point for managing and importing integration tests.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/integration_tests/base_store.py",
            "description": "This file defines standard test suites for both synchronous and asynchronous implementations of the `BaseStore` abstraction. It verifies the basic key-value API functionality of `BaseStore` subclasses.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/unit_tests/embeddings.py",
            "description": "This file defines base classes and utilities for writing unit tests for Langchain's `Embeddings` implementations. It provides a framework for testing model initialization, including from environment variables, and requires subclasses to specify the embeddings class to be tested.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/langchain_tests/unit_tests/__init__.py",
            "description": "This file initializes the `langchain_tests.unit_tests` package, configuring pytest assertion rewriting for its submodules. It consolidates and exposes key unit test classes from those submodules for easier access.",
            "spof": true
          },
          {
            "path": "libs/standard-tests/langchain_tests/unit_tests/chat_models.py",
            "description": "This file defines base classes and utilities for unit testing LangChain chat models. It provides a standardized framework for testing various chat model capabilities like tool calling, structured output, and multi-modal inputs.",
            "spof": false
          },
          {
            "path": "libs/standard-tests/README.md",
            "description": "This README.md describes `langchain-tests`, a Python library providing base classes for standard unit and integration tests for LangChain integrations. It guides users on how to incorporate these tests into their own projects to ensure compatibility and correct behavior of LangChain components.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/README.md",
            "description": "This file is a README for the LangChain tests directory, serving as a redirect to the updated testing guide in the project's official documentation.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/__init__.py",
            "description": "This is the initialization file for the 'tests' package within the 'langchain' library. It signifies that this directory contains all the tests for the package.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/test_globals.py",
            "description": "This file contains unit tests for the global debug and verbose flags within the LangChain framework, verifying their consistent setting and retrieval across different access methods without raising warnings.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/stubs.py",
            "description": "This file defines utility classes, `_AnyIdAIMessage` and `_AnyIdAIMessageChunk`, for unit testing Langchain's message types. These classes provide a custom equality comparison that ignores the `id` field, ensuring tests are not sensitive to dynamically generated identifiers.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/callbacks/test_imports.py",
            "description": "This file contains a unit test that verifies the `__all__` attribute of the `langchain_classic.callbacks` module, ensuring it exports all expected callback handlers and related functionalities.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/callbacks/test_manager.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_classic.callbacks.manager` module correctly exposes all expected public interfaces.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/callbacks/test_file.py",
            "description": "This file contains unit tests for the `FileCallbackHandler`, which logs chain execution details to a specified file. It includes a fake chain implementation and utility functions to facilitate testing the callback's functionality.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/callbacks/test_base.py",
            "description": "This file contains unit tests for the `langchain_core.callbacks` module. It verifies that the `__all__` variable correctly exposes all expected callback-related classes and mixins, ensuring API consistency.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/callbacks/fake_callback_handler.py",
            "description": "This file defines fake synchronous and asynchronous callback handlers for testing purposes within the LangChain framework. These handlers track various event calls (e.g., LLM starts/ends, chain starts/ends, tool actions, retries) to verify callback functionality during unit tests.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/callbacks/tracers/__init__.py",
            "description": "This file serves as the package initializer for unit tests related to tracers, providing a high-level description of its testing scope.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/callbacks/tracers/test_logging.py",
            "description": "This file contains unit tests for the `LoggingCallbackHandler` class, verifying its ability to log callback events to Python's standard logging system, including custom extra data and correct output formatting.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/__init__.py",
            "description": "This file serves as the `__init__.py` for the unit tests of LangChain's evaluation module, indicating the directory contains tests for that specific functionality.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/test_imports.py",
            "description": "This file contains a unit test that verifies whether the `__all__` variable in the `langchain_classic.evaluation` module correctly exports all expected public evaluation-related classes and functions.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/llms/fake_llm.py",
            "description": "This file defines a `FakeLLM` class, which serves as a mock Large Language Model (LLM) wrapper for testing purposes, allowing predefined or sequential responses.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/smith/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `langchain_classic.smith` module correctly exposes the expected public API members.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/shop",
            "description": "This directory serves as a placeholder within the LangChain unit test suite, specifically for test specifications and examples related to a 'shop' application or concept. Its current emptiness indicates that corresponding tests are either planned or not yet implemented. It helps organize unit tests by domain or example type.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/freetv-app",
            "description": "This directory is intended to house test specifications for the 'freetv-app' example, which is used within the unit tests of the LangChain library. It serves to define how the 'freetv-app' example should be tested.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/joinmilo",
            "description": "This directory is intended to contain unit test specifications or examples for a component or feature named \"joinmilo\" within the LangChain library. It serves as a dedicated location for tests related to this specific part of the codebase.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/milo",
            "description": "This directory is designated for unit test specifications or related data pertaining to a component named 'milo' within the Langchain library. It serves as a placeholder or container for tests related to specific examples, ensuring the correct behavior of the 'milo' component's integration or functionality within the library's examples suite.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/wellknown",
            "description": "This directory is part of the unit test suite for the `langchain` library. It is designated to hold 'well-known' test specifications or examples, categorizing standard and commonly referenced test scenarios for consistent testing.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/examples/test_specs/robot",
            "description": "This directory is designated for storing examples of Robot Framework test specifications within the Langchain library's unit test suite. Its current emptiness might suggest it's a placeholder for future test development or specific test configurations related to 'robot' tests.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/__init__.py",
            "description": "This `__init__.py` file marks the `integration_tests` directory as a Python package. Its docstring clarifies that this package is dedicated to integration tests that interact with external APIs.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 53
          },
          {
            "name": "Christophe Bornet",
            "percent": 13
          },
          {
            "name": "ccurme",
            "percent": 11
          }
        ]
      },
      "LangSmith Integration and Persistence": {
        "files": [
          {
            "path": "libs/partners/anthropic/tests/unit_tests/test_llms.py",
            "description": "This file contains unit tests for the `AnthropicLLM` class within LangChain, specifically verifying that model parameters are correctly extracted and formatted for internal tracing purposes (e.g., LangSmith integration). It checks how `_get_ls_params()` behaves with different constructor arguments.",
            "spof": true
          },
          {
            "path": "libs/partners/openai/tests/unit_tests/llms/test_azure.py",
            "description": "This file contains unit tests for the `AzureOpenAI` class, specifically verifying that its internal LangSmith (LS) tracing parameters are correctly populated based on the model configuration. It asserts the accurate mapping of Azure-specific model details to tracing parameters.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/document_loaders/langsmith.py",
            "description": "This file implements a `LangSmithLoader` class that loads examples from a LangSmith dataset as `Document` objects for use in LangChain applications. It allows users to specify dataset filters, content extraction, and formatting for creating documents from LangSmith examples.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/tracers/evaluation.py",
            "description": "This file defines a LangChain tracer (`EvaluatorCallbackHandler`) that automatically runs specified evaluators on completed LangChain runs and logs the results to LangSmith, often using a thread pool for concurrent evaluation.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/_compat.py",
            "description": "This file provides compatibility helpers for Pydantic v1 and v2, specifically for `langsmith.Run` objects and other Pydantic models. It offers functions to convert, copy, and construct Pydantic models, abstracting away version-specific method calls.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/tracers/langchain.py",
            "description": "This file implements the `LangChainTracer`, which sends tracing data, including LLM calls and other run information, to the LangChain (LangSmith) platform for monitoring and debugging purposes.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/document_loaders/test_langsmith.py",
            "description": "This file contains unit tests for the `LangSmithLoader` class, verifying its initialization and its ability to lazily load and transform LangSmith examples into LangChain Document objects.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/tracers/test_langchain.py",
            "description": "This file contains unit tests for the `LangChainTracer` class, verifying its functionality, thread safety, and integration with LangChain's tracing and run management features. It also tests utility functions related to extracting usage metadata from LLM generations.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_tracing_interops.py",
            "description": "This file contains unit tests for verifying the integration and propagation of LangSmith tracing context within LangChain runnables, including synchronous, asynchronous, and parallel execution flows. It ensures that trace information, such as project names, tags, and run nesting, is correctly captured and reported.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chat_loaders/langsmith.py",
            "description": "This file serves as a compatibility layer or proxy for `LangSmithDatasetChatLoader` and `LangSmithRunChatLoader`, dynamically importing them from `langchain_community.chat_loaders.langsmith`. It facilitates access to these chat loader classes, potentially for backward compatibility or module reorganization within the LangChain ecosystem.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/comet_ml_callback.py",
            "description": "This file facilitates the deprecated import of `CometCallbackHandler` from `langchain_community` for backward compatibility, dynamically redirecting requests to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/flyte_callback.py",
            "description": "This file acts as a shim, dynamically importing and redirecting `FlyteCallbackHandler` from `langchain_community` for backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/trubrics_callback.py",
            "description": "This file dynamically re-exports `TrubricsCallbackHandler` from `langchain_community.callbacks.trubrics_callback`, likely to manage deprecated imports or consolidate modules.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/whylabs_callback.py",
            "description": "This file provides backward compatibility for `WhyLabsCallbackHandler`, dynamically importing it from `langchain_community` where it has been moved.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/infino_callback.py",
            "description": "This file facilitates the dynamic lookup and re-export of the `InfinoCallbackHandler` from `langchain_community`, ensuring backward compatibility for users of `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/promptlayer_callback.py",
            "description": "This file acts as a deprecation shim, dynamically redirecting imports of `PromptLayerCallbackHandler` from `langchain_classic` to `langchain_community`. It ensures backward compatibility for users while transitioning the module's location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/llmonitor_callback.py",
            "description": "This file re-exports the `LLMonitorCallbackHandler` from `langchain_community.callbacks.llmonitor_callback` and provides a dynamic import mechanism, likely for backward compatibility or deprecation handling.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/aim_callback.py",
            "description": "This file provides backward compatibility for `AimCallbackHandler` related classes and functions, dynamically re-exporting them from `langchain_community.callbacks.aim_callback` for use within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/labelstudio_callback.py",
            "description": "This file acts as a compatibility layer, re-exporting `LabelStudio` related classes and functions from `langchain_community.callbacks.labelstudio_callback`. It facilitates a soft deprecation by dynamically redirecting imports to the new location, ensuring backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/openai_info.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `OpenAICallbackHandler` from the `langchain_classic` package to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/clearml_callback.py",
            "description": "This file acts as a compatibility layer, re-exporting `ClearMLCallbackHandler` from `langchain_community` under the `langchain_classic` namespace, managing its deprecated or relocated import.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/argilla_callback.py",
            "description": "This file acts as a compatibility layer, dynamically importing and re-exporting `ArgillaCallbackHandler` from `langchain_community` to maintain backward compatibility for `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/wandb_callback.py",
            "description": "This file acts as a compatibility layer or deprecation shim, re-exporting the `WandbCallbackHandler` from `langchain_community` to maintain backward compatibility in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/langchain.py",
            "description": "This file provides the LangChain Tracer implementation, which records tracing information to the LangChain endpoint. It re-exports `LangChainTracer` and `wait_for_all_tracers`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/evaluation.py",
            "description": "This file provides a tracer for running evaluators on completed LangChain runs, re-exporting `EvaluatorCallbackHandler` and `wait_for_all_evaluators`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/comet.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `CometTracer` and `import_comet_llm_api` from `langchain_community` to maintain backward compatibility for users of `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/wandb.py",
            "description": "This file acts as a deprecation and compatibility layer for `WandbRunArgs` and `WandbTracer`. It dynamically imports these classes from `langchain_community`, ensuring backward compatibility for older import paths.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/tracers/evaluation.py",
            "description": "This file re-exports `EvaluatorCallbackHandler` and `wait_for_all_evaluators` from the `langchain_core` library, serving as an aggregation point for evaluation-related tracer components within the classic LangChain schema.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/tracers/langchain.py",
            "description": "This file re-exports core LangChain tracing components such as `LangChainTracer`, `get_client`, `log_error_once`, and `wait_for_all_tracers` from `langchain_core`. It acts as an access point for these tracing utilities within the `langchain_classic` structure.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/smith/evaluation/__init__.py",
            "description": "This module provides utilities for evaluating Chains and other language model applications using LangChain evaluators and LangSmith. It includes functions for running evaluations on datasets and configuration classes for evaluation settings.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/arcee.py",
            "description": "This file serves as a compatibility layer or proxy for Arcee-related utilities, dynamically importing them from `langchain_community` into `langchain_classic` while handling potential deprecations.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Hunter Lovell",
            "percent": 32
          },
          {
            "name": "Christophe Bornet",
            "percent": 23
          },
          {
            "name": "Mason Daugherty",
            "percent": 21
          }
        ]
      },
      "Callback and Tracing Core": {
        "files": [
          {
            "path": "libs/core/langchain_core/exceptions.py",
            "description": "This file defines custom exceptions specific to the LangChain library, including a base exception, a specialized output parsing exception, and an enum for error codes. It also provides a utility function for formatting error messages with troubleshooting links.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/callbacks/usage.py",
            "description": "This file defines a callback handler (`UsageMetadataCallbackHandler`) for tracking token usage metadata from AI models, aggregating it by model name. It also provides a context manager (`get_usage_metadata_callback`) for convenient usage tracking across multiple LLM calls.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/callbacks/file.py",
            "description": "This file implements a `FileCallbackHandler` class, which is a callback handler that logs various events (like chain starts/ends, agent actions, tool outputs) to a specified file. It supports both direct instantiation and context manager usage for managing the file lifecycle.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/callbacks/manager.py",
            "description": "This file defines core components for managing callbacks and tracing within the LangChain framework, including synchronous and asynchronous run managers and utilities for grouping operations into traceable runs.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/callbacks/__init__.py",
            "description": "This file serves as the public API for the `langchain_core.callbacks` package, exposing all relevant callback handlers and manager classes from its submodules for direct import. It enables centralized access to various callback functionalities within LangChain.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/callbacks/base.py",
            "description": "This file defines base mixin classes for implementing custom callback handlers in LangChain, providing hooks for monitoring the lifecycle (start, end, error) and intermediate steps of LLMs, chains, retrievers, and tools. It establishes the interface for how callback managers interact with different components during execution.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/root_listeners.py",
            "description": "This file defines synchronous and asynchronous tracers (RootListenersTracer and AsyncRootListenersTracer) that enable calling specified listener functions at the beginning, end, or upon error of a root run within the LangChain tracing system.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/schemas.py",
            "description": "This file defines schemas for tracers within the langchain_core library. Specifically, it provides a backward-compatible alias `Run` for `langsmith.RunTree` to represent tracing run data.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/_streaming.py",
            "description": "This file defines the `_StreamingCallbackHandler` protocol, an internal interface for callback handlers used in `stream_log` and `astream` event implementations within `langchain_core`.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/run_collector.py",
            "description": "This file defines a tracer (RunCollectorCallbackHandler) that collects and stores all nested runs in a list, primarily for inspection and evaluation purposes. It extends BaseTracer to capture execution traces.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/log_stream.py",
            "description": "This file defines a tracer that streams incremental updates (patches) to run logs, allowing for real-time monitoring and reconstruction of the run state. It includes classes for representing log entries, run states, and the patches used to update them.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/event_stream.py",
            "description": "This file implements an internal tracer that powers LangChain's event stream API. It captures events from runnable executions and streams them, supporting both synchronous and asynchronous outputs.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/__init__.py",
            "description": "This file serves as the `__init__.py` for the `tracers` subpackage, dynamically importing and exposing various tracer-related classes and types like `BaseTracer`, `LangChainTracer`, and different callback handlers.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/context.py",
            "description": "This file provides context management utilities for LangChain tracers, enabling and configuring LangSmith tracing and run collection within specific execution contexts using context managers and `ContextVar`.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/base.py",
            "description": "This file defines the abstract base class `BaseTracer` which provides the core interface for tracing execution runs of LLMs, chains, and tools within LangChain, enabling detailed monitoring and persistence of run data.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/tracers/memory_stream.py",
            "description": "This module implements an asynchronous memory stream for inter-coroutine communication, enabling data transfer between a writer and a reader across different event loops or threads.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/tracers/core.py",
            "description": "This file defines the abstract base class and core utilities for implementing tracing functionalities within Langchain. It provides common logic for managing the lifecycle, structure, and events of execution runs, such as LLM and chat model interactions.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/callbacks/test_sync_callback_manager.py",
            "description": "This file contains unit tests for the `BaseCallbackManager` class in Langchain, verifying its functionality for removing handlers and merging different callback managers.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/callbacks/test_usage_callback.py",
            "description": "This file contains unit tests for the `UsageMetadataCallbackHandler` and `get_usage_metadata_callback` functions. It verifies that these callbacks correctly aggregate and track token usage metadata from language model invocations, including handling multiple models and both synchronous and asynchronous calls.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/callbacks/test_async_callback_manager.py",
            "description": "This file contains unit tests for `AsyncCallbackManager` and `AsyncCallbackHandler`, focusing on ensuring correct context variable propagation in asynchronous callbacks, especially for inline and shielded handlers.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/tracers/test_run_collector.py",
            "description": "This file contains unit tests for the `collect_runs` utility, verifying its functionality in capturing and storing details of LLM invocations within a specified context.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/tracers/test_memory_stream.py",
            "description": "This file contains unit tests for the `_MemoryStream` class, verifying its functionality for asynchronous communication, including scenarios with the same event loop and cross-thread operations.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/tracers/test_schemas.py",
            "description": "This file contains unit tests for the public API of the `schemas` module within `langchain_core.tracers`. It asserts that the module's public interface (`__all__`) matches an expected list of objects and that those objects are accessible.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/tracers/test_base_tracer.py",
            "description": "This file contains unit tests for the `BaseTracer` implementation in LangChain, verifying its ability to record and persist various types of execution runs (LLM, chat model, chain, tool, and nested runs) and handle associated events and errors.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/globals.py",
            "description": "This file re-exports global configuration functions for debugging, LLM caching, and verbosity from `langchain_core` for use within the `langchain_classic` library. It centralizes access to these global settings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/file.py",
            "description": "This file serves as a re-export point, making the `FileCallbackHandler` available within the `langchain_classic.callbacks` module by importing it from `langchain_core.callbacks.file`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/base.py",
            "description": "This file serves as a re-exporting module for core callback handler classes and mixins from `langchain_core`, making them accessible within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/utils.py",
            "description": "This file provides dynamic import handling for utilities that have been moved or deprecated, primarily re-exporting them from `langchain_community.callbacks.utils` for backward compatibility. It uses `__getattr__` to facilitate this dynamic lookup and potential deprecation warnings.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/human.py",
            "description": "This file acts as a compatibility layer or re-export module for human approval callback handlers. It dynamically imports and re-exposes classes like `HumanApprovalCallbackHandler` from `langchain_community.callbacks.human`, likely to manage module deprecation or relocation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/__init__.py",
            "description": "This `__init__.py` file makes various core and classic LangChain callback handlers available for import. It also handles dynamic loading and deprecation for callback handlers from the `langchain_community` package.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/streaming_aiter.py",
            "description": "This file defines an asynchronous callback handler that captures streaming LLM tokens and provides them via an async iterator for real-time processing.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/manager.py",
            "description": "This file consolidates and re-exports callback and tracing management functionalities from `langchain_core`, while also handling deprecated imports from `langchain_community` for backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/context_callback.py",
            "description": "This file acts as a compatibility layer, dynamically importing `ContextCallbackHandler` from `langchain_community` to maintain backward compatibility or facilitate migration. It uses `__getattr__` to expose the class as if it were defined locally, while internally redirecting to the new location.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/root_listeners.py",
            "description": "This file re-exports the `RootListenersTracer` class from `langchain_core`, making it available within the `langchain_classic` library's callback tracing utilities.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/log_stream.py",
            "description": "This file re-exports log streaming classes and types from `langchain_core`, serving as an access point for log stream functionality within the classic LangChain library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/schemas.py",
            "description": "This file re-exports the `Run` schema from `langchain_core` for use and compatibility within the `langchain_classic` module.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/__init__.py",
            "description": "This file defines and exposes various callback handlers and tracers for recording and monitoring LangChain run executions. It consolidates imports and handles deprecated tracer classes for backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/logging.py",
            "description": "This file defines a `LoggingCallbackHandler` class that integrates LangChain callbacks with Python's standard logging system. It allows LangChain events, particularly text outputs, to be directed to a specified logger at a given log level.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/base.py",
            "description": "This file re-exports base interfaces for tracing runs, specifically `BaseTracer` and `TracerException`, from the `langchain_core` library. It serves as a central point for these core tracing components within the `langchain_classic` structure.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/tracers/run_collector.py",
            "description": "This file re-exports the `RunCollectorCallbackHandler` from `langchain_core`, making it accessible within the `langchain_classic` package for collecting run data.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/streamlit/streamlit_callback_handler.py",
            "description": "This file provides backward compatibility for Streamlit callback-related classes by dynamically redirecting imports from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/base.py",
            "description": "This file re-exports core callback-related classes from `langchain_core` to maintain compatibility or provide a classic access point within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/manager.py",
            "description": "This file re-exports various callback manager classes and related utility functions for both synchronous and asynchronous operations, originating from `langchain_core`. It acts as an aggregation point for callback management within the classic LangChain library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/tracers/root_listeners.py",
            "description": "This file re-exports `RootListenersTracer` from `langchain_core`, making it accessible under the `langchain_classic` namespace. It serves as an alias or compatibility layer for callback tracing functionalities.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/tracers/run_collector.py",
            "description": "This file re-exports the `RunCollectorCallbackHandler` from `langchain_core.tracers.run_collector`, making it available within the `langchain_classic` tracing schema.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/tracers/log_stream.py",
            "description": "This file re-exports classes and variables related to log streaming and tracing, such as `LogEntry`, `RunLog`, and `LogStreamCallbackHandler`, from `langchain_core.tracers.log_stream`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/tracers/base.py",
            "description": "This file re-exports the `BaseTracer` and `TracerException` classes from `langchain_core`, making core tracing functionalities available within the `langchain_classic` library's schema.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/callbacks/tracers/schemas.py",
            "description": "This file re-exports the `Run` schema from `langchain_core.tracers.schemas`, providing it under the `langchain_classic` namespace for compatibility or structured access.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/smith/evaluation/progress.py",
            "description": "This file defines a `ProgressBarCallback` class that provides a simple console progress bar, designed to be used with LangChain operations to track their progress.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 45
          },
          {
            "name": "Christophe Bornet",
            "percent": 25
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 6
          }
        ]
      },
      "Application Evaluation Framework": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/model_laboratory.py",
            "description": "This file defines the `ModelLaboratory` class, a utility designed for experimenting with and comparing the outputs of various language models or chains on a given input text.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/callbacks/confident_callback.py",
            "description": "This file manages deprecated imports, specifically providing a dynamic lookup for `DeepEvalCallbackHandler` which has moved to `langchain_community`. It ensures backward compatibility by redirecting calls to the new module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/__init__.py",
            "description": "This module provides off-the-shelf evaluation chains and tools for grading the output of LangChain primitives, such as language models and chains, covering various use cases like accuracy, comparison, and criteria-based checks.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/loading.py",
            "description": "This file provides functions to load datasets from HuggingFace and to instantiate various types of evaluators (e.g., QA, criteria, string distance, JSON parsing) for evaluation tasks within the LangChain Classic framework.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/schema.py",
            "description": "This file defines the core interfaces and enumeration of types for various evaluators within the Langchain framework. It provides abstract base classes and mixins for implementing different strategies to evaluate string-based outputs from Language Models or chains.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/exact_match/base.py",
            "description": "This file defines a string evaluator that computes an exact match score between a prediction and a reference string. It supports options to ignore case, punctuation, and numbers during the comparison.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/scoring/prompt.py",
            "description": "This file defines chat prompt templates for scoring AI model responses based on specific criteria, designed for evaluating how well a model follows instructions and answers a given question. It includes templates for evaluation with and without a reference answer.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/scoring/__init__.py",
            "description": "This module defines and exports classes for scoring model outputs (LLMs, Chains) on a 1-10 scale, potentially using a reference answer, for evaluation purposes.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/scoring/eval_chain.py",
            "description": "This file defines base classes and components for evaluating and scoring model outputs (predictions) on a scale of 1-10 based on various criteria. It includes a chain (`ScoreStringEvalChain`) that uses an LLM to perform this scoring and an output parser for the results.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/qa/__init__.py",
            "description": "This file serves as the main entry point for question answering (QA) evaluation and generation utilities within the `langchain_classic` library, exporting various QA evaluation chains and a QA generation chain.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/qa/eval_chain.py",
            "description": "This file defines LLM-powered chains (`QAEvalChain` and `ContextQAEvalChain`) for evaluating the quality of question-answering systems. It includes logic to parse evaluation results, determining correctness or contextual accuracy based on an LLM's output.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/comparison/prompt.py",
            "description": "This file defines prompts and templates used for comparing and evaluating the quality of responses from two AI models to a given question, based on criteria like helpfulness, relevance, and accuracy. It is used to determine which assistant provides a better answer according to a specified evaluation methodology.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/comparison/eval_chain.py",
            "description": "This file provides base classes and tools for pairwise comparison and evaluation of two model outputs or responses, often against defined criteria.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/comparison/__init__.py",
            "description": "This module provides evaluators for comparing the outputs of two models, such as LLMs or Chains. It supports tasks like scoring preferences or measuring semantic equivalence between string pairs.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/criteria/__init__.py",
            "description": "This file provides criteria or rubric-based evaluators for assessing the output of language models or chains. It exports `Criteria`, `CriteriaEvalChain`, and `LabeledCriteriaEvalChain` for evaluating against predefined or custom criteria.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/criteria/prompt.py",
            "description": "This file defines Langchain `PromptTemplate` objects used for evaluating submitted answers against specified criteria, with an option to include a reference. These prompts guide an LLM to provide step-by-step reasoning and a binary 'Y'/'N' decision on whether the submission meets the criteria.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/criteria/eval_chain.py",
            "description": "This file defines classes and utilities for evaluating text using an LLM against predefined or custom criteria, including parsing the evaluation results into a structured format. It provides an `LLMChain` specifically designed for criterion-based evaluation.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/parsing/json_schema.py",
            "description": "This file defines the `JsonSchemaEvaluator` class, which validates if a given JSON prediction conforms to a provided JSON schema, returning a boolean score indicating validity.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/parsing/base.py",
            "description": "This file defines evaluators for assessing JSON strings, including checking for JSON validity and comparing two JSON strings for equality after parsing.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/regex_match/base.py",
            "description": "This file defines a string evaluator that checks if a prediction string matches a reference regular expression pattern. It provides a score of 1.0 for a match and 0.0 otherwise, with configurable regex flags.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/smith/__init__.py",
            "description": "This file serves as the `__init__.py` for the `langchain_classic.smith` package, providing utilities for connecting to LangSmith, primarily focused on running and configuring evaluations for language model applications. It exports key functions like `run_on_dataset`, `arun_on_dataset`, and the `RunEvalConfig` class.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/smith/evaluation/string_run_evaluator.py",
            "description": "This file provides a wrapper for string evaluators, defining mappers to extract relevant string inputs and predictions from LangChain `Run` objects and reference data from `Example` objects for evaluation purposes.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/smith/evaluation/config.py",
            "description": "This file defines configuration classes for various run evaluators used in LangChain Smith, including settings for different evaluation types like criteria, QA, embedding distance, and string matching.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/smith/evaluation/runner_utils.py",
            "description": "This file provides utilities for running and evaluating language models or Chains against datasets, including result aggregation and integration with LangSmith for tracing and evaluation.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/exact_match/test_base.py",
            "description": "This file contains unit tests for the `ExactMatchStringEvaluator` class, verifying its functionality for exact string matching, including scenarios with and without case sensitivity.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/parsing/test_json_schema.py",
            "description": "This file contains unit tests for the `JsonSchemaEvaluator` class, verifying its ability to validate JSON predictions against a provided JSON schema.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/parsing/test_base.py",
            "description": "This file contains unit tests for the `JsonValidityEvaluator` and `JsonEqualityEvaluator` classes, which are used to evaluate JSON string validity and equality, respectively. It covers various scenarios including valid/invalid JSON, custom comparison operators, and permutation-invariant list comparisons.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/criteria/test_eval_chain.py",
            "description": "This file contains unit tests for the `CriteriaEvalChain` and related components within the `langchain_classic.evaluation.criteria` module. It verifies functionality such as criteria resolution, output parsing, and chain execution for evaluating language model outputs.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/qa/__init__.py",
            "description": "This file contains unit tests for the QA evaluation chains within the Langchain library. It serves as an entry point or placeholder for such tests.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/qa/test_eval_chain.py",
            "description": "This file contains unit tests for the QA evaluation chains (QAEvalChain, ContextQAEvalChain, CotQAEvalChain) in the `langchain_classic` library. It verifies their functionality, output parsing, and adherence to the StringEvaluator protocol.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/regex_match/test_base.py",
            "description": "This file contains unit tests for the `RegexMatchStringEvaluator` class, verifying its ability to perform regex matching with and without case-insensitivity.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/scoring/test_eval_chain.py",
            "description": "This file contains unit tests for the `eval_chain` module, specifically for the `ScoreStringEvalChain` and `LabeledScoreStringEvalChain` classes, as well as their output parser `ScoreStringResultOutputParser`.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/comparison/test_eval_chain.py",
            "description": "This file contains unit tests for the pairwise string comparison evaluation chains and related utilities within the `langchain_classic` library. It tests components like `PairwiseStringEvalChain`, `LabeledPairwiseStringEvalChain`, `PairwiseStringResultOutputParser`, and criteria resolution.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/evaluation/run_evaluators",
            "description": "This directory contains unit tests for the `run_evaluators` functionality within the `langchain` library's evaluation framework. It ensures the correct execution and behavior of components responsible for orchestrating and performing evaluations.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/smith/evaluation/test_runner_utils.py",
            "description": "This file contains unit tests for the utility functions used in LangSmith evaluation, specifically testing input parsing, validation for LLMs and chains, and the `arun_on_dataset` asynchronous function.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/smith/evaluation/test_string_run_evaluator.py",
            "description": "This file contains unit tests for the `StringRunEvaluatorChain`, verifying its functionality and error handling when evaluating string runs using a mocked LLM and evaluation criteria.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/evaluation",
            "description": "This directory contains integration tests specifically designed to validate the functionality and performance of evaluation-related components within the Langchain library. It ensures that the evaluation features work correctly when integrated with other parts of the system.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 78
          },
          {
            "name": "Christophe Bornet",
            "percent": 16
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 2
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 169,
      "spofCount": 48
    },
    "busFactor": 4,
    "authorCount": 25
  },
  "Prompt Engineering & Management": {
    "description": "Offers a set of tools and templates to simplify the creation, optimization, and management of prompts for language models. This module helps developers construct dynamic and context-aware prompts that are crucial for controlling model behavior and achieving desired outcomes.",
    "functions": {
      "Prompty Format Integration": {
        "files": [
          {
            "path": "libs/partners/prompty/langchain_prompty/langchain.py",
            "description": "This file defines a utility function `create_chat_prompt` that generates a LangChain ChatPromptTemplate from a specified schema path. It dynamically constructs the prompt by processing messages and integrating a MessagesPlaceholder for agent scratchpad content.",
            "spof": false
          },
          {
            "path": "libs/partners/prompty/langchain_prompty/renderers.py",
            "description": "This file defines a `MustacheRenderer` class responsible for rendering Prompty templates using the Mustache templating engine. It includes a utility function to convert LangChain `BaseMessage` objects into dictionaries, ensuring compatibility with Mustache for template rendering.",
            "spof": true
          },
          {
            "path": "libs/partners/prompty/langchain_prompty/__init__.py",
            "description": "This file initializes the `langchain_prompty` package, setting up core components like renderers and parsers for Microsoft Prompty integration. It also exposes the `create_chat_prompt` function as part of its public API.",
            "spof": true
          },
          {
            "path": "libs/partners/prompty/langchain_prompty/core.py",
            "description": "This file defines the core data structures for 'Prompty' models, which are used to encapsulate prompt definitions, model configurations, and I/O specifications. It also provides an `InvokerFactory` for managing and invoking various processing components (renderers, parsers, executors, processors) associated with these prompty models.",
            "spof": false
          },
          {
            "path": "libs/partners/prompty/langchain_prompty/parsers.py",
            "description": "This file defines a parser for 'Prompty' chat prompts, converting a structured string input into a list of LangChain-compatible message dictionaries, including support for parsing and inlining local images.",
            "spof": false
          },
          {
            "path": "libs/partners/prompty/tests/unit_tests/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_prompty` package correctly lists all intended public exports, ensuring API consistency.",
            "spof": true
          },
          {
            "path": "libs/partners/prompty/tests/unit_tests/test_standard.py",
            "description": "This file contains a benchmark test for the `create_chat_prompt` function from the `langchain_prompty` library. It measures the initialization time required to create multiple chat prompts.",
            "spof": true
          },
          {
            "path": "libs/partners/prompty/tests/unit_tests/test_prompty_serialization.py",
            "description": "This file contains unit tests for the `langchain_prompty` serialization and integration with LangChain chains and agents. It verifies that Prompty prompts can be correctly created, invoked, and used within agent workflows.",
            "spof": false
          },
          {
            "path": "libs/partners/prompty/tests/unit_tests/test_invoker_thread_safety.py",
            "description": "This file contains unit tests for the `InvokerFactory` in the `langchain-prompty` library, primarily verifying its thread-safety and singleton pattern under concurrent and sequential access. It also includes a test for the proper registration of NOOP invokers.",
            "spof": true
          },
          {
            "path": "libs/partners/prompty/tests/unit_tests/prompts",
            "description": "This directory contains unit tests specifically for the prompt-related functionalities within the `prompty` library. Its purpose is to validate the correct behavior and integration of various prompt components, ensuring reliability and proper operation of the `libs/partners/prompty` module.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sourab Singh Bora",
            "percent": 35
          },
          {
            "name": "Mason Daugherty",
            "percent": 27
          },
          {
            "name": "Chuyuan Qu",
            "percent": 22
          }
        ]
      },
      "Prompt Templating Engine": {
        "files": [
          {
            "path": "libs/core/langchain_core/prompts/image.py",
            "description": "This file defines the `ImagePromptTemplate` class, which is used to create and format image prompts for multimodal models. It handles the structure and validation of image URLs within prompts.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/prompts/structured.py",
            "description": "This file defines the `StructuredPrompt` class, which extends `ChatPromptTemplate` to create prompts specifically designed for language models that are expected to return structured outputs, often based on a provided schema (like a Pydantic model or dictionary). It facilitates piping these prompts to language models that support structured output generation.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/prompts/prompt.py",
            "description": "This file defines the `PromptTemplate` class, which is used to create and manage templates for language model prompts. It supports various formatting syntaxes like f-strings, Jinja2, and Mustache, allowing for dynamic prompt generation.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/prompts/dict.py",
            "description": "This file defines the `DictPromptTemplate` class, which allows creating prompt templates based on dictionaries where variables can be embedded in dictionary values. It supports f-string and mustache formatting for variable substitution.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/prompts/loading.py",
            "description": "This file provides utilities for loading and parsing various types of LangChain prompt templates (e.g., PromptTemplate, FewShotPromptTemplate, ChatPromptTemplate) from configuration dictionaries or files (JSON/YAML).",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/prompts/__init__.py",
            "description": "This file serves as the main entry point for the `prompts` package, aggregating and exposing various prompt-related classes and functions via dynamic imports. It defines the public API for interacting with different types of prompt templates and utilities.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/prompts/chat.py",
            "description": "This file defines core components for creating and managing chat prompt templates within Langchain, including placeholders for message history and base classes for string-based message prompts.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/prompts/message.py",
            "description": "This file defines the `BaseMessagePromptTemplate` abstract base class, which provides a common interface for prompt templates that format messages. It includes methods for formatting messages, asynchronous formatting, and defining input variables for such templates.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/prompts/few_shot.py",
            "description": "This file defines prompt templates that support few-shot learning by incorporating example sets, either fixed or dynamically selected, into the prompt. It provides implementations for both string-based prompts (`FewShotPromptTemplate`) and chat message-based prompts (`FewShotChatMessagePromptTemplate`).",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/prompts/string.py",
            "description": "This file defines utility functions for formatting, validating, and extracting variables from prompt templates using different formats like f-strings, Jinja2, and Mustache. It includes security warnings and validation logic specific to each templating engine.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/prompts/base.py",
            "description": "This file defines the abstract base class `BasePromptTemplate` for all prompt templates in LangChain. It provides the core structure and functionality for managing input variables, partial variables, validation, and formatting prompts into `PromptValue` objects.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/utils/formatting.py",
            "description": "This file provides utility functions and a custom `StrictFormatter` class for robust string formatting, specifically designed to enforce keyword-only arguments and validate input variables for prompt templates within the LangChain core library.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/test_prompt_values.py",
            "description": "This file contains unit tests for the `ChatPromptValueConcrete` class, verifying its ability to correctly handle and store various types of chat messages and message chunks.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_core.prompts` accurately lists all the expected public API components for prompts.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_string.py",
            "description": "This file contains unit tests for functions related to parsing and generating schemas for 'mustache' style prompt templates in Langchain Core, including nested variable handling.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/__init__.py",
            "description": "This is the package initialization file for unit tests specifically designed to evaluate prompt-related functionalities within the langchain core library.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_chat.py",
            "description": "This file contains unit tests for the ChatPromptTemplate and related message prompt template classes within the `langchain_core` library, covering their creation, formatting, and behavior with different template types and variables.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_dict.py",
            "description": "This file contains unit tests for the `DictPromptTemplate` class. It specifically tests its f-string formatting capabilities and its deserialization from a legacy format.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_image.py",
            "description": "This file contains unit tests to ensure that image prompt templates within LangChain's core library can be correctly serialized and deserialized. It checks both the current and an older serialization format for `ChatPromptTemplate` instances containing image prompts.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_loading.py",
            "description": "This file contains unit tests for the prompt loading functionality within the Langchain core library. It verifies the ability to load various prompt types (e.g., PromptTemplate, FewShotPromptTemplate) from YAML and JSON files, including scenarios with external template files and example configurations, and tests for security vulnerabilities related to Jinja2.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_prompt.py",
            "description": "This file contains unit tests for the `PromptTemplate` class in the `langchain_core` library, covering its construction, template parsing, input variable handling, file loading with different encodings, and various template formats like Mustache.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_structured.py",
            "description": "This file contains unit tests for the `StructuredPrompt` class, verifying its functionality with different output schemas (Pydantic models and dictionaries), custom keyword arguments, and various template formats like Mustache.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/data/prompts",
            "description": "This directory is designated to store data utilized by unit tests for prompt-related functionalities within the `langchain/libs/core` library. It serves as a placeholder or container for test data specifically for prompt unit tests.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/formatting.py",
            "description": "This file provides deprecated formatting utilities for backward compatibility, re-exporting `StrictFormatter` and `formatter` from `langchain_core.utils.formatting`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/prompt_selector.py",
            "description": "This file defines abstract and concrete classes for dynamically selecting a prompt template based on the type of a given language model, along with helper functions for checking model types.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/openapi/prompts.py",
            "description": "This file acts as a compatibility layer, dynamically importing `REQUEST_TEMPLATE` and `RESPONSE_TEMPLATE` from `langchain_community.chains.openapi.prompts`. It ensures older code referencing these templates continues to function while directing usage to the community package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/llms/grammars",
            "description": "This directory is intended to store grammar definitions or specifications used by Language Models (LLMs) within the `langchain_classic` library. It likely holds rules or structures for guiding LLM output, even though it is currently empty.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/prompt.py",
            "description": "This file provides backward compatibility for the 'Prompt' class by aliasing 'PromptTemplate' from `langchain_core.prompts.prompt`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/base.py",
            "description": "This file serves as an aggregation point, re-exporting core prompt template classes and utility functions from `langchain_core.prompts` for easier access within the `langchain_classic` module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/loading.py",
            "description": "This file serves as an aggregation point for prompt loading utilities, re-exporting functions from `langchain_core.prompts.loading` to make them accessible within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/chat.py",
            "description": "This file serves as an aggregation point, re-exporting various chat prompt-related classes and types from `langchain_core` for use within the `langchain_classic` library. It makes chat prompt templates, message prompt templates, and prompt value classes easily accessible.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/few_shot.py",
            "description": "This file re-exports classes related to few-shot prompt templating, such as `FewShotChatMessagePromptTemplate` and `FewShotPromptTemplate`, from `langchain_core.prompts.few_shot` for use within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/__init__.py",
            "description": "This file serves as the main entry point for the `langchain_classic.prompts` module, aggregating and exporting various prompt template classes, chat prompt templates, and example selectors for easy access. It facilitates the construction and management of prompts for language models.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/schema/prompt.py",
            "description": "This file re-exports the `PromptValue` class from `langchain_core`, serving as part of the prompt schema within the `langchain_classic` library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/utilities/opaqueprompts.py",
            "description": "This file acts as a backward compatibility layer for `langchain_classic`, dynamically importing `sanitize` and `desanitize` functionalities which have been moved to `langchain_community.utilities.opaqueprompts`.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_prompt.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_classic.schema.prompt` module correctly exposes the expected public symbols, specifically `PromptValue`.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/prompts/test_loading.py",
            "description": "This file contains unit tests for the `langchain.prompts.loading` module, specifically verifying that the `__all__` variable correctly lists all public imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/prompts/__init__.py",
            "description": "This file is part of the unit tests for the `prompts` module within the LangChain library. It is designed to test the functionality related to prompts.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/prompts/test_chat.py",
            "description": "This file contains unit tests for the `__all__` variable in the `langchain_classic.prompts.chat` module, ensuring that all expected components are exposed for import.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/prompts/test_base.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_classic.prompts.base` correctly lists all expected public symbols.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/prompts/test_imports.py",
            "description": "This unit test file verifies that the `__all__` attribute of the `langchain_classic.prompts` module correctly exports all expected prompt-related classes and functions.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/prompts/test_prompt.py",
            "description": "This file contains a unit test that verifies the `__all__` variable in the `langchain_classic.prompts.prompt` module correctly exposes the `Prompt` and `PromptTemplate` classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/data/prompts",
            "description": "This directory is designated to store prompt-related data specifically used in unit tests for the LangChain library. Although currently empty, its purpose is to provide test data for verifying the functionality of prompt handling components.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/prompts",
            "description": "This directory contains integration tests specifically designed for the 'prompts' component of the LangChain library. It ensures that prompt-related functionalities, such as prompt templates and input formatting, work correctly when integrated with other parts of the system or external models.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 34
          },
          {
            "name": "Christophe Bornet",
            "percent": 21
          },
          {
            "name": "Bagatur",
            "percent": 10
          }
        ]
      },
      "Dynamic Example Selection": {
        "files": [
          {
            "path": "libs/core/langchain_core/example_selectors/length_based.py",
            "description": "This file defines the `LengthBasedExampleSelector` class, which selects examples for a prompt based on a maximum length constraint, prioritizing those that fit within the specified limit. It helps manage prompt length by dynamically choosing examples.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/example_selectors/__init__.py",
            "description": "This file defines and exposes various example selector implementations for `langchain_core`, which are used to select relevant examples for inclusion in prompts. It uses dynamic imports to make these selectors accessible.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/example_selectors/base.py",
            "description": "This file defines the abstract base interface, `BaseExampleSelector`, for selecting examples to include in prompts, providing methods to add and select examples both synchronously and asynchronously.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/example_selectors/semantic_similarity.py",
            "description": "This file defines example selectors that retrieve examples from a vector store based on semantic similarity or maximum marginal relevance. It provides mechanisms to select and manage examples for language model prompts.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/example_selectors/test_length_based_example_selector.py",
            "description": "This file contains unit tests for the `LengthBasedExampleSelector` class, verifying its ability to select, add, and trim examples based on a specified maximum length.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/example_selectors/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_core.example_selectors` correctly exposes all expected public components. It ensures the module's public interface is as intended.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/example_selectors/test_base.py",
            "description": "This file contains unit tests for the asynchronous methods of `BaseExampleSelector` by implementing a dummy selector and testing its `aadd_example` and `aselect_examples` functionality.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_few_shot.py",
            "description": "This file contains unit tests for the `FewShotPromptTemplate` and `FewShotChatMessagePromptTemplate` classes within the LangChain Core library, verifying their functionality with examples, partial variables, and different template formats like Jinja2.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/prompts/test_utils.py",
            "description": "This file contains unit tests for prompt utility functions, specifically testing the `sorted_values` function used for example selectors within the LangChain core library.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/example_selector/length_based.py",
            "description": "This file serves as a re-export of the `LengthBasedExampleSelector` class, likely for backward compatibility or module organization, making it accessible through this path.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/example_selector/semantic_similarity.py",
            "description": "This file serves as a re-export point, making semantic similarity example selectors and related utilities from `langchain_core` available within the `langchain_classic` library for backward compatibility or structured organization.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/example_selector/ngram_overlap.py",
            "description": "This file acts as a re-export or compatibility layer, dynamically importing `NGramOverlapExampleSelector` and `ngram_overlap_score` from `langchain_community.example_selectors.ngram_overlap`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/example_selector/__init__.py",
            "description": "This file serves as the `__init__.py` for the `example_selector` package, exposing various example selector classes from `langchain_core` and `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/prompts/example_selector/base.py",
            "description": "This file defines the base abstract class or interface for example selectors within the `langchain_classic` prompts module, re-exporting it from `langchain_core`.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/prompts/test_few_shot.py",
            "description": "This file contains unit tests for the `few_shot` prompt module, specifically verifying that its `__all__` attribute correctly exposes the intended public classes and mixins.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Christophe Bornet",
            "percent": 33
          },
          {
            "name": "Mason Daugherty",
            "percent": 26
          },
          {
            "name": "XXt",
            "percent": 13
          }
        ]
      },
      "Hub Integration for Prompts": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/hub.py",
            "description": "This file provides an interface for interacting with the LangChain Hub, allowing users to push and pull LangChain objects (like prompts) from the hub. It supports both the newer LangSmith client and the legacy `langchainhub` client.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/runnables/test_hub.py",
            "description": "This file contains unit tests for the `HubRunnable` class, verifying its ability to pull prompt templates from a hub and its configurable features for dynamically switching between different prompts.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/test_hub.py",
            "description": "This file contains integration tests for the LangChain Hub functionality, verifying the ability to pull both public and private prompts and asserting their structure and metadata.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 74
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 8
          },
          {
            "name": "Christophe Bornet",
            "percent": 6
          }
        ]
      },
      "Application-Specific Prompt Library": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/conversational_retrieval/prompts.py",
            "description": "This file defines prompt templates for conversational retrieval chains, including one to rephrase follow-up questions and another for answering questions based on provided context.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/constitutional_ai/principles.py",
            "description": "This file defines a collection of constitutional principles used in Constitutional AI, categorizing various ethical and safety-related guidelines (e.g., harmful, insensitive, unbiased reasoning) for critiquing and revising AI model responses.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/constitutional_ai/models.py",
            "description": "This file defines the `ConstitutionalPrinciple` Pydantic model, which specifies the structure for a constitutional principle used within the Constitutional AI chain, including critique and revision requests.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/constitutional_ai/prompts.py",
            "description": "This file defines prompt templates and few-shot examples for Constitutional AI, facilitating the critique and revision of a language model's responses. It includes prompts for generating critiques of model outputs and for revising those outputs based on given critiques and revision requests.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/api/prompt.py",
            "description": "This file defines PromptTemplate objects used to generate API URLs from documentation and user questions, and to summarize API responses based on the initial question and documentation. It provides templates for constructing API calls and interpreting their results.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/chat_vector_db/prompts.py",
            "description": "This file defines prompt templates for a chat-based question answering system. It includes templates for rephrasing follow-up questions into standalone questions and for answering questions based on provided context.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/elasticsearch_database/prompts.py",
            "description": "This file defines prompt templates for interacting with an Elasticsearch database using Langchain, including templates for generating Elasticsearch queries and for formulating answers based on query results.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/conversation/prompt.py",
            "description": "This file defines a default conversational prompt template for AI interactions, and re-exports various prompt constants related to entity extraction, summarization, and knowledge triples for use in Langchain's conversation chains.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/prompts.py",
            "description": "This file acts as a compatibility layer, re-exporting various graph QA prompt templates that have been moved to the `langchain_community` package. It provides backward compatibility through a dynamic import mechanism for these deprecated modules.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_math/prompt.py",
            "description": "This file defines a `PromptTemplate` for an LLM chain, instructing it to translate mathematical questions into `numexpr` compatible Python expressions, evaluate them, and use the result to answer the original question. It provides examples for this translation and evaluation process.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/flare/prompts.py",
            "description": "This file defines prompt templates and an output parser for a language model chain, specifically for generating responses, handling context, and formulating questions for uncertain spans. It includes a mechanism to signal the completion of a response using a 'FINISHED' marker.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/hyde/prompts.py",
            "description": "This file defines a collection of `PromptTemplate` objects, each tailored for generating different types of passages (e.g., web search results, scientific paper sections, counter-arguments) based on specific inputs like questions, claims, or topics. These templates are then compiled into a `PROMPT_MAP` for easy access and organization.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/natbot/prompt.py",
            "description": "This file defines a `PromptTemplate` for an AI agent designed to control a web browser. It provides instructions on how the agent should interpret simplified browser content and issue commands to achieve a given objective.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_summarization_checker/prompts",
            "description": "This directory is intended to store prompt templates or definitions specifically used by the LLM summarization checker chain within the classic LangChain library. It likely contains the linguistic instructions given to an LLM to perform or evaluate summarization tasks.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_checker/prompt.py",
            "description": "This file defines a set of `PromptTemplate` objects used in a multi-step LLM-based checking or reasoning process. These prompts guide the LLM to create a draft answer, list assumptions, check those assumptions, and then revise the answer based on the checks.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/question_answering/map_rerank_prompt.py",
            "description": "This file defines a `PromptTemplate` and `RegexParser` for a question-answering chain using a map-rerank strategy. It provides detailed instructions and examples for an AI to answer questions based on context, along with a scoring mechanism for its answer's completeness.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/question_answering/stuff_prompt.py",
            "description": "This file defines prompt templates for question answering with context, including both standard and chat-specific formats. It also provides a selector to dynamically choose the appropriate prompt based on the model type.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/question_answering/refine_prompts.py",
            "description": "This file defines and selects prompt templates for question-answering and answer refinement tasks. It provides different prompt versions tailored for chat models versus standard language models.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/question_answering/map_reduce_prompt.py",
            "description": "This file defines prompt templates for both standard language models and chat models, used in the 'map-reduce' question-answering chain. It includes prompts for extracting relevant text from a document and for combining extracted parts into a final answer.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/summarize/map_reduce_prompt.py",
            "description": "This file defines a `PromptTemplate` used for summarizing text, specifically designed for the 'map-reduce' summarization chain within Langchain. It provides a basic template for generating a concise summary from input text.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/summarize/stuff_prompt.py",
            "description": "This file defines a `PromptTemplate` for summarizing text, specifically for the 'stuff' method of summarization within the LangChain framework. It provides a simple prompt instructing an LLM to generate a concise summary from given input text.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/summarize/refine_prompts.py",
            "description": "This file defines prompt templates for summarization tasks within LangChain, including a template for generating an initial concise summary and another for refining an existing summary with additional context.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/sql_database/prompt.py",
            "description": "This file defines PromptTemplate objects used for generating database-specific SQL queries from natural language questions. It includes templates for various SQL dialects like Generic, CrateDB, DuckDB, GoogleSQL, MSSQL, MySQL, MariaDB, and Oracle.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/query_constructor/prompt.py",
            "description": "This file defines prompt templates, schemas, and example data used by LangChain's query constructor to convert natural language queries into structured requests with filters and optional limits.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/query_constructor/base.py",
            "description": "This file defines the base components for an LLM chain that transforms a natural language user query into a structured query. It includes an output parser for structured queries and functions for constructing prompts and setting up the query constructor chain.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/qa_with_sources/refine_prompts.py",
            "description": "This file defines prompt templates used in LangChain's question-answering with sources chain, specifically for refining existing answers, generating initial answers from context, and formatting source examples.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/qa_with_sources/stuff_prompt.py",
            "description": "This file defines prompt templates for a question-answering system with source attribution. It specifically sets up a 'stuffing' prompt that takes extracted document parts and a question to generate a final answer with references.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/qa_with_sources/map_reduce_prompt.py",
            "description": "This file defines prompt templates for a 'Question Answering with Sources' system, specifically designed for a map-reduce strategy. It includes a prompt to extract relevant text from documents and another to combine extracted information into a final answer with source attribution.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/retrieval_qa/prompt.py",
            "description": "This file defines a `PromptTemplate` for a Retrieval-Augmented Generation (RAG) question-answering chain. It instructs a language model to answer a question based on provided context, explicitly stating if the answer is unknown.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/evaluation/qa/eval_prompt.py",
            "description": "This file defines various PromptTemplate objects for evaluating student answers in a quiz-grading context, including general Q&A evaluations (with and without context, and with chain-of-thought reasoning) and specialized SQL answer comparisons.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/tools/sql_database/prompt.py",
            "description": "This file provides backwards compatibility by dynamically re-exporting `QUERY_CHECKER` from `langchain_community.tools.sql_database.prompt` for older `langchain_classic` implementations. It acts as a proxy to maintain API stability for a moved component.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/question_answering/test_map_rerank_prompt.py",
            "description": "This file contains unit tests for the `map_rerank_prompt`'s output parser in `langchain_classic`. It verifies that the parser correctly extracts the answer and score from various formatted strings.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 86
          },
          {
            "name": "Christophe Bornet",
            "percent": 11
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 104,
      "spofCount": 23
    },
    "busFactor": 3,
    "authorCount": 15
  },
  "Composable Workflow Engine (LCEL)": {
    "description": "Provides the LangChain Expression Language (LCEL), a powerful declarative way to build and customize complex AI applications. It allows developers to easily chain together components, from language models to retrievers, to create robust and production-ready workflows.",
    "functions": {
      "Workflow Serialization and Loading": {
        "files": [
          {
            "path": "libs/partners/openai/tests/unit_tests/test_load.py",
            "description": "This file contains unit tests for the serialization and deserialization of OpenAI LLM and Chat models, as well as RunnableSequence chains, using LangChain's `load`, `loads`, `dumpd`, and `dumps` utilities.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/load/dump.py",
            "description": "This file provides functions (`dumps` and `dumpd`) for serializing LangChain `Serializable` objects into JSON strings or dictionaries. It includes mechanisms for escaping plain dictionaries to prevent deserialization vulnerabilities.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/load/mapping.py",
            "description": "This file defines a `SERIALIZABLE_MAPPING` that maps old `lc_namespace` paths of LangChain objects to their current locations. This mapping ensures backward compatibility, allowing serialization and deserialization of objects even if their classes have moved within the codebase across different LangChain versions.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/load/load.py",
            "description": "This file provides functionality for securely loading (deserializing) LangChain objects from JSON strings or objects. It implements a security model using allowlists for classes and import paths, along with mechanisms to prevent injection and block unsafe templates like Jinja2 during deserialization.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/load/serializable.py",
            "description": "This file defines the `Serializable` base class for objects that can be serialized to JSON within the LangChain framework, including mechanisms for handling secrets, attributes, and unique identification during serialization and deserialization.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/load/_validation.py",
            "description": "Provides serialization validation utilities for LangChain, implementing an escape-based mechanism to protect against injection attacks by distinguishing actual LangChain objects from user data that might mimic their structure during serialization and deserialization.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/load/test_secret_injection.py",
            "description": "This file contains unit tests to ensure that the Langchain serialization and deserialization process prevents 'secret injection'. It verifies that sensitive information resembling environment variables cannot be extracted or leaked from user-provided data during serialization, even when `secrets_from_env=True` is enabled.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/load/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_core.load` module correctly defines its public API. It asserts that the actual exported symbols match a predefined list of expected exports.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/runnables/hub.py",
            "description": "This file defines the `HubRunnable` class, which allows dynamically loading and using runnables from the LangChain Hub by specifying their owner, repository, and commit details.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/load/test_load.py",
            "description": "This file contains unit tests for the `loads` and `load` functions, ensuring proper serialization and deserialization of Langchain components like LLMs and LLMChains, including handling of secrets and non-serializable arguments.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "ccurme",
            "percent": 67
          },
          {
            "name": "Mason Daugherty",
            "percent": 13
          },
          {
            "name": "Christophe Bornet",
            "percent": 8
          }
        ]
      },
      "Runnable Execution Core": {
        "files": [
          {
            "path": "libs/core/langchain_core/__init__.py",
            "description": "This file defines the base abstractions, interfaces, and universal invocation protocol for the core components of the LangChain ecosystem, explicitly avoiding third-party integrations.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/__init__.py",
            "description": "This file serves as the main entry point for the `runnables` package, introducing the LangChain Expression Language (LCEL) and exporting core `Runnable` primitives and related utilities for building scalable LLM programs.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/config.py",
            "description": "This file defines the `RunnableConfig` TypedDict for configuring `Runnable` objects in LangChain and provides utility functions for managing, propagating, and patching these configurations, including callback, tracing, and concurrency settings.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/base.py",
            "description": "This file defines the abstract base class `Runnable`, which is a foundational component in LangChain for creating composable units of work that support invocation, batching, streaming, and parallel execution. It also details composition patterns and utility methods for these runnables.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/schema.py",
            "description": "This module defines type definitions for streaming events (`StreamEvent`, `StandardStreamEvent`, `CustomStreamEvent`) and their associated data (`EventData`) used by `Runnable` objects in LangChain. These types provide a structured schema for event handling during runnable execution.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/runnables/utils.py",
            "description": "This file provides utility functions and AST visitors for LangChain's `Runnable` objects. It includes tools for asynchronous concurrency control, introspection of callable arguments (e.g., `run_manager`, `config`), and analysis of function/lambda arguments and non-local variables.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/test_setup.py",
            "description": "This file contains a unit test to verify the setup of `langchain_core`'s blocking call detection. It asserts that blocking operations within `langchain_core` raise a `BlockingError`.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_concurrency.py",
            "description": "This file contains unit tests for the concurrency behavior of Langchain's `abatch`, `abatch_as_completed`, `batch`, and `batch_as_completed` operations, ensuring they respect the `max_concurrency` configuration.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_imports.py",
            "description": "This file contains unit tests to ensure that the public API surface (`__all__` variable) of the `langchain_core.runnables` module is correctly defined and matches expected exports, along with tests for specific internal imports.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_runnable_events_v2.py",
            "description": "This file contains unit tests for the `astream_events` API of Langchain runnables. It verifies the correct generation and sequencing of stream events for various runnable configurations, including chains, tools, and lambda functions.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_utils.py",
            "description": "This file contains unit tests for utility functions within `langchain_core.runnables`, specifically testing the extraction of lambda source code, indentation of text, and identification of nonlocal variables or dependencies for runnable functions.",
            "spof": true
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_runnable_events_v1.py",
            "description": "This module contains unit tests for the `astream_events` API of LangChain runnables, specifically for version 1 events. It verifies that various runnable configurations correctly emit stream events.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_config.py",
            "description": "This file contains unit tests for the configuration utilities within the `langchain_core.runnables.config` module, covering functions like `ensure_config`, `merge_configs`, and `run_in_executor`, with a focus on callback handling and configuration merging logic.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_runnable.py",
            "description": "This file contains unit tests for various LangChain Runnable components, including `RunnableLambda`, `RunnableSequence`, and `RunnableBranch`. It defines fake implementations for testing purposes and verifies their schema generation and basic invocation behavior.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/runnables/__init__.py",
            "description": "This file introduces LangChain's Runnable and Expression Language (LCEL), emphasizing their support for synchronous, asynchronous, batch, and streaming operations. It specifically contains non-core Runnable classes for these functionalities.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/config.py",
            "description": "This file re-exports runnable configuration utilities and types from `langchain_core.runnables.config`, making them available under the `langchain_classic` namespace.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/__init__.py",
            "description": "This module serves as the `__init__.py` for the `runnable` package, defining the core LangChain Expression Language (LCEL) and exposing fundamental `Runnable` primitives. It enables synchronous, asynchronous, batch, and streaming operations for LLM-powered programs.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/utils.py",
            "description": "This file serves as a re-exporting module, making various utility functions and classes related to runnables from 'langchain_core.runnables.utils' available under the 'langchain_classic' namespace.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/base.py",
            "description": "This file re-exports core Runnable classes and utilities from `langchain_core` for use within the `langchain_classic` module. It also includes an alias for `RunnableParallel` to maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_base.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_classic.schema.runnable.base` correctly exports a specific set of expected symbols.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_imports.py",
            "description": "This unit test file verifies that the `__all__` variable in `langchain_classic.schema.runnable` module correctly lists all expected public `Runnable` components. It ensures that the module's public API matches the predefined `EXPECTED_ALL` list.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_utils.py",
            "description": "This unit test file verifies that the `__all__` variable in the `langchain_classic.schema.runnable.utils` module correctly exposes all expected public API elements. It ensures that the module's public interface matches a predefined list.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_config.py",
            "description": "This unit test file verifies that the `__all__` variable in the `langchain.schema.runnable.config` module correctly lists all expected public symbols. It ensures the module's public interface is as intended.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 45
          },
          {
            "name": "Christophe Bornet",
            "percent": 24
          },
          {
            "name": "Erick Friis",
            "percent": 11
          }
        ]
      },
      "Workflow Graph Visualization": {
        "files": [
          {
            "path": "libs/core/langchain_core/runnables/graph_ascii.py",
            "description": "This file provides functionality to draw Directed Acyclic Graphs (DAGs) in ASCII format. It uses the grandalf library for graph layout and includes classes for handling ASCII canvas operations and vertex/edge visualization.",
            "spof": true
          },
          {
            "path": "libs/core/langchain_core/runnables/graph_mermaid.py",
            "description": "This file provides utilities for generating Mermaid graph syntax from graph data (nodes and edges) and rendering these Mermaid graphs into PNG images using various methods like API calls or Pyppeteer.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/graph_png.py",
            "description": "This file defines the `PngDrawer` class, a helper for visualizing `langchain_core` state graphs as PNG images. It utilizes `pygraphviz` to render and save the graph structure, including nodes, edges, and subgraphs, to a specified output path.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/graph.py",
            "description": "This file defines data structures (Node, Edge, Graph) and utilities for representing and manipulating graphs, specifically used with 'Runnable' objects within the LangChain framework. It includes methods for adding/removing nodes and edges, and serializing the graph to JSON.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_graph.py",
            "description": "This file contains unit tests for the `Graph` functionality within `langchain_core.runnables`, specifically for generating and manipulating graph representations of runnables and testing their visualization, including Mermaid diagrams.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/graphs/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `langchain_classic.graphs` module correctly lists all expected graph implementations. It ensures all graph classes are properly exposed for import.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Christophe Bornet",
            "percent": 28
          },
          {
            "name": "Mason Daugherty",
            "percent": 21
          },
          {
            "name": "Nuno Campos",
            "percent": 10
          }
        ]
      },
      "Composable Workflow Primitives": {
        "files": [
          {
            "path": "libs/core/langchain_core/runnables/configurable.py",
            "description": "This file defines `DynamicRunnable`, a base class for LangChain `Runnable` objects that support dynamic configuration at runtime. It enables Runnables to adapt their behavior based on provided configuration, often initiated via `configurable_fields` or `configurable_alternatives` methods.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/passthrough.py",
            "description": "This file implements the `RunnablePassthrough` class, which acts primarily as an identity function within LangChain runnables. It can pass inputs through unchanged or, if the input is a dictionary, enrich it by adding new keys to the output.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/branch.py",
            "description": "This file defines a `Runnable` class, `RunnableBranch`, which selects and executes a specific `Runnable` branch based on conditions. It allows for conditional execution of different runnables within a LangChain application, falling back to a default branch if no conditions are met.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/fallbacks.py",
            "description": "This file defines a `Runnable` class that provides a mechanism for retrying operations with alternative `Runnable` objects (fallbacks) when the primary operation fails due to specified exceptions. It allows for graceful degradation by trying a sequence of runnables until one succeeds or all fail.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/retry.py",
            "description": "This file defines `RunnableRetry`, a class that adds configurable retry logic to any LangChain `Runnable` to handle transient failures, such as network errors, using the `tenacity` library.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_configurable.py",
            "description": "This file contains unit tests for the `configurable_fields` and `configurable_alternatives` features of `RunnableSerializable` in LangChain, demonstrating how runnables can be dynamically configured and how configurations are passed to their methods.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_fallbacks.py",
            "description": "This file contains unit tests for the `RunnableWithFallbacks` class in LangChain. It verifies the behavior of fallbacks in handling errors across synchronous and asynchronous invoke, batch, and stream operations.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/runnables/openai_functions.py",
            "description": "This file defines a runnable (`OpenAIFunctionsRouter`) that parses OpenAI function call outputs and routes execution to a corresponding runnable based on the detected function name.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/passthrough.py",
            "description": "This file re-exports core `RunnablePassthrough` components, `RunnableAssign`, and identity functions from `langchain_core` for compatibility or convenience within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/branch.py",
            "description": "This file re-exports the `RunnableBranch` class from `langchain_core.runnables.branch`, making it accessible via this module path. It serves to maintain compatibility or structure within the Langchain Classic library.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/configurable.py",
            "description": "This file re-exports configurable runnable components from `langchain_core`, making them accessible within the `langchain_classic.schema.runnable` module.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/retry.py",
            "description": "This file re-exports `RunnableRetry` and `U` from `langchain_core`, providing access to retry-related functionality for runnables within the `langchain_classic` schema.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/fallbacks.py",
            "description": "This file re-exports the `RunnableWithFallbacks` class from `langchain_core`, providing it within the `langchain_classic` schema. It serves as an access point for defining runnable fallbacks in older or specific parts of the codebase.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_passthrough.py",
            "description": "This file contains unit tests for the `__all__` variable in the `passthrough` module, ensuring it correctly exports `RunnableAssign`, `RunnablePassthrough`, `aidentity`, and `identity`.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_branch.py",
            "description": "This unit test file verifies that the `__all__` variable in the `langchain_classic.schema.runnable.branch` module correctly exports the `RunnableBranch` class.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_retry.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_classic.schema.runnable.retry` module correctly lists its public API elements.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_configurable.py",
            "description": "This file contains a unit test that verifies the `__all__` variable in the `langchain_classic.schema.runnable.configurable` module, ensuring its public API is correctly defined and exposed.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_fallbacks.py",
            "description": "This file contains a unit test to verify the `__all__` variable of the `langchain_classic.schema.runnable.fallbacks` module. It ensures that only `RunnableWithFallbacks` is explicitly exposed.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 47
          },
          {
            "name": "Christophe Bornet",
            "percent": 30
          },
          {
            "name": "Harrison Chase",
            "percent": 5
          }
        ]
      },
      "Legacy Chain Abstraction": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/sequential.py",
            "description": "This file defines two classes, `SequentialChain` and `SimpleSequentialChain`, which allow for chaining multiple LangChain `Chain` objects where the output of one chain feeds directly into the next. `SequentialChain` handles general cases with multiple inputs and outputs, while `SimpleSequentialChain` is a simplified version for chains with a single input and output.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/transform.py",
            "description": "This file defines the `TransformChain` class, which allows arbitrary Python functions (synchronous or asynchronous) to be integrated as steps within a larger processing chain to transform inputs into outputs.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/mapreduce.py",
            "description": "This file defines the `MapReduceChain`, which splits a document into smaller parts, processes them with an LLM, and then combines the results. It is marked as deprecated.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/base.py",
            "description": "This file defines the abstract base interface for all 'Chain' objects in Langchain, providing common methods, properties, and an API contract for sequential operations and component orchestration within the framework. It handles aspects like callbacks, memory, and input/output schema management for chains.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm.py",
            "description": "This file defines the deprecated `LLMChain` class, which integrates a prompt template with a language model to generate responses. It provides synchronous and asynchronous methods for LLM interaction, with a recommendation to use `RunnableSequence` instead.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/query_constructor/__init__.py",
            "description": "This file serves as the package initializer for `query_constructor`, exposing the `load_query_constructor_runnable` function for direct import.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_base.py",
            "description": "This file contains unit tests for the base Chain class in LangChain. It defines fake memory and chain implementations to test various functionalities, error handling, callback integration, and run ID management of the core chain logic.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_imports.py",
            "description": "This file contains a unit test to verify that all expected chain classes and functions are correctly exposed in the `langchain_classic.chains` module. It ensures the public API surface of the chains module matches a predefined list.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_sequential.py",
            "description": "This file contains unit tests for the `SequentialChain` and `SimpleSequentialChain` classes, verifying their functionality with single/multiple inputs/outputs, memory integration, callbacks, and error handling.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_transform.py",
            "description": "This file contains unit tests for the `TransformChain` class within the `langchain_classic` library. It verifies the chain's ability to apply a transformation function and handles cases with missing input variables.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/chains/__init__.py",
            "description": "This file serves as the package initializer for the integration tests specifically designed for LangChain's chain components. It indicates that this directory contains all integration tests related to chains.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 71
          },
          {
            "name": "Christophe Bornet",
            "percent": 17
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 4
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 68,
      "spofCount": 20
    },
    "busFactor": 3,
    "authorCount": 12
  },
  "Conversational Memory Management": {
    "description": "Provides a robust framework for managing conversation history in chat-based applications. This module allows applications to remember past interactions, enabling more natural, stateful, and context-aware conversations with users.",
    "functions": {
      "Runnable-Based History Management": {
        "files": [
          {
            "path": "libs/core/langchain_core/chat_history.py",
            "description": "This file defines an abstract base class (`BaseChatMessageHistory`) for managing and storing chat message interactions, along with a concrete in-memory implementation (`InMemoryChatMessageHistory`). It provides methods for adding, retrieving, and clearing chat messages, including synchronous and asynchronous variants.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/chat_sessions.py",
            "description": "This file defines the `ChatSession` TypedDict, which represents a single conversation or group of chat messages and associated function call specifications within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/chat_loaders.py",
            "description": "This file defines the abstract base class `BaseChatLoader` for asynchronously and synchronously loading chat sessions within the `langchain_core` library.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/modifier.py",
            "description": "This file defines the `RemoveMessage` class within the `langchain_core.messages` module, which represents a special message type used to signal the deletion of other messages by their ID.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/messages/chat.py",
            "description": "This file defines the `ChatMessage` and `ChatMessageChunk` classes, which represent a message with an arbitrary speaker role and its streamable chunk counterpart within Langchain's core messaging system. It includes logic for merging message chunks.",
            "spof": false
          },
          {
            "path": "libs/core/langchain_core/runnables/history.py",
            "description": "This file defines `RunnableWithMessageHistory`, a `Runnable` that wraps another `Runnable` to manage and update chat message history for conversational applications. It handles reading and writing chat messages based on a provided session history factory and configurable parameters.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/chat_history/test_chat_history.py",
            "description": "This file contains unit tests for the `BaseChatMessageHistory` abstract base class, verifying its message addition, bulk message addition, and asynchronous chat history operations.",
            "spof": false
          },
          {
            "path": "libs/core/tests/unit_tests/runnables/test_history.py",
            "description": "This file contains unit tests for the `RunnableWithMessageHistory` component in LangChain, verifying its behavior in managing chat message history across different input/output formats and synchronous/asynchronous execution modes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/chat.py",
            "description": "This file re-exports the `ChatSession` class from `langchain_core`, making it available within the `langchain_classic.schema` module. It serves to integrate and expose the core chat session definition.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/runnable/history.py",
            "description": "This file re-exports key components related to message history, including callables, message types, and runnables with message history, from `langchain_core` for use within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_history_aware_retriever.py",
            "description": "This file contains unit tests for the `create_history_aware_retriever` function, verifying its behavior with different inputs and chat history states using mock LLMs and retrievers.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/memory/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the unit tests pertaining to the `memory` module within the LangChain library.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_chat_history.py",
            "description": "This file contains unit tests for the `__all__` variable in the `langchain_classic.schema.chat_history` module. It verifies that only `BaseChatMessageHistory` is exposed publicly from that module.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_chat.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in the `langchain_classic.schema.chat` module correctly exposes the expected symbols, specifically `ChatSession`.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/runnable/test_history.py",
            "description": "This file contains a unit test to verify that the `__all__` variable in `langchain_classic.schema.runnable.history` correctly exports the expected symbols. It checks for the presence of `RunnableWithMessageHistory`, `GetSessionHistoryCallable`, and `MessagesOrDictWithMessages` in the module's public interface.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 40
          },
          {
            "name": "Christophe Bornet",
            "percent": 33
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 5
          }
        ]
      },
      "Chat History Storage Backends": {
        "files": [
          {
            "path": "libs/standard-tests/tests/unit_tests/test_in_memory_base_store.py",
            "description": "This file contains unit tests for the `InMemoryStore` class, verifying its synchronous and asynchronous functionalities using pytest fixtures and base test classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/motorhead_memory.py",
            "description": "This file acts as a compatibility layer to re-export `MotorheadMemory` from its new location in `langchain_community` while maintaining backward compatibility for `langchain_classic` imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/zep_memory.py",
            "description": "This file provides backward compatibility for `ZepMemory`, dynamically importing it from `langchain_community.memory.zep_memory`. It serves as a transitional module to handle deprecated imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/singlestoredb.py",
            "description": "This file acts as a compatibility layer for `SingleStoreDBChatMessageHistory`, dynamically importing it from `langchain_community.chat_message_histories`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/in_memory.py",
            "description": "This file provides an in-memory implementation of chat message history, re-exporting the `InMemoryChatMessageHistory` class from `langchain_core` as `ChatMessageHistory`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/astradb.py",
            "description": "This file acts as a compatibility layer, re-exporting `AstraDBChatMessageHistory` from `langchain_community` to maintain backward compatibility within `langchain_classic` and handle deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/elasticsearch.py",
            "description": "This file acts as a compatibility layer, re-exporting `ElasticsearchChatMessageHistory` from `langchain_community` to maintain backward compatibility within `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/__init__.py",
            "description": "This file acts as a compatibility layer and dynamic importer for chat message history classes. It re-exports various chat message history implementations, typically from the `langchain_community` package, handling deprecation and ensuring backward compatibility for `langchain_classic` users.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/cosmos_db.py",
            "description": "This file acts as a compatibility layer or redirect for the `CosmosDBChatMessageHistory` class, allowing it to be imported from `langchain_classic` while actually sourcing it from `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/rocksetdb.py",
            "description": "This file acts as a compatibility layer or re-exporter for `RocksetChatMessageHistory`, dynamically importing it from `langchain_community` while handling potential deprecation.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/momento.py",
            "description": "This file acts as a compatibility shim, dynamically re-exporting `MomentoChatMessageHistory` from `langchain_community.chat_message_histories` to ensure backward compatibility or facilitate module reorganization.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/file.py",
            "description": "This file acts as a compatibility layer, dynamically re-exporting `FileChatMessageHistory` from `langchain_community.chat_message_histories`. It uses a deprecated lookup mechanism to facilitate migration and maintain backward compatibility.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/postgres.py",
            "description": "This file acts as a compatibility layer to re-export `PostgresChatMessageHistory` from the `langchain_community` package, managing deprecated imports during package restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/redis.py",
            "description": "This file provides a compatibility layer for `RedisChatMessageHistory`, dynamically redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/mongodb.py",
            "description": "This file provides backward compatibility for the `MongoDBChatMessageHistory` class, redirecting imports from `langchain_classic` to its new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/sql.py",
            "description": "This file acts as a compatibility layer, dynamically redirecting imports for `BaseMessageConverter`, `DefaultMessageConverter`, and `SQLChatMessageHistory` from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/dynamodb.py",
            "description": "This file acts as a compatibility shim, dynamically importing `DynamoDBChatMessageHistory` from `langchain_community`. It ensures backward compatibility for older code expecting this class within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/firestore.py",
            "description": "This file acts as a re-exporter for `FirestoreChatMessageHistory`, dynamically importing it from `langchain_community.chat_message_histories`. It likely facilitates backward compatibility or a migration path for modules in `langchain_classic`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/zep.py",
            "description": "This file serves as a compatibility layer, redirecting imports of `ZepChatMessageHistory` to its new location within `langchain_community.chat_message_histories`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/neo4j.py",
            "description": "This file acts as a compatibility layer, redirecting imports of `Neo4jChatMessageHistory` from the classic package to its new location in `langchain_community`. It manages the deprecation and migration of this class.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/streamlit.py",
            "description": "This file re-exports `StreamlitChatMessageHistory` from `langchain_community.chat_message_histories` using a dynamic importer. It primarily serves to maintain backward compatibility or facilitate migration for this class within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/upstash_redis.py",
            "description": "This file dynamically imports and re-exports `UpstashRedisChatMessageHistory` from `langchain_community`, serving as a compatibility layer for deprecated imports within the `langchain_classic` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_message_histories/cassandra.py",
            "description": "This file provides backward compatibility for importing `CassandraChatMessageHistory` from `langchain_classic`, redirecting it to its new location in the `langchain_community` package.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/schema/chat_history.py",
            "description": "This file serves to re-export the `BaseChatMessageHistory` class from `langchain_core`, making it accessible within the `langchain_classic` module.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/memory/chat_message_histories/test_imports.py",
            "description": "This file contains a unit test to verify that the `langchain_classic.memory.chat_message_histories` module correctly exports a predefined list of chat message history classes via its `__all__` attribute.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/integration_tests/memory/docker-compose",
            "description": "This directory is designated for Docker Compose configurations, intended to set up external services required for integration testing of `langchain`'s memory components. It would typically house `docker-compose.yml` files and related assets to create isolated testing environments. Its purpose is to enable robust, containerized testing of memory functionalities.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Christophe Bornet",
            "percent": 55
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 32
          },
          {
            "name": "Bagatur",
            "percent": 11
          }
        ]
      },
      "Classic Chain Memory System": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/base_memory.py",
            "description": "This file defines the abstract base class `BaseMemory` for managing chain state and context within LangChain, primarily for versions predating `v1.0.0`, and is now deprecated.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/conversation/__init__.py",
            "description": "This file defines a chain designed to carry on a conversation, utilizing a prompt and conversation history.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/conversation/memory.py",
            "description": "This file serves as an aggregation point for various conversation memory modules within `langchain_classic` and manages dynamic imports, including handling backward compatibility for deprecated modules.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/conversation/base.py",
            "description": "This file defines the deprecated `ConversationChain` class, which handles conversational interactions with an LLM by managing memory to maintain context. It is superseded by `RunnableWithMessageHistory` for enhanced functionality.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/token_buffer.py",
            "description": "This file defines a deprecated conversation memory class that stores chat history, pruning older messages to ensure the total number of tokens does not exceed a specified limit.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/readonly.py",
            "description": "This file defines a ReadOnlySharedMemory class, which acts as a wrapper around an existing memory instance to provide a read-only view, preventing any modifications to the underlying memory.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/vectorstore.py",
            "description": "This file defines a deprecated memory class, `VectorStoreRetrieverMemory`, that stores conversation history in a vector store and retrieves relevant past conversations based on input.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/summary_buffer.py",
            "description": "This file defines `ConversationSummaryBufferMemory`, a deprecated class for managing conversation history by maintaining a running summary alongside recent messages, pruning older messages to stay within a token limit. It provides methods for loading, saving, pruning, and clearing memory, with both synchronous and asynchronous implementations.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/entity.py",
            "description": "This file defines abstract and concrete classes for entity storage, including in-memory and Redis-backed implementations. It is deprecated and scheduled for removal in a future version of LangChain.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/buffer_window.py",
            "description": "This file defines a deprecated LangChain memory class, `ConversationBufferWindowMemory`, which stores a fixed number of the most recent conversation turns. It allows retrieval of this buffered history as either a string or a list of messages.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/utils.py",
            "description": "This file provides a utility function to extract a single prompt input key from a dictionary of inputs, excluding specified memory variables and the 'stop' keyword.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/kg.py",
            "description": "This file provides a compatibility layer for `ConversationKGMemory`, dynamically importing it from `langchain_community.memory.kg` for backward compatibility or module restructuring.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/__init__.py",
            "description": "This file serves as the `__init__.py` for the `memory` package in `langchain_classic`, exposing various memory management classes for maintaining chain state. It also handles dynamic import and deprecation warnings for memory-related components moved to `langchain_community`.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/simple.py",
            "description": "This file defines the `SimpleMemory` class, an implementation of `BaseMemory` that stores a fixed set of context or information which does not change between prompts or interactions.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/combined.py",
            "description": "This file defines the `CombinedMemory` class, which aggregates multiple `BaseMemory` instances into a single memory object, managing their combined variables and delegating memory operations.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/chat_memory.py",
            "description": "This file defines the deprecated `BaseChatMemory` abstract base class, responsible for managing and saving chat message history. It provides methods to store human and AI messages, as well as clear conversation context.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/vectorstore_token_buffer_memory.py",
            "description": "This file defines a conversation memory class that stores recent messages in a token-limited buffer and offloads older messages to a vector store for persistent storage and retrieval.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/prompt.py",
            "description": "This file defines various prompt templates used for managing conversational memory, summarizing dialogue, and extracting entities and knowledge triples for AI agents within the LangChain framework.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/memory/buffer.py",
            "description": "This file defines two deprecated classes, `ConversationBufferMemory` and `ConversationStringBufferMemory`, which implement conversational memory to store chat history. `ConversationBufferMemory` stores messages, while `ConversationStringBufferMemory` stores conversation as a single string.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/memory/summary.py",
            "description": "This file defines classes for managing and summarizing conversation history for language models, including a mixin for summarization logic and a specific implementation for continually summarizing chat memory.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/schema/memory.py",
            "description": "This file re-exports the `BaseMemory` class, consolidating memory schema components under a single import path within the LangChain Classic library.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/tools/memorize/__init__.py",
            "description": "This file provides a dynamic import mechanism for the 'Memorize' tool, acting as a compatibility layer to handle deprecated import paths within the LangChain ecosystem. It exposes the 'Memorize' tool from 'langchain_community'.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_summary_buffer_memory.py",
            "description": "This file contains unit tests for the `ConversationSummaryBufferMemory` class, covering its functionality for loading/saving memory variables, handling buffered conversations, and generating summaries, including asynchronous operations.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_conversation.py",
            "description": "This file contains unit tests for various conversation chain and memory components in LangChain, including `ConversationBufferMemory`, `ConversationBufferWindowMemory`, and `ConversationSummaryMemory`. It tests their core functionalities, prefix handling, error conditions, and clearing mechanisms.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_memory.py",
            "description": "This file contains unit tests for various memory implementations within the `langchain_classic` library, including `SimpleMemory` and `ReadOnlySharedMemory`, ensuring their correct behavior for storing and retrieving conversational context.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/memory/test_imports.py",
            "description": "This file contains a unit test to verify that the `__all__` attribute of the `langchain_classic.memory` module correctly lists all expected public memory-related classes.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/memory/test_combined_memory.py",
            "description": "This file contains unit tests for the `CombinedMemory` class, verifying its basic functionality and ensuring it correctly handles scenarios with repeated memory variables.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/schema/test_memory.py",
            "description": "This file contains a unit test that verifies the '__all__' variable in the 'langchain_classic.schema.memory' module correctly exports 'BaseMemory'. It ensures that only the intended classes are exposed for import.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 82
          },
          {
            "name": "Christophe Bornet",
            "percent": 9
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 4
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 69,
      "spofCount": 20
    },
    "busFactor": 3,
    "authorCount": 11
  },
  "Pre-built Application Chains": {
    "description": "Offers a library of ready-to-use chains that solve common, high-level tasks such as question-answering, summarization, and data analysis. These pre-built solutions enable developers to rapidly implement standard functionalities and serve as building blocks for more complex applications.",
    "functions": {
      "Core Chain Primitives & Orchestration": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/__init__.py",
            "description": "This `__init__.py` file serves as the package entry point for LangChain's 'chains' module, providing lazy loading for various chain implementations. It defines a mapping of chain component names to their respective module paths, enabling on-demand import of these components.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/loading.py",
            "description": "This file provides utility functions for loading and reconstructing various types of LangChain chains, such as LLMChain, HypotheticalDocumentEmbedder, and document combination chains, from configuration dictionaries or files.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/combine_documents/map_reduce.py",
            "description": "This file defines the `MapReduceDocumentsChain` class, which combines multiple documents by first processing each document individually with an LLM (map step) and then reducing those results into a single output.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/combine_documents/base.py",
            "description": "This file defines the base interface for chains that combine multiple documents into a single output (`BaseCombineDocumentsChain`). It also includes a deprecated `AnalyzeDocumentChain` for processing a single document by splitting it and then combining the parts.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/qa_with_sources/loading.py",
            "description": "This file provides functions for loading different types of deprecated 'question answering with sources' chains, acting as a factory based on a specified chain type (e.g., 'stuff', 'map_reduce', 'refine', 'map_rerank'). It orchestrates the creation of these chains using various LLM and document processing components.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/__init__.py",
            "description": "This `__init__.py` file initializes the Python package for unit tests related to Langchain's 'chains'. It serves to group and organize these tests for correct functioning.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 74
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 26
          }
        ]
      },
      "Question Answering Chains": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/conversational_retrieval/__init__.py",
            "description": "This file defines the chain for conversational retrieval, specifically designed for chatting with a vector database.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/conversational_retrieval/base.py",
            "description": "This file defines the base class for conversational retrieval chains in LangChain. It enables a chatbot to answer questions by retrieving relevant documents, utilizing chat history to rephrase the user's question for improved retrieval, and then combining the retrieved information to formulate a final answer.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/question_answering/__init__.py",
            "description": "This file serves as the package initializer for the question-answering chains module, exposing `LoadingCallable` and `load_qa_chain` for direct import. It consolidates key components for creating and loading question-answering chains.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/question_answering/chain.py",
            "description": "This file provides a utility function to load different types of question-answering chains (e.g., 'stuff', 'map_reduce', 'refine', 'map_rerank') by delegating to specific loading functions for each chain type.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/qa_with_sources/retrieval.py",
            "description": "This file defines the `RetrievalQAWithSourcesChain` class, which performs question-answering by retrieving relevant documents from an index and then combining them to generate an answer with sources. It includes logic to reduce the number of retrieved documents based on token limits.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/qa_with_sources/__init__.py",
            "description": "This `__init__.py` file serves as the entry point for the `qa_with_sources` package, exposing the `load_qa_with_sources_chain` function. Its purpose is to facilitate the loading of question answering chains that include source attribution.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/qa_with_sources/base.py",
            "description": "This file defines base classes for question answering chains that extract answers and their sources from a collection of documents. It provides methods for constructing and running these chains, including handling synchronous and asynchronous calls, and is marked as deprecated.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/retrieval_qa/__init__.py",
            "description": "This file initializes the retrieval question-answering chain, which enables answering questions by retrieving information from a vector database.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_functions/citation_fuzzy_match.py",
            "description": "This file defines Pydantic models for structured question-answering with citations and provides functions to create LangChain runnables/chains that leverage LLMs to answer questions by extracting cited facts directly from a given context.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_functions/qa_with_structure.py",
            "description": "This file defines deprecated functions for creating LangChain question-answering chains that return structured responses, often including an answer and its sources, by leveraging OpenAI function calling capabilities.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_qa_with_sources.py",
            "description": "This file contains unit tests for the `QAWithSourcesChain` class, specifically testing its `_split_sources` method. It verifies that the chain correctly extracts the answer and sources from various input text formats.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 95
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 3
          },
          {
            "name": "Christophe Bornet",
            "percent": 1
          }
        ]
      },
      "Self-Critique & Verification Chains": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/constitutional_ai/__init__.py",
            "description": "This file implements the Constitutional AI chain, a method for self-critique based on the research by Bai et al. (2022).",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/constitutional_ai/base.py",
            "description": "This file defines the `ConstitutionalChain`, which applies constitutional principles to critique and revise the output of another chain. It is currently deprecated in favor of a LangGraph-based implementation.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_checker/__init__.py",
            "description": "This file defines an LLM chain designed to verify assumptions before answering questions, likely functioning as a fact-checker. It is based on the 'fact-checker' project by jagilley.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_checker/base.py",
            "description": "This file defines the `LLMCheckerChain`, a deprecated LangChain component for question-answering that employs self-verification. It orchestrates a series of language model calls to draft an answer, extract and check assertions, and then revise the answer based on those checks.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_llm_checker.py",
            "description": "This file contains unit tests for the `LLMCheckerChain` functionality, using a `FakeLLM` to simulate responses and verify the chain's behavior with specific prompts and a simple question.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_constitutional_ai.py",
            "description": "This file contains unit tests for the Constitutional AI chain, specifically focusing on the correct parsing of critique text from various input formats.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_flare.py",
            "description": "This file contains unit tests for the `FlareChain.from_llm` method, specifically verifying that it correctly uses and preserves the supplied `ChatOpenAI` instance and rejects non-`ChatOpenAI` types.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 82
          },
          {
            "name": "Gal Bloch",
            "percent": 11
          },
          {
            "name": "Christophe Bornet",
            "percent": 5
          }
        ]
      },
      "Structured Data Query Chains": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/cypher.py",
            "description": "This file serves as a compatibility layer, dynamically re-exporting modules and functions related to Cypher graph QA chains that have been moved to `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/gremlin.py",
            "description": "This file acts as a compatibility layer, forwarding deprecated imports related to Gremlin graph QA chains and utilities from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/falkordb.py",
            "description": "This file serves as a deprecated import shim, dynamically redirecting imports for `FalkorDBQAChain` and related utilities from `langchain_classic` to their new location in `langchain_community`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/sparql.py",
            "description": "This file provides a compatibility layer for `GraphSparqlQAChain`, dynamically importing it from `langchain_community` and handling deprecation for older `langchain_classic` imports.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/graph_qa/neptune_sparql.py",
            "description": "This file facilitates dynamic and deferred imports for Neptune SPARQL QA chain components, likely for backward compatibility or managing deprecation. It re-exports symbols from `langchain_community.chains.graph_qa.neptune_sparql`.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/sql_database/__init__.py",
            "description": "This file initializes the SQL Database chain module within the classic LangChain library, providing core functionalities for interacting with SQL databases.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/sql_database/query.py",
            "description": "This file defines a function `create_sql_query_chain` that constructs an LLM-powered chain to translate natural language questions into SQL queries, leveraging database schema information and handling security considerations.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 100
          }
        ]
      },
      "Mathematical & Code Execution Chains": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/llm_math/__init__.py",
            "description": "This file implements a chain that interprets prompts and executes Python code to perform mathematical operations. Its core functionality is inspired by a project found on Replit.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_math/base.py",
            "description": "This file defines the `LLMMathChain` class, which allows a Large Language Model to perform mathematical calculations by interpreting and executing expressions generated from its prompts. This class is deprecated in favor of a LangGraph-based approach.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_symbolic_math/__init__.py",
            "description": "This file serves as a deprecation notice, informing users that the `llm_symbolic_math` module has been moved to the `langchain-experimental` package and provides instructions for accessing it.",
            "spof": false
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_llm_math.py",
            "description": "This file contains unit tests for the `LLMMathChain` class, verifying its ability to process simple and complex mathematical questions and handle errors using a mocked LLM.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 96
          },
          {
            "name": "Eugene Yurtsev",
            "percent": 3
          },
          {
            "name": "Christophe Bornet",
            "percent": 1
          }
        ]
      },
      "Summarization Chains": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/llm_summarization_checker/__init__.py",
            "description": "This file implements a summarization checker chain designed to verify the accuracy of text generation. It works by breaking down generated text into facts, assessing their truthfulness, and iteratively rewriting the text until it achieves a high level of accuracy or reaches a maximum attempt limit.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/llm_summarization_checker/base.py",
            "description": "This file defines the `LLMSummarizationCheckerChain`, which performs summarization with self-verification by iteratively checking assertions, revising summaries, and re-evaluating until a satisfactory summary is achieved or a maximum check limit is reached. This class is deprecated in favor of LangGraph's self-reflection strategies.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/summarize/__init__.py",
            "description": "This `__init__.py` file serves as the package entry point for the `summarize` chain components. It imports and exposes `LoadingCallable` and `load_summarize_chain` from the `chain.py` module, making them directly accessible when the `langchain_classic.chains.summarize` package is imported.",
            "spof": false
          },
          {
            "path": "libs/langchain/langchain_classic/chains/summarize/chain.py",
            "description": "This file provides functions to load and configure different types of document summarization chains (stuff, map-reduce, refine) using the LangChain Classic framework.",
            "spof": true
          },
          {
            "path": "libs/langchain/tests/unit_tests/chains/test_llm_summarization_checker.py",
            "description": "This file contains unit tests for the `LLMSummarizationCheckerChain` class, verifying its prompt input variables and testing a basic summarization scenario using a mocked LLM.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 89
          },
          {
            "name": "wixarv",
            "percent": 5
          },
          {
            "name": "L Nam Khnh",
            "percent": 4
          }
        ]
      },
      "Information Extraction Chains": {
        "files": [
          {
            "path": "libs/langchain/langchain_classic/chains/openai_tools/extraction.py",
            "description": "This file defines a deprecated function for creating a LangChain extraction chain, which uses a language model and Pydantic schemas to extract structured information from text using OpenAI tool calling capabilities.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_functions/tagging.py",
            "description": "This file provides deprecated functions for creating LangChain chains that use OpenAI's function calling feature to extract structured information (tagging) from text based on a provided schema. Users are advised to use `with_structured_output` instead.",
            "spof": true
          },
          {
            "path": "libs/langchain/langchain_classic/chains/openai_functions/extraction.py",
            "description": "This file provides deprecated functions for information extraction using OpenAI function calling, allowing users to define extraction schemas either as dictionaries or Pydantic models to parse structured data from text.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Mason Daugherty",
            "percent": 95
          },
          {
            "name": "Chenyang Li",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 43,
      "spofCount": 23
    },
    "busFactor": 1,
    "authorCount": 10
  }
}