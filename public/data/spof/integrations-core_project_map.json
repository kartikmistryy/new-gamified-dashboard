{
  "BlueCat Edge DDI Monitoring": {
    "description": "Monitors BlueCat Edge for DNS, DHCP, and IPAM (DDI) services to ensure network service reliability and performance.",
    "functions": {
      "BlueCat Edge DDI Monitoring": {
        "files": [
          {
            "path": "bluecat_edge/README.md",
            "description": "This file is a README for the Datadog Agent check for BlueCat Edge, providing an overview, setup instructions, and details on data collected (or lack thereof).",
            "spof": true
          },
          {
            "path": "bluecat_edge/CHANGELOG.md",
            "description": "This file is the changelog for the BlueCat Edge integration. It documents all the significant changes, new features, and bug fixes for each version of the integration, starting with its initial release.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "surabhipatel-crest",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 2,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Argo CD Monitoring": {
    "description": "Provides observability into Argo CD, monitoring the health and sync status of applications for GitOps-based continuous delivery.",
    "functions": {
      "Integration Configuration & Packaging": {
        "files": [
          {
            "path": "argocd/README.md",
            "description": "This file is the README for the Datadog Agent's Argo CD integration, detailing how to set up, configure, and collect metrics and logs from Argo CD components.",
            "spof": false
          },
          {
            "path": "argocd/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Argo CD integration, detailing new features, bug fixes, and updates across different versions.",
            "spof": false
          },
          {
            "path": "argocd/tests/__init__.py",
            "description": "This file marks the 'tests' directory as a Python package for the ArgoCD integration. It does not contain any specific test code or initialization logic.",
            "spof": true
          },
          {
            "path": "argocd/assets/monitors",
            "description": "This directory is intended to store monitoring configurations or definitions specifically for the ArgoCD integration within the Datadog Integrations Core. Although currently empty, its purpose is to house assets related to monitoring functionalities.",
            "spof": false
          },
          {
            "path": "argocd/assets/configuration",
            "description": "This directory is designated to hold configuration assets for the Datadog ArgoCD integration. It serves as a placeholder for files that define how the integration should be configured, even though it currently contains no files.",
            "spof": false
          },
          {
            "path": "argocd/assets/dashboards",
            "description": "This directory is intended to store dashboard assets for the Datadog ArgoCD integration. It would typically contain JSON definitions or configuration files for pre-built dashboards that provide observability for ArgoCD.",
            "spof": false
          },
          {
            "path": "argocd/datadog_checks/argocd/__init__.py",
            "description": "This file serves as the package initializer for the ArgoCD integration, exposing its version and the main ArgocdCheck class for external use. It defines the public interface of the `datadog_checks.argocd` package.",
            "spof": true
          },
          {
            "path": "argocd/datadog_checks/argocd/config_models/instance.py",
            "description": "This file defines Pydantic models for validating and structuring the configuration parameters for the Datadog ArgoCD integration instance, autogenerated from a specification file.",
            "spof": false
          },
          {
            "path": "argocd/datadog_checks/argocd/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options, such as proxy settings, within the ArgoCD integration. It includes validation logic and is automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "argocd/datadog_checks/argocd/config_models/validators.py",
            "description": "This file is intended to define custom configuration validators and transformers for the Datadog ArgoCD integration, as shown by the example functions for `initialize_instance`.",
            "spof": true
          },
          {
            "path": "argocd/datadog_checks/argocd/config_models/defaults.py",
            "description": "This autogenerated file defines default configuration values for the Datadog ArgoCD integration. It provides default settings for shared components and individual integration instances, covering aspects like HTTP client behavior and metric collection parameters.",
            "spof": false
          },
          {
            "path": "argocd/datadog_checks/argocd/config_models/__init__.py",
            "description": "This file is part of the autogenerated configuration models for the ArgoCD integration. It defines a `ConfigMixin` that provides convenient access to both instance-specific and shared configuration objects.",
            "spof": true
          },
          {
            "path": "argocd/datadog_checks/argocd/data",
            "description": "This directory is typically reserved for storing static data files, such as default configurations or templates, that support the ArgoCD Datadog Agent integration. Although currently empty, its presence indicates a potential future need for such resources.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 24
          },
          {
            "name": "Steven Yuen",
            "percent": 15
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 12
          }
        ]
      },
      "Argo CD Metric Collection & Processing": {
        "files": [
          {
            "path": "argocd/tests/test_argocd.py",
            "description": "This file contains unit tests for the Datadog ArgoCD integration, verifying metric collection and service check functionality for various ArgoCD components like the app controller, API server, and repo server, as well as handling of empty instances.",
            "spof": true
          },
          {
            "path": "argocd/tests/conftest.py",
            "description": "This file provides pytest fixtures and setup functions for creating and configuring a Kind (Kubernetes in Docker) environment for ArgoCD integration tests. It sets up ArgoCD, forwards necessary ports, and generates configuration instances for testing metric collection.",
            "spof": false
          },
          {
            "path": "argocd/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the ArgoCD integration, verifying the collection of OpenMetrics v1 metrics and service checks from various ArgoCD components.",
            "spof": false
          },
          {
            "path": "argocd/tests/common.py",
            "description": "This file defines common mock instance configurations and lists of expected metrics for various ArgoCD components, used for testing the Datadog ArgoCD integration. It categorizes metrics by type (gauges, counters, histograms) and component, and includes lists of metrics that are not expected to be exposed in certain test environments.",
            "spof": true
          },
          {
            "path": "argocd/tests/fixtures",
            "description": "This directory is intended to store various test fixtures, such as sample data, configuration files, or mock responses. These fixtures are used to provide controlled and consistent environments for the unit and integration tests of the Datadog Argocd integration.",
            "spof": false
          },
          {
            "path": "argocd/tests/kind",
            "description": "This directory is intended to contain configurations or scripts for setting up and running tests for the ArgoCD integration using a local Kubernetes in Docker (Kind) cluster. It facilitates integration testing of the ArgoCD Datadog agent check in an isolated Kubernetes environment.",
            "spof": false
          },
          {
            "path": "argocd/datadog_checks/argocd/metrics.py",
            "description": "This file defines metric mappings for various Argo CD components (Application Controller, API Server, Repo Server, etc.) from their original Prometheus names to Datadog-standard metric names. It serves as a central place to configure which Argo CD metrics should be collected and how they should be named within Datadog.",
            "spof": true
          },
          {
            "path": "argocd/datadog_checks/argocd/check.py",
            "description": "This file implements the Datadog check for Argo CD, collecting metrics from various Argo CD components (API server, app controller, repo server, etc.) via OpenMetrics endpoints. It includes custom metric transformations and service checks for specific Argo CD metrics.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 89
          },
          {
            "name": "Serhiy Martynenko",
            "percent": 3
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 21,
      "spofCount": 9
    },
    "busFactor": 1,
    "authorCount": 4
  },
  "Developer Tools & Environment": {
    "description": "Provides a comprehensive toolkit and development environment for creating, testing, and maintaining Datadog integrations.",
    "functions": {
      "Integration Test Orchestration": {
        "files": [
          {
            "path": "argocd/tests/utils.py",
            "description": "This utility file provides helper functions for tests within the ArgoCD integration, primarily for locating test fixture files.",
            "spof": true
          },
          {
            "path": "calico/tests/utils.py",
            "description": "This file provides utility functions for the Calico integration's tests, specifically to locate fixture files within the test directory.",
            "spof": true
          },
          {
            "path": "boundary/tests/__init__.py",
            "description": "Marks the `tests` directory as a Python package. This allows Python to import modules and subpackages located within the `tests` directory.",
            "spof": true
          },
          {
            "path": "appgate_sdp/tests/docker",
            "description": "This directory is intended to house Docker-related configurations or files necessary for setting up containerized test environments for the `appgate_sdp` integration. It facilitates integration testing by providing a consistent and isolated testing infrastructure using Docker.",
            "spof": false
          },
          {
            "path": "cassandra/tests/__init__.py",
            "description": "This file marks the 'tests' directory as a Python package. It allows for test modules within this directory to be imported and recognized by test runners.",
            "spof": true
          },
          {
            "path": "aerospike/tests/docker",
            "description": "This directory is intended to contain Docker-related configurations and files for setting up a test environment for the Datadog Aerospike integration. Although currently empty, its purpose is to facilitate isolated and reproducible testing using Docker.",
            "spof": false
          },
          {
            "path": "apache/tests/compose",
            "description": "This directory is intended to house Docker Compose configurations for setting up test environments specific to the Apache integration. It facilitates the creation and management of isolated services required for running integration tests.",
            "spof": false
          },
          {
            "path": "ceph/tests/compose",
            "description": "This directory is intended to contain Docker Compose configurations for orchestrating test environments specific to the Datadog Ceph integration. Although currently empty, it serves as the designated location for defining multi-service setups required for integration testing.",
            "spof": false
          },
          {
            "path": "cilium/tests/__init__.py",
            "description": "This empty file marks the 'tests' directory as a Python package, allowing test modules within it to be imported and recognized by Python's module system.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the `tests` directory as a Python package, allowing its modules to be imported. It contains only a standard license header.",
            "spof": true
          },
          {
            "path": "datadog_checks_downloader/tests/local_http.py",
            "description": "This file provides context managers for setting up and managing a local HTTP server for end-to-end tests, capable of serving content extracted from a zip file or directly from a local directory.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/tests/conftest.py",
            "description": "This `conftest.py` file configures the `pytest` test suite for the `datadog_checks_downloader` component. It defines command-line options and fixtures for test parameters like distribution name, version, and local directories, and also sets up a temporary local repository for testing purposes.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/tests/scripts/download_test_data.py",
            "description": "This script downloads a minimal subset of files from an online repository to create test data for integration downloads. It saves these files as zip archives in the `tests/data` directory for testing purposes.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/__init__.py",
            "description": "This file serves as a package marker for the 'tests' directory, enabling Python to recognize it as a package and allowing test discovery tools to locate tests within it.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/conftest.py",
            "description": "This `conftest.py` file defines pytest fixtures to provide mock configurations and metadata for end-to-end tests within the Datadog integrations development environment.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/common.py",
            "description": "This file provides common utilities for tests, specifically a pytest mark to skip tests when running on Windows CI environments.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/test_conditions.py",
            "description": "This file contains unit tests for the condition-checking utilities provided by `datadog_checks_dev`, which are used to verify various states like command output, Docker logs, and endpoint availability within integration tests.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/test_kind.py",
            "description": "This file contains unit tests for the Kind cluster utility functions, specifically `kind_run` and `KindLoad`, which are used for managing and interacting with Kind (Kubernetes in Docker) clusters for development and testing purposes.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/test_docker.py",
            "description": "This file contains unit and integration tests for Docker utility functions within `datadog_checks_dev`, specifically `compose_file_active` and the `docker_run` context manager, verifying their functionality in managing and checking Docker Compose services.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/plugin/__init__.py",
            "description": "This `__init__.py` file marks the `plugin` directory as a Python package, enabling the import of modules within it for testing purposes in `datadog_checks_dev`.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/__init__.py",
            "description": "Marks the `tooling` directory as a Python package. This file is empty and does not contain any specific initialization logic.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/utils.py",
            "description": "This file provides utility functions for testing the configuration tooling within the Datadog Agent development environment, including helpers to create and process `ConfigSpec` objects for test cases.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/docker",
            "description": "This directory is designated for Docker-related test setups and configurations within the `datadog_checks_dev` test suite. It would specifically support integration tests that leverage Docker environments for development utilities.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/docker.py",
            "description": "This file provides utilities and a context manager for managing Docker environments, primarily for testing purposes within the datadog_checks_dev framework. It includes functions for interacting with Docker, handling Docker Compose setups and teardowns, and managing shared log configurations.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/kind.py",
            "description": "This file provides utilities and a context manager (`kind_run`) for setting up, managing, and tearing down Kind (Kubernetes in Docker) clusters for testing and development environments.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/warn.py",
            "description": "This file customizes Python's warning formatting, specifically shortening the output for warnings that occur during end-to-end (E2E) testing. It also provides a helper `warning` function for consistent warning issuance.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/testing.py",
            "description": "This module defines platform-specific pytest markers for skipping tests on certain operating systems, facilitating conditional test execution within the Datadog checks development environment.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/kube_port_forward.py",
            "description": "This file provides utilities for managing `kubectl port-forward` operations programmatically, enabling local access to remote ports of Kubernetes resources during development or testing. It handles the setup and teardown of port-forwarding processes, including finding available local ports.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/conditions.py",
            "description": "This file provides utility classes for synchronously waiting for various conditions to be met, such as function success, endpoint availability, command output patterns, Docker logs, or port listening, often with retries and timeouts.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/utils.py",
            "description": "Provides utility functions for common operations, primarily designed for use within Datadog Agent integration tests. It includes functionalities for file handling, network operations, check configuration loading, and CI environment detection.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/structures.py",
            "description": "This file defines utility classes for managing environment variables and temporary directories, particularly useful in testing contexts like End-to-End (E2E) testing.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/terraform.py",
            "description": "This file provides utilities and context managers for managing Terraform environments within testing frameworks, handling their setup, application, and teardown.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/testing.py",
            "description": "This file provides utilities for managing and selecting test environments (Tox/Hatch) for Datadog checks. It includes functions for listing available environments, filtering them based on various criteria (e.g., style, benchmark, e2e, changed files), and supporting CLI auto-completion for test commands.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/e2e/config.py",
            "description": "This module provides utility functions for managing end-to-end test environment configurations and metadata for Datadog checks, including path resolution, existence checks, and data serialization/deserialization.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/e2e/local.py",
            "description": "Provides a Python class `LocalAgentInterface` for managing and interacting with a locally installed Datadog Agent during end-to-end (E2E) testing of integrations. It handles configuration, running checks, agent commands, and environment setup for local testing scenarios.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/e2e/core.py",
            "description": "This file provides functions to determine and instantiate the correct environment interface (e.g., Docker, local agent) for checks based on configuration. It reads environment data and dynamically creates an interface object tailored to the specified environment type.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/e2e/format.py",
            "description": "This file provides utilities to extract and parse end-to-end (E2E) environment configuration and metadata from the output of a test run. It identifies a specific pattern in the output to deserialize the structured data.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/e2e/run.py",
            "description": "This file provides utilities for managing end-to-end testing environments for Datadog checks, specifically handling the starting and stopping of these environments. It leverages both Hatch and Tox for executing commands within these environments.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/e2e/__init__.py",
            "description": "Initializes the e2e (end-to-end) testing tooling for Datadog checks, consolidating core functionalities for managing test configurations and environments.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/e2e/docker.py",
            "description": "This file defines the `DockerInterface` class, which provides utilities for managing and interacting with Docker containers to facilitate end-to-end testing of Datadog checks. It handles tasks like running commands within containers, configuring checks, and managing agent versions.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/test.py",
            "description": "This file implements the `ddev test` command, a command-line tool for running various types of tests (e.g., unit, style, end-to-end, benchmarks, coverage) for Datadog Agent checks, including environment setup and test command execution.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/plugin/pytest.py",
            "description": "This file implements a pytest plugin that provides fixtures and utilities for testing Datadog Agent checks, including mocked agent components, environment setup for E2E tests, and HTTP response mocking.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/conftest.py",
            "description": "This file defines Pytest fixtures for setting up various test environments, including Docker-based SOCKS5 proxy, Kerberos, and Unix Domain Socket configurations, along with custom Pytest markers for integration tests.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/conftest.py",
            "description": "This conftest.py file configures pytest to ensure that tests within its scope are only collected and executed on Windows platforms, ignoring them on other operating systems.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/stubs/test_aggregator_similar.py",
            "description": "Tests the `similar` utility functions for aggregator stubs, ensuring they correctly identify and rank similar metrics, service checks, and histogram buckets based on various attributes. This is used to provide helpful assertion messages when expected items are not found.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/stubs/test_aggregator_no_duplicate.py",
            "description": "Tests the `assert_no_duplicate_metrics()` and `assert_no_duplicate_service_checks()` methods of the Datadog Agent `Aggregator` to ensure they correctly identify duplicate metrics and service checks under various conditions.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/stubs/test_aggregator_service_checks.py",
            "description": "This file contains unit tests for the service check assertion methods of the test aggregator object, demonstrating how to verify service checks within the Datadog Agent check testing framework.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/fixtures/prometheus",
            "description": "This directory is intended to house test fixtures specifically for Prometheus-related tests within the `datadog_checks_base` module. It serves as a designated location for auxiliary data or configuration files required by these tests.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/compose/uds/uds-nginx",
            "description": "This directory is part of the test infrastructure for `datadog_checks_base`, specifically for Docker Compose environments. It is designed to set up and test scenarios involving Nginx configured to use Unix Domain Sockets (UDS).",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/replay/execute.py",
            "description": "This module provides functionality to run Datadog checks in an isolated child process, facilitating communication between the parent and child processes for logging, metric aggregation, and agent interactions.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/stubs/aggregator.py",
            "description": "This file provides a stub implementation of the Datadog Agent's aggregator, designed to mimic its behavior for testing purposes. It includes methods for submitting metrics, service checks, events, and histogram buckets, along with utilities for asserting their reception and content in tests.",
            "spof": false
          },
          {
            "path": "datadog_checks_tests_helper/README.md",
            "description": "This README file describes the `datadog_checks_tests_helper` module. It primarily functions as a location to store large test fixtures for Datadog integration checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_tests_helper/CHANGELOG.md",
            "description": "This file is a changelog documenting the historical changes, new features, and bug fixes for the `datadog_checks_tests_helper` component. It provides a version-by-version summary of updates to the helper library.",
            "spof": true
          },
          {
            "path": "datadog_checks_tests_helper/scripts/README.md",
            "description": "This README describes helper scripts intended for common use across multiple tests. It specifically mentions Docker Compose configurations that are not test-specific and can be shared.",
            "spof": false
          },
          {
            "path": "datadog_checks_tests_helper/datadog_test_libs/__init__.py",
            "description": "This file initializes the `datadog_test_libs` Python package, defining its version and enabling it as a namespace package. It serves as a foundational component for shared testing utilities within Datadog integrations.",
            "spof": true
          },
          {
            "path": "datadog_checks_tests_helper/datadog_test_libs/utils/mock_dns.py",
            "description": "This file provides a context manager to mock DNS resolution and socket connections locally. It allows redirecting specific hostnames to different addresses and ports, primarily for testing purposes.",
            "spof": false
          },
          {
            "path": "datadog_checks_tests_helper/datadog_test_libs/win/pdh_mocks.py",
            "description": "This file provides mock implementations for Windows Performance Data Helper (PDH) and `winreg` functions, primarily used in pytest fixtures to simulate Windows performance counter and registry interactions for testing purposes.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/tests/conftest.py",
            "description": "This file contains pytest fixtures for setting up a testing environment for the Datadog CSI Driver integration, including a Dockerized environment and mock instances.",
            "spof": true
          },
          {
            "path": "ddev/tests/__init__.py",
            "description": "This file marks the `ddev/tests` directory as a Python package, allowing its contents to be imported as modules for testing. It serves primarily as a package initializer without specific functional code.",
            "spof": true
          },
          {
            "path": "ddev/tests/conftest.py",
            "description": "This file defines pytest fixtures and hooks for the `ddev` (Datadog Developer CLI) test suite. It provides common test resources, configurations, and environment setups, including temporary directories, mocked configurations, Git repository management, and platform-specific test skipping.",
            "spof": false
          },
          {
            "path": "ddev/tests/e2e/test_config.py",
            "description": "This file contains unit tests for the `EnvData` and `EnvDataStorage` classes, which manage environment-specific data and configuration for end-to-end tests within the `ddev` framework.",
            "spof": true
          },
          {
            "path": "ddev/tests/e2e/__init__.py",
            "description": "This empty `__init__.py` file marks the `e2e` directory as a Python package, allowing it to contain and organize end-to-end test modules for `ddev`.",
            "spof": true
          },
          {
            "path": "ddev/tests/e2e/test_run.py",
            "description": "This file contains end-to-end tests for the `E2EEnvironmentRunner` class, verifying its ability to manage test environment setup, teardown, and command generation using `pytest`.",
            "spof": false
          },
          {
            "path": "ddev/tests/helpers/assertions.py",
            "description": "This file provides a helper function `assert_calls` for comparing mock call lists in Python unit tests, with the option to ignore specific keyword arguments during comparison.",
            "spof": true
          },
          {
            "path": "ddev/tests/helpers/git.py",
            "description": "Provides a utility class, `ClonedRepo`, to manage a Git repository's state for testing purposes, including resetting branches and cleaning untracked files.",
            "spof": true
          },
          {
            "path": "ddev/tests/helpers/mocks.py",
            "description": "This file defines `MockPopen`, a mock class designed to mimic `subprocess.Popen` objects for use in tests, allowing control over return codes, stdout, and stderr.",
            "spof": true
          },
          {
            "path": "ddev/tests/helpers/api.py",
            "description": "This file provides various utility functions primarily used for testing, including helpers for text manipulation, `pytest.raises`, mocking Git subprocess calls, and file system operations.",
            "spof": true
          },
          {
            "path": "ddev/tests/helpers/hatch.py",
            "description": "This file defines a base configuration template for Hatch environments, intended for use as a helper in tests within the Datadog integrations development environment.",
            "spof": true
          },
          {
            "path": "ddev/tests/helpers/runner.py",
            "description": "A helper class that extends Click's `CliRunner` to simplify testing of `ddev` CLI commands by pre-setting the command and configuring default exception handling.",
            "spof": true
          },
          {
            "path": "ddev/tests/helpers/__init__.py",
            "description": "This file initializes helper objects and variables for `ddev` (Datadog Developer tool) tests, including platform details, an application instance, and a specific branch name for local repository testing.",
            "spof": false
          },
          {
            "path": "ddev/tests/config/__init__.py",
            "description": "This file marks the 'config' directory within 'ddev/tests' as a Python package, allowing its contents to be imported and used by test suites or other modules.",
            "spof": true
          },
          {
            "path": "ddev/tests/integration/test_manifest.py",
            "description": "This file contains an integration test for the `ddev` tool, specifically verifying that the `Manifest` class correctly inherits from `JSONPointerFile`.",
            "spof": true
          },
          {
            "path": "ddev/tests/integration/__init__.py",
            "description": "This file marks the 'integration' directory as a Python package. It allows integration test modules within this directory to be imported and executed.",
            "spof": true
          },
          {
            "path": "ddev/tests/integration/conftest.py",
            "description": "This file defines a pytest fixture (`fake_repo`) that creates a temporary, mock integrations repository with various dummy integrations and their configuration files for testing purposes. It also includes a helper function to write content to files within this fake repository structure.",
            "spof": true
          },
          {
            "path": "ddev/tests/integration/test_core.py",
            "description": "This file contains integration tests for the core functionalities of `ddev`, focusing on how it identifies, categorizes, and retrieves properties of integrations, packages, and tiles within a repository.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/__init__.py",
            "description": "This empty `__init__.py` file designates the `cli` directory as a Python package, allowing test runners to discover and import test modules within it.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/config/__init__.py",
            "description": "This `__init__.py` file marks the `config` directory as a Python package within the `ddev` CLI test suite. Its primary purpose is to allow Python to recognize and import modules from this directory for testing purposes.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/clean/__init__.py",
            "description": "This `__init__.py` file marks the `clean` directory as a Python package, enabling the discovery and import of test modules related to the `ddev clean` CLI command.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/status/__init__.py",
            "description": "This file is an empty `__init__.py` file, serving to mark the `status` directory as a Python package for testing purposes within the `ddev` CLI tests.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/test/__init__.py",
            "description": "This empty __init__.py file marks the 'test' directory as a Python package, enabling test discovery within the `ddev` CLI tests.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/test/test_test.py",
            "description": "This file contains unit and integration tests for the 'test' command of the 'ddev' CLI tool, covering input validation, environment listing, and various test execution scenarios.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/meta/__init__.py",
            "description": "This empty `__init__.py` file marks the `meta` directory as a Python package, enabling imports for testing purposes within the `ddev` CLI's test suite.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/meta/scripts/__init__.py",
            "description": "This file marks the 'scripts' directory as a Python package within the test suite for the 'ddev cli meta' component, facilitating the organization and import of test-related utilities.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/meta/scripts/conftest.py",
            "description": "This pytest configuration file defines a fixture that creates a fake Datadog integrations-core repository with various configuration and source files. It is used to provide a controlled environment for testing `ddev` CLI commands, especially those related to Python version upgrades.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/validate/conftest.py",
            "description": "This file defines pytest fixtures that create temporary, fake repository environments, populated with specific configuration and manifest files, for testing `ddev` validation commands.",
            "spof": true
          },
          {
            "path": "ddev/tests/testing/__init__.py",
            "description": "This file marks the 'testing' directory as a Python package. It allows modules within this directory to be imported as part of the 'ddev.tests.testing' package.",
            "spof": true
          },
          {
            "path": "ddev/tests/fixtures/network/github",
            "description": "This directory is intended to house test fixtures specifically for network interactions with GitHub. It supports the `ddev` testing framework used within the Datadog `integrations-core` repository, providing a dedicated location for GitHub-related network test data.",
            "spof": false
          },
          {
            "path": "ddev/tests/fixtures/network/list_versions",
            "description": "This directory serves as a container for test fixtures specifically used to validate network-related functionalities within the `ddev` tool, focusing on the listing of network versions. It holds predefined data or configurations necessary for robust testing of these capabilities.",
            "spof": false
          },
          {
            "path": "ddev/tests/fixtures/network/manifest",
            "description": "This directory is designated to store manifest files used as test fixtures for network-related testing within the `ddev` development environment. It serves as a placeholder for configurations or declarations that simulate network setups for integration tests. Although currently empty, its purpose is to provide structured test data for validating network-dependent functionalities.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/serve_openmetrics_payload.py",
            "description": "This script defines a DDEV command to serve OpenMetrics payloads using a local webserver within a Dockerized Agent. It configures the Agent to collect metrics from this local server, facilitating the testing of integrations against specific OpenMetrics data.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/test/__init__.py",
            "description": "This file defines the 'test' command for the 'ddev' CLI tool, enabling users to run various types of tests (unit, integration, linting, formatting, benchmarks) for Datadog integrations, with options for coverage, environment selection, and specific pytest arguments.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/e2e/constants.py",
            "description": "This file defines constants and classes for environment variables and metadata used in DDEV end-to-end testing, including default agent types, ports, and various E2E-specific settings.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/e2e/__init__.py",
            "description": "This `__init__.py` file marks the `e2e` directory as a Python package, intended for end-to-end testing functionalities within the `ddev` tool.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/e2e/run.py",
            "description": "This file defines a runner class for managing end-to-end test environments. It provides context managers to set up and tear down environments using `hatch`, preparing specific environment variables for test execution.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/testing/constants.py",
            "description": "Defines constant names for environment variables used across various `ddev` testing utilities and end-to-end tests.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/testing/__init__.py",
            "description": "This `__init__.py` file marks the `ddev/testing` directory as a Python package. It serves as a placeholder for potential future testing-related utilities or imports within the `ddev` development tool.",
            "spof": true
          },
          {
            "path": "directory/tests/common.py",
            "description": "This file defines common constants and helper functions, such as expected metrics, tags, and configuration stubs, used across tests for the Datadog 'directory' integration.",
            "spof": false
          },
          {
            "path": "duckdb/tests/__init__.py",
            "description": "This empty __init__.py file marks the 'tests' directory as a Python package, allowing test modules within it to be imported and organized effectively.",
            "spof": true
          },
          {
            "path": "druid/tests/__init__.py",
            "description": "This is an empty `__init__.py` file, serving to mark the `tests` directory as a Python package. It contains no functional code.",
            "spof": false
          },
          {
            "path": "druid/tests/common.py",
            "description": "This file defines common test configurations for the Datadog Druid integration, including hostnames and URLs for Druid services like Coordinator and Broker, typically used in test environments.",
            "spof": true
          },
          {
            "path": "druid/tests/README.md",
            "description": "This file provides quick start instructions for setting up Druid to test its StatsD emitter, detailing how to connect Druid to DogStatsD and send metrics to the Datadog Agent.",
            "spof": true
          },
          {
            "path": "druid/tests/conftest.py",
            "description": "This file provides pytest fixtures for the Druid integration tests, setting up a Dockerized Druid environment and defining test instance configuration.",
            "spof": true
          },
          {
            "path": "druid/tests/test_integration_e2e.py",
            "description": "This file contains integration and end-to-end tests for the Datadog Druid integration, verifying service checks for Druid coordinator and broker instances.",
            "spof": true
          },
          {
            "path": "druid/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Agent's Druid integration, specifically verifying its configuration handling, network connectivity checks, and service health reporting mechanisms.",
            "spof": true
          },
          {
            "path": "druid/tests/compose",
            "description": "This directory is intended to house Docker Compose configurations for setting up a testing environment for the Datadog Druid integration. While currently empty, its purpose would be to define the services required to run integration tests against Druid.",
            "spof": false
          },
          {
            "path": "falco/tests/fixtures",
            "description": "This directory is designated to store test fixtures for the Falco integration tests. While currently empty, it serves as a placeholder for data files, mock configurations, or any other static assets required to run the automated tests for the Falco integration within Datadog's integrations-core repository.",
            "spof": false
          },
          {
            "path": "dotnetclr/tests/__init__.py",
            "description": "This is an empty `__init__.py` file, marking the 'tests' directory as a Python package. It enables Python to recognize and load test modules within the `dotnetclr` integration.",
            "spof": true
          },
          {
            "path": "dotnetclr/tests/e2e_test.py",
            "description": "This file contains an end-to-end test for the Datadog .NET CLR integration, specifically verifying the basic functionality and service check reporting.",
            "spof": false
          },
          {
            "path": "dotnetclr/tests/conftest.py",
            "description": "This file provides pytest fixtures to set up the testing environment for the Datadog .NET CLR integration, specifically configuring a minimal Windows Docker environment.",
            "spof": true
          },
          {
            "path": "esxi/tests/ssh_tunnel.py",
            "description": "Provides utilities for setting up SSH SOCKS proxies and TCP tunnels. These are primarily used within the testing framework to establish connections to remote services for integration tests.",
            "spof": true
          },
          {
            "path": "elastic/tests/common.py",
            "description": "This file contains common utility functions, constants, and helper methods used across the Datadog Elasticsearch/OpenSearch integration tests for configuring and asserting metrics.",
            "spof": true
          },
          {
            "path": "elastic/tests/fixtures",
            "description": "This directory is intended to store test fixture files for the 'elastic' integration within 'datadog/integrations-core'. These fixtures would provide predefined data, configurations, or mock objects to ensure consistent and isolated testing of the integration's functionalities.",
            "spof": false
          },
          {
            "path": "docs/developer/testing.md",
            "description": "This document provides comprehensive instructions on how to test Datadog integrations using the `ddev test` command. It covers environment discovery, test execution methods, code coverage reporting, linting, and forwarding arguments to pytest.",
            "spof": true
          },
          {
            "path": "docs/developer/e2e.md",
            "description": "This document outlines how to perform end-to-end (E2E) testing for Datadog integrations using the `ddev env` command. It details the process of managing E2E environments, including discovery, creation, testing, debugging, and removal, for integrations running on a live Datadog Agent.",
            "spof": true
          },
          {
            "path": "docs/developer/ddev/plugins.md",
            "description": "This document describes the `ddev` plugins for Datadog integration development and testing, focusing on `pytest` fixtures for various testing scenarios like Agent stubs, check execution, E2E tests, state management, HTTP response mocking, and environment configuration.",
            "spof": true
          },
          {
            "path": "docs/developer/ddev/test.md",
            "description": "This document describes the testing framework for Datadog integrations, covering environment setup using Docker, Vagrant, and Terraform, along with tools for mocking, benchmarking, and log collection.",
            "spof": true
          },
          {
            "path": ".ddev/ci/scripts/cacti/linux",
            "description": "This directory is intended to house Continuous Integration (CI) scripts for the Cacti integration, specifically designed for Linux environments. It serves as a placeholder for DDEV-related automation tasks within the Datadog integrations-core repository.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 62
          },
          {
            "name": "Kyle Neale",
            "percent": 7
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 6
          }
        ]
      },
      "Secure Integration Downloader": {
        "files": [
          {
            "path": "datadog_checks_downloader/README.md",
            "description": "This README describes the Datadog Checks Downloader, a secure tool utilizing TUF and in-toto for downloading Agent-based integrations with end-to-end verification. It also provides instructions for development, testing, and troubleshooting.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/tests/data",
            "description": "This directory is designated to store test data and fixtures for the `datadog_checks_downloader` module. It provides necessary inputs and expected outputs for various test cases. Although currently empty, its purpose is to support comprehensive testing of the check downloading functionality.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/datadog_checks/downloader/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for `datadog_checks.downloader`, exposing the package's version and configuring logging behavior to suppress internal logging errors.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/datadog_checks/downloader/exceptions.py",
            "description": "This file defines custom exception classes for the datadog-checks-downloader module, covering errors related to CLI operations, package downloading, and TUF/in-toto verification failures.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/datadog_checks/downloader/__main__.py",
            "description": "This file serves as the main entry point for the `datadog_checks_downloader` tool, executing its core download functionality when run directly.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/datadog_checks/downloader/cli.py",
            "description": "This file provides the command-line interface (CLI) for downloading Datadog integration wheels using TUF (The Update Framework) for secure package distribution. It handles argument parsing, validation, and orchestrates the download process.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/signing.py",
            "description": "This file provides utilities for signing project artifacts using the in-toto supply chain security framework, handling GPG/Yubikey key management and ensuring proper file tracking for metadata generation.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Cdric Van Rompay",
            "percent": 37
          },
          {
            "name": "dkirov-dd",
            "percent": 36
          },
          {
            "name": "Fridoln Pokorn",
            "percent": 9
          }
        ]
      },
      "Developer Documentation Platform": {
        "files": [
          {
            "path": "datadog_checks_dev/CHANGELOG.md",
            "description": "This file is the changelog for the `datadog_checks_dev` component, detailing all changes, additions, fixes, and removals across different versions.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/changelog.d",
            "description": "This directory is intended to store individual, unreleased changelog fragments for development-related changes within `datadog_checks_dev`. These fragments are typically aggregated by a build or release process to generate the final changelog for the module.",
            "spof": false
          },
          {
            "path": "ddev/CHANGELOG.md",
            "description": "This file is the changelog for the `ddev` project, documenting new features, bug fixes, changes, and removals across different versions. It provides a historical overview of updates and improvements to the tool.",
            "spof": false
          },
          {
            "path": "ddev/changelog.d",
            "description": "This directory is intended to store individual changelog fragments for the `ddev` integration. These fragments are later collected and compiled into the full changelog for releases, ensuring each change is documented.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/docs/serve.py",
            "description": "This file defines a `ddev` CLI command that serves project documentation, utilizing `hatch run docs:serve` and providing an optional 'dirty reload' for faster development.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/docs/__init__.py",
            "description": "This file initializes the 'docs' command group for the 'ddev' CLI, aggregating subcommands like 'build' and 'serve' for managing documentation. It serves as the main entry point for documentation-related operations within the CLI.",
            "spof": true
          },
          {
            "path": "flink/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Flink integration, documenting version updates, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "druid/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Agent's Druid integration, detailing release versions, dates, and a summary of added features, bug fixes, and other changes.",
            "spof": false
          },
          {
            "path": "docs/proposals/TEMPLATE.md",
            "description": "This file is a Markdown template for writing design proposals within the `datadog` integrations-core repository. It outlines the structure and required sections for a technical proposal, including problem statements, solutions, constraints, and open questions.",
            "spof": false
          },
          {
            "path": "docs/dev/README.md",
            "description": "This file informs users that the documentation has moved and provides links to the new official documentation website and the documentation repository.",
            "spof": false
          },
          {
            "path": "docs/developer/index.md",
            "description": "This file serves as the main entry point for developers interested in creating or contributing to Datadog Agent Integrations. It provides an overview of the development process, best practices, setup instructions, and navigation guidance.",
            "spof": true
          },
          {
            "path": "docs/developer/setup.md",
            "description": "This document provides detailed, platform-specific instructions for setting up a development environment for Datadog integrations. It covers the installation of Python, pipx, and the `ddev` command-line interface, along with their configurations.",
            "spof": false
          },
          {
            "path": "docs/developer/.scripts/33_render_status.py",
            "description": "This script dynamically generates and inserts progress reports for various features and capabilities (like dashboards, logs, E2E tests, metadata, etc.) across Datadog integrations into documentation files. It calculates completion percentages and formats the output for easy readability in Markdown.",
            "spof": true
          },
          {
            "path": "docs/developer/.scripts/66_render_dependencies.py",
            "description": "This script dynamically generates and inserts a list of Python dependencies into documentation files, sourcing them from agent requirements and formatting them with PyPI links, including a humorous \"Other\" dependency.",
            "spof": true
          },
          {
            "path": "docs/developer/faq/acknowledgements.md",
            "description": "This file provides acknowledgements to various open-source software, services, and platforms that Datadog's Agent Integrations team utilizes, including programming languages, dependencies, documentation tools, and CI/CD services.",
            "spof": true
          },
          {
            "path": "docs/developer/faq/faq.md",
            "description": "This file provides a Frequently Asked Questions (FAQ) document for developers working on Datadog integrations. It addresses common topics such as the distinction between integrations and checks, and the rationale behind testing test code.",
            "spof": true
          },
          {
            "path": "docs/developer/guidelines/pr.md",
            "description": "This document provides guidelines for creating pull requests in Datadog repositories, covering topics like separation of concerns, merge strategies, and detailed instructions for generating changelog entries, which vary by repository.",
            "spof": true
          },
          {
            "path": "docs/developer/guidelines/conventions.md",
            "description": "This document outlines development conventions for Datadog Agent integrations, providing guidelines on Python file naming, attribute naming, and efficient handling of stateful checks by parsing configuration once.",
            "spof": true
          },
          {
            "path": "docs/developer/meta/docs.md",
            "description": "This document describes the tooling, configuration, and processes used for generating, building, and deploying the Datadog integrations documentation. It details the MkDocs setup, plugins, extensions, and conventions followed.",
            "spof": false
          },
          {
            "path": "docs/developer/meta/status.md",
            "description": "This file is a markdown template used to display dynamically generated status information for developers within the Datadog integrations-core documentation.",
            "spof": true
          },
          {
            "path": "docs/developer/.hooks/ddev_version.py",
            "description": "This script is an MkDocs hook that dynamically injects the current version of the 'ddev' tool into documentation pages by replacing a specific marker.",
            "spof": true
          },
          {
            "path": "docs/developer/.snippets",
            "description": "This directory is designated to store reusable text or code snippets specifically for inclusion within the developer documentation. It serves as a central location for consistent and easy-to-manage content fragments related to Integrations Core development.",
            "spof": false
          },
          {
            "path": "docs/developer/tutorials/jmx/integration.md",
            "description": "This tutorial provides a step-by-step guide on how to create, configure, and test a JMX integration for collecting metrics from JMX-enabled services.",
            "spof": true
          },
          {
            "path": "docs/developer/assets/images",
            "description": "This directory is intended to store image assets specifically used within the developer documentation for Datadog integrations. These images likely serve as visual aids, such as diagrams or screenshots, to enhance the clarity and understanding of development-related topics.",
            "spof": false
          },
          {
            "path": "docs/developer/assets/css",
            "description": "This directory is designated to store CSS stylesheets specifically for the developer documentation within the Datadog integrations-core repository. Its purpose is to house styling rules that ensure a consistent and readable presentation of the developer-facing content. Although currently empty, it serves as the intended location for these critical styling assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Wang",
            "percent": 23
          },
          {
            "name": "Ofek Lev",
            "percent": 17
          },
          {
            "name": "Juanpe Araque",
            "percent": 16
          }
        ]
      },
      "Developer CLI Framework": {
        "files": [
          {
            "path": "datadog_checks_dev/README.md",
            "description": "This README provides an overview of the Datadog Checks Dev toolkit, explaining its purpose for Agent-based checks and integrations, and directing users to installation and documentation resources.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/tooling/test_github.py",
            "description": "This file contains unit tests for the `get_pr_approvers` function, which extracts approved users from GitHub pull request review data. It uses mocked API responses to verify correct parsing of various review states.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/test_constants.py",
            "description": "This file contains unit tests for the utility functions that determine various file paths (e.g., requirements, changelog, integrations file) and the root directory for Datadog Agent development tools.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/test_utils.py",
            "description": "This file contains unit tests for various utility functions found in the Datadog Agent's development toolkit, such as parsing agent requirement files, retrieving version strings, checking log-only status, and managing repository root paths.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/test_git.py",
            "description": "This file contains unit tests for the Git utility functions in `datadog_checks.dev.tooling.git`. It verifies the correct behavior of functions interacting with Git commands like `rev-parse`, `diff`, `log`, `show`, `commit`, `tag`, `check-ignore`, `ls-files`, and `fetch`.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/ci.py",
            "description": "This file provides utility functions for detecting the Continuous Integration (CI) environment (GitHub Actions or Azure Pipelines) and the operating system (Windows, Linux, macOS) within that CI environment.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/errors.py",
            "description": "This file defines custom exception classes like `RetryError`, `SubprocessError`, and `ManifestError`. These exceptions are utilized within the Datadog Checks Development toolkit to signal specific error conditions.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/__main__.py",
            "description": "This file serves as the main entry point for the `ddev` command-line tool. It initializes and executes the CLI application for Datadog development checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/subprocess.py",
            "description": "Provides a utility function (`run_command`) for safely executing shell commands in a subprocess, capturing their output, and handling error conditions.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/__init__.py",
            "description": "This file serves as the main entry point for the `datadog_checks.dev` package, exposing core utilities and helpers for developing and testing Datadog integrations. It provides functionalities for managing environments, running commands, and interacting with Docker.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/fs.py",
            "description": "This file provides a collection of filesystem utility functions and context managers. It is designed to abstract common file and directory operations, primarily for use in integration tests.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/__main__.py",
            "description": "This file serves as the main entry point for the `ddev` command-line interface tool, executing its primary function and exiting the process.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/__init__.py",
            "description": "This file marks the 'tooling' directory as a Python package, allowing its modules to be imported. It serves as an entry point for development tools and utilities.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/config.py",
            "description": "This file manages the configuration for the `datadog_checks_dev` tooling, defining default settings, handling loading and saving configuration to a TOML file, and scrubbing sensitive data from the configuration.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/codeowners.py",
            "description": "This file provides utilities to parse a CODEOWNERS file, convert path patterns to regular expressions, and determine the owners or section for a given file path.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/cli.py",
            "description": "This file defines the main command-line interface (CLI) for the `datadog_checks_dev` tool, handling global options, configuration loading, and dispatching commands.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/clean.py",
            "description": "This file provides utility functions for cleaning up temporary files, build artifacts, and development-related directories within a project or package, such as compiled Python files, cache directories, and test output.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/github.py",
            "description": "This file provides utility functions and a class for interacting with the GitHub API, primarily for fetching information related to repositories, commits, tags, and pull requests, and parsing PR numbers from commit messages.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/constants.py",
            "description": "This file defines various constants, mappings, and utility functions used across the Datadog Agent integrations development tooling, particularly for repository identification, changelog management, file path resolution, and copyright detection.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/git.py",
            "description": "This file provides a collection of utility functions for interacting with Git repositories, enabling programmatic execution of common Git commands such as getting repository information, checking file status, committing, tagging, and fetching.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/utils.py",
            "description": "This file provides a collection of utility functions for the Datadog Agent integrations development tooling, including path management, naming conventions, repository configuration, and metadata extraction.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/e2e/platform.py",
            "description": "This file defines constants for operating system names (macOS, Windows, Linux) used within the tooling.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/clean.py",
            "description": "This file implements a `ddev` command-line tool for removing build and test artifacts from a specified integration check or the current project, with options for cleaning only compiled files or forcing removal of root-level artifacts.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/__init__.py",
            "description": "This file serves as the `__init__.py` for the `commands` package, importing and exposing various development and tooling commands. It consolidates all available commands into a single `ALL_COMMANDS` tuple for easy access.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/run.py",
            "description": "This file defines a Click command-line tool that executes arbitrary commands within the root directory of the repository, passing through arguments and exit codes.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/config.py",
            "description": "This file implements a command-line interface (CLI) for managing the `ddev` configuration file, allowing users to edit, view, update, restore, and set specific key-value pairs within the config.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/console.py",
            "description": "This file provides utility functions for CLI tools, including colored console output, GitHub Actions annotations for CI feedback, robust command execution, and argument validation.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/catalog.py",
            "description": "This file defines a `click` command to generate a catalog of Datadog integrations, listing various features and properties for each. The catalog can be outputted in CSV or Markdown format.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/__init__.py",
            "description": "This file serves as the entry point for the `meta` command group within the Datadog Checks development tooling, aggregating various experimental or niche utility commands like catalog, changes, JMX, and SNMP tooling.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/dashboard.py",
            "description": "This script provides command-line utilities for managing Datadog dashboards, specifically to export a dashboard from a given URL to a JSON file and associate it with a specific integration.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/changes.py",
            "description": "This script is a CLI tool that analyzes Git history to display changelog entries for integrations since a specified date, showing which authors made the releases.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/scripts/github_user.py",
            "description": "This script provides a command-line utility to look up a GitHub username associated with a given email address using the GitHub API.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/scripts/__init__.py",
            "description": "This file defines a `click` command group named `scripts` which serves as a container for various miscellaneous utility scripts, such as converting emails to GitHub usernames, generating metrics documentation, and removing labels.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/scripts/remove_labels.py",
            "description": "This script defines a command-line tool to remove all labels from a specified GitHub issue or pull request. It uses the GitHub API and requires user authentication to perform this action.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/windows/__init__.py",
            "description": "This file defines the 'windows' command group for the `datadog_checks_dev` tool, serving as the entry point for Windows-specific CLI utilities like PDH monitoring.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/ci/__init__.py",
            "description": "This file defines the main 'ci' command group for the Datadog Checks development tooling, serving as an entry point for various CI-related utilities. It registers subcommands like 'setup' to handle experimental CI tasks.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/plugin/__init__.py",
            "description": "This `__init__.py` file marks the 'plugin' directory as a Python package within the `datadog_checks_dev` toolkit. It likely serves as an entry point for defining or registering development plugins.",
            "spof": true
          },
          {
            "path": "ddev/README.md",
            "description": "This file is the README for the `ddev` command-line tooling, which is used for Datadog Agent integrations. It provides an overview of `ddev` and links to its installation guide and documentation.",
            "spof": true
          },
          {
            "path": "ddev/tests/test__utils.py",
            "description": "This file provides utility functions for Git repository interactions and contains a test for validating that a `ClonedRepo` object accurately reflects a specified Git branch state relative to a local repository.",
            "spof": true
          },
          {
            "path": "ddev/tests/repo/test_config.py",
            "description": "This file contains unit tests for the `ddev` repository configuration, specifically verifying that `RepositoryConfig` correctly inherits from `JSONPointerFile`.",
            "spof": true
          },
          {
            "path": "ddev/tests/repo/test_core.py",
            "description": "This file contains unit tests for the `ddev` tool's repository and integration management functionalities, including testing how integrations are identified, retrieved, and iterated over within a repository based on various criteria and changes.",
            "spof": true
          },
          {
            "path": "ddev/tests/config/test_model.py",
            "description": "This file contains unit tests for the `RootConfig` model in `ddev`, validating its default values, parsing logic, and error handling for various configuration sections like repositories, agents, and organizations.",
            "spof": true
          },
          {
            "path": "ddev/tests/utils/test_github.py",
            "description": "Tests GitHub utility functions from `ddev.utils.github`, specifically verifying the retrieval of pull request information and the creation of labels.",
            "spof": false
          },
          {
            "path": "ddev/tests/utils/test_check_pr.py",
            "description": "This file contains unit tests for the `check_pr` utility script, specifically focusing on its changelog validation logic. It tests various scenarios to ensure the script correctly identifies when changelogs are needed, are properly formatted, and correspond to the pull request.",
            "spof": true
          },
          {
            "path": "ddev/tests/utils/test_hatch.py",
            "description": "This file contains unit tests for the `ddev.utils.hatch` module, verifying its functionality for interacting with the Hatch build environment manager, including environment variable handling, configuration parsing, and managing Hatch environments for integrations.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/test_upgrade_check.py",
            "description": "This file contains unit tests for the `ddev` command-line tool's upgrade checking functionality. It verifies the proper handling of upgrade checks, including cache file operations, version comparison, PyPI interactions, and error handling.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/config/test_explore.py",
            "description": "Tests the `ddev config explore` command, ensuring it correctly attempts to launch the configuration file.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/config/test_show.py",
            "description": "Tests the `ddev config show` command, verifying its output scrubbing functionality and how it handles local configuration overrides.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/config/test_override.py",
            "description": "This file contains unit tests for the `ddev config override` CLI command, ensuring it correctly creates, updates, and handles local repository configuration overrides under various conditions.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/config/test_edit.py",
            "description": "This file contains unit tests for the `ddev config edit` command, verifying its functionality to open the main configuration file or the overrides configuration file for editing, and handling cases where override files are missing.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/config/test_restore.py",
            "description": "This file contains unit tests for the `ddev config restore` command, verifying its ability to restore default configurations, handle invalid settings, and manage local override files interactively.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/clean/test_clean.py",
            "description": "Tests the `ddev clean` CLI command to ensure it correctly removes specified artifacts while preserving others.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/status/test_status.py",
            "description": "This file contains unit tests for the `ddev status` command, verifying its output under various repository, branch, organization, and integration change scenarios, including configuration via flags and environment variables.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/__main__.py",
            "description": "This file serves as the entry point for the `ddev` command-line interface (CLI) application. When the `ddev` package is executed directly, it imports and runs the main CLI function.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/__init__.py",
            "description": "This is the `__init__.py` file for the `ddev` Python package within the Datadog integrations-core repository. Its primary purpose is to declare the `ddev` directory as a Python package.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/application.py",
            "description": "This file defines the Application class, which serves as the central context for the `ddev` CLI. It manages configuration, repository selection (e.g., core, extras, agent), and integration with GitHub, while also providing backward compatibility for an older CLI.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/__init__.py",
            "description": "This file initializes and defines the main command-line interface (CLI) for `ddev`, a development tool for Datadog integrations. It sets up global options, registers subcommands, and manages application configuration and context.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/upgrade_check.py",
            "description": "This file implements a utility function to check for available upgrades for the 'ddev' command-line tool, notifying the user if a newer version is found on PyPI after a specified interval.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/terminal.py",
            "description": "This file provides a utility class `Terminal` for standardized, styled, and interactive command-line output, leveraging the `rich` library for various display methods and status management.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/config/find.py",
            "description": "This file implements a command-line utility function to display the path of the configuration file and any applied override files.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/config/edit.py",
            "description": "Implements a CLI command to open and edit the ddev configuration file using the default editor, with an option to edit local overrides.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/config/set.py",
            "description": "This file implements the `ddev config set` CLI command, allowing users to assign or update values for configuration entries in either the global `ddev.toml` or a local overrides file. It supports nested keys, prompts for values, validates the new configuration, and saves the changes.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/clean/__init__.py",
            "description": "This file defines the `ddev clean` command, which removes all build and test artifacts from the repository using `git clean -fdX`, while preserving IDE configuration files and the `_version.py` file.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/__init__.py",
            "description": "This file defines the `meta` command group for the `ddev` CLI, serving as a collection point for various experimental or niche utility commands related to Datadog checks development.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/status/__init__.py",
            "description": "Implements the `status` command for the `ddev` CLI tool, displaying information about the current development environment, including repository details, current branch, organization, and changed integrations.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/repo/constants.py",
            "description": "This file defines various constants for the `ddev` tool, including configuration directory names, integration shipping statuses, full repository names, and Python versions.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/plugin/api.py",
            "description": "This file defines the `pluggy` hook implementation marker for the `ddev` plugin system, providing the API for extensions to register their functionalities.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/plugin/__init__.py",
            "description": "This file defines the `plugin` directory as a Python package within the `ddev` tool. It serves as an initializer, allowing other modules within this directory to be imported.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/integration/manifest.py",
            "description": "This file defines the `Manifest` class, which is used by the `ddev` tool to represent and interact with `manifest.json` files. It extends `JSONPointerFile` to provide structured access to manifest content.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/__init__.py",
            "description": "Marks the 'utils' directory as a Python package for the ddev tool. It will likely be used to group and expose general utility functions for the 'ddev' command-line interface.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/metadata.py",
            "description": "This file defines the data structure for 'ddev' tool metadata within a `pyproject.toml` file and provides a utility function to extract and validate this metadata from a repository's `pyproject.toml`.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/platform.py",
            "description": "This module provides a `Platform` class that centralizes cross-platform utility methods for running shell commands, managing processes, and handling platform-specific behaviors (like file URI formatting) within the `ddev` tool.",
            "spof": true
          },
          {
            "path": "docs/developer/.scripts/00_set_root.py",
            "description": "This script ensures the root directory for Datadog development tooling (`ddev`) is set to the current working directory if it hasn't been defined yet. This initialization is crucial for subsequent ddev operations.",
            "spof": true
          },
          {
            "path": "docs/developer/ddev/multirepo.md",
            "description": "This document explains how to use `.ddev.toml` files for local configuration overrides within the `ddev` CLI, enabling users to manage distinct settings for different repositories or Git worktrees. It details how these local overrides take precedence over global configurations and provides examples of `ddev` commands that interact with them.",
            "spof": true
          },
          {
            "path": "docs/developer/ddev/cli.md",
            "description": "This file uses mkdocs-click to automatically generate documentation for the 'ddev' command-line interface (CLI) from its Python module. It serves as a dynamic documentation source for the `ddev` tool within the project.",
            "spof": true
          },
          {
            "path": "docs/developer/ddev/configuration.md",
            "description": "This document describes how to configure the `ddev` command-line tool, detailing various options like repository context, Agent versions, organization settings, and GitHub credentials. It explains how to manage these configurations globally or with local overrides.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 55
          },
          {
            "name": "Steven Yuen",
            "percent": 36
          },
          {
            "name": "Ofek Lev",
            "percent": 3
          }
        ]
      },
      "Integration Asset Validation": {
        "files": [
          {
            "path": "datadog_checks_dev/tests/tooling/test_license_headers.py",
            "description": "This file contains unit tests for parsing and validating license headers in Python source files, ensuring they conform to required standards and handling various scenarios like file types, directory structures, and gitignore rules.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/commands/validate/test_models.py",
            "description": "This file contains unit tests for the `ddev validate models` command, verifying its behavior when generating and validating configuration model files for integrations. It checks for correct license headers and synchronization status across different repository types.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/commands/validate/test_config.py",
            "description": "This file contains unit tests for the configuration validation logic within the `datadog_checks.dev` tool, specifically verifying the mandatory presence of `spec.yaml` in core integrations and the correct handling of configless checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/commands/validate/test_package.py",
            "description": "This file contains unit tests for the `validate package` command within the `datadog_checks.dev` tooling. It specifically verifies the command's functionality in validating author email formats defined in `pyproject.toml` files for Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/commands/validate/data/my_check/datadog_checks/my_check/config_models",
            "description": "This directory is designed to house configuration models for the 'my_check' integration. It serves as a placeholder within the test data used by the `datadog_checks_dev` validation tooling, defining the expected structure or examples for the integration's configuration.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/tooling/commands/validate/data/my_check/datadog_checks/my_check/data",
            "description": "This directory serves as a test fixture within the `datadog_checks_dev` tooling, simulating the `data` directory of a Datadog integration named `my_check`. It is designed to hold mock configuration examples, manifests, or other static assets for `my_check` to facilitate testing of the `validate` command. Though currently empty, its role is to define the expected location for such data within a simulated integration package.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/tooling/commands/validate/data/my_check/assets/configuration",
            "description": "This directory serves as a placeholder for configuration assets within a test data fixture for the `datadog_checks_dev` validation tooling. It simulates the `assets/configuration` structure expected for an integration named `my_check` during testing. Being empty, it likely represents a test case where no specific configuration files are present or are dynamically generated.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/tooling/commands/meta/snmp/test_validate_mib_filenames.py",
            "description": "This file contains unit tests for the `_extract_mib_name` utility, which extracts the MIB name from the content of a MIB file, including cases with comment headers. It ensures the tooling correctly identifies MIB names for validation purposes.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/config_validator/__init__.py",
            "description": "This empty `__init__.py` file marks the `config_validator` directory as a Python package within the test suite for Datadog tooling development.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/tooling/config_validator/test_validator.py",
            "description": "This file contains unit tests for the configuration validator tool, specifically testing duplicate name detection, description validation, and data type validation for configuration blocks.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/config_validator/test_utils.py",
            "description": "This file contains unit tests for helper functions used in the configuration validator. It verifies functions related to indentation, blank lines, and determining the end of a logical section within text data.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/config_validator/test_config_block.py",
            "description": "This file contains unit tests for the `config_block` module, which is responsible for parsing and validating structured configuration blocks, including parameter declarations, descriptions, and comments, within the Datadog checks development tooling.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/license_headers.py",
            "description": "This file provides tooling to validate license headers in Python source files within a repository, detecting missing, incorrect, or changed headers, and respecting `.gitignore` rules.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/manifest_utils.py",
            "description": "This module provides a unified interface for loading and accessing data from different versions of integration manifests (V1, V2) and the Agent manifest, abstracting away version-specific retrieval logic.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/catalog_const.py",
            "description": "This file defines various sets of integration names used for internal tooling to categorize which integrations do not support specific Datadog features like out-of-the-box dashboards, log collection, or recommended monitors, or for other tooling exclusions.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/config_validator/__init__.py",
            "description": "This `__init__.py` file marks the `config_validator` directory as a Python package. It likely serves to organize and expose modules related to configuration validation within the `datadog_checks_dev` tooling.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/config_validator/validator.py",
            "description": "This file provides functionality to validate YAML configuration files. It parses the file into configuration blocks, ensures the presence of `init_config` and `instances` sections, checks for correct indentation, and detects duplicate variable names.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/config_validator/validator_errors.py",
            "description": "This file defines the `ValidatorError` class, used to encapsulate and format validation errors with their severity and line number. It also includes constants for error and warning severities.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/config_validator/utils.py",
            "description": "Provides utility functions for analyzing and validating the indentation and block structure of YAML-like configuration files.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/config_validator/config_block.py",
            "description": "This module provides classes and utilities for parsing and validating structured configuration blocks in source code, specifically those documented with an `@param` annotation, their descriptions, and content types.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/manifest.py",
            "description": "This file provides command-line utilities for managing integration manifests, specifically offering a tool to migrate an integration's manifest to a newer schema version.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/snmp/validate_snmp_profiles.py",
            "description": "This script provides a command-line tool to validate SNMP profiles, either individually or from specified directories, using a set of defined validators.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/snmp/validate_mib_filenames.py",
            "description": "This script validates and optionally renames MIB (Management Information Base) filenames to ensure they match the MIB name declared within their content, which is often required by MIB loading frameworks.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/snmp/validators/__init__.py",
            "description": "This file serves as the package initializer for SNMP validators, exposing functions to retrieve all group and single validators. It acts as an entry point for accessing SNMP validation utilities within the tooling.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/snmp/validators/utils.py",
            "description": "This file provides utility functions for locating, loading, and validating SNMP profile YAML files within the Datadog Agent's tooling, including a custom YAML loader that tracks line numbers.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/snmp/validators/validator.py",
            "description": "This file contains a collection of validator classes for SNMP profiles used within Datadog checks development tooling, ensuring schema conformity, uniqueness of OIDs and sysobjectids, and proper tagging for table-related metrics.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/license_headers.py",
            "description": "This file defines a `click` command for validating license headers in Python source files within the Datadog Agent integrations. It includes functionality to automatically fix common license header issues.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/models.py",
            "description": "This file defines a command-line tool for validating and optionally synchronizing configuration data models across various checks based on their `spec.yaml` files. It ensures that generated model files are consistent with their specifications.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/__init__.py",
            "description": "This file serves as the main entry point for the 'validate' command within the Datadog checks development tooling, aggregating and exposing various subcommands to verify different aspects of the repository.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/eula.py",
            "description": "This script defines a `click` command to validate End User License Agreement (EULA) files for checks in the repository. It ensures EULA files exist, have a .pdf extension, and are valid PDF documents.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/typos.py",
            "description": "This file defines a `click` command to validate spelling in the codebase using the `codespell` tool, providing options to fix errors or target specific checks. It parses `codespell` output to annotate detected typos.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/integration_style.py",
            "description": "Defines a command-line tool to validate the style of Python files within integration checks. It specifically identifies and warns about the use of the `instance` parameter in the `check()` function, which is slated for deprecation.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/jmx_metrics.py",
            "description": "This file implements a command-line tool for validating JMX metrics files and their corresponding configuration specifications across Datadog integrations. It checks for proper structure, duplicate bean definitions, and correct template usage for JMX configurations.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/imports.py",
            "description": "This file provides a tooling command to validate and optionally autofix Python import statements within Datadog agent checks, ensuring they correctly reference `datadog_checks.base` for shared components rather than direct `datadog_checks` imports.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/codeowners.py",
            "description": "This file contains a command to validate the `CODEOWNERS` file for Datadog integrations, ensuring every integration has an owner and that log assets are assigned to the correct team.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/readmes.py",
            "description": "This file defines a command-line tool for validating README.md files across various integrations, checking for proper structure, required headers, image link correctness, and ASCII character enforcement. It also includes an option to automatically format links within the READMEs.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/package.py",
            "description": "This file defines a command-line tool for validating Python package metadata within Datadog integrations. It checks naming conventions, version file paths, and author email validity in `pyproject.toml` or `setup.py` files.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/config.py",
            "description": "This script defines a `ddev validate config` command to validate default configuration files for Datadog checks, ensuring they conform to defined specifications or legacy patterns, and can also synchronize example configuration files.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/saved_views.py",
            "description": "This script defines a `click` command to validate the structure and content of `saved_views` JSON files for Datadog checks. It ensures that saved views adhere to predefined schemas for headers, types, pages, options, and other properties.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/dashboards.py",
            "description": "This file defines a `click` command to validate the structure and content of Datadog dashboard definition JSON files, including checking for required fields, correct format, and `app_id` consistency for Manifest V2 dashboards. It also offers an option to fix certain validation issues automatically.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/service_checks.py",
            "description": "This file implements a `click` command to validate `service_checks.json` files for Datadog integrations. It ensures the files adhere to predefined structural and data integrity rules, and can optionally synchronize the integration name within these files.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/manifest_validator/__init__.py",
            "description": "This file provides a function to retrieve all relevant manifest validators for a given manifest version, dynamically assembling a list of validators including a base version validator and potentially version-specific validators.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/manifest_validator/constants.py",
            "description": "This file defines constants for manifest schema versions, specifically 1.0.0 and 2.0.0, parsed for comparison. These constants are used within the manifest validation tooling.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/manifest_validator/v2/__init__.py",
            "description": "This `__init__.py` file marks the `v2` directory as a Python package, serving as an entry point for version 2 of the manifest validator within `datadog_checks_dev`.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/manifest_validator/v2/migration.py",
            "description": "This file provides functionality to migrate Datadog integration manifest files from an older version (v1) to a newer version (v2), handling field mapping, data transformation, and new field generation.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/manifest_validator/v2/validator.py",
            "description": "This file defines a collection of validators specifically designed for version 2 Datadog integration manifests. It includes checks for public display settings, tile descriptions, schema compliance, media gallery content, and changelog presence.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/manifest_validator/common/__init__.py",
            "description": "This empty `__init__.py` file marks the `common` directory as a Python package. It enables other modules within the `manifest_validator` tooling to import from this directory.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/validate/test_http.py",
            "description": "This file contains integration tests for the `ddev validate http` command, ensuring it correctly identifies and reports issues related to HTTP wrapper usage and configuration within agent checks. It covers scenarios like invalid parameter usage, direct `requests` library calls, and missing `spec.yaml` templates.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/validate/__init__.py",
            "description": "This is an empty `__init__.py` file that marks the `validate` directory as a Python package, intended for organizing tests related to the `ddev` CLI's validation functionalities.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/validate/test_codeowners.py",
            "description": "Tests the `ddev validate codeowners` command, ensuring it correctly validates the CODEOWNERS file for Datadog integrations, including both valid and invalid scenarios.",
            "spof": false
          },
          {
            "path": "ddev/tests/cli/validate/test_licenses.py",
            "description": "This file contains unit tests for the `ddev validate licenses` command, verifying its ability to detect and report issues related to dependency licenses and requirements in the agent's configuration.",
            "spof": false
          },
          {
            "path": "ddev/tests/cli/validate/test_dep.py",
            "description": "Tests the `ddev validate dep` command's ability to identify valid and invalid third-party dependencies in integration `pyproject.toml` files. It verifies that the command correctly passes for valid dependencies and fails for invalid or unrecognized ones.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/validate/test_openmetrics.py",
            "description": "This file contains unit tests for the `ddev validate openmetrics` command, verifying its functionality for checking OpenMetrics integrations. It tests various scenarios including successful validations, failures, and repository-specific behavior.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/validate/test_labeler.py",
            "description": "This file contains unit tests for the `ddev validate labeler` command, which validates and syncs the GitHub PR labeler configuration file. It covers various scenarios including invalid configurations, missing integrations, and the auto-correction (`--sync`) functionality.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/validate/test_metrics.py",
            "description": "This file contains unit tests for the `ddev validate metadata` command. It verifies that the command correctly identifies various validation issues in `metadata.csv` files, such as empty files, incorrect column numbers, invalid headers, unnormalized metric names, missing manifest prefixes, and invalid metric types or units.",
            "spof": false
          },
          {
            "path": "ddev/tests/cli/validate/test_version.py",
            "description": "This file contains unit tests for the `ddev validate version` command, ensuring it correctly validates version consistency between Python packages' `__about__.py` files and their `CHANGELOG.md` entries across different integration types and scenarios.",
            "spof": true
          },
          {
            "path": "ddev/tests/validation/__init__.py",
            "description": "This `__init__.py` file marks the 'validation' directory as a Python package within the ddev test suite. It facilitates the import of validation-related modules.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/validate/__init__.py",
            "description": "This file defines the 'validate' command-line group using Click, acting as an aggregator for numerous validation subcommands. It brings together various checks for different aspects of the repository and its integrations.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/validate/openmetrics.py",
            "description": "This file defines a `click` command for validating OpenMetrics-based integrations. It ensures that `DEFAULT_METRIC_LIMIT = 0` is present in the source code of OpenMetrics checks within the 'core' or 'extras' repositories.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/validate/http.py",
            "description": "This module provides a command-line utility to validate that Datadog integrations correctly use the HTTP wrapper provided by the `ddev` framework, and that their `spec.yaml` files are configured appropriately for HTTP-based checks. It also identifies and flags direct usage of the `requests` library, which is discouraged.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/validate/metadata.py",
            "description": "This file implements a CLI command to validate `metadata.csv` files for Datadog integrations. It checks for correctness, consistency, and adherence to various rules for metrics metadata.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/validate/metadata_utils.py",
            "description": "Defines constants and regular expressions used for validating metric metadata, including headers, metric types, units, and naming conventions, within the Datadog development environment (ddev) CLI.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/validate/version.py",
            "description": "This script defines a CLI command to validate the versioning and changelog consistency of integrations, ensuring Python packages follow specific rules regarding `__about__.py` and autogenerated `CHANGELOG.md`.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/validation/__init__.py",
            "description": "This file serves as the package initialization file for the `validation` module within the `ddev` tool, marking it as a Python package.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/validation/tracker.py",
            "description": "This module provides a `ValidationTracker` class for hierarchically tracking and displaying the results of validation checks. It utilizes the `rich` library to render a tree-like structure of validation errors and warnings, along with a summary.",
            "spof": true
          },
          {
            "path": "docs/developer/guidelines/style.md",
            "description": "This document outlines the code style enforcement tools and guidelines used in the integrations-core repository, including formatters, linters, and type checkers like Black, isort, Flake8, and Mypy.",
            "spof": true
          },
          {
            "path": "docs/developer/guidelines/dashboards.md",
            "description": "This document provides guidelines and best practices for creating, exporting, and verifying Datadog dashboards, particularly for integrations. It covers visual style, design principles, and standard group inclusions for effective monitoring dashboards.",
            "spof": false
          },
          {
            "path": "docs/developer/meta/ci/validation.md",
            "description": "This document describes the various validation checks performed within the Datadog integrations-core repository, detailing the purpose and usage of each `ddev validate` subcommand.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 22
          },
          {
            "name": "Nicholas Muesch",
            "percent": 21
          },
          {
            "name": "Steven Yuen",
            "percent": 15
          }
        ]
      },
      "Integration Scaffolding": {
        "files": [
          {
            "path": "datadog_checks_dev/tests/tooling/commands/test_create.py",
            "description": "This file contains tests for the `datadog_checks.dev create` command, verifying its ability to generate, install, and run tests for new integration types like checks, JMX integrations, tiles, and logs integrations.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/create.py",
            "description": "This module provides tooling to create new Datadog integration projects by processing and generating files from predefined templates, filling in dynamic information based on the integration type and repository choice.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/create.py",
            "description": "This file implements the `create` command for the Datadog Agent's development tooling, used to scaffold new integrations by generating the necessary file structure and template files based on user input and integration type.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "James Eichelbaum",
            "percent": 29
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 26
          },
          {
            "name": "Juanpe Araque",
            "percent": 18
          }
        ]
      },
      "Advanced Development and Analysis Tools": {
        "files": [
          {
            "path": "datadog_checks_dev/tests/tooling/commands/meta/snmp/data",
            "description": "This directory is intended to store test data specifically for the SNMP meta commands within the `datadog_checks_dev` testing suite. It would contain files used to validate the functionality of SNMP-related tooling commands.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/jmx.py",
            "description": "This file defines lists of JVM and JMX metrics used for End-to-End (E2E) testing within the `datadog_checks_dev` package, including logic to consolidate and transform these metric lists.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/create_commits.py",
            "description": "This script automates the creation of sequential Git commits on a feature branch, primarily to demonstrate the process of building a new integration by copying content from numbered subdirectories as commit stages.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/jmx.py",
            "description": "This file provides command-line utilities for interacting with JMX endpoints. It includes a subcommand to query a JMX service for MBean information.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/prometheus.py",
            "description": "This file provides command-line utilities for interacting with Prometheus metrics. It allows users to inspect metrics from an endpoint or file, and interactively parse them to generate `metadata.csv` and Python code snippets for Datadog checks.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/snmp/__init__.py",
            "description": "This file defines the `snmp` command-line utility group, aggregating various subcommands for managing and validating SNMP profiles, MIBs, and traps database within the Datadog Agent development tools.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/snmp/constants.py",
            "description": "This file defines constants for the SNMP meta-command tooling in Datadog checks development, including URLs for MIB source and compiled MIBs, as well as a terminal escape code.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/snmp/translate_profile.py",
            "description": "This file provides a command-line tool to translate MIB (Management Information Base) names and symbols within a given SNMP profile into their corresponding OIDs (Object Identifiers). It automates this process by parsing a YAML profile, resolving MIB entities using pysnmp, and fetching missing MIBs if required.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/scripts/metrics2md.py",
            "description": "This script provides a command-line tool to convert a check's `metadata.csv` file into a Markdown table. It allows users to specify which metric fields to include and outputs the formatted table to the console.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/meta/windows/pdh.py",
            "description": "This file provides a command-line utility for exploring Windows Performance Data Helper (PDH) counters, including their types and descriptions. It helps users browse available counter sets and their associated counters and instances.",
            "spof": false
          },
          {
            "path": "ddev/tests/cli/meta/scripts/test_dynamicd.py",
            "description": "Tests for the `_dynamicd.context_builder` module, verifying its ability to extract metrics, tags, tag values, and service checks from integration dashboards and metadata files.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/size/__init__.py",
            "description": "This file marks the 'size' directory as a Python package, which likely contains test modules for the 'ddev' CLI tool related to size analysis or functionality.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/size/conftest.py",
            "description": "This `conftest.py` file provides a pytest fixture that globally mocks `matplotlib.pyplot` functions to prevent their execution during tests, indicating that these tests are not concerned with `matplotlib`'s functionality.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/size/test_timeline.py",
            "description": "This file contains pytest unit tests for the `ddev size timeline` command-line interface subcommand. It verifies the functionality of tracking size changes for integrations and dependencies across different Git commits, including various output formats and error handling.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/size/test_status.py",
            "description": "This file contains unit and integration tests for the 'ddev size status' CLI command, including parameter validation and various command-line arguments.",
            "spof": false
          },
          {
            "path": "ddev/tests/cli/size/test_diff.py",
            "description": "This file contains unit tests for the `ddev size diff` command, verifying its functionality and argument handling for comparing file and dependency sizes between different commits under various scenarios, including valid/invalid platforms and Python versions.",
            "spof": true
          },
          {
            "path": "ddev/tests/size/test_diff.py",
            "description": "This file contains unit tests for the `get_diff` function, which calculates the size differences between two sets of integration data.",
            "spof": true
          },
          {
            "path": "ddev/tests/size/test_timeline.py",
            "description": "This file contains unit tests for the `ddev.cli.size.timeline` module, verifying its functions for calculating and formatting size data for integrations and their dependencies over time. It covers aspects like file compression, version extraction, commit data formatting, and dependency size retrieval.",
            "spof": true
          },
          {
            "path": "ddev/tests/size/test_common.py",
            "description": "This file contains unit tests for the common utility functions used by the `ddev size` command. It verifies the correctness of functions related to file size calculations, dependency parsing, platform/version handling, and data formatting.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/size/diff.py",
            "description": "This script defines a `click` command to compare the size of integrations and their dependencies between two specified Git commits. It calculates and displays size differences, with options for output formatting and visualization.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/size/__init__.py",
            "description": "This file defines the 'size' command-line group for the `ddev` tool, which orchestrates subcommands to analyze and monitor the download size of integrations and their dependencies. It serves as the main entry point for inspecting size status, comparing changes, and tracking size timelines across different contexts.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/size/timeline.py",
            "description": "This file defines a command-line interface (CLI) tool that analyzes and displays the size evolution of a specified module (either an integration or a dependency) across different commits in a Git repository. It supports filtering by commits, date, platform, and outputting results in various formats.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/size/status.py",
            "description": "This file implements a `ddev` CLI command to analyze and report the disk usage size of integrations and their dependencies across different platforms and Python versions. It can display results, export them in various formats, or send metrics to Datadog.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/size/historical_metrics.py",
            "description": "This script processes historical Git commits from a specified date, calculating and uploading code size metrics for each commit to a Datadog organization using the `ddev size status` command. It allows for tracking code size evolution over time.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/size/utils/common_params.py",
            "description": "This file defines a `common_params` decorator for Click commands, which adds common command-line options related to size analysis such as platform, compression, output format, and GUI display.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/size/utils/common_funcs.py",
            "description": "This file provides utility functions for analyzing the size of Datadog integrations and dependencies. It includes methods for filtering files based on packaging rules, compressing files, extracting version information, and checking Python version compatibility.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/__init__.py",
            "description": "This file defines and groups various miscellaneous utility scripts for the `ddev` command-line interface. It aggregates commands like `dynamicd`, `generate_metrics`, `metrics2md`, and others under a 'scripts' CLI subgroup.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/dynamicd.py",
            "description": "This file defines a CLI command (`ddev meta scripts dynamicd`) for generating realistic, AI-powered fake telemetry data for an integration. It uses Claude to create scenario-aware data simulators for testing and development purposes.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/monitor.py",
            "description": "This file provides a CLI tool within `ddev meta monitor` to create standardized monitor specifications from Datadog UI exports. It allows users to wrangle monitor JSON by renaming, adding, and dropping fields, and editing the title and description.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/_dynamicd/__init__.py",
            "description": "This file initializes the 'DynamicD' package, which provides utilities for generating smart fake data specifically for Datadog integrations.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/_dynamicd/README.md",
            "description": "This README documents DynamicD, a tool that leverages AI to generate realistic, scenario-aware fake telemetry data for Datadog integrations. It provides instructions on setup, usage, available scenarios, and generated data types for simulating metrics, logs, and service checks.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/_dynamicd/prompts.py",
            "description": "This file defines prompt templates used for large language model (LLM) interactions within the DynamicD tool, specifically for analyzing Datadog integrations and generating telemetry simulation scripts.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/_dynamicd/constants.py",
            "description": "This file defines various constants used by the DynamicD tool, including configurations for LLM, rate limiting, simulation scenarios, Datadog API endpoints, and Docker sandbox settings.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/_dynamicd/cli.py",
            "description": "This file implements the command-line interface for the `DynamicD` tool, which generates and executes synthetic data simulation scripts for Datadog integrations. It handles API key validation, scenario selection, script generation, and simulation execution.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/_dynamicd/executor.py",
            "description": "Orchestrates the execution of dynamically generated Python scripts for DynamicD, including error handling, retries with AI-based correction, and optional sandboxed execution via Docker.",
            "spof": true
          },
          {
            "path": ".devcontainer/dbm",
            "description": "This empty directory is part of the development container configuration for Datadog's `integrations-core` repository, specifically reserved for Database Monitoring (DBM) related settings. It is intended to house DBM-specific devcontainer configurations.",
            "spof": false
          },
          {
            "path": "docs/developer/tutorials/jmx/tools.md",
            "description": "This file provides a tutorial on using JMXTerm to list JMX beans from a Java application. It includes commands and examples for connecting to JMX services, both standard and with additional JARs.",
            "spof": true
          },
          {
            "path": "docs/developer/tutorials/snmp/sim-format.md",
            "description": "This document describes the format and conventions for `.snmprec` simulation data files, which are used to simulate SNMP agent responses for profiles. It details line formatting, required sorting, and examples for simulating symbol and table metrics.",
            "spof": true
          },
          {
            "path": "docs/developer/tutorials/snmp/tools.md",
            "description": "This document provides a tutorial on using `tcpdump`, `snmpwalk`, and `snmpget` to analyze and debug SNMP communication, including instructions for running these tools directly and within a Docker Agent container.",
            "spof": true
          },
          {
            "path": "docs/developer/tutorials/snmp/how-to.md",
            "description": "This document provides a how-to guide for developers to simulate SNMP devices, configure local test environments, and execute various SNMP queries using command-line tools for testing and debugging purposes.",
            "spof": true
          },
          {
            "path": "docs/developer/tutorials/snmp/introduction.md",
            "description": "This document provides an introduction to the SNMP protocol, covering its overview, different versions, and core concepts such as Object Identifiers (OIDs) and Management Information Bases (MIBs).",
            "spof": true
          },
          {
            "path": "docs/developer/tutorials/snmp/profile-format.md",
            "description": "This document provides a reference for the SNMP profile format, detailing how to structure YAML files for monitoring network devices, including definitions for metrics and tagging.",
            "spof": false
          },
          {
            "path": "docs/developer/tutorials/snmp/profiles.md",
            "description": "This document provides a tutorial on manually building SNMP profiles for monitoring network devices. It covers researching devices, selecting metrics, implementing the profile with YAML, adding unit tests, and creating simulation data.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "mahipdeora25",
            "percent": 39
          },
          {
            "name": "luciasanchezbella01",
            "percent": 33
          },
          {
            "name": "Luca",
            "percent": 17
          }
        ]
      },
      "Configuration Modeling and Generation": {
        "files": [
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/test_load.py",
            "description": "This file contains unit tests for the configuration specification loader within the Datadog Agent's tooling, verifying its ability to parse and validate configuration files against defined schemas.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/__init__.py",
            "description": "This `__init__.py` file marks the `configuration` directory as a Python package, organizing tests related to configuration tooling within the `datadog_checks_dev` library.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/test_example.py",
            "description": "This file contains unit tests for the example configuration consumer, verifying its ability to render various configurations into example YAML files. It tests different scenarios for options, sections, their visibility, and display order.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/__init__.py",
            "description": "This `__init__.py` file marks the `consumers` directory as a Python package, enabling its modules to be imported within the `datadog_checks_dev` test suite for configuration tooling.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_deprecations.py",
            "description": "This file contains tests for the `model_consumer`'s ability to correctly extract and format deprecation information from configuration models into a `deprecations.py` file.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_array.py",
            "description": "This file contains a test case for the model consumer, verifying its ability to correctly generate Pydantic models and associated files for configurations that include array type fields.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_enum.py",
            "description": "Tests the `model_consumer`'s ability to correctly generate Pydantic models for configuration options defined with enum (enumerated) values, covering both string and integer enum types.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_only_shared.py",
            "description": "This file contains a test for the model consumer, verifying its ability to correctly generate model files (__init__.py, shared.py, validators.py) when the input schema defines only shared configuration options.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_all_required.py",
            "description": "This file tests the generation of a Python configuration model (`instance.py`) when an option is marked as `required: true` in the model definition, ensuring proper Pydantic model and validator generation.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_defaults.py",
            "description": "This file contains a test case for ensuring that default values specified in configuration schemas are correctly processed and generated into the `defaults.py` and `instance.py` model files by the configuration consumer tool.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_no_models.py",
            "description": "This file contains a test case to ensure that the model consumer does not generate any models when provided with a specific configuration that is expected to yield no models.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_nested_option.py",
            "description": "Tests the configuration model consumer's ability to correctly generate Pydantic models for nested options and objects within a configuration schema.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/__init__.py",
            "description": "This empty `__init__.py` file marks the `model` directory as a Python package within the test suite for Datadog checks development tooling. It enables importing modules related to configuration consumer models in tests.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_both_models_basic.py",
            "description": "Tests the `model_consumer` tool's ability to generate configuration models (Pydantic models for shared and instance configurations, `ConfigMixin`, and supporting files) from a YAML definition that includes both init_config and instance templates.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_option_name_normalization.py",
            "description": "This file contains a test case for ensuring that option names with special characters (like hyphens) are correctly normalized into valid Python identifiers (snake_case) with appropriate aliases when generating configuration models.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_merge_instances.py",
            "description": "This file contains a test that verifies the correct generation of Pydantic models and supporting files for agent check configuration when multiple instance definitions are provided and their options need to be merged.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_union_types.py",
            "description": "This test file verifies that the configuration model consumer correctly generates Pydantic models when union types (specifically `anyOf`) are defined in the configuration schema. It checks the generated `instance.py` to ensure `Optional[Union[str, tuple[str, ...]]]` is correctly produced.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_duplicate_hidden.py",
            "description": "Tests the configuration model consumer's ability to generate code from a configuration definition, specifically focusing on how it handles templated fields with overrides, such as marking a password field as hidden.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/tooling/configuration/consumers/model/test_common_validators.py",
            "description": "This test file verifies that the configuration model consumer correctly generates Python model files, including Pydantic models and a validator module, that properly integrate common validators specified in the input schema.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/spec.py",
            "description": "This file provides utility functions to locate and load configuration specification (spec) files for Datadog checks, supporting discovery from manifest files or common asset locations.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/constants.py",
            "description": "This file defines constants related to OpenAPI specification, specifically listing valid OpenAPI data types and schema properties for use in tooling.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/spec.py",
            "description": "This file contains validators for Datadog Agent check configuration specifications. It ensures the correct structure and content of configuration files, including handling templates and overrides.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/consumers/__init__.py",
            "description": "This `__init__.py` file serves as the entry point for the `consumers` package, exposing `ExampleConsumer` and `ModelConsumer` classes which are likely different types of configuration consumers.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/consumers/openapi_document.py",
            "description": "This module is responsible for generating an OpenAPI specification document and associated model information from a given configuration specification. It processes configuration options, normalizes names, handles type data, and sanitizes properties to conform to the OpenAPI standard.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/consumers/model/model_info.py",
            "description": "This module defines the `ModelInfo` class, which aggregates and manages configuration model information such as default values, validators, and deprecation details for generating or validating configuration files. It handles the processing and storage of various attributes derived from configuration specifications.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/consumers/model/model_file.py",
            "description": "This module generates and customizes Pydantic model files for Datadog integrations. It modifies base model definitions (often from OpenAPI) by adding specific imports, fixing Python types, and injecting validation and deprecation handling logic.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/consumers/model/model_consumer.py",
            "description": "This file defines a `ModelConsumer` class responsible for processing a configuration specification and generating Python data models (e.g., Pydantic) and associated files for Datadog checks based on that specification.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/consumers/example.py",
            "description": "This file contains utilities for validating configuration option definitions and generating well-formatted YAML configuration examples from a given specification, including descriptions, types, and defaults.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/saved_views.py",
            "description": "This script provides a CLI tool to convert a Datadog Logs Saved View's JSON definition, fetched via its permalink, into a formatted asset definition JSON for configuration management.",
            "spof": true
          },
          {
            "path": "docs/developer/meta/config-models.md",
            "description": "This document describes the structure, generation, and validation process of configuration models used in Datadog integrations, primarily leveraging Pydantic. It details how instance and shared configurations are defined, default values are handled, and validation stages are implemented.",
            "spof": true
          },
          {
            "path": "docs/developer/meta/config-specs.md",
            "description": "This document describes the structure and usage of configuration specifications for Datadog integrations. It details how these `spec.yaml` files are processed by 'producers' and consumed for various purposes like generating example configurations, documentation, and data models.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "ddog-nasirthomas",
            "percent": 54
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 21
          },
          {
            "name": "Ofek Lev",
            "percent": 11
          }
        ]
      },
      "Dependency and License Management": {
        "files": [
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/dependencies.py",
            "description": "This file provides utilities for managing Python dependencies across Datadog checks and the Agent, including reading and updating dependency information from various configuration files like pyproject.toml, requirements.in, and setup.py.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/dep.py",
            "description": "This file implements a `ddev validate dep` command to verify Python dependencies across Datadog integrations, ensuring they are correctly specified, pinned, unique, and compatible with agent requirements.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/licenses.py",
            "description": "This file implements a command-line tool for validating, standardizing, and generating attribution for third-party package licenses and copyrights within the Datadog Agent's dependencies. It includes extensive mappings for license names to SPDX identifiers and mechanisms to scrape license data.",
            "spof": false
          },
          {
            "path": "datadog_checks_tests_helper/setup.py",
            "description": "This setup.py file defines the metadata and packaging instructions for the `datadog_checks_tests_helper` Python package, used for testing Datadog Agent checks. It includes information like package name, version, description, dependencies, and author details.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/test_dep.py",
            "description": "This file contains unit tests for the `ddev` CLI's `dep` command, which is responsible for managing Python dependencies across Datadog integrations, including pinning, freezing, syncing, and checking for updates.",
            "spof": false
          },
          {
            "path": "ddev/tests/cli/meta/scripts/test_update_py_config.py",
            "description": "Tests the `ddev meta scripts update-python-config` command, ensuring it correctly updates Python version references across various configuration files like constants.py, CI workflows, Hatch, and pyproject.toml files.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/meta/scripts/test_upgrade_python.py",
            "description": "Tests the `ddev meta scripts upgrade-python-version` CLI command, ensuring it correctly updates Python versions and associated hashes in various configuration files, and handles different scenarios like already being at the latest version or failing to find a new version.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/dep/pin.py",
            "description": "This script defines a CLI command to pin a specific version of a dependency across all checks that utilize it within the repository.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/dep/freeze.py",
            "description": "This file implements a CLI command to collect and combine all dependencies from individual integrations into a single `agent_requirements.in` file for the Datadog Agent's static environment.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/dep/updates.py",
            "description": "This script defines a `ddev` CLI command to automatically check for out-of-date Python dependencies in Datadog Agent integrations. It can optionally update these dependencies and synchronize the dependency definitions.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/dep/sync.py",
            "description": "This script synchronizes the dependency specifications of individual integrations with the overall agent dependencies. It reads agent dependencies and propagates relevant parts to each integration's dependency spec.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/dep/common.py",
            "description": "This module provides utilities for managing Python package dependencies across Datadog integrations, including reading, updating, and normalizing dependency specifications from various sources, and scraping package version data from external repositories.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/validate/licenses_utils.py",
            "description": "This file provides utility data structures and regular expressions for identifying, validating, and standardizing license and copyright information within a source code repository. It includes mappings for various license names to SPDX identifiers and patterns for extracting copyright statements.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/validate/licenses.py",
            "description": "This file provides utilities for validating and scraping license and copyright information for third-party dependencies. It includes functionalities to extract data from package archives, probe GitHub for repository details, and process custom license attribution files.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/update_py_config.py",
            "description": "This script provides a CLI command to update Python version references across various configuration files (e.g., Hatch, pyproject, setup, CI workflows, constants) within a source code repository. It automates the process of upgrading the Python version for test environments and other configurations.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/hatch.py",
            "description": "This file provides utility functions for interacting with and managing Hatch project environments, including listing, parsing, and removing environments, and configuring Hatch-related environment variables.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 48
          },
          {
            "name": "Juanpe Araque",
            "percent": 21
          },
          {
            "name": "dkirov-dd",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 386,
      "spofCount": 265
    },
    "busFactor": 3,
    "authorCount": 47
  },
  "Bitwarden Audit Log Integration": {
    "description": "Collects event logs from Bitwarden to monitor user activity, credential access, and security events within the password manager.",
    "functions": {
      "Integration Assets and Dashboards": {
        "files": [
          {
            "path": "bitwarden/CHANGELOG.md",
            "description": "This file documents the version history and changes made to the `bitwarden` integration over time, including new features and updates.",
            "spof": true
          },
          {
            "path": "bitwarden/README.md",
            "description": "This README documents the Datadog integration for Bitwarden, detailing its functionality for collecting Bitwarden event logs, setup instructions, and the types of data collected.",
            "spof": false
          },
          {
            "path": "bitwarden/images",
            "description": "This directory is intended to store image assets related to the Datadog Bitwarden integration. These images would likely be used for documentation, UI elements, or other visual components of the integration.",
            "spof": false
          },
          {
            "path": "bitwarden/assets/dashboards",
            "description": "This directory is designated to store Datadog dashboard definitions specifically for the Bitwarden integration. It holds visual representations and metrics configurations, enabling monitoring and observability of the Bitwarden service within the Datadog platform.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Akshit Vaid",
            "percent": 49
          },
          {
            "name": "manan-crest",
            "percent": 46
          },
          {
            "name": "dkirov-dd",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Cacti Monitoring": {
    "description": "Collects performance metrics from Cacti's MySQL database and RRD files to integrate legacy network monitoring data.",
    "functions": {
      "Cacti Metric Collection": {
        "files": [
          {
            "path": "cacti/README.md",
            "description": "This file is the README for the Datadog Cacti integration, providing instructions on how to install, configure, and troubleshoot the integration to collect metrics and logs from Cacti.",
            "spof": false
          },
          {
            "path": "cacti/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Cacti integration, documenting all version releases, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "cacti/tests/README.md",
            "description": "This file provides instructions for installing `python-rrdtool`, a prerequisite for running integration tests for the Cacti integration.",
            "spof": true
          },
          {
            "path": "cacti/tests/common.py",
            "description": "This file defines common constants and configuration used for testing the Datadog Cacti integration, including MySQL connection details, RRD path, and End-to-End test setup commands.",
            "spof": false
          },
          {
            "path": "cacti/tests/__init__.py",
            "description": "This `__init__.py` file serves to mark the `tests` directory as a Python package, enabling test discovery for the Cacti integration.",
            "spof": true
          },
          {
            "path": "cacti/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Cacti integration, verifying that the agent collects expected metrics.",
            "spof": true
          },
          {
            "path": "cacti/tests/conftest.py",
            "description": "This file provides Pytest fixtures for the Cacti integration, setting up a Docker-based test environment and providing instances of the Cacti check for testing.",
            "spof": true
          },
          {
            "path": "cacti/tests/test_cacti.py",
            "description": "This file contains unit tests for the Datadog Cacti integration. It uses mocked RRDtool and MySQL data to verify the check's metric collection and configuration, including RRD file whitelisting and MySQL connection parameters.",
            "spof": false
          },
          {
            "path": "cacti/datadog_checks/cacti/__init__.py",
            "description": "This file initializes the `cacti` Python package, making `__version__` and `CactiCheck` available for import by other modules.",
            "spof": false
          },
          {
            "path": "cacti/datadog_checks/cacti/cacti.py",
            "description": "This file implements a Datadog Agent check that collects metrics from a Cacti installation. It connects to the Cacti MySQL database to retrieve metadata about RRD files and then reads these RRD files to extract and transform metrics for submission to Datadog.",
            "spof": true
          },
          {
            "path": "cacti/datadog_checks/cacti/config_models/validators.py",
            "description": "This file is intended to house additional configuration validators or transformers for the Cacti integration, allowing for custom logic to process and validate integration settings.",
            "spof": true
          },
          {
            "path": "cacti/datadog_checks/cacti/config_models/defaults.py",
            "description": "This file defines default configuration values for the Cacti integration, specifying default settings for various instance-level parameters.",
            "spof": true
          },
          {
            "path": "cacti/datadog_checks/cacti/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` that aggregates instance-specific and shared configuration models for the Cacti integration. It acts as an entry point for accessing the integration's configuration settings.",
            "spof": false
          },
          {
            "path": "cacti/datadog_checks/cacti/config_models/shared.py",
            "description": "This file defines an autogenerated Pydantic model (`SharedConfig`) for common configuration options within the Cacti integration. It includes validation logic for these shared configuration fields.",
            "spof": true
          },
          {
            "path": "cacti/datadog_checks/cacti/config_models/instance.py",
            "description": "This file defines the Pydantic data model for the configuration of a Cacti integration instance. It is automatically generated from a `spec.yaml` file and includes validation logic for the instance settings.",
            "spof": true
          },
          {
            "path": "cacti/datadog_checks/cacti/data",
            "description": "This directory is intended to hold static data files, configuration templates, or other resources specific to the Cacti integration's Datadog check. Although currently empty, its presence suggests a designated location for such assets.",
            "spof": false
          },
          {
            "path": "cacti/assets/configuration",
            "description": "This directory is intended to house configuration files or examples specific to the Datadog Cacti integration. Its primary role is to provide configuration assets for the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 19
          },
          {
            "name": "Kyle Neale",
            "percent": 17
          },
          {
            "name": "HadhemiDD",
            "percent": 16
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 17,
      "spofCount": 9
    },
    "busFactor": 2,
    "authorCount": 13
  },
  "Infrastructure": {
    "description": "",
    "functions": {
      "Build & Configuration": {
        "files": [
          {
            "path": "cacti/tests/compose",
            "description": "This directory is designated to store Docker Compose files that define the testing environment for the Cacti integration. Its purpose is to facilitate the setup of services required for integration tests, such as a Cacti instance or a mock environment, though it is currently empty.",
            "spof": false
          },
          {
            "path": "cloudera/tests/common.py",
            "description": "This file provides common fixtures, configurations, and utility functions for testing the Cloudera integration. It includes test instance settings, initial configurations, and helpers for generating simulated metric data and tags.",
            "spof": true
          },
          {
            "path": "cloudera/tests/docker/etc/caddy",
            "description": "This directory is designated to store configuration files for the Caddy web server within the Dockerized test environment for the Datadog Cloudera integration. It is part of the `etc` structure, indicating its role in providing system-level Caddy configurations for testing purposes, even if currently empty.",
            "spof": false
          },
          {
            "path": "bentoml/tests/conftest.py",
            "description": "This file defines common pytest fixtures, `dd_environment` and `instance`, to be used by tests for the Datadog Bentoml integration. It sets up the test environment and provides a default instance configuration.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/test_ci.py",
            "description": "This file contains unit tests for the utility functions that detect if the code is currently executing within a Continuous Integration (CI) environment, specifically testing for general CI presence and platform-specific CI environments (Windows, Linux, macOS).",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/ci/setup.py",
            "description": "This file defines a command-line tool for running platform-specific CI setup scripts for various checks within the repository. It automates the execution of these scripts to prepare test environments.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/commands/validate/all_validations.py",
            "description": "This file consolidates and orchestrates the execution of all CI validations for Datadog Agent integrations, allowing them to be run for a specific check or across a repository.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/compose/kerberos/kerberos-kdc",
            "description": "This directory is part of the test infrastructure for Datadog integrations, specifically for Kerberos-related checks. It is designed to host configurations or scripts for a Kerberos Key Distribution Center (KDC) within a Docker Compose testing environment. Its purpose is to facilitate the setup of a KDC service required for robust Kerberos authentication tests.",
            "spof": false
          },
          {
            "path": "ddev/tests/repo/__init__.py",
            "description": "This file marks the 'repo' directory as a Python package, enabling its contents to be imported as modules within the test suite.",
            "spof": true
          },
          {
            "path": "ddev/tests/config/test_file.py",
            "description": "This file contains unit tests for the `ddev.config.file` module, covering functionality such as loading configuration files with local overrides, resolving override file paths, and the `deep_merge_with_list_handling` utility function.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/config/test_find.py",
            "description": "This file contains unit tests for the `ddev config find` command-line interface, verifying its ability to locate the configuration file and correctly display override information.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/config/test_set.py",
            "description": "This file contains unit tests for the `ddev config set` command, verifying its functionality for setting various configuration values, handling prompts, validating input, and managing global and override configurations.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/ci/test_codeowners.py",
            "description": "This file contains unit tests for the `ddev ci codeowners` CLI command, verifying its ability to correctly identify code owners for specified files based on a CODEOWNERS file, using different input methods like file paths, pull request numbers, or commit SHAs.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/ci/__init__.py",
            "description": "This is an empty `__init__.py` file that marks the `ci` directory as a Python package. It facilitates the organization and import of modules related to continuous integration tests for the `ddev` CLI tool.",
            "spof": true
          },
          {
            "path": "ddev/tests/cli/validate/test_ci.py",
            "description": "This file contains integration tests for the `ddev validate ci` command, ensuring it correctly identifies and reports issues in various CI-related configuration files like `.codecov.yml` and `hatch.toml`.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/config/constants.py",
            "description": "This file defines constants for environment variables and verbosity levels used within the `ddev` tool. It centralizes configuration-related names and values for application and configuration settings.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/config/utils.py",
            "description": "This file provides utility functions for reading, writing, and creating TOML configuration documents. It also includes functionality to scrub sensitive information from configuration dictionaries before use or display.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/config/model.py",
            "description": "This file defines a robust, lazily-parsed configuration system for ddev, including classes for handling and validating various application settings such as repositories, agents, organizations, and service-specific configurations (e.g., GitHub, PyPI).",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/config/file.py",
            "description": "This file defines how `ddev` loads and merges its configuration from a global file and local `.ddev.toml` override files, including functionality to track the source of each configuration line.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/dep/__init__.py",
            "description": "This file initializes the `dep` command group for the `ddev` CLI, serving as an entry point for dependency management subcommands like freeze, pin, sync, and updates.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/config/__init__.py",
            "description": "This file defines the 'config' command group for the `ddev` CLI tool, aggregating various sub-commands for managing configuration files such as editing, exploring, finding, overriding, restoring, setting, and showing configurations.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/config/update.py",
            "description": "This file defines a command-line interface (CLI) command responsible for updating the application's configuration file by adding any new, missing fields. It ensures the configuration is up-to-date with the latest schema or requirements.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/config/show.py",
            "description": "This file implements the `ddev config show` command, which displays the current configuration values for the `ddev` tool. It can show configuration from global or local files and has an option to display secret fields.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/config/restore.py",
            "description": "Implements the `ddev config restore` command, which restores the application's configuration file to default settings and prompts the user to delete any associated override files.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/config/explore.py",
            "description": "This file defines a CLI command `explore` which opens the DDev configuration file's location in the user's file manager.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/config/override.py",
            "description": "This module provides a `click` command to create or update a local `.ddev.toml` file, overriding the repository configuration for `ddev` in the current working directory.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/ci/__init__.py",
            "description": "This file defines the `ci` command group for the `ddev` CLI tool, serving as a collection point for experimental CI-related utilities. It registers subcommands like `setup` and `codeowners` under this group.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/ci/codeowners.py",
            "description": "This file implements a command-line interface tool to check the code owners for a given pull request, commit SHA, or list of files within a repository, utilizing the project's CODEOWNERS file.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/validate/labeler.py",
            "description": "This module provides a DDEV command to validate and synchronize the GitHub labeler configuration for integrations, ensuring that all valid integrations have corresponding and correctly configured PR labels.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/validate/ci.py",
            "description": "This file provides a CLI command (`ddev validate ci`) to validate and synchronize the repository's GitHub Actions CI workflow configurations. It dynamically generates test job matrices and updates `test-all.yml` and `test-all-windows.yml` files based on the project structure and testing requirements.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/upgrade_python.py",
            "description": "This script automates the process of upgrading the Python version across the repository. It detects the latest Python version, fetches SHA256 hashes, and updates version references in Dockerfiles, macOS build dependency workflows, and repository constants.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/e2e/config.py",
            "description": "This file defines utilities for managing integration-specific environment data, including reading/writing configuration and metadata files, within a structured directory hierarchy. It provides classes for interacting with individual environment data (`EnvData`) and for managing collections of environments (`EnvDataStorage`).",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/repo/config.py",
            "description": "This file defines the `RepositoryConfig` class, which is responsible for loading and saving TOML-formatted configuration data for a `.ddev/config.toml` file.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/event_bus/exceptions.py",
            "description": "This file defines custom exception classes for handling various errors that can occur during message processing and orchestration within the ddev event bus system.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/ci.py",
            "description": "This module provides a utility function to determine if the current execution environment is within a Continuous Integration (CI) pipeline, specifically checking for common CI environment variables.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/git.py",
            "description": "This file provides utility classes for programmatic interaction with Git repositories, offering methods to manage commits, branches, tags, worktrees, and capture output from Git commands.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/utils/scripts/__init__.py",
            "description": "This is an empty `__init__.py` file, serving to mark the `scripts` directory as a Python package.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/scripts/ci_matrix.py",
            "description": "This script generates a CI job matrix for GitHub Actions, determining which integrations to test based on changed files and their configurations. It can run standalone or be imported by ddev for CI validation.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/utils/scripts/check_pr.py",
            "description": "This script validates changelog entries within Pull Requests for Datadog integrations, ensuring they adhere to project-specific formatting and conventions for both core and non-core repositories.",
            "spof": true
          },
          {
            "path": "flink/assets/dashboards",
            "description": "This directory is intended to store pre-defined dashboard configurations or templates specifically designed for the Datadog Flink integration. These assets facilitate quick visualization and monitoring of Flink metrics within Datadog.",
            "spof": false
          },
          {
            "path": "druid/datadog_checks/druid/config_models/defaults.py",
            "description": "This file defines default configuration values for the Druid Datadog integration. It contains functions that return default settings for various instance and shared properties, and is autogenerated from a specification file.",
            "spof": true
          },
          {
            "path": "druid/assets/dashboards",
            "description": "This directory is intended to store pre-built dashboard configurations and definitions specifically for the Datadog integration with Druid. These assets would typically provide immediate visualization and monitoring capabilities for Druid instances.",
            "spof": false
          },
          {
            "path": "esxi/tests/docker",
            "description": "This directory is intended for Docker-related testing configurations or assets specifically for the Datadog ESXi integration. It would typically house Dockerfiles or `docker-compose` setups used to create isolated environments for running integration tests.",
            "spof": false
          },
          {
            "path": "docs/proposals/remove_resolved_requirements.md",
            "description": "This document outlines the historical evolution of dependency management in the `integrations-core` repository, detailing the reasons for the introduction and subsequent proposal to remove various `requirements.txt` and `requirements.in` files due to evolving build processes and encountered issues.",
            "spof": true
          },
          {
            "path": "docs/developer/meta/ci/labels.md",
            "description": "This document describes the automatic labeling system for pull requests in the `integrations-core` repository, detailing the various labels and the conditions under which they are applied by the `labeler` action.",
            "spof": true
          },
          {
            "path": "docs/developer/meta/ci/testing.md",
            "description": "This document describes the various CI testing workflows and configurations used in the `integrations-core` repository. It details how tests are run, configured, and reported across different scenarios and platforms.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/ibm_mq/windows/55_install_ibm_mq_client.py",
            "description": "This script downloads a specific version of the IBM MQ client redistributable for Windows and extracts it to a designated installation directory.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/activemq/linux",
            "description": "This directory is intended to house Continuous Integration (CI) scripts specifically tailored for the ActiveMQ integration on Linux environments. While currently empty, its path indicates its role as a designated location for platform-specific CI automation related to ActiveMQ.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/cilium/linux",
            "description": "This directory is intended to house Continuous Integration (CI) scripts specifically designed for testing Datadog integrations with Cilium on Linux environments. It serves as a placeholder for these OS-specific CI scripts related to the development environment setup.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/elastic/linux",
            "description": "This directory is designated for continuous integration (CI) scripts related to Elastic integrations, specifically for execution within a Linux environment. It serves to house automation scripts for testing or building Elastic components as part of the development workflow managed by `.ddev`.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/mapreduce/linux",
            "description": "This directory is designated for continuous integration (CI) scripts specifically tailored for MapReduce-related tasks, intended for execution on Linux systems. It serves as a platform-specific location for CI automation within the Datadog Integrations Core development environment.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/ddev/linux",
            "description": "This directory is intended to store DDEV-related continuous integration scripts specifically designed for Linux environments. It serves as a placeholder for platform-specific automation within the Datadog integrations-core CI pipeline.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/ddev/windows",
            "description": "This directory is intended to contain continuous integration (CI) scripts specifically designed for DDEV-related tasks on Windows environments. Its purpose is to provide platform-specific automation for CI pipelines within the Datadog integrations-core repository.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/sqlserver/linux",
            "description": "This directory is designated for Continuous Integration scripts specifically designed to test the Datadog SQL Server integration on Linux environments. It serves as the location for automation related to SQL Server setup and validation within a Linux-based CI pipeline.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/sap_hana/linux",
            "description": "This directory is designated to store Continuous Integration (CI) scripts specifically tailored for the SAP HANA integration on Linux environments. These scripts would manage and automate testing and deployment processes for the SAP HANA integration when executed on Linux systems.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/kafka_consumer/linux",
            "description": "This directory is designated to store Linux-specific continuous integration scripts for the Kafka consumer integration within the Datadog integrations-core repository. Its purpose is to provide an OS-specific location for CI tasks related to the Kafka consumer on Linux environments.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/weblogic/linux",
            "description": "This directory is intended to store Continuous Integration (CI) scripts specifically designed for the WebLogic integration, tailored for execution within a Linux environment. These scripts likely support the `.ddev` development and testing setup for Datadog's core integrations.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/datadog_checks_base/linux",
            "description": "This directory is part of the development environment's CI script organization, specifically intended for Linux-specific automation related to the `datadog_checks_base` component. Although currently empty, it serves as a structured placeholder for OS-specific CI scripts within the `integrations-core` repository.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 40
          },
          {
            "name": "Kyle Neale",
            "percent": 30
          },
          {
            "name": "lucia",
            "percent": 8
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 58,
      "spofCount": 34
    },
    "busFactor": 1,
    "authorCount": 10
  },
  "Argo Workflows Monitoring": {
    "description": "Collects metrics on workflow and task execution from Argo Workflows to monitor the status of container-native workflows in Kubernetes.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "argo_workflows/README.md",
            "description": "This README provides documentation for the Datadog Agent check for Argo Workflows, detailing its setup, configuration for metrics and logs, and validation steps.",
            "spof": true
          },
          {
            "path": "argo_workflows/CHANGELOG.md",
            "description": "This file is a changelog documenting all version updates, new features, bug fixes, and other changes for the Argo Workflows integration within the Datadog integrations-core repository.",
            "spof": false
          },
          {
            "path": "argo_workflows/changelog.d",
            "description": "This directory contains individual changelog fragments for the `argo_workflows` integration. Each fragment typically represents a single change or fix, which are then compiled to generate the full changelog for this specific Datadog integration.",
            "spof": false
          },
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/__init__.py",
            "description": "This file initializes the `argo_workflows` Python package, exposing its version and the main `ArgoWorkflowsCheck` class for external use.",
            "spof": true
          },
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/data",
            "description": "This directory is intended to store static data files, such as configuration templates or metric definitions, for the Datadog Argo Workflows integration. Its purpose is to provide essential assets required by the check.",
            "spof": false
          },
          {
            "path": "argo_workflows/assets/dashboards",
            "description": "This directory is intended to store dashboard assets specifically designed for the Datadog Argo Workflows integration. While currently empty, its purpose is to house pre-built dashboards that users can import to monitor Argo Workflows.",
            "spof": false
          },
          {
            "path": "argo_workflows/assets/monitors",
            "description": "This directory is intended to house monitoring-related assets for the Datadog Argo Workflows integration. It would typically contain configurations, definitions, or templates for monitors and alerts within the Datadog platform.",
            "spof": false
          },
          {
            "path": "argo_workflows/assets/saved_views",
            "description": "This directory is intended to store definitions or configurations for saved views specifically related to the Argo Workflows integration. It likely serves as a placeholder for pre-defined or user-customizable dashboard layouts or visualization settings. Its purpose is to centralize these view configurations.",
            "spof": false
          },
          {
            "path": "argo_workflows/assets/configuration",
            "description": "This directory is intended to house configuration assets for the Datadog Argo Workflows integration. It would typically contain example or default configuration files that users can adapt for their specific deployments. As it is currently empty, it serves as a designated, albeit unused, location for such assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 21
          },
          {
            "name": "Kyle Neale",
            "percent": 17
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 16
          }
        ]
      },
      "Integration Testing Framework": {
        "files": [
          {
            "path": "argo_workflows/tests/__init__.py",
            "description": "This is an empty `__init__.py` file, serving to mark the `tests` directory for the `argo_workflows` integration as a Python package.",
            "spof": true
          },
          {
            "path": "argo_workflows/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Argo Workflows integration, verifying metric collection from different Argo Workflows versions and asserting service check behavior.",
            "spof": false
          },
          {
            "path": "argo_workflows/tests/conftest.py",
            "description": "This file contains pytest fixtures for setting up a test environment for the Argo Workflows integration. It deploys Argo Workflows on a Kubernetes Kind cluster and exposes its metrics endpoint for testing.",
            "spof": true
          },
          {
            "path": "argo_workflows/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Argo Workflows integration, specifically validating the `argo_workflows.openmetrics.health` service check for OpenMetrics v2.",
            "spof": true
          },
          {
            "path": "argo_workflows/tests/fixtures",
            "description": "This directory is designated to store test fixtures for the `argo_workflows` integration. These fixtures provide necessary data or setup configurations to support automated tests for the integration's functionality.",
            "spof": false
          },
          {
            "path": "argo_workflows/tests/kind",
            "description": "This directory is designated for resources used to test the Datadog Argo Workflows integration within a 'Kubernetes in Docker' (kind) environment. It would typically contain configurations, manifests, or scripts for setting up local Kubernetes clusters for testing purposes. Though currently empty, it serves as a placeholder for kind-specific test infrastructure.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Brian Hartford",
            "percent": 49
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 48
          },
          {
            "name": "Juanpe Araque",
            "percent": 3
          }
        ]
      },
      "OpenMetrics Scraping and Processing": {
        "files": [
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/metrics.py",
            "description": "This file defines the mapping of raw Argo Workflows metric names (and Go runtime metrics) to their standardized Datadog metric names for the integration. It includes separate mappings for general metrics and those available in newer versions of Argo Workflows.",
            "spof": false
          },
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/check.py",
            "description": "This file defines the Datadog integration check for Argo Workflows, inheriting from `OpenMetricsBaseCheckV2`. It configures the default settings for collecting and processing metrics from Argo Workflows.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Brian Hartford",
            "percent": 61
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 39
          }
        ]
      },
      "Configuration Modeling and Validation": {
        "files": [
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/config_models/validators.py",
            "description": "This file is intended for defining custom validation and transformation logic for the Argo Workflows integration's configuration, such as remapping legacy options or enforcing value constraints.",
            "spof": true
          },
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/config_models/defaults.py",
            "description": "This file provides default values for the configuration options of the Argo Workflows integration. It is automatically generated from the integration's specification file.",
            "spof": true
          },
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` that provides convenient access to autogenerated instance-specific and shared configuration models for the `argo_workflows` integration. It serves as an entry point for accessing the structured configuration settings.",
            "spof": true
          },
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/config_models/instance.py",
            "description": "This file defines the Pydantic models for validating and structuring the configuration of the Argo Workflows integration, including various sub-configurations like authentication, metrics, and proxy settings.",
            "spof": true
          },
          {
            "path": "argo_workflows/datadog_checks/argo_workflows/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options within the `argo_workflows` integration. It includes models for proxy settings and general shared parameters, along with validation and default value handling, and is automatically generated from a configuration specification.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 93
          },
          {
            "name": "Yann Armelin",
            "percent": 6
          },
          {
            "name": "Steven Yuen",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 22,
      "spofCount": 10
    },
    "busFactor": 1,
    "authorCount": 4
  },
  "Brevo Email & Marketing Integration": {
    "description": "Collects marketing and transactional email events from Brevo webhooks to monitor engagement and delivery performance.",
    "functions": {
      "Brevo Monitoring Assets and Dashboards": {
        "files": [
          {
            "path": "brevo/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Brevo integration, documenting all changes and releases, starting with its initial version.",
            "spof": true
          },
          {
            "path": "brevo/README.md",
            "description": "This README provides instructions for integrating Brevo with Datadog. It details how to configure webhooks in Brevo to send marketing and transactional events as logs to Datadog.",
            "spof": true
          },
          {
            "path": "brevo/images",
            "description": "This directory is intended to store images specifically associated with the Brevo integration. These images might include logos, diagrams, or screenshots relevant to the integration's documentation or UI. Although currently empty, its purpose is to house visual assets for the Brevo integration.",
            "spof": false
          },
          {
            "path": "brevo/assets/monitors",
            "description": "This directory is intended to store monitor definitions or configurations for the Brevo integration within the Datadog integrations-core repository. It is currently empty, suggesting no specific monitor assets have been defined or are necessary for this integration at this location.",
            "spof": false
          },
          {
            "path": "brevo/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions and related assets specifically for the Brevo Datadog integration. It serves as the location for visualizations that display metrics and monitoring data from Brevo within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "rajshah-crest",
            "percent": 85
          },
          {
            "name": "dkirov-dd",
            "percent": 15
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 2
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "Calico Network & Security Monitoring": {
    "description": "Monitors Calico-powered container networking and security policies, collecting metrics on network performance and enforcement.",
    "functions": {
      "Calico Metrics Collection and Integration": {
        "files": [
          {
            "path": "calico/CHANGELOG.md",
            "description": "This file is the changelog for the Calico integration, detailing all the changes, additions, fixes, and removals across different versions of the integration for Datadog Agent.",
            "spof": false
          },
          {
            "path": "calico/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor Calico, including collecting metrics and logs from Calico-enabled Kubernetes clusters. It covers both Kubernetes-based and OS-based Agent installations and configurations.",
            "spof": false
          },
          {
            "path": "calico/tests/__init__.py",
            "description": "Marks the `calico/tests` directory as a Python package, allowing test modules within it to be imported.",
            "spof": true
          },
          {
            "path": "calico/tests/test_calico.py",
            "description": "This file contains unit tests for the Datadog Calico integration. It verifies that the CalicoCheck collects and reports the expected metrics from a mock Calico Felix endpoint.",
            "spof": true
          },
          {
            "path": "calico/tests/common.py",
            "description": "This file defines common constants used in Calico integration tests, including lists of expected metrics, a mock instance configuration, and optional metrics.",
            "spof": false
          },
          {
            "path": "calico/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Calico integration, verifying that the Datadog Agent correctly collects and reports all expected metrics.",
            "spof": false
          },
          {
            "path": "calico/tests/conftest.py",
            "description": "This file provides pytest fixtures and setup functions for testing the Datadog Calico integration. It sets up a Kubernetes Kind cluster, deploys Calico, configures Felix to expose Prometheus metrics, and provides the necessary endpoint for the integration tests.",
            "spof": true
          },
          {
            "path": "calico/tests/fixtures",
            "description": "This directory is intended to store test fixture data or configurations specifically for the Calico integration's tests. Although currently empty, it serves as a placeholder for any necessary test resources.",
            "spof": false
          },
          {
            "path": "calico/tests/kind",
            "description": "This directory is intended to house tests or configuration files specifically designed for the Calico integration when run within a `kind` (Kubernetes in Docker) environment. It serves as a placeholder for `kind`-specific testing scenarios for the integration.",
            "spof": false
          },
          {
            "path": "calico/datadog_checks/calico/check.py",
            "description": "This file implements the Datadog Calico integration check, extending OpenMetricsBaseCheckV2 to collect Calico metrics.",
            "spof": true
          },
          {
            "path": "calico/datadog_checks/calico/metrics.py",
            "description": "This file defines a mapping between raw metric names exposed by Calico's Felix component and their standardized Datadog metric names.",
            "spof": true
          },
          {
            "path": "calico/datadog_checks/calico/__init__.py",
            "description": "This file initializes the Calico integration package, exposing its version and the main `CalicoCheck` class for external use.",
            "spof": true
          },
          {
            "path": "calico/datadog_checks/calico/config_models/validators.py",
            "description": "This file is a placeholder for custom configuration validators and transformers for the Calico integration, allowing for logic to modify or validate configuration values before use.",
            "spof": true
          },
          {
            "path": "calico/datadog_checks/calico/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options, such as proxy settings, within the Calico integration. It includes validation logic and default value handling, and is automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "calico/datadog_checks/calico/config_models/__init__.py",
            "description": "This autogenerated `__init__.py` file aggregates `InstanceConfig` and `SharedConfig` models into a `ConfigMixin` class, providing properties to access integration-specific and shared configuration settings.",
            "spof": true
          },
          {
            "path": "calico/datadog_checks/calico/config_models/defaults.py",
            "description": "This file contains autogenerated default configuration values for the Datadog Calico integration. It defines functions that return specific default settings for various integration parameters.",
            "spof": true
          },
          {
            "path": "calico/datadog_checks/calico/config_models/instance.py",
            "description": "This file defines the Pydantic models for the Calico integration's instance configuration, automatically generated from a specification file. It includes schema definitions and validation logic for various configuration parameters.",
            "spof": false
          },
          {
            "path": "calico/datadog_checks/calico/data",
            "description": "This directory is intended to store static data files, configuration templates, or other persistent resources for the Datadog Calico integration. While currently empty, it serves as the designated location for data artifacts that the check may require or generate.",
            "spof": false
          },
          {
            "path": "calico/assets/dashboards",
            "description": "This directory is intended to store dashboard configurations or templates specifically for the Datadog Calico integration. These assets would typically define how Calico metrics are visualized within Datadog.",
            "spof": false
          },
          {
            "path": "calico/assets/monitors",
            "description": "This directory is designated to store configuration files or definitions for Datadog monitors specific to the Calico integration. It would typically contain templates or specifications for alerting rules and dashboard setups related to Calico's health and performance.",
            "spof": false
          },
          {
            "path": "calico/assets/configuration",
            "description": "This directory is intended to store configuration assets specific to the Datadog Calico integration. It would typically hold example configuration files, templates, or schema definitions necessary for setting up and running the integration. Although currently empty, its purpose is to provide structured configuration resources.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 24
          },
          {
            "name": "Juanpe Araque",
            "percent": 13
          },
          {
            "name": "Kyle Neale",
            "percent": 10
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 21,
      "spofCount": 10
    },
    "busFactor": 2,
    "authorCount": 6
  },
  "Box Enterprise Event Monitoring": {
    "description": "Ingests enterprise event logs from Box to monitor user activity, file access, and security events for compliance and security.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "box/README.md",
            "description": "This file is a README for the Datadog Box integration, detailing how to ingest Box Enterprise Events logs into Datadog for monitoring and security analysis. It covers an overview, setup instructions for generating API credentials, and information about the collected data.",
            "spof": true
          },
          {
            "path": "box/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Box integration, documenting all changes and versions, starting with its initial release.",
            "spof": true
          },
          {
            "path": "box/images",
            "description": "This directory likely stores static image assets, such as icons, logos, or screenshots, specifically used by the 'box' integration. These images would support documentation, UI elements, or other visual representations related to the Box integration within Datadog.",
            "spof": false
          },
          {
            "path": "box/assets/dashboards",
            "description": "This directory is designated for storing Datadog dashboard definitions or configurations specific to the Box integration. Although currently empty, it is intended to house visualizations and monitoring layouts for the Box service.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "shubhamvekariya-crest",
            "percent": 95
          },
          {
            "name": "dkirov-dd",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Cassandra Nodetool-Based Monitoring": {
    "description": "Collects Cassandra cluster health and status metrics by executing the `nodetool` command-line utility for environments where JMX is not available.",
    "functions": {
      "Nodetool Status Polling and Parsing": {
        "files": [
          {
            "path": "cassandra_nodetool/README.md",
            "description": "This file is the README for the Datadog Agent's Cassandra Nodetool integration, detailing how to set up and configure it to collect Cassandra cluster metrics using the `nodetool` utility.",
            "spof": false
          },
          {
            "path": "cassandra_nodetool/CHANGELOG.md",
            "description": "This file is the changelog for the Cassandra Nodetool integration, documenting all version updates, new features, bug fixes, and other changes made to the integration over time.",
            "spof": false
          },
          {
            "path": "cassandra_nodetool/images",
            "description": "This directory is designated to store images and other visual assets specifically for the `cassandra_nodetool` Datadog integration. These images would typically be used in documentation, UI elements, or other supporting visual materials for the integration.",
            "spof": false
          },
          {
            "path": "cassandra_nodetool/datadog_checks/cassandra_nodetool/__init__.py",
            "description": "This file initializes the `cassandra_nodetool` Python package, exposing its version information and the main `CassandraNodetoolCheck` class.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/datadog_checks/cassandra_nodetool/cassandra_nodetool.py",
            "description": "This file implements a Datadog Agent check that collects metrics and service checks from a Cassandra cluster by executing and parsing the output of the `nodetool status` command.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/datadog_checks/cassandra_nodetool/config_models/defaults.py",
            "description": "This file defines default configuration values for the Cassandra Nodetool integration, such as the `nodetool` executable path, host, port, and collection interval.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/datadog_checks/cassandra_nodetool/config_models/validators.py",
            "description": "This file is a placeholder for custom configuration validators and transformers for the Cassandra Nodetool integration. It allows for advanced logic to validate or modify integration configuration parameters.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/datadog_checks/cassandra_nodetool/config_models/shared.py",
            "description": "This file defines the Pydantic model for shared configuration options of the Cassandra Nodetool integration, including `nodetool` path and `service` name, with auto-generated validation and default value handling.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/datadog_checks/cassandra_nodetool/config_models/instance.py",
            "description": "This file defines the Pydantic configuration model for an instance of the Datadog `cassandra_nodetool` integration. It is autogenerated and includes validation logic for configuration fields.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/datadog_checks/cassandra_nodetool/config_models/__init__.py",
            "description": "This file is an autogenerated entry point for the Cassandra Nodetool integration's configuration models, providing a ConfigMixin to access instance-specific and shared configuration objects.",
            "spof": false
          },
          {
            "path": "cassandra_nodetool/datadog_checks/cassandra_nodetool/data",
            "description": "This `data` directory is typically reserved for static data files, configuration templates, or other supplementary assets specific to the `cassandra_nodetool` integration. As it is currently empty, it serves as a placeholder for future data-related content.",
            "spof": false
          },
          {
            "path": "cassandra_nodetool/assets/configuration",
            "description": "This directory is designated to store configuration-related assets or templates for the `cassandra_nodetool` integration within the Datadog `integrations-core` repository. While currently empty, its purpose is to centralize configuration files if they become necessary.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 24
          },
          {
            "name": "HadhemiDD",
            "percent": 19
          },
          {
            "name": "Kyle Neale",
            "percent": 19
          }
        ]
      },
      "Integration and E2E Test Suite": {
        "files": [
          {
            "path": "cassandra_nodetool/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Cassandra Nodetool check, verifying its ability to collect metrics like replication availability and factor.",
            "spof": false
          },
          {
            "path": "cassandra_nodetool/tests/common.py",
            "description": "This file defines common constants and test configuration instances for the `cassandra_nodetool` Datadog integration, including container names, Nodetool command definitions, and connection details.",
            "spof": false
          },
          {
            "path": "cassandra_nodetool/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Cassandra nodetool integration. It verifies that the integration correctly collects and reports various Cassandra metrics, including replication status, replication factor, load, and node status.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/tests/conftest.py",
            "description": "This file provides pytest fixtures for the Cassandra Nodetool integration's End-to-End tests, primarily setting up and tearing down a Dockerized Cassandra cluster environment.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Cassandra Nodetool integration, verifying that it correctly parses 'nodetool status' output and emits the expected metrics and service checks for different output formats.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/tests/__init__.py",
            "description": "This is an `__init__.py` file for the `cassandra_nodetool` integration's test suite. Its primary purpose is to mark the `tests` directory as a Python package.",
            "spof": true
          },
          {
            "path": "cassandra_nodetool/tests/fixtures",
            "description": "This directory serves as a placeholder for test fixtures, which would typically include static data, configurations, or pre-defined states necessary for running tests related to the Cassandra Nodetool integration. As it is currently empty, no specific test data is provided here.",
            "spof": false
          },
          {
            "path": "cassandra_nodetool/tests/compose/config",
            "description": "This directory is designated to store configuration files for Docker Compose environments, used to set up test scenarios for the `cassandra_nodetool` Datadog integration. Although currently empty, it serves as the intended location for these test environment setups.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Florent Clarret",
            "percent": 94
          },
          {
            "name": "Julia",
            "percent": 4
          },
          {
            "name": "Alex Lopez",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 20,
      "spofCount": 10
    },
    "busFactor": 3,
    "authorCount": 12
  },
  "Amazon MSK Monitoring": {
    "description": "Monitors Amazon Managed Streaming for Apache Kafka (MSK) clusters, collecting metrics on broker, topic, and consumer group performance.",
    "functions": {
      "Metric Definitions and Visualization Assets": {
        "files": [
          {
            "path": "amazon_msk/CHANGELOG.md",
            "description": "This file is the changelog for the Amazon MSK integration, detailing version updates, new features, bug fixes, and other changes for each release.",
            "spof": false
          },
          {
            "path": "amazon_msk/README.md",
            "description": "This file provides documentation for the Datadog Agent integration with Amazon MSK (Managed Streaming for Apache Kafka), detailing setup, configuration, and data collection.",
            "spof": false
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/metrics.py",
            "description": "This file defines mappings for various metrics (Go runtime, Node Exporter, JMX, and Kafka) to their standardized Datadog names, used within the Amazon MSK integration.",
            "spof": false
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/data",
            "description": "This directory is intended to store data files pertinent to the Amazon MSK Datadog integration check. These files could include configuration templates, static definitions, or other non-code assets required by the check.",
            "spof": false
          },
          {
            "path": "amazon_msk/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions for the Datadog Amazon MSK integration. These dashboards would be used for visualizing metrics and logs collected by the integration. Although currently empty, its role is to serve as the repository for default or example dashboards provided with the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 16
          },
          {
            "name": "Kyle Neale",
            "percent": 13
          },
          {
            "name": "Sarah Wang",
            "percent": 10
          }
        ]
      },
      "Integration Testing and Simulation": {
        "files": [
          {
            "path": "amazon_msk/tests/__init__.py",
            "description": "This empty `__init__.py` file indicates that the `tests` directory is a Python package, allowing test modules within it to be imported as part of the `amazon_msk` integration's test suite.",
            "spof": true
          },
          {
            "path": "amazon_msk/tests/conftest.py",
            "description": "This file defines pytest fixtures for the Amazon MSK integration tests, providing mocked data, client interactions, and environment setup for testing purposes.",
            "spof": true
          },
          {
            "path": "amazon_msk/tests/common.py",
            "description": "This file defines common constants, test configurations, expected metrics, and helper functions used across various tests for the Amazon MSK integration.",
            "spof": true
          },
          {
            "path": "amazon_msk/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Amazon MSK integration, verifying its functionality and metric collection under various configurations, including legacy settings, exporter enablement, and proxy configurations.",
            "spof": false
          },
          {
            "path": "amazon_msk/tests/test_e2e.py",
            "description": "End-to-end tests for the Amazon MSK integration, verifying metric collection and service checks from MSK clusters, including both legacy and current monitoring setups.",
            "spof": true
          },
          {
            "path": "amazon_msk/tests/mock_boto3/setup.py",
            "description": "This `setup.py` file defines a mock `boto3` Python package with a high version number (9000) for testing purposes. It includes a `list_nodes.json` file as package data, likely to simulate AWS MSK API responses.",
            "spof": true
          },
          {
            "path": "amazon_msk/tests/mock_boto3/boto3/__init__.py",
            "description": "This file is a mock implementation of the `boto3` client, designed to simulate AWS MSK API responses for testing purposes. It loads pre-defined JSON data from local fixtures when specific methods like `list_nodes` are called.",
            "spof": true
          },
          {
            "path": "amazon_msk/tests/fixtures",
            "description": "This directory is designated to hold static test data, mock responses, or configuration files. These fixtures are utilized by the automated tests for the `amazon_msk` integration. They ensure consistent and reliable input for testing various integration scenarios.",
            "spof": false
          },
          {
            "path": "amazon_msk/tests/docker/exporter_jmx",
            "description": "This directory is designated for Docker-related components used in testing the Datadog Amazon MSK integration with a JMX exporter. Its purpose is to encapsulate the setup required for simulating JMX metric collection within a containerized test environment.",
            "spof": false
          },
          {
            "path": "amazon_msk/tests/docker/exporter_node",
            "description": "This directory is intended to house Docker-related test infrastructure specifically for an exporter node within the Amazon MSK integration. It would typically contain files needed to spin up a Docker container simulating an exporter for testing purposes.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/bench_utils.py",
            "description": "This file defines a mapping of Amazon MSK (Managed Streaming for Kafka) JMX metrics to standardized Datadog metric names. It is likely used for benchmarking or testing OpenMetrics-based JMX metric collection for Kafka integrations.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 36
          },
          {
            "name": "Steven Yuen",
            "percent": 29
          },
          {
            "name": "dkirov-dd",
            "percent": 24
          }
        ]
      },
      "MSK Cluster Metric Collection": {
        "files": [
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/__init__.py",
            "description": "This is the initialization file for the `amazon_msk` Datadog check package. It makes the `__version__` and the `AmazonMskCheck` class directly accessible when the package is imported.",
            "spof": true
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/utils.py",
            "description": "This utility file provides a function to construct a `botocore.config.Config` object, specifically handling and prioritizing proxy settings for AWS API calls.",
            "spof": true
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/amazon_msk.py",
            "description": "This file implements a legacy Datadog check for Amazon MSK, responsible for collecting JMX and Node Exporter metrics directly from MSK broker nodes. It uses boto3 to interact with the AWS Kafka API and can assume an IAM role for authentication.",
            "spof": false
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/check.py",
            "description": "This file implements the Datadog check for Amazon MSK (Managed Streaming for Apache Kafka). It dynamically discovers MSK broker nodes, handles AWS authentication, and collects metrics from JMX and node exporters using OpenMetrics scrapers.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 39
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 28
          },
          {
            "name": "Kyle Neale",
            "percent": 18
          }
        ]
      },
      "Configuration Schema and Validation": {
        "files": [
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/config_models/instance.py",
            "description": "This file defines the Pydantic models for the configuration schema of the `amazon_msk` integration, including validation logic for its various instance settings.",
            "spof": true
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/config_models/__init__.py",
            "description": "This file defines configuration models and provides a ConfigMixin for accessing instance-specific and shared configuration settings for the Amazon MSK integration, generated from a specification file.",
            "spof": false
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/config_models/defaults.py",
            "description": "This file defines default configuration values for the Amazon MSK integration, automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/config_models/shared.py",
            "description": "This file defines shared Pydantic models for configuration, specifically `Proxy` and `SharedConfig`, used within the Amazon MSK integration. It is an autogenerated file based on a YAML specification.",
            "spof": true
          },
          {
            "path": "amazon_msk/datadog_checks/amazon_msk/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators and transformers for the Datadog Amazon MSK integration. It allows for advanced logic to manipulate or validate configuration options before they are used.",
            "spof": true
          },
          {
            "path": "amazon_msk/assets/configuration",
            "description": "This directory is intended to store configuration-related assets or example files for the Amazon MSK integration. While currently empty, its purpose is to provide standard configuration resources within the integration's asset structure.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 82
          },
          {
            "name": "Yann Armelin",
            "percent": 9
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 26,
      "spofCount": 12
    },
    "busFactor": 1,
    "authorCount": 5
  },
  "Cato Networks SASE Integration": {
    "description": "Collects audit logs and security events from the Cato Networks SASE platform for unified network and security monitoring.",
    "functions": {
      "Cato Networks Log and Event Collection": {
        "files": [
          {
            "path": "cato_networks/CHANGELOG.md",
            "description": "This file is the CHANGELOG for the `cato_networks` integration. It documents the changes and updates made to the integration over time, starting with its initial release.",
            "spof": true
          },
          {
            "path": "cato_networks/README.md",
            "description": "This file provides instructions for integrating Cato Networks with Datadog to collect audit logs and security events. It details the setup for both audit log collection via client credentials and event log collection through AWS S3 and the Datadog Forwarder.",
            "spof": true
          },
          {
            "path": "cato_networks/images",
            "description": "This directory is intended to store image assets specifically used by or related to the `cato_networks` integration within the `integrations-core` repository. These images might include icons, diagrams, or other visual resources for documentation or UI purposes.",
            "spof": false
          },
          {
            "path": "cato_networks/assets/dashboards",
            "description": "This directory is intended to store JSON definitions for dashboards related to the Cato Networks integration. These dashboards would typically provide visualizations for metrics and logs collected by the integration. Although currently empty, its purpose is to house these monitoring assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "shubhamvekariya-crest",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "AWS App Mesh Observability": {
    "description": "Collects metrics, logs, and traces from microservices deployed on AWS App Mesh to monitor service mesh health and traffic.",
    "functions": {
      "Integration Documentation and Packaging": {
        "files": [
          {
            "path": "amazon_app_mesh/CHANGELOG.md",
            "description": "This file is the changelog for the AWS App Mesh integration, documenting all version updates and changes made to it.",
            "spof": true
          },
          {
            "path": "amazon_app_mesh/README.md",
            "description": "This README provides instructions for integrating Datadog with AWS App Mesh to collect metrics, logs, and traces from microservices deployed on Amazon EKS, ECS Fargate, and ECS EC2 environments.",
            "spof": true
          },
          {
            "path": "amazon_app_mesh/assets",
            "description": "This directory is designated for storing static assets and ancillary files related to the `amazon_app_mesh` integration. It would typically contain resources like images, icons, or other non-code elements that support the integration's functionality or documentation. While currently empty, it serves as a placeholder for such future assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Nicholas Muesch",
            "percent": 99
          },
          {
            "name": "dkirov-dd",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Active Directory Monitoring": {
    "description": "Collects performance metrics, service status, and logs to monitor the health and security of Microsoft Active Directory environments.",
    "functions": {
      "Packaged Integration Assets": {
        "files": [
          {
            "path": "active_directory/CHANGELOG.md",
            "description": "This file is the changelog for the Active Directory integration, documenting all version releases and their respective changes, additions, and fixes.",
            "spof": false
          },
          {
            "path": "active_directory/README.md",
            "description": "This file is the README for the Datadog Active Directory integration, providing instructions on how to set up, configure, and validate the integration, along with details on the metrics collected.",
            "spof": false
          },
          {
            "path": "active_directory/tests/conftest.py",
            "description": "This file provides Pytest configuration and fixtures, specifically defining an empty `dd_environment` fixture for test setup within the `active_directory` integration.",
            "spof": true
          },
          {
            "path": "active_directory/tests/__init__.py",
            "description": "This empty `__init__.py` file designates the `active_directory` integration's `tests` directory as a Python package. It allows test modules within this directory to be imported and discovered.",
            "spof": true
          },
          {
            "path": "active_directory/datadog_checks/__init__.py",
            "description": "This file marks the 'datadog_checks' directory as a Python package. It uses `pkgutil.extend_path` to configure it as a namespace package, allowing other modules to extend this package.",
            "spof": true
          },
          {
            "path": "active_directory/datadog_checks/active_directory/__init__.py",
            "description": "This `__init__.py` file initializes the Active Directory integration package, exposing its version and the main ActiveDirectoryCheck class.",
            "spof": false
          },
          {
            "path": "active_directory/datadog_checks/active_directory/data",
            "description": "This directory is designated to store static data files or configuration templates pertinent to the Datadog Active Directory integration. Although currently empty, it serves as a placeholder for any non-code assets required by the check.",
            "spof": false
          },
          {
            "path": "active_directory/assets/configuration",
            "description": "This directory is intended to store configuration assets for the Active Directory integration. It would typically contain example configuration files, schemas, or templates to guide users in setting up the integration.",
            "spof": false
          },
          {
            "path": "active_directory/assets/dashboards",
            "description": "This directory is intended to store dashboard configurations or definitions specifically for the Datadog Active Directory integration. It serves as a designated location for visual assets used to monitor Active Directory performance and status within Datadog.",
            "spof": false
          },
          {
            "path": "active_directory/assets/monitors",
            "description": "This directory is intended to contain Datadog monitor definitions or configurations specifically designed for the Active Directory integration. It serves as a repository for alerts and health checks related to Active Directory services monitored by Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "davidioin",
            "percent": 31
          },
          {
            "name": "Brian Tu",
            "percent": 18
          },
          {
            "name": "Kyle Neale",
            "percent": 12
          }
        ]
      },
      "AD Performance Metric Collection": {
        "files": [
          {
            "path": "active_directory/tests/test_unit.py",
            "description": "This file contains unit tests for the Active Directory integration, specifically for the `ActiveDirectoryCheckV2`. It tests metric collection and service check functionality under various conditions, including different Windows service states, by mocking performance objects.",
            "spof": true
          },
          {
            "path": "active_directory/tests/common.py",
            "description": "This file defines common performance object configurations, derived from the Active Directory integration's metric definitions, for use in tests. It provides structured mock data for performance counters.",
            "spof": true
          },
          {
            "path": "active_directory/datadog_checks/active_directory/active_directory.py",
            "description": "This file implements the Active Directory check, acting as a dispatcher that instantiates either a legacy or a newer version of the check based on configuration. It inherits from `PDHBaseCheck` and uses default performance counters.",
            "spof": true
          },
          {
            "path": "active_directory/datadog_checks/active_directory/metrics.py",
            "description": "This file defines the configuration and mapping for collecting various Active Directory performance counters and transforming them into Datadog metrics.",
            "spof": false
          },
          {
            "path": "active_directory/datadog_checks/active_directory/check.py",
            "description": "This file defines the `ActiveDirectoryCheckV2` class, a Datadog integration check that collects performance metrics from Active Directory and related Windows services. It dynamically configures which metrics to collect based on the availability of specific services like Netlogon, DHCP, and DFSR.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "davidioin",
            "percent": 76
          },
          {
            "name": "Brian Tu",
            "percent": 22
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 1
          }
        ]
      },
      "Configuration Schema Management": {
        "files": [
          {
            "path": "active_directory/datadog_checks/active_directory/config_models/validators.py",
            "description": "This file is intended for defining custom configuration validators or transformers for the Active Directory integration. It can be used to initialize instance values, migrate legacy options, or perform data validation like checking numerical ranges.",
            "spof": true
          },
          {
            "path": "active_directory/datadog_checks/active_directory/config_models/instance.py",
            "description": "This file defines the Pydantic models for the instance-level configuration of the Active Directory integration. It is an autogenerated file based on a specification YAML.",
            "spof": true
          },
          {
            "path": "active_directory/datadog_checks/active_directory/config_models/defaults.py",
            "description": "This file defines the default configuration values for the Active Directory integration. It is automatically generated from the integration's configuration specification.",
            "spof": true
          },
          {
            "path": "active_directory/datadog_checks/active_directory/config_models/shared.py",
            "description": "This file defines the shared configuration model (`SharedConfig`) for the Active Directory integration using Pydantic, including schema validation and default value handling. It is an autogenerated file based on a specification.",
            "spof": true
          },
          {
            "path": "active_directory/datadog_checks/active_directory/config_models/__init__.py",
            "description": "This file serves as the entry point for Active Directory integration's configuration models, defining a mixin to provide convenient access to both instance-specific and shared configuration settings. It aggregates configuration parts generated from a specification file.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 93
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 5
          },
          {
            "name": "Julia",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 20,
      "spofCount": 11
    },
    "busFactor": 2,
    "authorCount": 10
  },
  "HashiCorp Boundary Monitoring": {
    "description": "Collects health and performance metrics from HashiCorp Boundary to monitor secure remote access sessions and infrastructure.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "boundary/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Boundary integration, detailing version updates, added features, fixes, and changes.",
            "spof": false
          },
          {
            "path": "boundary/README.md",
            "description": "This file provides instructions and documentation for setting up and configuring the Datadog Agent to monitor Boundary, covering metric collection, service checks, and log collection.",
            "spof": false
          },
          {
            "path": "boundary/datadog_checks/boundary/data",
            "description": "This directory is intended to store static data, configuration files, or other non-code assets specifically required by the Datadog `boundary` integration check. Although currently empty, it serves as the designated location for such auxiliary files.",
            "spof": false
          },
          {
            "path": "boundary/assets/dashboards",
            "description": "This directory stores dashboard assets specifically for the Datadog 'boundary' integration. These assets likely define the visualizations and metrics displayed in Datadog dashboards related to Boundary monitoring. Its purpose is to provide ready-to-use dashboard configurations for the integration.",
            "spof": false
          },
          {
            "path": "boundary/assets/monitors",
            "description": "This directory is designated to store Datadog monitor definitions or configurations specifically for the 'Boundary' integration. Its role is to house alerting and monitoring rule assets relevant to the Boundary service within the Datadog ecosystem.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 19
          },
          {
            "name": "Kyle Neale",
            "percent": 19
          },
          {
            "name": "HadhemiDD",
            "percent": 15
          }
        ]
      },
      "Integration Testing Framework": {
        "files": [
          {
            "path": "boundary/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Boundary integration, focusing on service check reporting for health and metrics endpoints under various HTTP response scenarios, including success, errors, and warnings.",
            "spof": false
          },
          {
            "path": "boundary/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Boundary integration, verifying service checks and metric collection from its health and metrics endpoints.",
            "spof": true
          },
          {
            "path": "boundary/tests/common.py",
            "description": "This file defines common variables and utilities used across tests for the Datadog Boundary integration, including Docker environment setup and service endpoints.",
            "spof": true
          },
          {
            "path": "boundary/tests/conftest.py",
            "description": "This file defines Pytest fixtures for the Datadog Boundary integration tests. It sets up a Dockerized test environment and provides a Boundary check instance configuration.",
            "spof": true
          },
          {
            "path": "boundary/tests/test_integration.py",
            "description": "Integration tests for the Datadog Boundary check, verifying metric collection and service check statuses under various conditions, including endpoint health.",
            "spof": true
          },
          {
            "path": "boundary/tests/docker",
            "description": "This directory is intended to house Docker-related test configurations or assets specifically for the Datadog 'boundary' integration. It would typically contain Dockerfiles or Docker Compose setups for integration testing environments.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 74
          },
          {
            "name": "Florent Clarret",
            "percent": 13
          },
          {
            "name": "Ofek Lev",
            "percent": 12
          }
        ]
      },
      "Metric Collection and Configuration": {
        "files": [
          {
            "path": "boundary/datadog_checks/boundary/metrics.py",
            "description": "This file defines a mapping of raw Boundary metrics to standardized metric names or metadata types used within the Datadog integration. It serves as a configuration for processing and renaming metrics collected from Boundary.",
            "spof": true
          },
          {
            "path": "boundary/datadog_checks/boundary/__init__.py",
            "description": "Initializes the `datadog_checks.boundary` Python package, making the package version and the main BoundaryCheck class directly importable.",
            "spof": true
          },
          {
            "path": "boundary/datadog_checks/boundary/check.py",
            "description": "This file defines the Datadog check for Boundary, responsible for collecting metrics from its OpenMetrics endpoint and reporting on its health status.",
            "spof": false
          },
          {
            "path": "boundary/datadog_checks/boundary/config_models/validators.py",
            "description": "This file is intended for defining configuration validators or transformers specific to the Boundary integration.",
            "spof": true
          },
          {
            "path": "boundary/datadog_checks/boundary/config_models/defaults.py",
            "description": "This file defines default values for various configuration options used by the Datadog Boundary integration. It is an autogenerated file based on the integration's specification.",
            "spof": true
          },
          {
            "path": "boundary/datadog_checks/boundary/config_models/__init__.py",
            "description": "This file provides a `ConfigMixin` class to access autogenerated configuration models, `InstanceConfig` and `SharedConfig`, for the `boundary` integration.",
            "spof": true
          },
          {
            "path": "boundary/datadog_checks/boundary/config_models/shared.py",
            "description": "This file defines the shared Pydantic configuration models, including proxy settings, for the Boundary integration. It is an autogenerated file that incorporates default values and validation rules from associated modules.",
            "spof": true
          },
          {
            "path": "boundary/datadog_checks/boundary/config_models/instance.py",
            "description": "This file defines the Pydantic models for the configuration schema of a Datadog integration instance. It is autogenerated from a YAML specification and includes various configuration parameters and validation logic.",
            "spof": true
          },
          {
            "path": "boundary/assets/configuration",
            "description": "This directory is intended to house configuration files or templates specifically for the Datadog 'Boundary' integration. It defines the setup and parameters required for the integration to function correctly within the Datadog monitoring system.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 84
          },
          {
            "name": "Yann Armelin",
            "percent": 8
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 20,
      "spofCount": 11
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Amazon EKS Monitoring": {
    "description": "Monitors the performance and health of Amazon Elastic Kubernetes Service (EKS) clusters, nodes, and the workloads running on them.",
    "functions": {
      "EKS Integration Package": {
        "files": [
          {
            "path": "amazon_eks/CHANGELOG.md",
            "description": "This file documents the release history and changes made to the Amazon EKS integration, starting with its initial release.",
            "spof": true
          },
          {
            "path": "amazon_eks/README.md",
            "description": "This README provides an overview and setup instructions for integrating Amazon Elastic Kubernetes Service (EKS) with Datadog. It covers how to monitor EKS environments, including details on metric and log collection, and troubleshooting.",
            "spof": true
          },
          {
            "path": "amazon_eks/images",
            "description": "This directory is intended to store images associated with the `amazon_eks` integration. It would typically contain visual assets used for documentation, UI elements, or other integration-specific graphics.",
            "spof": false
          },
          {
            "path": "amazon_eks/assets",
            "description": "This directory is designated for storing static assets and supporting files pertaining to the `amazon_eks` integration. While currently empty, it is intended to house resources like images, icons, configuration examples, or other non-code elements that enrich the integration's functionality or documentation.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/kube_leader/__init__.py",
            "description": "This file serves as the `__init__.py` for the `kube_leader` package, utilizing `lazy_loader` to efficiently manage the package's imports and improve startup performance.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/kube_leader/record.py",
            "description": "This file defines classes for parsing, validating, and extracting information from Kubernetes leader election records, supporting both annotation-based and Lease-based record formats.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 51
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 22
          },
          {
            "name": "Bryce Eadie",
            "percent": 16
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 6,
      "spofCount": 4
    },
    "busFactor": 5,
    "authorCount": 8
  },
  "Airbyte Data Integration Monitoring": {
    "description": "Provides visibility into Airbyte data pipelines by collecting metrics on data synchronization jobs, connection statuses, and performance.",
    "functions": {
      "Datadog Integration Assets and Documentation": {
        "files": [
          {
            "path": "airbyte/README.md",
            "description": "This file is the README for the Datadog Airbyte integration, providing an overview, setup instructions, and details on collected data such as metrics and their DogStatsD mapping configuration.",
            "spof": false
          },
          {
            "path": "airbyte/CHANGELOG.md",
            "description": "This file is the changelog for the Airbyte integration, documenting all releases, new features, and bug fixes.",
            "spof": true
          },
          {
            "path": "airbyte/assets/monitors",
            "description": "This directory is intended to house monitoring assets, such as Datadog monitor definitions or configurations, specifically for the Airbyte integration. It defines how Airbyte instances are monitored within the Datadog ecosystem, even if currently empty.",
            "spof": false
          },
          {
            "path": "airbyte/assets/dashboards",
            "description": "This directory is intended to house dashboard assets and configurations for the Datadog Airbyte integration. Although currently empty, it serves as the designated location for visualizing Airbyte integration metrics within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 63
          },
          {
            "name": "dkirov-dd",
            "percent": 24
          },
          {
            "name": "davidfeng-datadog",
            "percent": 13
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "ActiveMQ XML-Based Monitoring": {
    "description": "Gathers metrics from legacy ActiveMQ brokers by parsing their XML-based administration consoles, providing visibility into older deployments.",
    "functions": {
      "XML Metric Collection and Configuration": {
        "files": [
          {
            "path": "activemq_xml/README.md",
            "description": "This file is the README for the Datadog Agent's ActiveMQ XML integration, providing instructions on how to set up, configure, and validate the integration to collect metrics and logs from ActiveMQ XML.",
            "spof": false
          },
          {
            "path": "activemq_xml/CHANGELOG.md",
            "description": "This file is the changelog for the `activemq_xml` Datadog integration, detailing version updates, added features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "activemq_xml/datadog_checks/activemq_xml/__init__.py",
            "description": "This `__init__.py` file initializes the `activemq_xml` package, exposing its version and the `ActiveMQXML` check class for the Datadog Agent.",
            "spof": false
          },
          {
            "path": "activemq_xml/datadog_checks/activemq_xml/activemq_xml.py",
            "description": "This file implements a Datadog Agent integration to collect metrics from ActiveMQ by parsing its XML administration pages for queues, topics, and subscribers. It fetches data via HTTP, extracts relevant statistics, and reports them as gauges to Datadog.",
            "spof": true
          },
          {
            "path": "activemq_xml/datadog_checks/activemq_xml/config_models/defaults.py",
            "description": "This file contains autogenerated Python functions that define the default configuration values for the ActiveMQ XML integration. These defaults are used when specific configuration options are not explicitly set.",
            "spof": true
          },
          {
            "path": "activemq_xml/datadog_checks/activemq_xml/config_models/instance.py",
            "description": "This file defines the Pydantic models for the `activemq_xml` integration's instance configuration, including schemas for authentication tokens, metric patterns, and proxy settings. It is an autogenerated file used for validating and structuring the integration's configuration.",
            "spof": true
          },
          {
            "path": "activemq_xml/datadog_checks/activemq_xml/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides access to instance-specific and shared configuration models for the ActiveMQ XML integration, typically used in autogenerated code for configuration handling.",
            "spof": false
          },
          {
            "path": "activemq_xml/datadog_checks/activemq_xml/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators and transformers for the `activemq_xml` integration. It allows for additional logic to process or validate configuration values beyond what is provided by default.",
            "spof": true
          },
          {
            "path": "activemq_xml/datadog_checks/activemq_xml/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration settings, such as proxy details, used across Datadog integrations. It includes validation logic and is automatically generated from a specification.",
            "spof": true
          },
          {
            "path": "activemq_xml/datadog_checks/activemq_xml/data",
            "description": "This directory is designated for storing static data, configuration templates, or other supporting assets specific to the ActiveMQ XML integration. While currently empty, it serves as the intended location for these files.",
            "spof": false
          },
          {
            "path": "activemq_xml/assets/configuration",
            "description": "This directory is designated to store configuration assets for the `activemq_xml` integration within the Datadog Agent. Although currently empty, its purpose is to centralize configuration-related resources for this specific integration. It serves as a placeholder for potential configuration files or templates.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 25
          },
          {
            "name": "Sarah Wang",
            "percent": 20
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 11
          }
        ]
      },
      "Containerized Integration Testing": {
        "files": [
          {
            "path": "activemq_xml/tests/test_activemq_xml.py",
            "description": "This file contains integration and end-to-end tests for the `activemq_xml` integration, verifying that metrics are collected correctly from an ActiveMQ instance.",
            "spof": true
          },
          {
            "path": "activemq_xml/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the `tests` directory as a Python package, enabling test discovery for the `activemq_xml` integration.",
            "spof": true
          },
          {
            "path": "activemq_xml/tests/common.py",
            "description": "This file defines common constants, configurations, and expected metric lists used for testing the ActiveMQ XML integration. It provides shared test utilities and data for the integration's test suite.",
            "spof": false
          },
          {
            "path": "activemq_xml/tests/fixtures",
            "description": "This directory is designated to store test fixtures and static data required by the unit and integration tests for the ActiveMQ XML integration. It provides stable, predefined inputs and configurations to ensure reliable and repeatable testing scenarios. Although currently empty, its purpose is to serve as a repository for test-specific resources.",
            "spof": false
          },
          {
            "path": "activemq_xml/tests/compose",
            "description": "This directory is designated for Docker Compose configurations used to set up isolated test environments for the `activemq_xml` integration. Although currently empty, it serves as the standard location for defining multi-service test setups.",
            "spof": false
          },
          {
            "path": "activemq_xml/tests/conftest.py",
            "description": "This file provides pytest fixtures, specifically a `dd_environment` fixture, to set up a Dockerized ActiveMQ instance for integration testing. It prepares ActiveMQ data directories and permissions before starting the container.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Alex Lopez",
            "percent": 62
          },
          {
            "name": "Julia",
            "percent": 18
          },
          {
            "name": "Hippolyte HENRY",
            "percent": 12
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 17,
      "spofCount": 8
    },
    "busFactor": 3,
    "authorCount": 11
  },
  "Anthropic LLM Observability": {
    "description": "Enables performance monitoring and troubleshooting for applications built with Anthropic's large language models by tracking requests and latency.",
    "functions": {
      "Integration Documentation and Assets": {
        "files": [
          {
            "path": "anthropic/CHANGELOG.md",
            "description": "Documents all notable changes and releases for the Datadog Anthropic integration. It records version updates, new features, bug fixes, and other significant modifications.",
            "spof": true
          },
          {
            "path": "anthropic/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Anthropic integration to enable LLM Observability for Anthropic models. It covers prerequisites, API key generation, Datadog integration setup, and different installation methods for various environments.",
            "spof": false
          },
          {
            "path": "anthropic/assets",
            "description": "This directory is intended to store various assets, such as images, configuration files, or templates, specifically for the Datadog Anthropic integration. Although currently empty, its purpose is to centralize resources supporting the integration's functionality and documentation.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "apiazza-dd",
            "percent": 58
          },
          {
            "name": "yahya-mouman",
            "percent": 39
          },
          {
            "name": "dkirov-dd",
            "percent": 4
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "VMware NSX Advanced Load Balancer (Avi) Monitoring": {
    "description": "Monitors VMware's NSX Advanced Load Balancer (formerly Avi Vantage) for application delivery, security, and load balancing performance.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "avi_vantage/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog Agent check for Avi Vantage, detailing its configuration, collected metrics, and service checks.",
            "spof": false
          },
          {
            "path": "avi_vantage/CHANGELOG.md",
            "description": "This file is the changelog for the Avi Vantage integration, documenting all releases, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "avi_vantage/changelog.d",
            "description": "This directory is intended to store individual changelog fragments or entries for the `avi_vantage` integration. These fragments are typically used to generate a consolidated changelog for new releases or updates to the integration.",
            "spof": false
          },
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/data",
            "description": "This directory is intended to store static data files, configuration templates, or other auxiliary non-code assets specific to the Avi Vantage Datadog integration. Despite currently being empty, its `data` naming convention suggests it would house support files for the check.",
            "spof": false
          },
          {
            "path": "avi_vantage/assets/monitors",
            "description": "This directory is intended to house Datadog monitor definitions specific to the Avi Vantage integration. It serves as a dedicated location for monitoring-related assets that help observe the health and performance of Avi Vantage environments within Datadog.",
            "spof": false
          },
          {
            "path": "avi_vantage/assets/configuration",
            "description": "This directory is designated to store configuration assets or example configuration files specific to the `avi_vantage` integration. Its purpose is to provide ready-to-use or templated configuration for users deploying this integration.",
            "spof": false
          },
          {
            "path": "avi_vantage/assets/dashboards",
            "description": "This directory is intended to store pre-built dashboard definitions specifically for the Avi Vantage integration. These assets enable immediate visualization of metrics collected from Avi Vantage within the Datadog platform.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 20
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 18
          },
          {
            "name": "HadhemiDD",
            "percent": 13
          }
        ]
      },
      "Test Suite and Mock Environment": {
        "files": [
          {
            "path": "avi_vantage/tests/test_config_validation.py",
            "description": "This file contains unit tests for validating the configuration of the Datadog Avi Vantage integration, ensuring proper error handling for missing or invalid parameters.",
            "spof": false
          },
          {
            "path": "avi_vantage/tests/__init__.py",
            "description": "This empty file marks the 'tests' directory as a Python package, enabling the import of test modules for the 'avi_vantage' integration.",
            "spof": true
          },
          {
            "path": "avi_vantage/tests/test_avi_vantage.py",
            "description": "This file contains unit, integration, and end-to-end tests for the Datadog Avi Vantage integration. It verifies metric collection and service checks across various tenant configurations.",
            "spof": true
          },
          {
            "path": "avi_vantage/tests/conftest.py",
            "description": "This file defines pytest fixtures and utilities for testing the Avi Vantage Datadog integration, including setting up a Docker environment, mocking API responses, and providing test instance configurations.",
            "spof": false
          },
          {
            "path": "avi_vantage/tests/compose/manage.py",
            "description": "This file implements a mock Flask API server for the Avi Vantage integration tests. It simulates login/logout, provides metrics from fixture files, and returns a mock cluster version, enabling isolated testing of the integration.",
            "spof": true
          },
          {
            "path": "avi_vantage/tests/compose/fixtures/multiple_tenants",
            "description": "This directory contains fixtures and configurations for Docker Compose-based integration tests of the Avi Vantage integration. Specifically, these fixtures are designed to simulate and test scenarios involving multiple tenants within the Avi Vantage environment.",
            "spof": false
          },
          {
            "path": "avi_vantage/tests/compose/fixtures/admin_tenant",
            "description": "This directory contains fixtures specifically for setting up Docker Compose-based test environments for the Avi Vantage integration. It provides configuration or data related to an 'admin tenant' scenario, used to establish a pre-defined state for integration tests.",
            "spof": false
          },
          {
            "path": "avi_vantage/tests/compose/fixtures/no_tenant",
            "description": "This directory is intended to contain test fixtures for Docker Compose-based tests of the Avi Vantage integration. Specifically, it would hold configurations and data simulating an environment where no tenant is configured, for testing various integration behaviors under such conditions. Although currently empty, its purpose is to define a specific test scenario.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "NouemanKHAL",
            "percent": 68
          },
          {
            "name": "dkirov-dd",
            "percent": 29
          },
          {
            "name": "Florian Veaux",
            "percent": 2
          }
        ]
      },
      "Avi Vantage Metric Collection": {
        "files": [
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/__init__.py",
            "description": "This file marks the 'avi_vantage' directory as a Python package, exposing the package version and the main Avi Vantage check class for import.",
            "spof": true
          },
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/metrics.py",
            "description": "This file defines dictionaries mapping raw metric names from Avi Vantage to standardized metric names and types. It is used to specify metrics collected for virtual services and pools within the Avi Vantage integration.",
            "spof": true
          },
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/check.py",
            "description": "This file implements the Datadog Agent check for Avi Vantage, collecting metrics from the Avi controller's Prometheus endpoint for various entities like virtual services and pools, and also gathers controller metadata.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "NouemanKHAL",
            "percent": 49
          },
          {
            "name": "Florian Veaux",
            "percent": 48
          },
          {
            "name": "Ofek Lev",
            "percent": 1
          }
        ]
      },
      "Integration Configuration Management": {
        "files": [
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/config_models/defaults.py",
            "description": "This file contains autogenerated default configuration values for the Avi Vantage integration, used to define the initial settings for various parameters.",
            "spof": false
          },
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/config_models/validators.py",
            "description": "This file is intended for defining additional configuration validators and transformers for the Avi Vantage integration. It provides a placeholder and examples for custom validation or data manipulation logic for integration configurations.",
            "spof": false
          },
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/config_models/__init__.py",
            "description": "This file serves as the entry point for Avi Vantage integration configuration models, defining a mixin class to access both instance-specific and shared configuration settings. It is automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options, such as proxy settings, used within the `avi_vantage` integration. It includes mechanisms for schema validation and applying default values to these configurations.",
            "spof": true
          },
          {
            "path": "avi_vantage/datadog_checks/avi_vantage/config_models/instance.py",
            "description": "This file defines Pydantic models for the configuration schema of the Avi Vantage integration, specifically for its instance-level settings. It is an autogenerated file from a YAML specification.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 72
          },
          {
            "name": "Florian Veaux",
            "percent": 10
          },
          {
            "name": "NouemanKHAL",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 23,
      "spofCount": 8
    },
    "busFactor": 1,
    "authorCount": 5
  },
  "Bitdefender EDR Integration": {
    "description": "Ingests Endpoint Detection and Response (EDR) logs from Bitdefender via webhooks for real-time security threat analysis.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "bitdefender/CHANGELOG.md",
            "description": "This file documents all notable changes and version history for the Bitdefender integration, starting with its initial release.",
            "spof": true
          },
          {
            "path": "bitdefender/README.md",
            "description": "This file is the README for the Datadog Bitdefender integration, detailing how to set up the integration to ingest Bitdefender EDR logs via webhooks. It describes the types of events collected and provides step-by-step configuration instructions for both Datadog and Bitdefender platforms.",
            "spof": false
          },
          {
            "path": "bitdefender/images",
            "description": "This directory is designated to store images specifically associated with the Bitdefender integration. These images would typically be used for documentation, UI elements, or other visual assets within the integration's context.",
            "spof": false
          },
          {
            "path": "bitdefender/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions and configurations specifically for the Datadog Bitdefender integration. These assets would enable users to visualize and monitor metrics and logs collected from Bitdefender environments within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "shubhamvekariya-crest",
            "percent": 49
          },
          {
            "name": "madhavpandya-crest",
            "percent": 45
          },
          {
            "name": "dkirov-dd",
            "percent": 4
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 1
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "Asana Audit Trail Integration": {
    "description": "Ingests Asana audit logs to monitor user activity, changes, and security events within the Asana project management platform.",
    "functions": {
      "AsanaMonitoringAssets": {
        "files": [
          {
            "path": "asana/README.md",
            "description": "This README details the Datadog Asana integration, which collects and forwards Asana audit logs to Datadog for analysis. It provides setup instructions for generating API credentials in Asana and connecting the account to Datadog.",
            "spof": true
          },
          {
            "path": "asana/CHANGELOG.md",
            "description": "This file documents the changes, new features, and version history for the Datadog Asana integration.",
            "spof": true
          },
          {
            "path": "asana/images",
            "description": "This directory is intended to store images related to the Asana integration for Datadog. These images could be used for documentation, UI elements, or other visual assets within the integration's context.",
            "spof": false
          },
          {
            "path": "asana/assets/dashboards",
            "description": "This directory is designated to store JSON definitions or configuration files for Datadog dashboards specific to the Asana integration. Its purpose is to provide pre-built visualizations for monitoring Asana performance and usage metrics within the Datadog platform.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Tirthraj Chaudhari",
            "percent": 90
          },
          {
            "name": "dkirov-dd",
            "percent": 10
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Apache Airflow Monitoring": {
    "description": "Monitors Apache Airflow instances to track the status of DAGs, tasks, and overall scheduler health for workflow orchestration.",
    "functions": {
      "Packaged Assets and User Documentation": {
        "files": [
          {
            "path": "airflow/CHANGELOG.md",
            "description": "This file documents all notable changes, new features, bug fixes, and other updates for the Datadog Airflow integration across various versions. It serves as a historical record of releases for the integration.",
            "spof": false
          },
          {
            "path": "airflow/README.md",
            "description": "This README provides documentation for the Datadog Agent's Airflow integration, detailing how to set up metric and log collection from Airflow instances for monitoring within Datadog.",
            "spof": false
          },
          {
            "path": "airflow/tests/README.md",
            "description": "This README provides instructions for manually testing the Datadog Agent's Airflow integration, including the StatsD emitter with DogStatsD Mapper and the collection of Airflow REST API metrics.",
            "spof": true
          },
          {
            "path": "airflow/datadog_checks/airflow/data",
            "description": "This directory is designated to hold data files pertinent to the Datadog Airflow integration. While currently empty, it serves as a placeholder for static configurations, schemas, or other data assets that the integration might require.",
            "spof": false
          },
          {
            "path": "airflow/assets/dashboards",
            "description": "This directory is intended to store JSON dashboard definitions that are used by the Datadog Airflow integration. These dashboards provide visualization for Airflow metrics within Datadog.",
            "spof": false
          },
          {
            "path": "airflow/assets/monitors",
            "description": "This directory is intended to hold monitor definitions or configurations specific to the Datadog Airflow integration. It is part of the assets required for monitoring Airflow components within Datadog.",
            "spof": false
          },
          {
            "path": "airflow/assets/saved_views",
            "description": "This directory is intended to store definitions or configurations for 'saved views' specifically tailored for the Datadog integration with Apache Airflow. While currently empty, its purpose is to hold pre-configured visualization or dashboard layouts relevant to Airflow monitoring.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ian Moroney",
            "percent": 41
          },
          {
            "name": "Jackson Davenport",
            "percent": 19
          },
          {
            "name": "Marwan Zibaoui",
            "percent": 15
          }
        ]
      },
      "Integration Testing and Validation Suite": {
        "files": [
          {
            "path": "airflow/tests/test_e2e.py",
            "description": "This file contains end-to-end (E2E) tests for the Datadog Airflow integration, verifying that service checks and metrics are correctly reported.",
            "spof": true
          },
          {
            "path": "airflow/tests/__init__.py",
            "description": "This empty file marks the `tests` directory as a Python package, allowing test modules within it to be imported and run.",
            "spof": true
          },
          {
            "path": "airflow/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Airflow integration. It specifically tests service checks for connectivity and health, and metrics collection for Airflow DAGs and tasks, utilizing mocking for isolated testing.",
            "spof": false
          },
          {
            "path": "airflow/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Airflow check, verifying that service checks and metrics are correctly reported by the integration.",
            "spof": false
          },
          {
            "path": "airflow/tests/test_check_metrics_up_to_date.py",
            "description": "This file contains a test that verifies if the hardcoded list of expected Airflow metrics is up to date with the metrics documented in the official Apache Airflow GitHub repository for a specified version.",
            "spof": true
          },
          {
            "path": "airflow/tests/conftest.py",
            "description": "This file defines pytest fixtures and helper functions to set up a Dockerized Airflow environment and configure the Datadog Agent for integration tests of the Airflow check.",
            "spof": false
          },
          {
            "path": "airflow/tests/common.py",
            "description": "This file defines common variables and configurations, including hostnames, URLs, and instance settings, used across the Airflow integration's test suite.",
            "spof": true
          },
          {
            "path": "airflow/tests/fixtures",
            "description": "This directory is intended to store test fixtures used by the Datadog Airflow integration tests. These fixtures would provide consistent test data, mock objects, or setup environments for various test cases. Although currently empty, its purpose is to centralize reusable components for testing.",
            "spof": false
          },
          {
            "path": "airflow/tests/compose/dags/tutorial.py",
            "description": "This file defines an example Airflow DAG named 'tutorial', demonstrating basic Airflow concepts such as defining tasks with BashOperators, setting task dependencies, and documenting tasks and DAGs. It serves as a tutorial or test case for an Airflow integration.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ian Moroney",
            "percent": 79
          },
          {
            "name": "Kyle Neale",
            "percent": 12
          },
          {
            "name": "dkirov-dd",
            "percent": 5
          }
        ]
      },
      "Airflow Metric and Health Collection": {
        "files": [
          {
            "path": "airflow/datadog_checks/airflow/airflow.py",
            "description": "This file implements the Datadog Agent check for Airflow, collecting metrics and service checks related to Airflow's health and task execution by interacting with its API endpoints.",
            "spof": true
          },
          {
            "path": "airflow/datadog_checks/airflow/__init__.py",
            "description": "This file serves as the initialization module for the `airflow` package within the `datadog_checks` directory. It defines the package's public interface by exposing the `__version__` and `AirflowCheck`.",
            "spof": true
          },
          {
            "path": "airflow/datadog_checks/airflow/config_models/validators.py",
            "description": "This file is intended for defining custom validation and transformation logic for configuration models within the Datadog Airflow integration.",
            "spof": true
          },
          {
            "path": "airflow/datadog_checks/airflow/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration settings and their validation logic, intended to be used across Datadog integrations.",
            "spof": true
          },
          {
            "path": "airflow/datadog_checks/airflow/config_models/defaults.py",
            "description": "This file defines default configuration values for the Datadog Airflow integration. It is autogenerated from the integration's configuration specification.",
            "spof": true
          },
          {
            "path": "airflow/datadog_checks/airflow/config_models/__init__.py",
            "description": "This file defines and provides access to the configuration models (instance and shared) for the Airflow integration, serving as an autogenerated entry point for configuration-related components.",
            "spof": false
          },
          {
            "path": "airflow/datadog_checks/airflow/config_models/instance.py",
            "description": "This file defines the Pydantic models for the Airflow integration's instance configuration schema, including validation logic and default value handling. It is autogenerated from the `spec.yaml` configuration.",
            "spof": false
          },
          {
            "path": "airflow/assets/configuration",
            "description": "This directory is designated to store configuration assets for the Datadog Apache Airflow integration. Its purpose is to house files that define how the integration is set up or customized, even if currently empty.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 57
          },
          {
            "name": "Kyle Neale",
            "percent": 32
          },
          {
            "name": "Yann Armelin",
            "percent": 9
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 24,
      "spofCount": 11
    },
    "busFactor": 2,
    "authorCount": 6
  },
  "Authorize.Net Payment Analytics": {
    "description": "Collects transaction and settlement data from Authorize.Net to provide insights into payment processing and financial reporting.",
    "functions": {
      "Integration Manifest and Assets": {
        "files": [
          {
            "path": "authorize_net/CHANGELOG.md",
            "description": "This file documents the changes and new features for the authorize.net integration, serving as a version history log.",
            "spof": true
          },
          {
            "path": "authorize_net/README.md",
            "description": "This file is the README for the Datadog Authorize.Net integration, detailing its purpose, how to configure it, and what data (logs and metrics) it collects from Authorize.Net accounts.",
            "spof": false
          },
          {
            "path": "authorize_net/images",
            "description": "This directory is designated to store images specifically related to the Authorize.Net integration. These images would likely be used for documentation, UI elements, or other visual assets pertinent to the integration's representation within Datadog.",
            "spof": false
          },
          {
            "path": "authorize_net/assets/dashboards",
            "description": "This directory is intended to contain dashboard definitions and configuration files specific to the Authorize.Net integration. If populated, it would hold JSON or YAML files outlining how to visualize metrics and logs related to the integration within Datadog dashboards.",
            "spof": false
          },
          {
            "path": "authorize_net/assets/monitors",
            "description": "This directory is intended to contain monitor definitions or configuration files specifically for the Datadog Authorize.Net integration. While currently empty, its purpose is to house assets related to monitoring the Authorize.Net service.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "DhruvaPatel-crest",
            "percent": 56
          },
          {
            "name": "Akshit Vaid",
            "percent": 34
          },
          {
            "name": "dkirov-dd",
            "percent": 10
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 1
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "ActiveMQ Monitoring": {
    "description": "Monitors Apache ActiveMQ brokers by collecting metrics via JMX to ensure the health of message queues and topics.",
    "functions": {
      "ActiveMQ JMX Monitoring": {
        "files": [
          {
            "path": "activemq/CHANGELOG.md",
            "description": "This file is the changelog for the ActiveMQ integration, detailing updates, bug fixes, and new features across different versions. It tracks changes such as Python version bumps, dependency updates, and configuration enhancements.",
            "spof": false
          },
          {
            "path": "activemq/README.md",
            "description": "This README provides documentation for the Datadog Agent's ActiveMQ integration, detailing how to set up, configure, and monitor ActiveMQ metrics and logs.",
            "spof": false
          },
          {
            "path": "activemq/datadog_checks/activemq/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the ActiveMQ integration, primarily exposing the integration's version number.",
            "spof": true
          },
          {
            "path": "activemq/datadog_checks/activemq/config_models/validators.py",
            "description": "This file is intended for defining custom configuration validators and transformers for the ActiveMQ integration, providing additional logic beyond standard schema validation.",
            "spof": true
          },
          {
            "path": "activemq/datadog_checks/activemq/config_models/shared.py",
            "description": "This file defines the Pydantic model for shared configuration settings of the ActiveMQ integration, including validation and default value handling. It is autogenerated from a specification file.",
            "spof": true
          },
          {
            "path": "activemq/datadog_checks/activemq/config_models/defaults.py",
            "description": "This file defines default configuration values for various parameters within the ActiveMQ integration, such as metrics collection, JMX settings, and RMI timeouts. It is automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "activemq/datadog_checks/activemq/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides structured access to instance-specific and shared configuration models for the ActiveMQ integration, auto-generated from a specification file.",
            "spof": false
          },
          {
            "path": "activemq/datadog_checks/activemq/config_models/instance.py",
            "description": "This file defines the Pydantic model for the ActiveMQ integration's instance configuration, including JMX connection parameters and various settings. It is an autogenerated file from a specification, incorporating default values and validation logic.",
            "spof": true
          },
          {
            "path": "activemq/datadog_checks/activemq/data",
            "description": "This directory is designated to hold static data or configuration files specific to the ActiveMQ integration. Although currently empty, its presence suggests it serves as a placeholder for future resources like templates or default configurations.",
            "spof": false
          },
          {
            "path": "activemq/assets/dashboards",
            "description": "This directory is intended to store assets related to pre-built dashboards for the ActiveMQ integration. These assets typically define the layout and widgets for visualizing ActiveMQ metrics within Datadog.",
            "spof": false
          },
          {
            "path": "activemq/assets/monitors",
            "description": "This directory is designated to store monitor definitions or configurations specifically for the ActiveMQ integration within Datadog. Although currently empty, its purpose is to house any monitoring assets that would be deployed with the integration.",
            "spof": false
          },
          {
            "path": "activemq/assets/saved_views",
            "description": "This directory is intended to store configurations for saved views or dashboards specific to the Apache ActiveMQ integration. While currently empty, it serves as a designated location for pre-defined visualizations or monitoring layouts.",
            "spof": false
          },
          {
            "path": "activemq/assets/configuration",
            "description": "This directory is intended to store configuration files and related assets specifically for the Datadog ActiveMQ integration. It would typically contain templates or examples for how to set up the integration's monitoring. Although currently empty, its purpose is to centralize configuration resources for this particular integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 28
          },
          {
            "name": "HadhemiDD",
            "percent": 17
          },
          {
            "name": "Kyle Neale",
            "percent": 17
          }
        ]
      },
      "Integration Test Suite": {
        "files": [
          {
            "path": "activemq/tests/conftest.py",
            "description": "This file provides pytest fixtures for setting up and tearing down a Dockerized ActiveMQ or Artemis environment, including populating it with test data, to support integration tests for the Datadog ActiveMQ integration.",
            "spof": true
          },
          {
            "path": "activemq/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the `activemq/tests` directory as a Python package, enabling test discovery for the ActiveMQ integration.",
            "spof": false
          },
          {
            "path": "activemq/tests/test_check.py",
            "description": "This file contains end-to-end tests for the Datadog ActiveMQ integration, verifying that it correctly collects and reports metrics from both ActiveMQ and ArtemisMQ instances.",
            "spof": true
          },
          {
            "path": "activemq/tests/common.py",
            "description": "This file defines common constants, test utilities, and expected metric lists for end-to-end testing of the Datadog ActiveMQ integration. It distinguishes between ActiveMQ and ActiveMQ Artemis configurations for testing purposes.",
            "spof": true
          },
          {
            "path": "activemq/tests/compose",
            "description": "This directory is intended to contain Docker Compose configurations for setting up isolated test environments specific to the ActiveMQ integration. It would define the services and network needed to run integration tests against ActiveMQ.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Florent Clarret",
            "percent": 87
          },
          {
            "name": "Mike Garabedian",
            "percent": 11
          },
          {
            "name": "Paul",
            "percent": 2
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 18,
      "spofCount": 8
    },
    "busFactor": 2,
    "authorCount": 6
  },
  "Anthropic Usage & Cost Management": {
    "description": "Tracks token consumption and costs associated with Anthropic API usage, providing financial visibility and budget control for LLM-powered applications.",
    "functions": {
      "Anthropic Usage & Cost Monitoring": {
        "files": [
          {
            "path": "anthropic_usage_and_costs/CHANGELOG.md",
            "description": "This file documents all notable changes and releases for the Anthropic Usage and Costs integration, serving as a version history.",
            "spof": true
          },
          {
            "path": "anthropic_usage_and_costs/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog integration that monitors and tracks Anthropic AI usage and associated costs. It details how to gain visibility into LLM token consumption, cost attribution, and usage trends.",
            "spof": true
          },
          {
            "path": "anthropic_usage_and_costs/images/IMAGES_README.md",
            "description": "This file provides guidelines for creating and uploading media (images and videos) for a marketplace media carousel. It details file requirements such as type, size, dimensions, and naming conventions for both images and videos.",
            "spof": true
          },
          {
            "path": "anthropic_usage_and_costs/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions and configurations specific to the Anthropic Usage and Costs integration. These dashboards would typically provide visualizations for monitoring and analyzing Anthropic API usage and associated costs.",
            "spof": false
          },
          {
            "path": "anthropic_usage_and_costs/assets/monitors",
            "description": "This directory is intended to store Datadog monitor definitions or configurations specifically for the 'Anthropic usage and costs' integration. It would contain assets used to observe and alert on metrics or logs related to Anthropic's service usage and associated costs within a Datadog environment.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Bo Huang",
            "percent": 98
          },
          {
            "name": "dkirov-dd",
            "percent": 2
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 3
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "BlazeMeter Performance Testing Monitoring": {
    "description": "Collects metrics from the BlazeMeter continuous testing platform to monitor the performance and results of load tests.",
    "functions": {
      "Integration Assets and Presentation": {
        "files": [
          {
            "path": "blazemeter/CHANGELOG.md",
            "description": "This file is the changelog for the BlazeMeter integration, documenting all version releases and their corresponding changes.",
            "spof": false
          },
          {
            "path": "blazemeter/README.md",
            "description": "This file provides documentation for the Datadog BlazeMeter integration. It details the setup process, including API key generation, and outlines the metrics collected.",
            "spof": true
          },
          {
            "path": "blazemeter/images",
            "description": "This directory is intended to store any images pertinent to the Datadog Blazemeter integration. These might include assets for documentation, UI elements, or other visual resources.",
            "spof": false
          },
          {
            "path": "blazemeter/assets/monitors",
            "description": "This directory is designated to store monitor definitions and configurations specific to the Datadog Blazemeter integration. Although currently empty, it serves as the intended location for files that define alerts and health checks for Blazemeter services within Datadog.",
            "spof": false
          },
          {
            "path": "blazemeter/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions or configurations specific to the Datadog Blazemeter integration. It would typically contain files that define how Blazemeter metrics are visualized within Datadog dashboards. Although currently empty, its purpose is to house these visualization assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Bhavik Parmar",
            "percent": 83
          },
          {
            "name": "dkirov-dd",
            "percent": 9
          },
          {
            "name": "Doug Gunter",
            "percent": 8
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Azure Active Directory (Entra ID) Monitoring": {
    "description": "Ingests audit, sign-in, and credential expiration logs from Microsoft Entra ID to monitor for security events and user activity.",
    "functions": {
      "Entra ID Log and Event Ingestion": {
        "files": [
          {
            "path": "azure_active_directory/README.md",
            "description": "This README provides instructions for setting up the Datadog integration with Microsoft Entra ID (formerly Azure Active Directory) to forward audit and sign-in logs to Datadog. It also details the collection of log data and credential expiration events from Azure services.",
            "spof": true
          },
          {
            "path": "azure_active_directory/CHANGELOG.md",
            "description": "This file is the changelog for the Azure Active Directory integration, detailing version updates and changes made over time for the Datadog Agent.",
            "spof": true
          },
          {
            "path": "azure_active_directory/assets",
            "description": "This directory is intended to store static assets or supplementary files specifically for the Azure Active Directory integration. These assets might include icons, images, documentation snippets, or other non-code resources required by the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Bryce Eadie",
            "percent": 69
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 12
          },
          {
            "name": "rahulkaukuntla",
            "percent": 9
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 2
    },
    "busFactor": 5,
    "authorCount": 5
  },
  "Appgate SDP Monitoring": {
    "description": "Collects health and performance metrics from Appgate SDP (Software-Defined Perimeter) for secure access and network monitoring.",
    "functions": {
      "Appgate SDP Metric Collection": {
        "files": [
          {
            "path": "appgate_sdp/CHANGELOG.md",
            "description": "This file documents the version history, new features, bug fixes, and other changes for the Appgate SDP integration. It provides a chronological record of updates to the integration.",
            "spof": false
          },
          {
            "path": "appgate_sdp/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor Appgate SDP. It details the metrics collected and outlines the installation and validation steps for the integration.",
            "spof": false
          },
          {
            "path": "appgate_sdp/tests/conftest.py",
            "description": "This file defines pytest fixtures for the AppGate SDP integration tests, setting up a Dockerized test environment and providing mocked instance configurations.",
            "spof": true
          },
          {
            "path": "appgate_sdp/tests/test_unit.py",
            "description": "This file contains unit tests for the `appgate_sdp` integration, verifying its ability to collect metrics, report service checks, and handle configuration errors.",
            "spof": true
          },
          {
            "path": "appgate_sdp/tests/__init__.py",
            "description": "This file marks the 'tests' directory as a Python package for the AppGate SDP integration, allowing test modules within it to be imported and run.",
            "spof": true
          },
          {
            "path": "appgate_sdp/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the AppGate SDP integration. It verifies that the integration correctly reports the `appgate_sdp.openmetrics.health` service check.",
            "spof": true
          },
          {
            "path": "appgate_sdp/tests/common.py",
            "description": "This file defines common utilities, configurations, and expected metric names for testing the `appgate_sdp` integration. It includes paths to test fixtures, mock instance settings, and a list of metrics to be collected.",
            "spof": true
          },
          {
            "path": "appgate_sdp/tests/fixtures",
            "description": "This directory is intended to store test fixtures for the `appgate_sdp` integration. These fixtures would provide consistent data, configurations, or mock objects necessary for running tests efficiently and reliably.",
            "spof": false
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/__init__.py",
            "description": "This `__init__.py` file serves as the package entry point for the `appgate_sdp` Datadog integration. It exposes the package version and the main `AppgateSDPCheck` class for import.",
            "spof": true
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/check.py",
            "description": "This file defines the `AppgateSDPCheck` class, which implements an OpenMetrics-based Datadog integration to collect metrics from Appgate SDP. It extends `OpenMetricsBaseCheckV2` and configures metric collection and label renaming.",
            "spof": true
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/metrics.py",
            "description": "This file defines the mapping of raw Appgate SDP metric names to standardized Datadog metric names and specifies label renames for the integration. It categorizes metrics by Appgate components such as appliance, controller, gateway, and portal.",
            "spof": true
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/config_models/validators.py",
            "description": "This file is intended to house custom validation and transformation logic for the configuration of the AppGate SDP integration, as demonstrated by the commented-out example functions.",
            "spof": true
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/config_models/__init__.py",
            "description": "This file provides a `ConfigMixin` class that consolidates access to instance-specific and shared configuration models for the AppGate SDP integration. It serves as an entry point for configuration models within the package, generated automatically from a `spec.yaml`.",
            "spof": true
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/config_models/defaults.py",
            "description": "This file defines default configuration values for the AppGate SDP Datadog integration, automatically generated from its configuration specification.",
            "spof": true
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/config_models/instance.py",
            "description": "This file defines the Pydantic data model for configuring a single instance of the AppGate SDP Datadog integration. It specifies the structure and validation rules for all supported configuration parameters.",
            "spof": true
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/config_models/shared.py",
            "description": "This autogenerated file defines Pydantic models for shared configuration parameters, including proxy settings, and incorporates validation logic for these configurations.",
            "spof": true
          },
          {
            "path": "appgate_sdp/datadog_checks/appgate_sdp/data",
            "description": "This directory is intended to store static data files or configuration templates specific to the Appgate SDP Datadog integration check. Although currently empty, it serves as a placeholder for any auxiliary data required by the check's functionality.",
            "spof": false
          },
          {
            "path": "appgate_sdp/assets/configuration",
            "description": "This directory is designated to store configuration-related assets for the AppGate SDP integration. While currently empty, its intended purpose is to hold example configurations, default settings, or schema definitions necessary for setting up the integration.",
            "spof": false
          },
          {
            "path": "appgate_sdp/assets/dashboards",
            "description": "This directory stores dashboard configurations specifically for the `appgate_sdp` integration. It provides pre-defined visualization assets that can be imported into Datadog to monitor AppGate SDP performance and health.",
            "spof": false
          },
          {
            "path": "appgate_sdp/assets/monitors",
            "description": "This directory is designated to store monitor definitions and configurations specific to the Datadog AppGate SDP integration. It would typically contain files defining alerts, metrics, or other monitoring-related assets for this integration. Currently, it is empty, suggesting no explicit monitor assets are defined here yet.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Laura",
            "percent": 76
          },
          {
            "name": "Kyle Neale",
            "percent": 6
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 4
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 20,
      "spofCount": 13
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Amazon EKS Blueprints Deployment": {
    "description": "Simplifies the deployment and configuration of the Datadog Agent on Amazon EKS clusters using the EKS Blueprints framework.",
    "functions": {
      "EKS Blueprints Integration Documentation": {
        "files": [
          {
            "path": "amazon_eks_blueprints/CHANGELOG.md",
            "description": "This file is a changelog documenting the release history and updates for the `amazon_eks_blueprints` integration.",
            "spof": true
          },
          {
            "path": "amazon_eks_blueprints/README.md",
            "description": "This README provides instructions and configuration details for the Datadog EKS Blueprints add-on, which facilitates the deployment of the Datadog Agent on Amazon EKS clusters.",
            "spof": false
          },
          {
            "path": "amazon_eks_blueprints/assets",
            "description": "This directory is intended to store static assets, such as images, icons, or other non-code resources, specifically for the Amazon EKS Blueprints integration. While currently empty, it serves as a designated location for supporting files should they be required.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 40
          },
          {
            "name": "Bryce Eadie",
            "percent": 26
          },
          {
            "name": "cswatt",
            "percent": 24
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 1
    },
    "busFactor": 3,
    "authorCount": 3
  },
  "Azure IoT Edge Monitoring": {
    "description": "Monitors Azure IoT Edge devices and runtime modules to ensure the health and performance of edge computing applications.",
    "functions": {
      "Declarative Assets and Packaging": {
        "files": [
          {
            "path": "azure_iot_edge/CHANGELOG.md",
            "description": "This file documents all notable changes, additions, fixes, and removals for the Azure IoT Edge integration, organized by version number and release date.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor Azure IoT Edge devices, detailing how to collect metrics, logs, and service checks from IoT Edge runtime and custom modules.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/data",
            "description": "This directory is designated to hold static data files or configuration templates for the `azure_iot_edge` Datadog integration. It typically stores default metric definitions, service check configurations, or other non-code assets necessary for the integration's operation.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/assets/monitors",
            "description": "This directory is designated for storing monitoring assets specific to the Datadog Azure IoT Edge integration. It would typically contain monitor configurations or definitions used to observe the health and performance of Azure IoT Edge instances.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/assets/dashboards",
            "description": "This directory is intended to store dashboard configurations or templates specifically for the Datadog Azure IoT Edge integration. While currently empty, it serves as the designated location for any related dashboard assets.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/assets/configuration",
            "description": "This directory is intended to store configuration assets for the Datadog Azure IoT Edge integration. It would typically contain default or sample configuration files, or configuration schemas, for setting up the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 18
          },
          {
            "name": "HadhemiDD",
            "percent": 16
          },
          {
            "name": "Kyle Neale",
            "percent": 16
          }
        ]
      },
      "Integration Test Suite and Environment Management": {
        "files": [
          {
            "path": "azure_iot_edge/tests/README.md",
            "description": "This README provides instructions for setting up, interacting with, and troubleshooting an Azure IoT Edge End-to-End (E2E) test environment, including generating mock metrics for testing purposes.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/tests/test_config.py",
            "description": "This file contains unit tests for the `Config` class within the Azure IoT Edge integration, ensuring it correctly processes and validates instance configurations, including Prometheus URLs and custom tags.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/tests/e2e_utils.py",
            "description": "This file provides utility functions and classes for managing and verifying Azure IoT Edge test environments, including Docker Compose setup/teardown and endpoint readiness checks, primarily for end-to-end testing.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/tests/test_check.py",
            "description": "This file contains unit tests for the Azure IoT Edge integration, verifying metric collection, service check behavior, and version metadata reporting under normal and error conditions.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/tests/conftest.py",
            "description": "This file contains pytest fixtures for setting up and tearing down Dockerized test environments for the Azure IoT Edge integration, including an end-to-end (E2E) environment and a mock server environment.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/tests/common.py",
            "description": "This file defines common constants, mock server URLs, and expected metric assertions used across tests for the Azure IoT Edge integration. It standardizes variables and metric definitions for testing purposes.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Azure IoT Edge integration, verifying metric collection, service check statuses, and error handling for invalid configurations.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/tests/__init__.py",
            "description": "This empty file marks the 'tests' directory as a Python package. It allows Python to recognize subdirectories and modules within 'tests' for test organization and execution.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/tests/tls/README.md",
            "description": "This README describes the TLS certificates used for testing Azure IoT Edge integration, particularly for devices provisioned with X.509 certificates. It explains their creation process, purpose in encrypting IoT Edge communication, and provides instructions for regenerating them for end-to-end testing.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/tests/compose/device",
            "description": "This directory is intended to contain Docker Compose configurations and related files for simulating an Azure IoT Edge device. Its purpose is to provide a controlled environment for testing the Azure IoT Edge integration within the Datadog agent.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/tests/compose/mock_server/data/metrics",
            "description": "This directory is intended to store mock metric data. This data is used by a mock server within Docker Compose-based test environments for the Azure IoT Edge integration, facilitating the testing of metric collection.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 54
          },
          {
            "name": "Florimond Manca",
            "percent": 24
          },
          {
            "name": "Steven Yuen",
            "percent": 16
          }
        ]
      },
      "IoT Edge Metric Collection and Configuration": {
        "files": [
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/config.py",
            "description": "This file defines the `Config` class, which handles the validation and processing of configuration parameters for the Azure IoT Edge check. It configures Prometheus instances for collecting metrics from both the Edge Hub and Edge Agent components.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/check.py",
            "description": "This file defines the AzureIoTEdgeCheck class, which is the core check for the Azure IoT Edge integration. It extends OpenMetricsBaseCheck to collect metrics from Azure IoT Edge Prometheus endpoints.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/metrics.py",
            "description": "This file defines and maps metrics collected from Azure IoT Edge's Edge Hub and Edge Agent components, including type overrides for certain metrics.",
            "spof": false
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/__init__.py",
            "description": "This `__init__.py` file serves as the package entry point for the `azure_iot_edge` integration, exposing its version and the main `AzureIoTEdgeCheck` class for external use.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/types.py",
            "description": "This file defines the `Instance` TypedDict, which outlines the expected structure for configuration instances of the Azure IoT Edge integration. It specifies fields such as Prometheus URLs for Edge Hub and Edge Agent, and an optional list of tags.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient access to the autogenerated instance and shared configuration models for the Azure IoT Edge integration. It serves as an entry point for accessing the integration's typed configuration.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/config_models/validators.py",
            "description": "This file is a placeholder for custom validation and transformation logic applied to the Azure IoT Edge integration's configuration. It can be used to migrate legacy options or enforce specific constraints on configuration values.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/config_models/defaults.py",
            "description": "This file defines default configuration values for the Azure IoT Edge integration, automatically generated from the integration's specification file. It contains functions that return default settings for various instance and shared configuration options.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration settings, including proxy settings and general parameters, along with validation logic for these configurations. It is an autogenerated file derived from a specification YAML.",
            "spof": true
          },
          {
            "path": "azure_iot_edge/datadog_checks/azure_iot_edge/config_models/instance.py",
            "description": "This file defines the Pydantic data models for the Azure IoT Edge integration's instance configuration. It includes the schema and validation logic for various configuration settings, autogenerated from a spec file.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 64
          },
          {
            "name": "Yann Armelin",
            "percent": 33
          },
          {
            "name": "Steven Yuen",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 27,
      "spofCount": 12
    },
    "busFactor": 1,
    "authorCount": 4
  },
  "ArangoDB Monitoring": {
    "description": "Monitors ArangoDB multi-model databases, collecting metrics on cluster health, queries, and performance.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "arangodb/README.md",
            "description": "This README provides documentation for the Datadog Agent's ArangoDB integration, detailing its setup, configuration, data collection, and troubleshooting.",
            "spof": false
          },
          {
            "path": "arangodb/CHANGELOG.md",
            "description": "This file is a changelog documenting the release history, new features, bug fixes, and other changes for the ArangoDB integration.",
            "spof": false
          },
          {
            "path": "arangodb/datadog_checks/arangodb/data",
            "description": "This directory is intended to store data files specific to the ArangoDB integration. While currently empty, it serves as a designated location for potential configuration examples, metric definitions, or other static assets that the integration might require.",
            "spof": false
          },
          {
            "path": "arangodb/assets/configuration",
            "description": "This directory is intended to house configuration assets or example configuration files specifically for the ArangoDB integration within Datadog's core integrations. It would typically contain templates or reference configurations to guide users.",
            "spof": false
          },
          {
            "path": "arangodb/assets/monitors",
            "description": "This directory is intended to house monitoring-related assets for the ArangoDB integration within Datadog's core integrations repository. It would typically contain configurations for dashboards, alerts, or other monitoring definitions specific to ArangoDB.",
            "spof": false
          },
          {
            "path": "arangodb/assets/dashboards",
            "description": "This directory is designated for storing Datadog dashboard configurations and templates specific to the ArangoDB integration. Its role is to provide pre-defined visualizations for ArangoDB metrics, enhancing monitoring capabilities within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 19
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 18
          },
          {
            "name": "HadhemiDD",
            "percent": 15
          }
        ]
      },
      "Integration Testing and Validation": {
        "files": [
          {
            "path": "arangodb/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Arangodb integration, ensuring that metrics are collected and tagged correctly from a running Arangodb instance.",
            "spof": true
          },
          {
            "path": "arangodb/tests/test_arangodb.py",
            "description": "This file contains unit and integration tests for the Datadog ArangodbCheck, verifying its metric collection, service checks, dynamic tag handling, and error logging.",
            "spof": true
          },
          {
            "path": "arangodb/tests/conftest.py",
            "description": "This file defines pytest fixtures for setting up and tearing down a Dockerized ArangoDB instance and providing configuration parameters for testing the Datadog ArangoDB integration.",
            "spof": true
          },
          {
            "path": "arangodb/tests/common.py",
            "description": "This file defines common constants and expected metric lists used across the Datadog ArangoDB integration's test suite, including host, port, and various ArangoDB metric names.",
            "spof": true
          },
          {
            "path": "arangodb/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the `tests` directory as a Python package, allowing test modules within it to be imported and discovered.",
            "spof": true
          },
          {
            "path": "arangodb/tests/docker/arangodb3",
            "description": "This directory is part of the test infrastructure for the Arangodb integration, specifically defining or containing components related to a Dockerized Arangodb version 3 test environment. Although currently empty, its path indicates its purpose in segregating tests for a particular database version within a Docker setup.",
            "spof": false
          },
          {
            "path": "arangodb/tests/fixtures/invalid_mode_valid_id",
            "description": "This directory contains test fixtures for the ArangoDB integration, specifically designed for scenarios where a test involves an invalid operational mode while other identifiers are valid. It's used to test the integration's robust error handling and validation logic under specific misconfigurations.",
            "spof": false
          },
          {
            "path": "arangodb/tests/fixtures/invalid_mode_invalid_id",
            "description": "This directory serves as a fixture for testing error scenarios within the ArangoDB integration. It specifically targets situations involving invalid modes and invalid IDs, providing a context to validate how the integration handles such erroneous inputs.",
            "spof": false
          },
          {
            "path": "arangodb/tests/fixtures/valid_id_mode",
            "description": "This directory contains fixtures specifically designed for testing the Arangodb integration in a \"valid ID mode\" scenario. It provides predefined data or configurations necessary to validate the integration's behavior when operating with valid identifiers.",
            "spof": false
          },
          {
            "path": "arangodb/tests/fixtures/valid_mode_invalid_id",
            "description": "This directory serves as a test fixture for the ArangoDB integration. It represents a specific test scenario where the integration is configured with a valid operational mode but an invalid ID. This setup likely verifies error handling and validation logic within the integration's test suite.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 52
          },
          {
            "name": "Andrew Zhang",
            "percent": 40
          },
          {
            "name": "Fanny Jiang",
            "percent": 8
          }
        ]
      },
      "ArangoDB Metric Collection": {
        "files": [
          {
            "path": "arangodb/datadog_checks/arangodb/__init__.py",
            "description": "This file serves as the package initializer for the Datadog ArangoDB integration. It imports and exposes the package version and the main ArangodbCheck class.",
            "spof": true
          },
          {
            "path": "arangodb/datadog_checks/arangodb/check.py",
            "description": "This file defines the ArangodbCheck class, an integration for Datadog that collects OpenMetrics-based metrics and server-specific tags from an Arangodb instance.",
            "spof": false
          },
          {
            "path": "arangodb/datadog_checks/arangodb/metrics.py",
            "description": "This file defines the mapping between raw metric names exposed by ArangoDB and their normalized names used within Datadog. It organizes a comprehensive list of metrics across various ArangoDB components like agency, network, AQL, client connections, HTTP, process, server, collections, transactions, and RocksDB.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Andrew Zhang",
            "percent": 67
          },
          {
            "name": "Juanpe Araque",
            "percent": 30
          },
          {
            "name": "Fanny Jiang",
            "percent": 3
          }
        ]
      },
      "Configuration Model Management": {
        "files": [
          {
            "path": "arangodb/datadog_checks/arangodb/config_models/defaults.py",
            "description": "This file defines default values for various configuration parameters for the Arangodb integration, used by its autogenerated configuration models.",
            "spof": true
          },
          {
            "path": "arangodb/datadog_checks/arangodb/config_models/validators.py",
            "description": "This file is a placeholder for defining custom configuration validators and transformers for the ArangoDB integration. It includes commented-out examples illustrating how to implement logic for processing or validating configuration options.",
            "spof": true
          },
          {
            "path": "arangodb/datadog_checks/arangodb/config_models/instance.py",
            "description": "This file defines Pydantic models for the ArangoDB integration's instance-level configuration. It specifies the structure and validation rules for various configuration parameters, and is autogenerated from a spec file.",
            "spof": false
          },
          {
            "path": "arangodb/datadog_checks/arangodb/config_models/__init__.py",
            "description": "This file serves as the `config_models` package entry point, defining a `ConfigMixin` class that provides convenient accessors for the autogenerated `InstanceConfig` and `SharedConfig` models used by the ArangoDB integration.",
            "spof": true
          },
          {
            "path": "arangodb/datadog_checks/arangodb/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options within the ArangoDB Datadog integration, including proxy settings and timeout. It is an autogenerated file from a specification to ensure consistent configuration validation.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 74
          },
          {
            "name": "Andrew Zhang",
            "percent": 11
          },
          {
            "name": "Yann Armelin",
            "percent": 9
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 24,
      "spofCount": 11
    },
    "busFactor": 1,
    "authorCount": 5
  },
  "BeyondTrust Identity Security Insights Integration": {
    "description": "Ingests detection logs from BeyondTrust to provide visibility into identity-based threats and security risks.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "beyondtrust_identity_security_insights/CHANGELOG.md",
            "description": "This file documents all changes and version updates for the BeyondTrust Identity Security Insights integration.",
            "spof": true
          },
          {
            "path": "beyondtrust_identity_security_insights/README.md",
            "description": "This README provides instructions on how to integrate BeyondTrust Identity Security Insights with Datadog to forward detection logs for analysis, visualization, and security monitoring.",
            "spof": true
          },
          {
            "path": "beyondtrust_identity_security_insights/images",
            "description": "This directory is intended to house image assets specifically for the BeyondTrust Identity Security Insights integration. These images would typically be used for documentation, UI elements, or other visual content related to the integration.",
            "spof": false
          },
          {
            "path": "beyondtrust_identity_security_insights/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions or configurations specific to the BeyondTrust Identity Security Insights integration. These assets are typically used to visualize metrics and logs collected by the integration within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Tirthraj Chaudhari",
            "percent": 94
          },
          {
            "name": "dkirov-dd",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "ASP.NET Application Monitoring": {
    "description": "Collects performance counters from ASP.NET applications to monitor the health, request rate, and error status of web applications.",
    "functions": {
      "ASP.NET Performance Counter Collection": {
        "files": [
          {
            "path": "aspdotnet/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Aspdotnet integration, detailing all the version updates, added features, fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "aspdotnet/README.md",
            "description": "This file is a README for the Datadog ASP.NET integration, providing instructions for setting up and configuring the Datadog Agent to collect metrics from ASP.NET applications. It details the setup process, data collected, and troubleshooting information.",
            "spof": false
          },
          {
            "path": "aspdotnet/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the 'tests' directory as a Python package, allowing test discovery and execution for the ASP.NET integration.",
            "spof": true
          },
          {
            "path": "aspdotnet/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog ASP.NET integration, verifying metric collection and service checks using mocked performance objects.",
            "spof": true
          },
          {
            "path": "aspdotnet/tests/test_aspdotnet.py",
            "description": "This file contains unit tests for the Datadog `aspdotnet` integration. It verifies that the `AspdotnetCheck` properly collects ASP.NET performance metrics from Windows PDH, including scenarios with and without custom tags.",
            "spof": false
          },
          {
            "path": "aspdotnet/tests/common.py",
            "description": "This file defines common constants, test configurations, and expected metric lists used across the tests for the Datadog ASP.NET integration.",
            "spof": true
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the ASP.NET integration, exposing the `AspdotnetCheck` class and the package version.",
            "spof": false
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/metrics.py",
            "description": "This file defines the default metrics configuration for the ASP.NET integration, mapping Windows Performance Counters to Datadog metric names for both ASP.NET and ASP.NET Applications.",
            "spof": true
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/check.py",
            "description": "This file defines the Datadog integration check for ASP.NET, responsible for collecting performance counter metrics from Windows systems.",
            "spof": true
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/aspdotnet.py",
            "description": "This file defines the main Datadog check for ASP.NET, acting as a dispatcher to instantiate either a newer version (`AspdotnetCheckV2`) or a legacy version of the check based on configuration.",
            "spof": false
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/config_models/__init__.py",
            "description": "This file initializes configuration models for the ASP.NET integration. It defines a `ConfigMixin` class that provides properties to access autogenerated instance and shared configuration models.",
            "spof": false
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/config_models/shared.py",
            "description": "This file defines the shared configuration model (`SharedConfig`) for the ASP.NET integration, including common configuration parameters, their types, and associated validation and default value logic. It is autogenerated from a specification file.",
            "spof": true
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/config_models/defaults.py",
            "description": "This file defines default configuration settings for the ASP.NET integration. It is an autogenerated file based on the integration's specification.",
            "spof": true
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/config_models/validators.py",
            "description": "This file is a placeholder for custom configuration validators and transformers for the ASP.NET integration, allowing for logic to modify or validate configuration values before they are used.",
            "spof": true
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/config_models/instance.py",
            "description": "This file defines the Pydantic models for validating and structuring the configuration parameters of a Datadog ASP.NET integration instance. It is auto-generated from a specification file.",
            "spof": true
          },
          {
            "path": "aspdotnet/datadog_checks/aspdotnet/data",
            "description": "This directory is intended to store static data files, configuration templates, or other non-code assets specifically required by the `aspdotnet` Datadog integration. It serves as a designated location for data-related resources that the integration might utilize.",
            "spof": false
          },
          {
            "path": "aspdotnet/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions and configurations pertinent to the ASP.NET integration for Datadog. These assets typically define the visualizations and metrics used for monitoring ASP.NET applications within the Datadog platform.",
            "spof": false
          },
          {
            "path": "aspdotnet/assets/configuration",
            "description": "This directory is designated to store configuration assets for the Datadog ASP.NET integration. It would typically contain files or templates necessary for setting up and customizing monitoring for ASP.NET applications.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 27
          },
          {
            "name": "HadhemiDD",
            "percent": 12
          },
          {
            "name": "Kyle Neale",
            "percent": 12
          }
        ]
      },
      ".NET CLR Performance Counter Collection": {
        "files": [
          {
            "path": "dotnetclr/README.md",
            "description": "This README file provides documentation for the Datadog Agent's .NET CLR integration, detailing its setup, configuration, and how to collect performance metrics.",
            "spof": false
          },
          {
            "path": "dotnetclr/CHANGELOG.md",
            "description": "This file is a changelog document that records all notable changes, additions, fixes, and removals for the Dotnetclr integration over its various versions. It provides a historical overview of updates and their corresponding agent compatibility.",
            "spof": false
          },
          {
            "path": "dotnetclr/tests/common.py",
            "description": "This file defines common test data and configurations for the Datadog .NET CLR integration, including example instances and performance object structures used in tests.",
            "spof": true
          },
          {
            "path": "dotnetclr/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog .NET CLR integration, verifying the collection of performance metrics and service checks from mocked Windows performance objects.",
            "spof": true
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/metrics.py",
            "description": "This file defines the configuration for collecting .NET CLR performance metrics, including custom metric mappings and a list of default counters to be monitored by the Datadog Agent.",
            "spof": true
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/__init__.py",
            "description": "This `__init__.py` file serves as the package entry point for the `dotnetclr` integration, exposing the package version and the main `DotnetclrCheck` class.",
            "spof": false
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/check.py",
            "description": "This file defines the Datadog check for collecting .NET CLR performance counters. It extends a base class for Windows performance counter checks and specifies the metrics to be collected.",
            "spof": true
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/dotnetclr.py",
            "description": "This file defines the main Datadog `DotnetclrCheck` class, which acts as an entry point to monitor .NET CLR performance counters. It conditionally delegates to `DotnetclrCheckV2` based on a configuration flag for versioning or legacy support.",
            "spof": true
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/config_models/defaults.py",
            "description": "This file defines default configuration values for the 'dotnetclr' integration, automatically generated from the spec.yaml file.",
            "spof": true
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/config_models/validators.py",
            "description": "This file is intended to house custom validators and transformers for the `dotnetclr` integration's configuration, allowing for pre-processing or validation of configuration values.",
            "spof": true
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/config_models/__init__.py",
            "description": "This autogenerated file defines a `ConfigMixin` class that provides structured access to instance-specific and shared configuration models for a Datadog integration.",
            "spof": false
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/config_models/shared.py",
            "description": "This file defines the shared configuration model for the dotnetclr integration, using Pydantic for validation and default handling, and is automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/config_models/instance.py",
            "description": "This file defines Pydantic models for the instance configuration of the Datadog .NET CLR integration, including schemas for various metric collection settings and associated validation logic. It is autogenerated from a `spec.yaml` file.",
            "spof": true
          },
          {
            "path": "dotnetclr/datadog_checks/dotnetclr/data",
            "description": "This directory is designated to store static data files, configuration templates, or other ancillary resources required by the Datadog .NET CLR integration. Although currently empty, its typical role within a check's structure suggests it would house non-code assets supporting the integration's functionality.",
            "spof": false
          },
          {
            "path": "dotnetclr/assets/configuration",
            "description": "This directory is designated for storing configuration assets pertinent to the Datadog .NET CLR integration. It would typically contain example configuration files or templates to guide users in setting up the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 27
          },
          {
            "name": "HadhemiDD",
            "percent": 13
          },
          {
            "name": "Kyle Neale",
            "percent": 13
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 33,
      "spofCount": 18
    },
    "busFactor": 1,
    "authorCount": 12
  },
  "Adyen Payment Processing Analytics": {
    "description": "Ingests and analyzes transaction, dispute, and settlement data from Adyen webhooks to provide insights into payment operations.",
    "functions": {
      "Integration Asset and Documentation Management": {
        "files": [
          {
            "path": "adyen/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog Adyen integration. It explains how the integration collects transaction, dispute, and payout data via Adyen webhooks and sends it to Datadog for analysis.",
            "spof": false
          },
          {
            "path": "adyen/CHANGELOG.md",
            "description": "This file documents the changes and version history for the Datadog Adyen integration.",
            "spof": true
          },
          {
            "path": "adyen/images",
            "description": "This directory is designated to store images specifically associated with the Datadog Adyen integration. These images could include icons, logos, or other visual assets pertinent to the integration's documentation or user interface.",
            "spof": false
          },
          {
            "path": "adyen/assets/monitors",
            "description": "This directory is intended to store Datadog monitor definitions or configurations specifically for the Adyen integration. These monitors would typically alert on key metrics or events related to Adyen service health and performance.",
            "spof": false
          },
          {
            "path": "adyen/assets/dashboards",
            "description": "This directory is designated to store Datadog dashboard definitions for the Adyen integration. These assets would provide pre-configured visualizations for metrics and logs. Currently, it is empty, indicating no dashboards have been defined here yet.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Akshit Vaid",
            "percent": 45
          },
          {
            "name": "Doug Gunter",
            "percent": 34
          },
          {
            "name": "Esther Kim",
            "percent": 12
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 1
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "Avast Business Hub Security Monitoring": {
    "description": "Ingests security logs from the Avast Business Hub to monitor endpoint protection status and detected threats across managed devices.",
    "functions": {
      "Integration Manifest and Assets": {
        "files": [
          {
            "path": "avast/CHANGELOG.md",
            "description": "This file documents all notable changes and new features for the 'avast' integration, serving as a changelog for its releases.",
            "spof": true
          },
          {
            "path": "avast/README.md",
            "description": "This README details the Datadog integration for Avast, explaining how to set up the connection with Avast Business Hub and the types of security logs collected and forwarded to Datadog.",
            "spof": true
          },
          {
            "path": "avast/images",
            "description": "This directory is dedicated to storing image assets specifically used by the Datadog integration for Avast. It likely contains icons, logos, or screenshots relevant to the integration's documentation or UI.",
            "spof": false
          },
          {
            "path": "avast/assets/dashboards",
            "description": "This directory is intended to store JSON definitions or configurations for Datadog dashboards specifically designed for the Avast integration. These dashboards would provide visualizations and metrics related to the Avast service, enabling users to monitor its performance and status within Datadog. Although currently empty, its purpose is to house these dashboard assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "narendranandaniya-crest",
            "percent": 90
          },
          {
            "name": "dkirov-dd",
            "percent": 10
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Anyscale Platform Monitoring": {
    "description": "Provides visibility into the Anyscale platform for scaling Ray applications, monitoring compute clusters and job performance.",
    "functions": {
      "Anyscale Integration Package": {
        "files": [
          {
            "path": "anyscale/README.md",
            "description": "This file provides an overview and setup instructions for the Datadog Agent's Anyscale integration, detailing how to monitor Anyscale with Datadog.",
            "spof": false
          },
          {
            "path": "anyscale/CHANGELOG.md",
            "description": "This file documents the version history and release notes for the Anyscale integration within the Datadog integrations-core repository. It lists changes and new features introduced in each version.",
            "spof": true
          },
          {
            "path": "anyscale/assets/monitors",
            "description": "This directory is designated to store monitor definitions and configurations specific to the Anyscale integration. Although currently empty, it serves as the intended location for any alerts or monitoring assets within the Anyscale integration's structure.",
            "spof": false
          },
          {
            "path": "anyscale/assets/dashboards",
            "description": "This directory is designated to hold JSON definitions or configuration files for Datadog dashboards specifically tailored for the Anyscale integration. Although currently empty, its purpose is to centralize dashboard assets for monitoring and visualization within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 71
          },
          {
            "name": "dkirov-dd",
            "percent": 19
          },
          {
            "name": "davidfeng-datadog",
            "percent": 10
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Cassandra Monitoring": {
    "description": "Monitors Apache Cassandra clusters using JMX to collect performance metrics on nodes, keyspaces, and operations.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "cassandra/README.md",
            "description": "This file provides instructions for setting up the Datadog Agent to monitor Cassandra, including steps for collecting metrics and logs.",
            "spof": false
          },
          {
            "path": "cassandra/CHANGELOG.md",
            "description": "This file is a changelog for the Cassandra integration, detailing all released versions, their release dates, and a summary of added features, fixes, and other changes.",
            "spof": false
          },
          {
            "path": "cassandra/images",
            "description": "This directory is intended to store image files associated with the Datadog Cassandra integration. While currently empty, it serves as a designated location for visual assets such as diagrams, icons, or screenshots that might be used in documentation or UI.",
            "spof": false
          },
          {
            "path": "cassandra/datadog_checks/cassandra/__init__.py",
            "description": "This file initializes the Cassandra integration package and makes the package version accessible.",
            "spof": true
          },
          {
            "path": "cassandra/datadog_checks/cassandra/data",
            "description": "This directory is intended to store data files relevant to the Datadog Cassandra integration. Although currently empty, it serves as a designated location for static assets, configuration templates, or other supplementary information used by the check.",
            "spof": false
          },
          {
            "path": "cassandra/assets/saved_views",
            "description": "This directory is intended to store configuration files or definitions for predefined views, such as dashboards or monitoring perspectives, specifically tailored for the Datadog Cassandra integration. Although currently empty, it serves as a designated location for persistent view configurations related to this integration.",
            "spof": false
          },
          {
            "path": "cassandra/assets/dashboards",
            "description": "This directory is intended to house dashboard configurations and templates specific to the Datadog Cassandra integration. These assets would define the visualizations and metrics used for monitoring Cassandra within Datadog.",
            "spof": false
          },
          {
            "path": "cassandra/assets/configuration",
            "description": "This directory is designated to hold configuration-related assets for the Datadog Cassandra integration. It would typically contain example configurations or templates that users can adapt for their monitoring setup.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "HadhemiDD",
            "percent": 22
          },
          {
            "name": "Kyle Neale",
            "percent": 22
          },
          {
            "name": "Sarah Wang",
            "percent": 21
          }
        ]
      },
      "JMX Metric Collection": {
        "files": [
          {
            "path": "cassandra/tests/conftest.py",
            "description": "This file is a pytest conftest that defines fixtures for setting up and tearing down a Dockerized Cassandra environment, primarily for integration tests involving JMX monitoring.",
            "spof": true
          },
          {
            "path": "cassandra/tests/common.py",
            "description": "This file defines common constants and expected metric lists for the Cassandra integration's End-to-End (E2E) tests. It includes specific Cassandra metrics, filtered JVM metrics, and JMX metrics.",
            "spof": false
          },
          {
            "path": "cassandra/tests/test_check.py",
            "description": "This file contains end-to-end tests for the Datadog Cassandra integration, verifying that all expected metrics are collected by the agent.",
            "spof": true
          },
          {
            "path": "cassandra/tests/compose/resources",
            "description": "This directory is designated to hold resources, such as configuration files or setup scripts, essential for the Docker Compose-based integration tests of the Cassandra integration. These resources are utilized by the services defined in the compose files to create a test environment.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Alexandre Yang",
            "percent": 48
          },
          {
            "name": "Ofek Lev",
            "percent": 34
          },
          {
            "name": "Steven Yuen",
            "percent": 17
          }
        ]
      },
      "Cassandra Configuration Management": {
        "files": [
          {
            "path": "cassandra/datadog_checks/cassandra/config_models/instance.py",
            "description": "This file defines the Pydantic model for the Cassandra integration's instance configuration. It is autogenerated and includes validation logic for the configuration parameters.",
            "spof": true
          },
          {
            "path": "cassandra/datadog_checks/cassandra/config_models/__init__.py",
            "description": "This file provides a `ConfigMixin` class that allows components of the Cassandra integration to access its instance-specific and shared configuration models. It is an autogenerated file derived from a specification YAML.",
            "spof": false
          },
          {
            "path": "cassandra/datadog_checks/cassandra/config_models/defaults.py",
            "description": "This file defines default configuration values for the Datadog Cassandra integration. It is an autogenerated file, with its content derived from a specification YAML.",
            "spof": true
          },
          {
            "path": "cassandra/datadog_checks/cassandra/config_models/validators.py",
            "description": "This file is intended to define custom validation and transformation logic for configuration values specific to the Cassandra integration, allowing for advanced checks or data manipulation during config initialization.",
            "spof": true
          },
          {
            "path": "cassandra/datadog_checks/cassandra/config_models/shared.py",
            "description": "This file defines the `SharedConfig` Pydantic model for the Cassandra integration, specifying common configuration options and their validation logic. It is an autogenerated file based on a configuration specification.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 98
          },
          {
            "name": "Julia",
            "percent": 1
          },
          {
            "name": "Sarah Witt",
            "percent": 0
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 17,
      "spofCount": 7
    },
    "busFactor": 1,
    "authorCount": 5
  },
  "Aerospike Database Monitoring": {
    "description": "Collects performance metrics and statistics from Aerospike clusters to monitor database health, throughput, and latency.",
    "functions": {
      "Packaging and Assets": {
        "files": [
          {
            "path": "aerospike/CHANGELOG.md",
            "description": "This file is a changelog documenting all the changes, additions, fixes, and removals for the Aerospike integration across different versions and agent releases. It serves as a historical record of updates to the integration.",
            "spof": false
          },
          {
            "path": "aerospike/README.md",
            "description": "This file provides instructions for setting up and configuring the Datadog Agent to monitor Aerospike, including collecting metrics and logs from both host and containerized environments.",
            "spof": false
          },
          {
            "path": "aerospike/datadog_checks/aerospike/__init__.py",
            "description": "This `__init__.py` file serves as the package entry point for the Aerospike integration. It defines the public API for the package by exposing the version information and the main AerospikeCheck class.",
            "spof": true
          },
          {
            "path": "aerospike/datadog_checks/aerospike/data",
            "description": "This directory is intended to store data files, such as default configurations, schemas, or other static assets, specific to the Datadog Aerospike integration. Its current emptiness suggests that no such data files are presently required or have been defined for this integration.",
            "spof": false
          },
          {
            "path": "aerospike/assets/configuration",
            "description": "This directory is designated to store configuration-related assets or files for the Datadog Aerospike integration. While currently empty, it would typically contain examples, schemas, or default configuration files necessary for setting up or understanding the integration's configuration.",
            "spof": false
          },
          {
            "path": "aerospike/assets/dashboards",
            "description": "This directory is designated to store JSON definitions for Datadog dashboards specifically tailored for the Aerospike integration. These dashboards would provide visualizations for metrics collected, aiding in monitoring the performance and health of Aerospike. Although currently empty, it serves as the intended location for these dashboard assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 14
          },
          {
            "name": "Sarah Wang",
            "percent": 13
          },
          {
            "name": "Kyle Neale",
            "percent": 13
          }
        ]
      },
      "Integration Testing": {
        "files": [
          {
            "path": "aerospike/tests/test_unit_openmetricsv2.py",
            "description": "This file contains unit tests for the Aerospike integration, specifically verifying the collection and tagging of Prometheus metrics via the OpenMetricsV2 endpoint.",
            "spof": false
          },
          {
            "path": "aerospike/tests/test_aerospike.py",
            "description": "This file contains integration and end-to-end tests for the Datadog Aerospike integration. It verifies metric collection, service checks, and version metadata reporting for various Aerospike versions and configurations.",
            "spof": false
          },
          {
            "path": "aerospike/tests/conftest.py",
            "description": "This file contains pytest fixtures and setup logic for integration tests of the Aerospike check, including spinning up a Dockerized Aerospike environment and populating it with sample data.",
            "spof": true
          },
          {
            "path": "aerospike/tests/__init__.py",
            "description": "Marks the `tests` directory as a Python package, enabling its modules to be imported and run as part of the test suite. This file is empty, serving only to define the package structure.",
            "spof": true
          },
          {
            "path": "aerospike/tests/common.py",
            "description": "This file defines common variables, configurations, and expected metric lists used across Aerospike integration tests. It includes host/port settings, various metric categories, and mock data for testing purposes.",
            "spof": true
          },
          {
            "path": "aerospike/tests/test_unit.py",
            "description": "This file contains unit tests for the Aerospike integration. It verifies the proper collection of various metrics like datacenter, XDR, sindex, and latency metrics, as well as connection handling, by mocking Aerospike client responses.",
            "spof": true
          },
          {
            "path": "aerospike/tests/fixtures",
            "description": "This directory is designated to store test fixtures for the Datadog Aerospike integration. These fixtures provide controlled data or states necessary for repeatable and reliable testing of the integration's functionalities. Although currently empty, it serves as the intended location for such test resources.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 66
          },
          {
            "name": "Hristo Voyvodov",
            "percent": 29
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 2
          }
        ]
      },
      "Aerospike Metric Collection": {
        "files": [
          {
            "path": "aerospike/datadog_checks/aerospike/metrics.py",
            "description": "This file defines a mapping of raw Aerospike metric names to a standardized format for use within the Datadog integration. It includes various metrics related to Aerospike namespaces, nodes, and XDR.",
            "spof": false
          },
          {
            "path": "aerospike/datadog_checks/aerospike/check.py",
            "description": "This file defines the Datadog check for collecting Aerospike metrics. It extends the OpenMetricsBaseCheckV2 to gather and process metrics from Aerospike instances.",
            "spof": true
          },
          {
            "path": "aerospike/datadog_checks/aerospike/aerospike.py",
            "description": "This file implements the legacy Datadog Agent check for monitoring Aerospike databases, collecting various metrics and performing service checks based on Aerospike's 'asinfo' commands and version compatibility.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 49
          },
          {
            "name": "Florent Clarret",
            "percent": 18
          },
          {
            "name": "Nathan Pezzotti",
            "percent": 9
          }
        ]
      },
      "Configuration Model Management": {
        "files": [
          {
            "path": "aerospike/datadog_checks/aerospike/config_models/defaults.py",
            "description": "This file defines default configuration values for the Aerospike integration, automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "aerospike/datadog_checks/aerospike/config_models/instance.py",
            "description": "This file defines the Pydantic models for the Aerospike integration's instance configuration, including schema validation and default values, and is automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "aerospike/datadog_checks/aerospike/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient access to the autogenerated instance and shared configuration models for the Aerospike integration. It serves as an entry point for configuration models generated from `spec.yaml`.",
            "spof": false
          },
          {
            "path": "aerospike/datadog_checks/aerospike/config_models/validators.py",
            "description": "This file contains a validation function for agent integration configurations. It specifically prevents the simultaneous use of 'metrics' and 'openmetrics_endpoint' parameters, guiding users towards recommended OpenMetrics settings.",
            "spof": true
          },
          {
            "path": "aerospike/datadog_checks/aerospike/config_models/shared.py",
            "description": "This autogenerated file defines Pydantic models for shared configuration settings, such as proxy details, used by the Datadog Aerospike integration, including validation logic.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 78
          },
          {
            "name": "Yann Armelin",
            "percent": 8
          },
          {
            "name": "Nathan Pezzotti",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 21,
      "spofCount": 10
    },
    "busFactor": 1,
    "authorCount": 8
  },
  "BeyondTrust Password Safe Audit": {
    "description": "Collects audit and activity logs from BeyondTrust Password Safe to monitor privileged account access and password management events.",
    "functions": {
      "Integration Packaging and Assets": {
        "files": [
          {
            "path": "beyondtrust_password_safe/README.md",
            "description": "This file provides detailed documentation for the BeyondTrust Password Safe integration with Datadog, covering setup instructions for log collection via Agent/Event Forwarder and Audit API, and outlining the types of data collected.",
            "spof": true
          },
          {
            "path": "beyondtrust_password_safe/CHANGELOG.md",
            "description": "This file documents all notable changes, new features, and bug fixes for the BeyondTrust Password Safe integration across different versions.",
            "spof": false
          },
          {
            "path": "beyondtrust_password_safe/datadog_checks/__init__.py",
            "description": "This `__init__.py` file defines `datadog_checks` as a Python namespace package, ensuring that the `beyondtrust_password_safe` integration's modules are discoverable within this namespace.",
            "spof": true
          },
          {
            "path": "beyondtrust_password_safe/datadog_checks/beyondtrust_password_safe/__init__.py",
            "description": "This file marks the directory as a Python package and exposes the package's version number.",
            "spof": true
          },
          {
            "path": "beyondtrust_password_safe/datadog_checks/beyondtrust_password_safe/data",
            "description": "This directory is intended to store static data or configuration files specifically for the `beyondtrust_password_safe` Datadog integration. As it is currently empty, it serves as a placeholder for potential future data assets required by the check.",
            "spof": false
          },
          {
            "path": "beyondtrust_password_safe/images",
            "description": "This directory is intended to store any images, such as icons, logos, or screenshots, that are directly associated with the 'beyondtrust_password_safe' integration. These images would typically be used for documentation, dashboards, or UI elements related to the integration's presence in Datadog.",
            "spof": false
          },
          {
            "path": "beyondtrust_password_safe/assets/dashboards",
            "description": "This directory is intended to store Datadog dashboard configurations specific to the BeyondTrust Password Safe integration. These configurations define the visualizations and metrics displayed within Datadog for monitoring the integration's performance and status.",
            "spof": false
          },
          {
            "path": "beyondtrust_password_safe/assets/configuration",
            "description": "This directory is designated to store configuration-related assets for the BeyondTrust Password Safe integration. It would typically contain templates or example configuration files, although it is currently empty.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "manan-crest",
            "percent": 73
          },
          {
            "name": "Akshit Vaid",
            "percent": 15
          },
          {
            "name": "HadhemiDD",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 8,
      "spofCount": 3
    },
    "busFactor": 2,
    "authorCount": 3
  },
  "VMware Carbon Black Cloud Integration": {
    "description": "Ingests security event logs from Carbon Black Cloud to monitor endpoint protection and threat detection.",
    "functions": {
      "Integration Assets and Dashboards": {
        "files": [
          {
            "path": "carbon_black_cloud/CHANGELOG.md",
            "description": "This file documents the version history and changes made to the Carbon Black Cloud integration, detailing updates and new features across releases.",
            "spof": true
          },
          {
            "path": "carbon_black_cloud/README.md",
            "description": "This README describes the integration of Carbon Black Cloud with Datadog. It details the setup steps for data forwarding to send security event logs from Carbon Black Cloud to Datadog for monitoring and analysis.",
            "spof": true
          },
          {
            "path": "carbon_black_cloud/images",
            "description": "This directory is designated for storing image assets relevant to the `carbon_black_cloud` integration. These images likely include icons, logos, or other graphical elements used for documentation, dashboards, or UI within the Datadog integration.",
            "spof": false
          },
          {
            "path": "carbon_black_cloud/assets/dashboards",
            "description": "This directory is designated to store pre-configured Datadog dashboards specifically tailored for the Carbon Black Cloud integration. These dashboards would typically provide visualizations for metrics and logs collected, aiding users in monitoring and analysis.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "ravindrasojitra-crest",
            "percent": 92
          },
          {
            "name": "dkirov-dd",
            "percent": 8
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "Ambari Cluster Management Monitoring": {
    "description": "Monitors Ambari-managed Hadoop clusters, collecting health and performance metrics for hosts and big data services.",
    "functions": {
      "Ambari Metric and Status Collection": {
        "files": [
          {
            "path": "ambari/README.md",
            "description": "This file is the README documentation for the Datadog Agent's Ambari integration. It details how to set up, configure, and validate the Ambari check for metric and log collection, including host-based and containerized deployments.",
            "spof": false
          },
          {
            "path": "ambari/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Ambari integration, detailing all version updates, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "ambari/tests/test_common.py",
            "description": "Tests the utility function `create_endpoint` which constructs Ambari API URLs for different services and paths.",
            "spof": true
          },
          {
            "path": "ambari/tests/conftest.py",
            "description": "This file provides pytest fixtures for testing the Datadog Ambari integration, including a mock instance configuration and initial configuration settings.",
            "spof": true
          },
          {
            "path": "ambari/tests/__init__.py",
            "description": "This empty __init__.py file marks the 'tests' directory as a Python package, enabling test discovery and organization for the Ambari integration.",
            "spof": false
          },
          {
            "path": "ambari/tests/manual_test.py",
            "description": "This file contains a manual pytest for the Datadog Ambari integration, configuring and testing the `AmbariCheck` with specific instance settings and metric collection.",
            "spof": true
          },
          {
            "path": "ambari/tests/responses.py",
            "description": "This file contains mock API responses for testing the Datadog Ambari integration. It includes simulated data for host metrics, host information, and component-specific metrics, such as those from an HDFS Datanode.",
            "spof": true
          },
          {
            "path": "ambari/tests/test_ambari.py",
            "description": "This file contains unit and integration tests for the Datadog Ambari integration. It verifies the check's ability to connect, collect various host, service, and component metrics, report service checks, and handle different configuration settings.",
            "spof": true
          },
          {
            "path": "ambari/datadog_checks/ambari/common.py",
            "description": "This file defines common constants, URL templates for the Ambari API, and utility functions for processing Ambari service statuses within the Datadog Ambari integration.",
            "spof": true
          },
          {
            "path": "ambari/datadog_checks/ambari/__init__.py",
            "description": "This `__init__.py` file initializes the `ambari` Python package, making `__version__` and `AmbariCheck` available for import when the package is used.",
            "spof": false
          },
          {
            "path": "ambari/datadog_checks/ambari/ambari.py",
            "description": "This file implements the Datadog Agent check for Ambari, collecting metrics and service statuses from Ambari clusters, hosts, and services. It reports these as gauges and service checks to Datadog.",
            "spof": true
          },
          {
            "path": "ambari/datadog_checks/ambari/data",
            "description": "This directory is designated to store static data files or configuration data specifically for the Datadog Ambari integration. While currently empty, it would typically contain assets like default metric definitions, service check configurations, or other lookup tables required by the check.",
            "spof": false
          },
          {
            "path": "ambari/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions or configurations specifically for the Datadog Ambari integration. It serves as a placeholder for UI assets that visualize metrics and logs collected from Ambari.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 17
          },
          {
            "name": "HadhemiDD",
            "percent": 15
          },
          {
            "name": "Kyle Neale",
            "percent": 15
          }
        ]
      },
      "Integration Configuration Management": {
        "files": [
          {
            "path": "ambari/datadog_checks/ambari/config_models/validators.py",
            "description": "This file is intended to define custom configuration validators and transformers for the Ambari integration, allowing for additional checks and modifications to the integration's configuration values.",
            "spof": true
          },
          {
            "path": "ambari/datadog_checks/ambari/config_models/defaults.py",
            "description": "This file contains autogenerated default configuration values and settings for the Datadog Ambari integration. It defines default functions for shared and instance-specific parameters, such as timeouts, metric collection, and authentication types.",
            "spof": true
          },
          {
            "path": "ambari/datadog_checks/ambari/config_models/__init__.py",
            "description": "This autogenerated file defines the `ConfigMixin` class, providing properties to access instance-specific and shared configuration models for the Ambari integration.",
            "spof": false
          },
          {
            "path": "ambari/datadog_checks/ambari/config_models/shared.py",
            "description": "This file defines shared Pydantic models for configuration, including validation and default value handling, used across Datadog integrations. It is an autogenerated file from a `spec.yaml`.",
            "spof": true
          },
          {
            "path": "ambari/datadog_checks/ambari/config_models/instance.py",
            "description": "This file defines the Pydantic models for an Ambari integration instance's configuration, including nested models for authentication, metric patterns, and proxy settings. It is autogenerated from a specification file to enforce configuration schema and validation.",
            "spof": true
          },
          {
            "path": "ambari/assets/configuration",
            "description": "This directory is designated to store configuration assets for the Datadog Ambari integration. It would typically contain templates, examples, or default settings necessary for the integration's setup and operation.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 85
          },
          {
            "name": "Yann Armelin",
            "percent": 13
          },
          {
            "name": "Steven Yuen",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 19,
      "spofCount": 11
    },
    "busFactor": 1,
    "authorCount": 5
  },
  "Apache HTTP Server Monitoring": {
    "description": "Monitors the performance and health of Apache HTTP servers by collecting metrics on traffic, connections, and worker status.",
    "functions": {
      "Packaged Monitoring Assets": {
        "files": [
          {
            "path": "apache/CHANGELOG.md",
            "description": "This file documents all notable changes, additions, and fixes across different versions of the Datadog Apache integration. It serves as a release history for the Apache check.",
            "spof": false
          },
          {
            "path": "apache/README.md",
            "description": "This README provides instructions on how to set up and configure the Datadog Agent to monitor Apache web servers. It details how to collect Apache metrics and logs across different environments like Host, Docker, Kubernetes, and ECS.",
            "spof": false
          },
          {
            "path": "apache/images",
            "description": "This directory is intended to store image assets specifically for the Datadog Apache integration. It serves as a dedicated location for visual resources related to this monitoring integration.",
            "spof": false
          },
          {
            "path": "apache/assets/saved_views",
            "description": "This directory is intended to store pre-defined configurations or templates for saved views related to the Apache integration. These saved views likely provide pre-configured dashboards or visualizations for monitoring Apache web servers within Datadog.",
            "spof": false
          },
          {
            "path": "apache/assets/monitors",
            "description": "This directory is part of the Datadog Apache integration within the `integrations-core` repository. It is designated to store monitor definitions for the Apache integration. These monitors are used to alert on the health and performance of Apache services.",
            "spof": false
          },
          {
            "path": "apache/assets/dashboards",
            "description": "This directory is intended to contain pre-configured dashboards specifically for the Apache integration. These dashboards provide visualizations of metrics collected from Apache servers, facilitating monitoring and analysis within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Wang",
            "percent": 19
          },
          {
            "name": "Kyle Neale",
            "percent": 15
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 14
          }
        ]
      },
      "Apache Metric Collection": {
        "files": [
          {
            "path": "apache/tests/common.py",
            "description": "This file defines common constants, URLs, and test configurations for the Apache integration's test suite. It includes various test configurations, such as URLs for different status pages and lists of expected Apache metrics (gauges and rates).",
            "spof": false
          },
          {
            "path": "apache/tests/conftest.py",
            "description": "This `conftest.py` file provides pytest fixtures and helper functions to set up and manage a Dockerized Apache test environment, generate test metrics, and mock HTTP requests for the Apache integration tests.",
            "spof": true
          },
          {
            "path": "apache/tests/__init__.py",
            "description": "This `__init__.py` file marks the 'tests' directory as a Python package, enabling Python to recognize and import modules from within it. It contains only copyright and licensing information.",
            "spof": true
          },
          {
            "path": "apache/tests/test_apache.py",
            "description": "This file contains unit and integration tests for the Datadog Apache integration, covering various scenarios like connection failures, metric collection, metadata submission, and scoreboard parsing.",
            "spof": true
          },
          {
            "path": "apache/datadog_checks/apache/__init__.py",
            "description": "This file serves as the package initializer for the Apache integration, exposing the package version and the main Apache check class.",
            "spof": false
          },
          {
            "path": "apache/datadog_checks/apache/apache.py",
            "description": "This file implements the Datadog Agent check for Apache, collecting metrics like worker status, requests, and network usage from the Apache mod_status page, and submitting them to Datadog.",
            "spof": false
          },
          {
            "path": "apache/datadog_checks/apache/config_models/validators.py",
            "description": "This file is intended for defining custom validators or transformers for the Apache integration's configuration models, allowing for data manipulation or validation logic during configuration initialization.",
            "spof": true
          },
          {
            "path": "apache/datadog_checks/apache/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient accessors for instance-specific and shared configuration models of the Apache integration. It acts as an entry point for accessing autogenerated configuration models.",
            "spof": false
          },
          {
            "path": "apache/datadog_checks/apache/config_models/instance.py",
            "description": "This file defines Pydantic models for the configuration schema of an Apache integration instance. It is an autogenerated file based on a configuration specification.",
            "spof": true
          },
          {
            "path": "apache/datadog_checks/apache/config_models/shared.py",
            "description": "This file defines shared Pydantic configuration models for the Apache integration. It includes validation logic and default value handling for common configuration options like proxy settings and timeouts.",
            "spof": true
          },
          {
            "path": "apache/datadog_checks/apache/config_models/defaults.py",
            "description": "This file contains autogenerated Python functions that define default configuration values for the Datadog Apache integration. These defaults are generated from a `spec.yaml` file.",
            "spof": true
          },
          {
            "path": "apache/datadog_checks/apache/data",
            "description": "This directory is intended to store static data or configuration files specific to the Apache integration. Although currently empty, it serves as a designated location for such assets, should they be needed.",
            "spof": false
          },
          {
            "path": "apache/assets/configuration",
            "description": "This directory is intended to store configuration assets for the Datadog Apache integration. It would typically contain example configuration files or default settings required for the integration to function correctly. As it currently contains no files, it may serve as a placeholder.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 69
          },
          {
            "name": "Yann Armelin",
            "percent": 11
          },
          {
            "name": "dkirov-dd",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 19,
      "spofCount": 7
    },
    "busFactor": 2,
    "authorCount": 8
  },
  "AWS Neuron Monitoring": {
    "description": "Collects performance metrics from AWS Neuron devices (Inferentia and Trainium) to monitor machine learning inference and training workloads.",
    "functions": {
      "Integration Assets and Presentation": {
        "files": [
          {
            "path": "aws_neuron/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor AWS Neuron devices (Inferentia and Trainium). It details installation, metric collection, log configuration, and validation for this integration.",
            "spof": true
          },
          {
            "path": "aws_neuron/CHANGELOG.md",
            "description": "This file is the changelog for the AWS Neuron integration, documenting version updates, new features, and bug fixes over time.",
            "spof": false
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/data",
            "description": "This directory is designated for holding data files or static assets pertinent to the AWS Neuron Datadog integration. While currently empty, it serves as the intended location for configurations, default settings, or other supporting resources used by the check.",
            "spof": false
          },
          {
            "path": "aws_neuron/assets/monitors",
            "description": "This directory is a placeholder for monitoring-related assets for the Datadog AWS Neuron integration. It would typically contain configuration files or definitions for monitors relevant to this integration, though it is currently empty.",
            "spof": false
          },
          {
            "path": "aws_neuron/assets/dashboards",
            "description": "This directory is designated to store Datadog dashboard definitions specific to the AWS Neuron integration. These dashboards would typically provide visualizations for metrics collected from AWS Neuron instances.",
            "spof": false
          },
          {
            "path": "aws_neuron/assets/saved_views",
            "description": "This directory is designated to store pre-configured saved views or dashboard definitions specifically for the AWS Neuron integration. These assets would provide users with ready-to-use visualizations and insights into their AWS Neuron environments within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 31
          },
          {
            "name": "Kyle Neale",
            "percent": 16
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 16
          }
        ]
      },
      "Neuron Metric Collection and Configuration": {
        "files": [
          {
            "path": "aws_neuron/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the AWS Neuron integration. It verifies that the integration collects expected metrics and reports a healthy service check.",
            "spof": true
          },
          {
            "path": "aws_neuron/tests/conftest.py",
            "description": "This file contains pytest fixtures for setting up and tearing down the test environment for the AWS Neuron integration, including Docker container management and providing a mocked instance configuration.",
            "spof": true
          },
          {
            "path": "aws_neuron/tests/test_unit.py",
            "description": "This file contains unit tests for the `AwsNeuronCheck` integration. It verifies metric collection, tag assertion, and configuration validation for the AWS Neuron integration check.",
            "spof": true
          },
          {
            "path": "aws_neuron/tests/common.py",
            "description": "This file defines common constants, helper functions, and configuration used across the `aws_neuron` integration's test suite, including mocked instance settings, Docker compose paths, and expected metric definitions.",
            "spof": true
          },
          {
            "path": "aws_neuron/tests/__init__.py",
            "description": "This `__init__.py` file marks the `tests` directory for the `aws_neuron` integration as a Python package.",
            "spof": true
          },
          {
            "path": "aws_neuron/tests/docker",
            "description": "This directory is designated for Docker-related testing configurations and files for the `aws_neuron` integration. It would typically house Dockerfiles or compose files necessary for setting up a containerized test environment, even if currently empty.",
            "spof": false
          },
          {
            "path": "aws_neuron/tests/fixtures",
            "description": "This directory is designated to store various test fixtures, such as sample data, mock objects, or configuration files, specifically for the `aws_neuron` integration tests. Its purpose is to provide controlled and consistent data or environments for test execution.",
            "spof": false
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/metrics.py",
            "description": "This file defines mappings for metric names and label renamings used by the Datadog AWS Neuron integration to standardize collected data.",
            "spof": true
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/check.py",
            "description": "This file defines the `AwsNeuronCheck` class, which is a Datadog integration check responsible for collecting metrics from AWS Neuron using the OpenMetricsBaseCheckV2 framework. It configures metric mapping and label renaming for the collected data.",
            "spof": true
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/__init__.py",
            "description": "This `__init__.py` file initializes the `aws_neuron` Python package. It imports and exposes the package's version and the main `AwsNeuronCheck` class, defining the public interface of the package.",
            "spof": true
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/config_models/validators.py",
            "description": "This file provides validation functions for configuration parameters, specifically for URL endpoints like the `openmetrics_endpoint`, ensuring they have the correct scheme, network location, and path.",
            "spof": true
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides access to autogenerated configuration models (`InstanceConfig` and `SharedConfig`) for the AWS Neuron integration, enabling structured access to its settings.",
            "spof": true
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/config_models/defaults.py",
            "description": "This file defines default configuration values for the `aws_neuron` integration. It is automatically generated from the integration's specification YAML file.",
            "spof": true
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration parameters, such as proxy settings and timeouts, used across Datadog checks. It is an autogenerated file from a `spec.yaml`.",
            "spof": true
          },
          {
            "path": "aws_neuron/datadog_checks/aws_neuron/config_models/instance.py",
            "description": "This file defines the Pydantic data model for the `aws_neuron` integration's instance-level configuration, including sub-models and validation logic. It is autogenerated from the integration's specification file.",
            "spof": true
          },
          {
            "path": "aws_neuron/assets/configuration",
            "description": "This directory is intended to house configuration files and assets for the Datadog AWS Neuron integration. It defines how the integration can be configured for various deployments, though it currently appears to be empty.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 97
          },
          {
            "name": "Yann Armelin",
            "percent": 2
          },
          {
            "name": "Juanpe Araque",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 22,
      "spofCount": 14
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Barracuda SecureEdge Integration": {
    "description": "Collects security, traffic, and system logs from Barracuda SecureEdge to monitor SASE (Secure Access Service Edge) activity.",
    "functions": {
      "Integration Asset and Package Management": {
        "files": [
          {
            "path": "barracuda_secure_edge/CHANGELOG.md",
            "description": "This file is the changelog for the Barracuda Secure Edge integration, documenting all changes and version releases over time.",
            "spof": false
          },
          {
            "path": "barracuda_secure_edge/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent integration for Barracuda SecureEdge, detailing how to collect and analyze logs for security events, network traffic, and system activity.",
            "spof": false
          },
          {
            "path": "barracuda_secure_edge/images",
            "description": "This directory is intended to store image assets specific to the Datadog Barracuda SecureEdge integration. These images would typically be used for documentation, dashboards, or other visual elements related to the integration. It is currently empty.",
            "spof": false
          },
          {
            "path": "barracuda_secure_edge/datadog_checks/barracuda_secure_edge/__init__.py",
            "description": "Initializes the `barracuda_secure_edge` package, exposing its version information. This file primarily serves to define package-level attributes like `__version__`.",
            "spof": true
          },
          {
            "path": "barracuda_secure_edge/datadog_checks/barracuda_secure_edge/data",
            "description": "This `data` directory is intended to store any static data files or assets required by the Barracuda Secure Edge Datadog integration. Currently, it is empty, suggesting no such static data is required for its operation or is generated dynamically.",
            "spof": false
          },
          {
            "path": "barracuda_secure_edge/assets/dashboards",
            "description": "This directory is designated for storing JSON definitions of Datadog dashboards specific to the Barracuda SecureEdge integration. These dashboards would provide visual representations of metrics and logs collected, enabling monitoring and analysis. Although currently empty, it serves as the intended location for such assets.",
            "spof": false
          },
          {
            "path": "barracuda_secure_edge/assets/configuration",
            "description": "This directory is intended to house configuration assets for the Datadog Barracuda Secure Edge integration. It would typically contain default configuration files, examples, or schema definitions necessary for its setup. Although currently empty, its purpose is to centralize configuration-related resources for the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 54
          },
          {
            "name": "vinodkumar-sacumen",
            "percent": 39
          },
          {
            "name": "HadhemiDD",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 7,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "Device Battery Health Monitoring": {
    "description": "Monitors the battery health, charge level, and status on macOS and Windows laptops for IT asset management and device health tracking.",
    "functions": {
      "Integration Packaging and Documentation": {
        "files": [
          {
            "path": "battery/CHANGELOG.md",
            "description": "This file documents the version history and changes for the Datadog 'battery' integration, starting with its initial release.",
            "spof": true
          },
          {
            "path": "battery/README.md",
            "description": "This file is the README documentation for the Datadog Agent's 'battery' check. It describes how the check monitors battery health on MacOS and Windows laptops, along with setup, configuration, and data collected.",
            "spof": true
          },
          {
            "path": "battery/assets",
            "description": "This directory is intended to store static assets, such as images or icons, for the 'battery' integration within the Datadog integrations-core repository. Currently, it is empty, suggesting no specific assets are presently required or have been added. Its primary role is to centralize visual or static resources for the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mohammad Rafi",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Check Point Harmony Email & Collaboration Security": {
    "description": "Ingests security logs from Check Point Harmony to monitor threats in email and collaboration applications like Office 365 and G Suite.",
    "functions": {
      "Integration Assets and Dashboards": {
        "files": [
          {
            "path": "checkpoint_harmony_email_and_collaboration/CHANGELOG.md",
            "description": "This file is the changelog for the `checkpoint_harmony_email_and_collaboration` integration, documenting all changes and releases over time.",
            "spof": true
          },
          {
            "path": "checkpoint_harmony_email_and_collaboration/README.md",
            "description": "This README details the Datadog integration for Check Point Harmony Email & Collaboration, explaining its security monitoring capabilities for various cyber threats and providing setup instructions.",
            "spof": true
          },
          {
            "path": "checkpoint_harmony_email_and_collaboration/images",
            "description": "This directory is designated for storing image assets. These images are specific to the Check Point Harmony Email and Collaboration integration, likely used for its documentation or visual representation within Datadog.",
            "spof": false
          },
          {
            "path": "checkpoint_harmony_email_and_collaboration/assets/dashboards",
            "description": "This directory is designated to store JSON definitions for Datadog dashboards. These dashboards are specifically designed to visualize metrics and logs collected from the Checkpoint Harmony Email and Collaboration integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "shubhamvekariya-crest",
            "percent": 90
          },
          {
            "name": "dkirov-dd",
            "percent": 10
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "cert-manager Certificate Monitoring": {
    "description": "Monitors `cert-manager` in Kubernetes to track the status and lifecycle of TLS certificates, ensuring their validity.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "cert_manager/CHANGELOG.md",
            "description": "This file is the changelog for the `cert_manager` integration, documenting all version releases, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "cert_manager/README.md",
            "description": "This file is the README for the Datadog Agent's `cert_manager` integration. It provides instructions on how to set up, configure, and troubleshoot the check to collect metrics and service checks from cert-manager.",
            "spof": false
          },
          {
            "path": "cert_manager/images",
            "description": "This directory is designated for storing image assets pertinent to the `cert_manager` integration. These images could include diagrams, screenshots, or icons for documentation, UI, or other visual resources related to the integration.",
            "spof": false
          },
          {
            "path": "cert_manager/datadog_checks/cert_manager/data",
            "description": "This directory is intended to house data files specific to the `cert_manager` Datadog integration. These might include default configurations, static assets, or other resources required by the check. Although currently empty, it serves as a placeholder for such integration-specific data.",
            "spof": false
          },
          {
            "path": "cert_manager/assets/configuration",
            "description": "This directory is designated to store configuration files or examples specific to the `cert_manager` integration. It serves as a central location for integration-related settings and setup assets within the `integrations-core` repository.",
            "spof": false
          },
          {
            "path": "cert_manager/assets/dashboards",
            "description": "This directory is designated to store JSON definitions or configurations for Datadog dashboards specific to the `cert_manager` integration. These dashboards would typically provide pre-built visualizations for monitoring Cert Manager metrics and status.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 21
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 19
          },
          {
            "name": "HadhemiDD",
            "percent": 14
          }
        ]
      },
      "Integration Testing Suite": {
        "files": [
          {
            "path": "cert_manager/tests/test_e2e.py",
            "description": "This file contains end-to-end (e2e) tests for the `cert_manager` integration, ensuring it correctly collects and reports metrics from a running agent.",
            "spof": true
          },
          {
            "path": "cert_manager/tests/test_cert_manager.py",
            "description": "This file contains unit tests for the Datadog `CertManagerCheck` integration, verifying metric collection, configuration, and error handling using mocked HTTP responses and a Prometheus fixture.",
            "spof": true
          },
          {
            "path": "cert_manager/tests/common.py",
            "description": "This file defines common constants, such as expected metric names and types, and mock instance configurations used across tests for the Datadog Cert Manager integration.",
            "spof": false
          },
          {
            "path": "cert_manager/tests/__init__.py",
            "description": "Marks the 'tests' directory as a Python package, allowing test modules within it to be imported.",
            "spof": true
          },
          {
            "path": "cert_manager/tests/conftest.py",
            "description": "This file provides pytest fixtures to set up a Kubernetes environment with Cert Manager for integration testing of the Datadog Cert Manager check. It deploys Cert Manager, issues various certificates, and configures a testing environment with an OpenMetrics endpoint.",
            "spof": false
          },
          {
            "path": "cert_manager/tests/fixtures",
            "description": "This directory is intended to store test fixtures for the `cert_manager` integration. These fixtures provide predefined test data, mock configurations, or other assets needed to set up and execute unit or integration tests for the integration.",
            "spof": false
          },
          {
            "path": "cert_manager/tests/kubernetes",
            "description": "This directory is intended to house tests specifically designed for the Cert Manager integration when deployed or interacting with Kubernetes environments. Although currently empty, it establishes a dedicated location for future Kubernetes-related test files, ensuring a structured approach to integration testing.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 37
          },
          {
            "name": "David Ortiz",
            "percent": 37
          },
          {
            "name": "David Jones",
            "percent": 17
          }
        ]
      },
      "Certificate Monitoring and Configuration": {
        "files": [
          {
            "path": "cert_manager/datadog_checks/cert_manager/__init__.py",
            "description": "This file initializes the `cert_manager` package, exposing the integration's version and the main `CertManagerCheck` class for use.",
            "spof": true
          },
          {
            "path": "cert_manager/datadog_checks/cert_manager/metrics.py",
            "description": "This file defines mappings for Cert Manager metrics, including certificate, controller, and ACME client-related metrics, for use within the Datadog integration.",
            "spof": false
          },
          {
            "path": "cert_manager/datadog_checks/cert_manager/cert_manager.py",
            "description": "This file defines the Datadog integration check for Cert Manager, designed to collect metrics related to its controller, ACME challenges, and certificates. It leverages the OpenMetricsBaseCheckV2 for metric collection.",
            "spof": true
          },
          {
            "path": "cert_manager/datadog_checks/cert_manager/config_models/validators.py",
            "description": "This file is intended for defining custom configuration validators or transformers for the cert_manager integration. It provides an entry point to modify or validate configuration values before they are used.",
            "spof": true
          },
          {
            "path": "cert_manager/datadog_checks/cert_manager/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient access to autogenerated instance-specific and shared configuration models for the Datadog cert_manager integration. It acts as an entry point for configuration models within the integration.",
            "spof": true
          },
          {
            "path": "cert_manager/datadog_checks/cert_manager/config_models/instance.py",
            "description": "This file defines the Pydantic models for the 'cert_manager' integration's instance configuration, including schema validation and default value handling. It is autogenerated from a specification file.",
            "spof": false
          },
          {
            "path": "cert_manager/datadog_checks/cert_manager/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration settings, such as proxy and timeout, used by the Datadog Cert Manager integration. It is an autogenerated file that includes validation and default value handling for these configurations.",
            "spof": true
          },
          {
            "path": "cert_manager/datadog_checks/cert_manager/config_models/defaults.py",
            "description": "This file defines default values for various configuration parameters of the Datadog `cert_manager` integration. It is an autogenerated file, with its content derived from the integration's `spec.yaml`.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Florent Clarret",
            "percent": 82
          },
          {
            "name": "Yann Armelin",
            "percent": 9
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 21,
      "spofCount": 9
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Ceph Storage Monitoring": {
    "description": "Monitors Ceph distributed storage clusters, collecting metrics on cluster health, OSDs, pools, and performance.",
    "functions": {
      "User-Facing Assets and Documentation": {
        "files": [
          {
            "path": "ceph/README.md",
            "description": "This file is the README for the Datadog-Ceph integration, providing instructions on its setup, configuration, and how to monitor Ceph metrics, logs, and service checks using Datadog.",
            "spof": false
          },
          {
            "path": "ceph/CHANGELOG.md",
            "description": "This file is the changelog for the Ceph integration, documenting all changes, additions, and fixes across different versions. It serves as a historical record of updates for the Ceph integration.",
            "spof": false
          },
          {
            "path": "ceph/images",
            "description": "This directory is intended to store visual assets, such as icons or logos, specifically for the Ceph integration. Although currently empty, its purpose is to house images relevant to the integration's documentation or user interface.",
            "spof": false
          },
          {
            "path": "ceph/assets/dashboards",
            "description": "This directory is designated to store dashboard assets for the Datadog Ceph integration. It contains configuration files or templates used to visualize metrics and logs from Ceph clusters within the Datadog platform.",
            "spof": false
          },
          {
            "path": "ceph/assets/configuration",
            "description": "This directory is intended to house configuration examples or default configuration files specifically for the Ceph integration. As part of the integration's assets, its purpose is to provide users with a starting point for setting up monitoring. Currently, it is empty, indicating no default configurations are provided within this location.",
            "spof": false
          },
          {
            "path": "ceph/assets/saved_views",
            "description": "This directory is intended to store pre-configured saved views or dashboard definitions for the Datadog Ceph integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 22
          },
          {
            "name": "HadhemiDD",
            "percent": 18
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 17
          }
        ]
      },
      "Integration Test Suite": {
        "files": [
          {
            "path": "ceph/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Ceph check. It verifies that the Ceph integration correctly collects metrics and service checks from a running Ceph environment.",
            "spof": true
          },
          {
            "path": "ceph/tests/common.py",
            "description": "This file defines common constants, expected metrics, service checks, and utility functions for testing the Ceph integration.",
            "spof": false
          },
          {
            "path": "ceph/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Ceph integration. It verifies that the integration correctly collects expected metrics and service checks from a Ceph cluster.",
            "spof": true
          },
          {
            "path": "ceph/tests/__init__.py",
            "description": "This empty `__init__.py` file designates the `ceph/tests` directory as a Python package, enabling test discovery and execution within the Ceph integration tests.",
            "spof": true
          },
          {
            "path": "ceph/tests/conftest.py",
            "description": "This file provides a pytest fixture to set up and tear down a Ceph Docker environment for end-to-end testing of the Datadog Ceph integration. It defines the Docker Compose setup, waits for services to become ready, and applies initial configurations to the Ceph cluster.",
            "spof": true
          },
          {
            "path": "ceph/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Ceph integration, verifying that it correctly collects and reports metrics and service checks under various simulated Ceph cluster health and configuration scenarios.",
            "spof": false
          },
          {
            "path": "ceph/tests/fixtures",
            "description": "This directory is designated to store test fixtures for the Ceph integration. These fixtures would provide pre-defined data or configurations necessary for setting up and executing various tests for the Ceph integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Witt",
            "percent": 68
          },
          {
            "name": "apritcha1",
            "percent": 20
          },
          {
            "name": "Juanpe Araque",
            "percent": 7
          }
        ]
      },
      "Ceph Metric Collection and Configuration": {
        "files": [
          {
            "path": "ceph/datadog_checks/ceph/__init__.py",
            "description": "This `__init__.py` file defines the `ceph` Python package, making the `Ceph` check class and the package version (`__version__`) directly accessible upon import.",
            "spof": true
          },
          {
            "path": "ceph/datadog_checks/ceph/ceph.py",
            "description": "This file implements a Datadog Agent check for monitoring Ceph clusters. It collects various metrics, health statuses, and events from Ceph by executing 'ceph' commands and parsing their JSON output.",
            "spof": true
          },
          {
            "path": "ceph/datadog_checks/ceph/config_models/validators.py",
            "description": "This file is intended for defining custom validation and transformation logic for the Ceph integration's configuration. It provides a dedicated place for functions to modify or validate configuration values before they are used.",
            "spof": true
          },
          {
            "path": "ceph/datadog_checks/ceph/config_models/defaults.py",
            "description": "This file defines default configuration values for the Ceph integration, autogenerated from the spec.yaml file. It provides default settings for various instance-level parameters like cluster name, command path, and collection interval.",
            "spof": true
          },
          {
            "path": "ceph/datadog_checks/ceph/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient access to autogenerated instance and shared configuration models for the Ceph integration. It serves as an entry point for configuration models, allowing other parts of the integration to easily retrieve configuration settings.",
            "spof": false
          },
          {
            "path": "ceph/datadog_checks/ceph/config_models/instance.py",
            "description": "This file defines the Pydantic models for the Ceph integration's instance configuration, including schema, default values, and validation logic. It is autogenerated from a spec.yaml file.",
            "spof": true
          },
          {
            "path": "ceph/datadog_checks/ceph/config_models/shared.py",
            "description": "This file defines the `SharedConfig` Pydantic model, providing a standardized structure for shared configuration options within the Ceph integration. It includes autogenerated validation logic derived from a `spec.yaml`.",
            "spof": true
          },
          {
            "path": "ceph/datadog_checks/ceph/data",
            "description": "This directory is intended to store static data files or configuration templates specific to the Ceph Datadog integration. Although currently empty, its purpose is to hold supplementary resources used by the `ceph` check.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Dan Meyers",
            "percent": 79
          },
          {
            "name": "Ofek Lev",
            "percent": 12
          },
          {
            "name": "apritcha1",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 21,
      "spofCount": 10
    },
    "busFactor": 3,
    "authorCount": 10
  },
  "Celery Task Queue Monitoring": {
    "description": "Monitors Celery distributed task queues by collecting metrics on tasks, workers, and broker health via the Flower API.",
    "functions": {
      "Declarative Assets and Documentation": {
        "files": [
          {
            "path": "celery/CHANGELOG.md",
            "description": "This file is the changelog for the Celery integration. It tracks all the version releases, new features, bug fixes, and other changes made to the integration over time.",
            "spof": false
          },
          {
            "path": "celery/README.md",
            "description": "This README.md file describes the Datadog Agent check for Celery, detailing how to set up and configure the integration to monitor Celery's task queue system, worker health, and task execution metrics.",
            "spof": true
          },
          {
            "path": "celery/assets/monitors",
            "description": "This directory is intended to store Datadog monitor definitions or configurations specifically for the Celery integration. These monitors would be used to observe and alert on the health and performance of Celery instances. Although currently empty, its purpose is to house these monitoring assets.",
            "spof": false
          },
          {
            "path": "celery/assets/dashboards",
            "description": "This directory is designated to store JSON definitions for pre-built Datadog dashboards specific to the Celery integration. Its purpose is to provide ready-to-use visualization assets for monitoring Celery metrics and logs within the Datadog platform.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 61
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 11
          },
          {
            "name": "HadhemiDD",
            "percent": 7
          }
        ]
      },
      "Integration Test Suite": {
        "files": [
          {
            "path": "celery/tests/test_unit.py",
            "description": "This file contains unit tests for the Celery integration's `CeleryCheck` class, verifying its functionality for metric collection, service checks, and error handling with the Flower OpenMetrics endpoint.",
            "spof": true
          },
          {
            "path": "celery/tests/common.py",
            "description": "This file provides common utilities, constants, and test configurations (like host, port, mocked instance, expected metrics, and E2E metadata) for the Celery integration tests.",
            "spof": true
          },
          {
            "path": "celery/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Celery integration, verifying that metrics and service checks are collected correctly by the Datadog Agent.",
            "spof": true
          },
          {
            "path": "celery/tests/conftest.py",
            "description": "This `conftest.py` file defines pytest fixtures for the Celery integration tests. It sets up a Dockerized Redis environment and provides a mocked instance configuration for testing purposes.",
            "spof": true
          },
          {
            "path": "celery/tests/__init__.py",
            "description": "This file marks the 'tests' directory of the Celery integration as a Python package, enabling the import of its test modules.",
            "spof": true
          },
          {
            "path": "celery/tests/fixtures",
            "description": "This directory is intended to store test fixtures or setup data specifically for the Celery integration's tests within the Datadog integrations-core repository. While currently empty, it serves as a designated location for test-related resources to ensure consistent and reproducible testing environments.",
            "spof": false
          },
          {
            "path": "celery/tests/docker/proj/tasks.py",
            "description": "This file defines Celery tasks for basic arithmetic operations (addition and multiplication), demonstrating task execution and state updates within a Celery application, likely for testing purposes.",
            "spof": true
          },
          {
            "path": "celery/tests/docker/proj/producer.py",
            "description": "This file acts as a Celery task producer, continuously submitting 'add' and 'multiply' tasks to a Celery broker at regular intervals. It logs the IDs of the submitted tasks and handles potential submission errors.",
            "spof": true
          },
          {
            "path": "celery/tests/docker/config",
            "description": "This directory is designated for storing configuration files specifically tailored for the Docker test environments of the Celery integration. It facilitates the setup and customization of Docker containers used during the testing process.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 100
          }
        ]
      },
      "Celery Metric Collection and Configuration": {
        "files": [
          {
            "path": "celery/datadog_checks/__init__.py",
            "description": "This `__init__.py` file is part of the `datadog_checks` namespace package within the Celery integration. It uses `pkgutil.extend_path` to enable the `datadog_checks` directory to be split across multiple locations.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/__init__.py",
            "description": "This file is the package initializer for the Datadog Celery integration, exposing its version and the main check class.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/metrics.py",
            "description": "This file defines a mapping between internal metric names collected by the Celery integration (specifically from Flower events, tasks, and workers) and their standardized names for reporting to Datadog.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/check.py",
            "description": "This file implements the Datadog Celery integration check, extending OpenMetricsBaseCheckV2 to collect metrics from Celery Flower. It defines the check's namespace and default metric configuration.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/config_models/instance.py",
            "description": "This file defines Pydantic models for the Celery integration's instance configuration, including various settings for metrics, authentication, and connection properties. It is an autogenerated file used for schema validation and default value handling.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/config_models/validators.py",
            "description": "This file provides a location for defining custom configuration validators or transformers for the Celery integration. It allows for advanced validation logic or data manipulation of configuration settings before they are used.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/config_models/defaults.py",
            "description": "This file defines default values for the configuration options of the Datadog Celery integration. It is an autogenerated file based on the integration's `spec.yaml`.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration settings and includes validation logic, automatically generated from a YAML specification.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/config_models/__init__.py",
            "description": "Defines a `ConfigMixin` class that provides convenient accessors for autogenerated instance and shared configuration models within an integration. This file is automatically generated from a configuration specification.",
            "spof": true
          },
          {
            "path": "celery/datadog_checks/celery/data",
            "description": "This empty directory is designated to store auxiliary data files for the Datadog Celery integration. It would typically house default configuration templates, static assets, or other non-code resources required by the check.",
            "spof": false
          },
          {
            "path": "celery/assets/configuration",
            "description": "This directory is designated for storing configuration assets pertaining to the Datadog Celery integration. It serves as a placeholder or location for configuration files, templates, or documentation necessary for setting up and monitoring Celery with Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 99
          },
          {
            "name": "Yann Armelin",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 24,
      "spofCount": 17
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "Check Point Harmony Endpoint Security": {
    "description": "Collects security logs from Check Point Harmony Endpoint to monitor for threats and policy violations on user devices.",
    "functions": {
      "Integration Packaging and Assets": {
        "files": [
          {
            "path": "checkpoint_harmony_endpoint/CHANGELOG.md",
            "description": "This file is a changelog documenting the release history, new features, and updates for the Checkpoint Harmony Endpoint integration. It lists version numbers, release dates, and corresponding agent compatibility.",
            "spof": false
          },
          {
            "path": "checkpoint_harmony_endpoint/README.md",
            "description": "This README provides an overview and setup instructions for integrating Checkpoint Harmony Endpoint with the Datadog Agent, focusing on collecting and monitoring security logs.",
            "spof": true
          },
          {
            "path": "checkpoint_harmony_endpoint/images",
            "description": "This directory is designated to store image assets for the `checkpoint_harmony_endpoint` integration. These images likely include documentation screenshots, UI elements, or other visual resources associated with the integration.",
            "spof": false
          },
          {
            "path": "checkpoint_harmony_endpoint/datadog_checks/checkpoint_harmony_endpoint/__init__.py",
            "description": "This `__init__.py` file defines the `checkpoint_harmony_endpoint` Python package, making its version and the main `CheckpointHarmonyEndpointCheck` class accessible for import by other modules.",
            "spof": true
          },
          {
            "path": "checkpoint_harmony_endpoint/datadog_checks/checkpoint_harmony_endpoint/data",
            "description": "This directory is intended to store static data files or auxiliary resources specifically used by the Checkpoint Harmony Endpoint Datadog integration. It serves as a location for non-code assets, such as default configurations, templates, or other data critical for the check's operation.",
            "spof": false
          },
          {
            "path": "checkpoint_harmony_endpoint/assets/configuration",
            "description": "This directory is designated for configuration assets specific to the Datadog Checkpoint Harmony Endpoint integration. Although currently empty, it is intended to store configuration files or templates that define how the integration should operate.",
            "spof": false
          },
          {
            "path": "checkpoint_harmony_endpoint/assets/dashboards",
            "description": "This directory is designated for storing Datadog dashboard definitions or configurations specifically tailored for the Check Point Harmony Endpoint integration. These dashboards would typically provide visualizations of metrics and logs collected by the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "vinodkumar-sacumen",
            "percent": 83
          },
          {
            "name": "HadhemiDD",
            "percent": 7
          },
          {
            "name": "Kyle Neale",
            "percent": 5
          }
        ]
      },
      "Integration Configuration Management": {
        "files": [
          {
            "path": "checkpoint_harmony_endpoint/datadog_checks/checkpoint_harmony_endpoint/config_models/validators.py",
            "description": "This file provides a location for custom configuration validators and transformers for the Check Point Harmony Endpoint integration. It allows for advanced validation logic and data manipulation beyond standard schema definitions.",
            "spof": true
          },
          {
            "path": "checkpoint_harmony_endpoint/datadog_checks/checkpoint_harmony_endpoint/config_models/defaults.py",
            "description": "This file defines default configuration values for the Check Point Harmony Endpoint integration. It is an autogenerated file, derived from the `spec.yaml` configuration specification.",
            "spof": true
          },
          {
            "path": "checkpoint_harmony_endpoint/datadog_checks/checkpoint_harmony_endpoint/config_models/instance.py",
            "description": "This file defines the Pydantic models for the Checkpoint Harmony Endpoint integration's instance configuration, including schema validation and default value handling.",
            "spof": true
          },
          {
            "path": "checkpoint_harmony_endpoint/datadog_checks/checkpoint_harmony_endpoint/config_models/shared.py",
            "description": "This file defines the `SharedConfig` Pydantic model for the Checkpoint Harmony Endpoint integration, handling shared configuration settings and their validation. It is autogenerated from the integration's `spec.yaml`.",
            "spof": true
          },
          {
            "path": "checkpoint_harmony_endpoint/datadog_checks/checkpoint_harmony_endpoint/config_models/__init__.py",
            "description": "This autogenerated file defines `ConfigMixin`, a class that provides convenient property-based access to the `InstanceConfig` and `SharedConfig` models for the Checkpoint Harmony Endpoint integration.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "vinodkumar-sacumen",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 12,
      "spofCount": 7
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "Cisco Umbrella DNS Security Integration": {
    "description": "Collects and analyzes DNS and proxy logs from Cisco Umbrella to monitor for security threats and enforce web filtering policies.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "cisco_umbrella_dns/CHANGELOG.md",
            "description": "This file is the changelog for the Cisco Umbrella DNS integration, detailing all release versions and their respective changes and updates.",
            "spof": false
          },
          {
            "path": "cisco_umbrella_dns/README.md",
            "description": "This file is the README for the Datadog Cisco Umbrella DNS integration, detailing its purpose of collecting and forwarding DNS and Proxy logs to Datadog for security monitoring and analysis, and providing setup instructions.",
            "spof": false
          },
          {
            "path": "cisco_umbrella_dns/images",
            "description": "This directory is intended to store image assets, such as screenshots or diagrams, specifically for the 'cisco_umbrella_dns' integration. These images would likely be used in documentation, dashboards, or other visual representations related to the integration.",
            "spof": false
          },
          {
            "path": "cisco_umbrella_dns/assets/dashboards",
            "description": "This directory is intended to house dashboard definitions for the `cisco_umbrella_dns` integration. Such dashboards would offer visual monitoring and analytics for the integration's performance and collected data.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Bhargav Nariyani",
            "percent": 55
          },
          {
            "name": "dkirov-dd",
            "percent": 38
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 0
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "Cisco Secure Email Threat Defense Integration": {
    "description": "Ingests and analyzes email logs from Cisco's cloud-based email security service to detect and respond to threats.",
    "functions": {
      "Integration Manifest and Assets": {
        "files": [
          {
            "path": "cisco_secure_email_threat_defense/CHANGELOG.md",
            "description": "This file is the changelog for the `cisco_secure_email_threat_defense` integration, documenting its version history and changes, starting with its initial release.",
            "spof": true
          },
          {
            "path": "cisco_secure_email_threat_defense/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog integration with Cisco Secure Email Threat Defense, focusing on ingesting and analyzing email message logs.",
            "spof": false
          },
          {
            "path": "cisco_secure_email_threat_defense/images",
            "description": "This directory is designated to store image assets for the Datadog Cisco Secure Email Threat Defense integration. These images would typically include screenshots, icons, or diagrams used in documentation or UI elements related to the integration. While currently empty, its purpose is to house visual resources supporting the integration's representation and usage.",
            "spof": false
          },
          {
            "path": "cisco_secure_email_threat_defense/assets/dashboards",
            "description": "This directory is designated to store pre-built dashboards tailored for the Cisco Secure Email Threat Defense integration. Its purpose is to provide ready-to-use visualizations and monitoring tools for Datadog users once implemented.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "manan-crest",
            "percent": 36
          },
          {
            "name": "ankitarajput-crest",
            "percent": 32
          },
          {
            "name": "Vraj Patel",
            "percent": 20
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 1
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "Cisco SD-WAN Monitoring": {
    "description": "Monitors Cisco SD-WAN (Viptela) environments for WAN edge health, transport performance, and application-aware routing.",
    "functions": {
      "Pre-packaged Monitoring Assets": {
        "files": [
          {
            "path": "cisco_sdwan/CHANGELOG.md",
            "description": "This file is the changelog for the Cisco SD-WAN integration, documenting its initial release and future updates.",
            "spof": false
          },
          {
            "path": "cisco_sdwan/README.md",
            "description": "This README provides an overview, setup instructions, and details on data collected for the Datadog Agent integration with Cisco SD-WAN, enabling monitoring of WAN edge health, transport performance, and application traffic.",
            "spof": false
          },
          {
            "path": "cisco_sdwan/assets/dashboards",
            "description": "This directory is intended to store JSON definitions or configurations for Datadog dashboards specific to the Cisco SD-WAN integration. These dashboards would provide visualizations and monitoring capabilities for the SD-WAN environment.",
            "spof": false
          },
          {
            "path": "cisco_sdwan/assets/monitors",
            "description": "This directory is designated for storing monitoring configurations or templates specific to the Datadog Cisco SD-WAN integration. It would typically contain files defining default alerts, dashboards, or other monitoring resources intended for the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Vic Weiss",
            "percent": 56
          },
          {
            "name": "Thibaud Cheruy",
            "percent": 17
          },
          {
            "name": "Garrison Stauffer",
            "percent": 10
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 0
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "Cisco ACI Monitoring": {
    "description": "Monitors Cisco's Application Centric Infrastructure (ACI), collecting metrics on fabric health, capacity, faults, and tenant policies.",
    "functions": {
      "Integration Configuration Management": {
        "files": [
          {
            "path": "cisco_aci/CHANGELOG.md",
            "description": "This file is the changelog for the `cisco_aci` integration, detailing version updates, new features, bug fixes, and security enhancements over time.",
            "spof": false
          },
          {
            "path": "cisco_aci/README.md",
            "description": "This README provides an overview, setup instructions, and troubleshooting guide for the Datadog Cisco ACI integration. It details how the integration collects metrics, events, and fault logs to monitor the health and performance of Cisco ACI environments.",
            "spof": false
          },
          {
            "path": "cisco_aci/tests/__init__.py",
            "description": "This empty __init__.py file marks the 'tests' directory as a Python package, allowing test modules within it to be imported and run.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/conftest.py",
            "description": "This `conftest.py` file provides pytest fixtures for the Cisco ACI integration tests. It defines a base configuration for the ACI instance used across various tests.",
            "spof": false
          },
          {
            "path": "cisco_aci/tests/common.py",
            "description": "This file defines common constants, test configurations, and fixture names used across the test suite for the Datadog Cisco ACI integration. It facilitates consistent setup for API mocking and test data.",
            "spof": true
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/config_models/defaults.py",
            "description": "This autogenerated file defines default configuration values for the Cisco ACI integration, derived from its specification. It provides functions that return default settings for various integration parameters.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/config_models/validators.py",
            "description": "This file is intended for defining additional configuration validators or transformers for the Cisco ACI integration. It allows for custom logic to process or validate configuration values before use.",
            "spof": true
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/config_models/__init__.py",
            "description": "This file provides autogenerated configuration models, `InstanceConfig` and `SharedConfig`, for the Cisco ACI integration. It defines a `ConfigMixin` to expose these configurations via properties.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/config_models/instance.py",
            "description": "This file defines the Pydantic models for the configuration schema of a single instance of the Cisco ACI integration. It is an autogenerated file based on a specification.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options like proxy settings and general parameters. It is an autogenerated file that handles validation and default values for these shared configurations across different integrations.",
            "spof": true
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/data",
            "description": "This directory is intended to store static data files, configuration templates, or other non-code assets specific to the Cisco ACI integration. Although currently empty, it serves as a placeholder for any necessary supplementary resources required by the check.",
            "spof": false
          },
          {
            "path": "cisco_aci/assets/dashboards",
            "description": "This directory is intended to house dashboard definitions and configurations specifically for the Datadog Cisco ACI integration. It serves as a dedicated location for visualization assets related to the integration's monitoring capabilities.",
            "spof": false
          },
          {
            "path": "cisco_aci/assets/monitors",
            "description": "This directory is intended to store Datadog monitor definitions specific to the Cisco ACI integration. These monitor definitions, if present, would automatically create or update monitors in Datadog to alert on critical conditions or metrics from Cisco ACI.",
            "spof": false
          },
          {
            "path": "cisco_aci/assets/configuration",
            "description": "This directory is designated to store configuration-related assets and templates for the Datadog Cisco ACI integration, although it currently contains no files.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "zoe",
            "percent": 31
          },
          {
            "name": "Alicia Thuerk",
            "percent": 14
          },
          {
            "name": "Ofek Lev",
            "percent": 7
          }
        ]
      },
      "ACI API Client and Orchestration": {
        "files": [
          {
            "path": "cisco_aci/tests/README.md",
            "description": "This file provides guidance on how to test the `cisco_aci` integration, detailing various testing methods like unit tests, simulators, and public/private sandboxes, along with their respective advantages and disadvantages.",
            "spof": false
          },
          {
            "path": "cisco_aci/tests/test_cisco.py",
            "description": "This file contains unit and end-to-end tests for the Datadog Cisco ACI integration. It verifies metric collection, API authentication recovery mechanisms, and configuration parsing.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/cisco_aci_query.py",
            "description": "A utility script to query specific tenant metrics from Cisco ACI, handling login, API requests, and logout.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/mock_sender.py",
            "description": "This file defines a mock `send` function for testing purposes, specifically to simulate API login responses for Cisco ACI by loading data from local fixture files.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/certificate",
            "description": "This directory is intended to house certificate files specifically used for testing the `cisco_aci` integration. Its purpose is to provide necessary cryptographic assets for validating secure communication features during the integration's test suite.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/exceptions.py",
            "description": "This file defines custom exception classes specifically for the Cisco ACI integration to handle various API-related errors, including authentication, connection, and parsing issues.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/cisco.py",
            "description": "This file implements the main Cisco ACI integration check, handling API authentication, data collection for tenants, fabric, capacity, and faults, and reporting metrics and service checks to Datadog.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the `cisco_aci` integration. It defines the public interface for the package, making the `CiscoACICheck` class and its version available for import.",
            "spof": true
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/api.py",
            "description": "This file defines the API client for interacting with Cisco ACI (Application Centric Infrastructure). It handles authentication (password or certificate-based), session management, and provides methods to fetch various data from the ACI API.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "zoe",
            "percent": 55
          },
          {
            "name": "Jim Wilson",
            "percent": 33
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 4
          }
        ]
      },
      "ACI Fault and Event Collection": {
        "files": [
          {
            "path": "cisco_aci/tests/test_faults.py",
            "description": "Tests the fault collection functionality of the Cisco ACI integration, including scenarios with and without network device metadata collection, using mocked API responses.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/fixtures/faults.py",
            "description": "This file contains a list of expected Cisco ACI fault log dictionaries, serving as fixture data for testing the Cisco ACI integration.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/fixtures/faults",
            "description": "This directory is intended to store test fixtures or sample data specifically related to 'faults' within the Cisco ACI integration tests. These fixtures would simulate fault conditions for testing purposes, even though no files are currently present.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/faults.py",
            "description": "This module defines a class responsible for collecting and submitting various types of faults (e.g., faultInst, faultDelegate) from Cisco APIC. It processes fault data, namespaces attributes, and submits them as logs, utilizing persistent caching to track processed faults.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Jim Wilson",
            "percent": 100
          }
        ]
      },
      "ACI Data Tagging and Metric Mapping": {
        "files": [
          {
            "path": "cisco_aci/tests/test_helpers.py",
            "description": "This file contains unit tests for helper functions used in the Datadog Cisco ACI integration. It verifies the functionality of various parsing and extraction utilities from the `cisco_aci.helpers` module.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/test_tags.py",
            "description": "This file contains unit tests for the `CiscoTags` class, which is responsible for extracting and mapping tags (like tenant, application, endpoint group, IP, MAC) from Cisco ACI data structures.",
            "spof": true
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/aci_metrics.py",
            "description": "This file defines the metric names and their mappings from Cisco ACI API responses to Datadog metric names for various components like fabric nodes, tenants, applications, endpoint groups, and capacity metrics.",
            "spof": true
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/helpers.py",
            "description": "This file provides helper functions for parsing various IDs, tags, and hostnames from Cisco ACI 'Distinguished Name' (DN) strings. It also includes utilities for extracting attributes from ACI API responses and handling metric values.",
            "spof": true
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/tags.py",
            "description": "This file defines a `CiscoTags` class responsible for extracting and generating tags from Cisco ACI (Application Centric Infrastructure) object data, such as applications, endpoint groups, and fabric components. It uses regular expressions and API calls to enrich data with meaningful tags for monitoring purposes.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Florent Clarret",
            "percent": 60
          },
          {
            "name": "zoe",
            "percent": 24
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 16
          }
        ]
      },
      "Tenant Policy and Application Monitoring": {
        "files": [
          {
            "path": "cisco_aci/tests/test_tenant.py",
            "description": "This file contains unit and integration tests for the Cisco ACI integration, specifically verifying the collection of metrics related to tenants, applications, and endpoint groups (EPGs). It uses a mocked API to simulate responses and asserts that the correct metrics are emitted with appropriate tags.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/fixtures/tenant",
            "description": "This directory is intended to store test fixtures specifically related to tenant configurations or data for the Cisco ACI integration. These fixtures would be used by the integration's test suite to simulate various tenant-related scenarios or responses.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/tenant.py",
            "description": "This file defines the `Tenant` class, which is responsible for collecting metrics and events related to Cisco ACI tenants, applications, and endpoint groups from the APIC.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 49
          },
          {
            "name": "zoe",
            "percent": 43
          },
          {
            "name": "Ofek Lev",
            "percent": 5
          }
        ]
      },
      "ACI Capacity Planning Monitoring": {
        "files": [
          {
            "path": "cisco_aci/tests/test_capacity.py",
            "description": "This file contains unit tests for the Cisco ACI integration's capacity monitoring component, verifying that it correctly processes mocked API responses and emits the expected capacity metrics.",
            "spof": false
          },
          {
            "path": "cisco_aci/tests/fixtures/capacity",
            "description": "This directory is intended to store test fixtures specifically designed for capacity-related testing of the Cisco ACI integration. It would likely contain sample data representing various capacity scenarios or responses to be used by test cases.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/capacity.py",
            "description": "This file defines a class responsible for collecting various capacity-related metrics from a Cisco ACI Application Policy Infrastructure Controller (APIC) and reporting them.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 95
          },
          {
            "name": "Ofek Lev",
            "percent": 3
          },
          {
            "name": "Gregory Zussa",
            "percent": 1
          }
        ]
      },
      "Fabric Health and Topology Monitoring": {
        "files": [
          {
            "path": "cisco_aci/tests/test_fabric.py",
            "description": "This file contains unit tests for the Cisco ACI integration, specifically verifying the collection and tagging of fabric node and port metrics, as well as network device metadata, using mocked API responses.",
            "spof": false
          },
          {
            "path": "cisco_aci/tests/fixtures/metadata.py",
            "description": "This file provides mock metadata fixtures for Cisco ACI devices, interfaces, and network topology, used in tests for the `cisco_aci` integration.",
            "spof": true
          },
          {
            "path": "cisco_aci/tests/fixtures/fabric",
            "description": "This directory is designated for storing test fixtures relevant to the Cisco ACI fabric within the `cisco_aci` integration tests. Its purpose is to provide predefined data representing various ACI fabric configurations or states to ensure robust integration testing.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/ndm.py",
            "description": "This file contains functions for processing Cisco ACI data to create and format network device, interface, and topology link metadata, and for batching these payloads for network device monitoring (NDM).",
            "spof": true
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/models.py",
            "description": "This file defines Pydantic models for parsing Cisco ACI API responses and for structuring that data into a standardized format for Datadog's Network Device Monitoring (NDM), including device, interface, and topology link metadata.",
            "spof": false
          },
          {
            "path": "cisco_aci/datadog_checks/cisco_aci/fabric.py",
            "description": "This file defines the `Fabric` class, which collects metrics and metadata from Cisco ACI fabric pods, nodes, and interfaces. It also supports submitting network device metadata to Datadog's Network Device Monitoring (NDM).",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "zoe",
            "percent": 58
          },
          {
            "name": "jedupau",
            "percent": 41
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 44,
      "spofCount": 22
    },
    "busFactor": 3,
    "authorCount": 16
  },
  "Cisco Duo Security Monitoring": {
    "description": "Ingests authentication and administrative activity logs from Cisco Duo to monitor multi-factor authentication and access policies.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "cisco_duo/CHANGELOG.md",
            "description": "This file is the changelog for the `cisco_duo` integration, documenting version updates and changes made over time. It currently indicates the initial release of the integration.",
            "spof": false
          },
          {
            "path": "cisco_duo/README.md",
            "description": "This file is the README for the Datadog Cisco Duo integration. It explains how to set up the integration to collect Cisco Duo authentication and activity logs for analysis in Datadog.",
            "spof": false
          },
          {
            "path": "cisco_duo/images",
            "description": "This directory is intended to store image assets specifically for the Cisco Duo integration within the Datadog Agent. These images would typically be used for documentation, dashboards, or other visual components related to the integration. It is currently empty, suggesting no images are presently required or have been added.",
            "spof": false
          },
          {
            "path": "cisco_duo/assets/dashboards",
            "description": "This directory is intended to store Datadog dashboard definitions specifically for the Cisco Duo integration. These dashboards would provide visualizations and insights into metrics and logs collected by the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "mohittilala-crest",
            "percent": 66
          },
          {
            "name": "dkirov-dd",
            "percent": 23
          },
          {
            "name": "Nathan Adams",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 0
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Cisco Secure Endpoint Monitoring": {
    "description": "Collects audit and event logs from Cisco Secure Endpoint (formerly AMP for Endpoints) for advanced malware protection analysis.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "cisco_secure_endpoint/CHANGELOG.md",
            "description": "This file is the changelog for the `cisco_secure_endpoint` integration, detailing all release history and updates. It documents changes made in each version of the integration.",
            "spof": true
          },
          {
            "path": "cisco_secure_endpoint/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog Cisco Secure Endpoint integration, which collects audit and event logs to provide security insights.",
            "spof": false
          },
          {
            "path": "cisco_secure_endpoint/images",
            "description": "This directory is designated to store image assets such as icons, screenshots, or diagrams specifically related to the `cisco_secure_endpoint` integration. These images would typically be used for documentation, UI elements, or other visual representations of the integration.",
            "spof": false
          },
          {
            "path": "cisco_secure_endpoint/assets/dashboards",
            "description": "This directory is designated to store pre-configured Datadog dashboards for the Cisco Secure Endpoint integration. While currently empty, its purpose is to provide out-of-the-box visualizations for monitoring Cisco Secure Endpoint data within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "ankitarajput-crest",
            "percent": 62
          },
          {
            "name": "Vraj Patel",
            "percent": 25
          },
          {
            "name": "dkirov-dd",
            "percent": 11
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Cisco ASA Firewall Log Analysis": {
    "description": "Collects and analyzes logs from Cisco ASA firewalls to monitor for security threats, user authentication, and network activity.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "cisco_asa/CHANGELOG.md",
            "description": "This file is the changelog for the Cisco ASA integration within the Datadog integrations-core repository, documenting changes and updates over time.",
            "spof": true
          },
          {
            "path": "cisco_asa/README.md",
            "description": "This file provides comprehensive instructions and information for integrating Cisco ASA with Datadog to collect logs, enabling threat detection, user authentication, and other security insights. It details configuration steps for both the Datadog Agent and Cisco ASA CLI, validation, data collected, and troubleshooting.",
            "spof": true
          },
          {
            "path": "cisco_asa/changelog.d",
            "description": "This directory stores individual changelog fragments or entries specifically for the `cisco_asa` integration. These fragments are typically used to generate the full changelog for this integration.",
            "spof": false
          },
          {
            "path": "cisco_asa/images",
            "description": "This directory is intended to store images specifically associated with the `cisco_asa` integration. These images would typically be used for documentation or other visual assets related to the integration, though it is currently empty.",
            "spof": false
          },
          {
            "path": "cisco_asa/datadog_checks/cisco_asa/__init__.py",
            "description": "This `__init__.py` file marks the `cisco_asa` directory as a Python package. It imports the package version from `__about__.py` and exposes it for direct access.",
            "spof": true
          },
          {
            "path": "cisco_asa/datadog_checks/cisco_asa/data",
            "description": "This `data` directory is intended to store static configuration files, default templates, or other integration-specific data for the Cisco ASA Datadog check. While currently empty, it serves as a designated location for such assets should they be required.",
            "spof": false
          },
          {
            "path": "cisco_asa/assets/configuration",
            "description": "This directory is designated to store configuration assets for the Datadog 'cisco_asa' integration. Although currently empty, its purpose is to house files or templates related to the integration's setup and configuration.",
            "spof": false
          },
          {
            "path": "cisco_asa/assets/dashboards",
            "description": "This directory stores pre-defined dashboard configurations and assets for the Datadog Cisco ASA integration, enabling users to visualize key metrics and performance data. It provides ready-to-use visualizations to monitor the Cisco ASA appliance within the Datadog platform.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "manan-crest",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 8,
      "spofCount": 3
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Check Point Quantum Firewall Monitoring": {
    "description": "Ingests logs from Check Point Quantum firewalls to monitor network traffic, security events, and potential threats.",
    "functions": {
      "Integration Packaging and Assets": {
        "files": [
          {
            "path": "checkpoint_quantum_firewall/CHANGELOG.md",
            "description": "This file is the changelog for the `checkpoint_quantum_firewall` integration, detailing its version history, release dates, and updates. It tracks significant changes made to the integration over time.",
            "spof": false
          },
          {
            "path": "checkpoint_quantum_firewall/README.md",
            "description": "This README.md file describes the Datadog integration for Check Point Quantum Firewall, detailing how to set it up for log collection and what data types are ingested. It provides instructions for installation, configuration, validation, and troubleshooting.",
            "spof": true
          },
          {
            "path": "checkpoint_quantum_firewall/images",
            "description": "This directory is intended to store image assets specifically related to the Datadog integration for Checkpoint Quantum Firewall. These images might include icons, screenshots for documentation, or other visual resources used in the integration's representation or documentation.",
            "spof": false
          },
          {
            "path": "checkpoint_quantum_firewall/datadog_checks/checkpoint_quantum_firewall/__init__.py",
            "description": "Initializes the `checkpoint_quantum_firewall` package and exposes its version information.",
            "spof": true
          },
          {
            "path": "checkpoint_quantum_firewall/datadog_checks/checkpoint_quantum_firewall/data",
            "description": "This directory is intended to store ancillary data for the Checkpoint Quantum Firewall integration. Such data might include configuration examples, MIB files, or other static assets necessary for the integration's operation. Currently, it appears to be empty.",
            "spof": false
          },
          {
            "path": "checkpoint_quantum_firewall/assets/dashboards",
            "description": "This directory is designated to store dashboard configurations specific to the Check Point Quantum Firewall integration. Although currently empty, its purpose is to house JSON definitions or similar assets for visualizing collected metrics or logs. It implies that no pre-defined dashboards are shipped with this integration by default.",
            "spof": false
          },
          {
            "path": "checkpoint_quantum_firewall/assets/configuration",
            "description": "This directory is intended to store configuration-related assets for the `checkpoint_quantum_firewall` Datadog integration. It would typically contain example configuration files or schema definitions, although it is currently empty.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Tirthraj Chaudhari",
            "percent": 41
          },
          {
            "name": "HadhemiDD",
            "percent": 18
          },
          {
            "name": "Kyle Neale",
            "percent": 16
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 7,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Cofense Triage Phishing Response Integration": {
    "description": "Ingests phishing threat reports from Cofense Triage to analyze and respond to user-reported suspicious emails.",
    "functions": {
      "Integration Assets and Dashboards": {
        "files": [
          {
            "path": "cofense_triage/CHANGELOG.md",
            "description": "This file documents the version history and changes made to the Cofense Triage integration for Datadog.",
            "spof": true
          },
          {
            "path": "cofense_triage/README.md",
            "description": "This README.md provides an overview and setup instructions for integrating Cofense Triage with Datadog. It details how to configure API credentials, connect the accounts, whitelist Datadog IP addresses, and specifies the types of data collected (logs).",
            "spof": true
          },
          {
            "path": "cofense_triage/images",
            "description": "This directory is designated to store visual assets like icons, screenshots, or diagrams that are specific to the Cofense Triage integration. These images would typically be used for documentation, user interface elements, or other visual representations within the integration's context.",
            "spof": false
          },
          {
            "path": "cofense_triage/assets/dashboards",
            "description": "This directory is intended to store JSON definitions for Datadog dashboards specific to the Cofense Triage integration. These dashboards would typically provide visualizations for metrics and logs collected by the integration, offering insights into its performance and the monitored Cofense Triage system.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Vraj Patel",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "CockroachDB Monitoring": {
    "description": "Monitors CockroachDB distributed SQL databases for health, performance, and operational metrics.",
    "functions": {
      "CockroachDB Metric Collection": {
        "files": [
          {
            "path": "cockroachdb/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor CockroachDB, including metric and log collection details for host and containerized environments.",
            "spof": false
          },
          {
            "path": "cockroachdb/CHANGELOG.md",
            "description": "This file is the changelog for the CockroachDB integration, detailing version updates, new features, bug fixes, and other changes for each release.",
            "spof": false
          },
          {
            "path": "cockroachdb/tests/README.md",
            "description": "This README provides instructions on how to populate `cockroachdb.sql.*` metrics for development and sample data generation within the CockroachDB integration's test environment.",
            "spof": true
          },
          {
            "path": "cockroachdb/tests/test_bench.py",
            "description": "This file contains a benchmark test for the CockroachDB integration. It measures the performance of running the CockroachDB check.",
            "spof": true
          },
          {
            "path": "cockroachdb/tests/__init__.py",
            "description": "This empty `__init__.py` file indicates that the `tests` directory is a Python package, allowing its modules to be imported and run as tests for the CockroachDB integration.",
            "spof": true
          },
          {
            "path": "cockroachdb/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog CockroachDB integration, specifically verifying that the integration collects the expected metrics.",
            "spof": false
          },
          {
            "path": "cockroachdb/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog CockroachDB integration, verifying its ability to collect metrics, service checks, and version metadata from a running CockroachDB instance.",
            "spof": true
          },
          {
            "path": "cockroachdb/tests/common.py",
            "description": "This file defines common constants, host information, and expected metric names used across various tests for the CockroachDB integration.",
            "spof": true
          },
          {
            "path": "cockroachdb/tests/conftest.py",
            "description": "This file defines pytest fixtures for setting up and tearing down a CockroachDB test environment using Docker, including configuration for integration tests. It handles different CockroachDB versions and metric population.",
            "spof": false
          },
          {
            "path": "cockroachdb/tests/test_unit.py",
            "description": "Unit and integration tests for the Datadog CockroachDB integration, verifying metric collection, service checks, and metric mapping using mocked HTTP responses and fixtures.",
            "spof": true
          },
          {
            "path": "cockroachdb/tests/legacy/test_e2e.py",
            "description": "This file contains an end-to-end test for the Datadog CockroachDB integration, verifying its functionality using a legacy instance configuration.",
            "spof": true
          },
          {
            "path": "cockroachdb/tests/legacy/__init__.py",
            "description": "This file marks the 'legacy' directory as a Python package within the test suite for the Datadog CockroachDB integration.",
            "spof": true
          },
          {
            "path": "cockroachdb/tests/legacy/common.py",
            "description": "This file contains common assertion utilities for CockroachDB integration tests, verifying that expected metrics and service checks are reported.",
            "spof": false
          },
          {
            "path": "cockroachdb/tests/legacy/test_integration.py",
            "description": "This file contains integration tests for the Datadog CockroachDB check, verifying basic functionality and ensuring correct reporting of version metadata.",
            "spof": false
          },
          {
            "path": "cockroachdb/tests/fixtures",
            "description": "This directory is designated to store test fixtures and auxiliary data specifically for the CockroachDB integration tests. Its purpose is to provide controlled and reproducible environments or data sets required by the test suite.",
            "spof": false
          },
          {
            "path": "cockroachdb/tests/docker",
            "description": "This directory is designated for storing Docker-related configurations and files essential for setting up a CockroachDB environment. Its primary role is to support integration tests by providing a containerized and reproducible instance of CockroachDB for testing the Datadog integration.",
            "spof": false
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/metrics.py",
            "description": "This file defines a mapping for CockroachDB metrics, translating raw metric names into standardized Datadog metric names for the integration.",
            "spof": true
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/__init__.py",
            "description": "This `__init__.py` file defines the package version and exposes the `CockroachdbCheck` class, serving as the entry point for the CockroachDB integration.",
            "spof": true
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/check.py",
            "description": "This file implements the Datadog check for CockroachDB using OpenMetrics V2, including custom metric transformations for specific metrics and labels.",
            "spof": true
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/cockroachdb.py",
            "description": "This file defines the main Datadog check for CockroachDB, supporting both older Prometheus-style metric collection and delegating to a V2 OpenMetrics check based on the configuration.",
            "spof": true
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/config_models/defaults.py",
            "description": "This file defines default values for configuration options used by the CockroachDB integration. It is automatically generated from the `spec.yaml` file.",
            "spof": true
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/config_models/instance.py",
            "description": "This file defines the Pydantic models for the CockroachDB integration's instance configuration, automatically generated from a specification file. It provides the structure and validation rules for the configuration parameters.",
            "spof": false
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options used across Datadog integrations, including proxy settings and general parameters. It is an autogenerated file from a YAML specification.",
            "spof": true
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides typed access to integration instance and shared configuration models. It serves as an entry point for accessing autogenerated configuration models within the CockroachDB integration.",
            "spof": false
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/config_models/validators.py",
            "description": "This file defines configuration validators for the CockroachDB integration. It ensures that either a `prometheus_url` or an `openmetrics_endpoint` is provided in the instance configuration.",
            "spof": false
          },
          {
            "path": "cockroachdb/datadog_checks/cockroachdb/data",
            "description": "This `data` directory is intended to store static data files or configuration templates specifically used by the Datadog CockroachDB integration check. Although currently empty, its purpose would be to house non-code assets supporting the integration's functionality.",
            "spof": false
          },
          {
            "path": "cockroachdb/assets/configuration",
            "description": "This directory is designated to store configuration assets specific to the CockroachDB integration. Although currently empty, it serves as a placeholder for any necessary configuration files, such as examples or default settings, that might be added in the future.",
            "spof": false
          },
          {
            "path": "cockroachdb/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions and configurations specific to the Datadog CockroachDB integration. These assets are crucial for visualizing performance metrics and operational data from CockroachDB instances.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Florent Clarret",
            "percent": 71
          },
          {
            "name": "Ofek Lev",
            "percent": 9
          },
          {
            "name": "Kyle Neale",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 28,
      "spofCount": 14
    },
    "busFactor": 2,
    "authorCount": 9
  },
  "Cisco Secure Firewall Monitoring": {
    "description": "Collects logs from Cisco Secure Firewall Threat Defense (FTD) devices to monitor network security and threat events.",
    "functions": {
      "Integration Asset Management and Documentation": {
        "files": [
          {
            "path": "cisco_secure_firewall/CHANGELOG.md",
            "description": "This file is a changelog for the `cisco_secure_firewall` integration, detailing new features, updates, and fixes across different versions. It tracks the evolution of the integration over time.",
            "spof": false
          },
          {
            "path": "cisco_secure_firewall/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to collect logs from Cisco Secure Firewall Threat Defense (FTD) devices, managed by Cisco Secure Firewall Management Center (FMC). It details the installation, configuration steps, log collection, and troubleshooting for the integration.",
            "spof": false
          },
          {
            "path": "cisco_secure_firewall/images",
            "description": "This directory is designated for storing visual assets, such as screenshots, icons, or diagrams, directly associated with the `cisco_secure_firewall` integration. Its purpose is to house graphical resources used for documentation, UI elements, or monitoring dashboard examples within the Datadog integrations-core project.",
            "spof": false
          },
          {
            "path": "cisco_secure_firewall/datadog_checks/cisco_secure_firewall/__init__.py",
            "description": "This is an initialization file for the `cisco_secure_firewall` Python package, primarily used to expose the package's version number.",
            "spof": true
          },
          {
            "path": "cisco_secure_firewall/datadog_checks/cisco_secure_firewall/data",
            "description": "This directory is designated for storing data files, such as configuration templates or static assets, that support the `cisco_secure_firewall` Datadog integration. Despite currently being empty, it is reserved for any necessary ancillary data.",
            "spof": false
          },
          {
            "path": "cisco_secure_firewall/assets/dashboards",
            "description": "This directory is intended to store dashboard assets for the Datadog integration with Cisco Secure Firewall. It would typically contain JSON files that define pre-built dashboards for monitoring purposes. Although currently empty, its role is to centralize these visualization configurations.",
            "spof": false
          },
          {
            "path": "cisco_secure_firewall/assets/configuration",
            "description": "This directory is intended to house configuration assets or example configuration files pertinent to the Datadog integration for Cisco Secure Firewall. Although currently empty, its path indicates it serves as a designated location for integration-specific configuration resources.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Tirthraj Chaudhari",
            "percent": 38
          },
          {
            "name": "prerakdali",
            "percent": 20
          },
          {
            "name": "HadhemiDD",
            "percent": 14
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 7,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Cloudera Data Platform Monitoring": {
    "description": "Monitors Cloudera Data Platform (CDP) environments, collecting health and performance metrics for clusters, hosts, and services.",
    "functions": {
      "Integration Configuration and Assets": {
        "files": [
          {
            "path": "cloudera/CHANGELOG.md",
            "description": "This file serves as the changelog for the Datadog Cloudera integration, documenting all version updates, new features, bug fixes, and other significant changes over time.",
            "spof": false
          },
          {
            "path": "cloudera/README.md",
            "description": "This README provides instructions for integrating Datadog with Cloudera Data Platform to monitor clusters, hosts, and roles, detailing setup, configuration, and troubleshooting.",
            "spof": false
          },
          {
            "path": "cloudera/images",
            "description": "This directory is intended to store images related to the Datadog integration for Cloudera. It likely contains icons, diagrams, or other visual assets used in documentation or UI for the Cloudera integration.",
            "spof": false
          },
          {
            "path": "cloudera/tests/conftest.py",
            "description": "This file defines pytest fixtures for the Cloudera integration, including setting up a Docker-based test environment, providing test configurations, and mocking the Cloudera CM client for testing purposes.",
            "spof": false
          },
          {
            "path": "cloudera/tests/__init__.py",
            "description": "This file marks the `tests` directory for the `cloudera` integration as a Python package. It is an empty `__init__.py` file, serving to enable Python's module import mechanism for the test suite.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/common.py",
            "description": "This file defines common constants, such as metric names for connectivity and health status, used across the Cloudera integration.",
            "spof": false
          },
          {
            "path": "cloudera/datadog_checks/cloudera/config.py",
            "description": "This file defines a utility function `normalize_discover_config_include` to standardize the 'include' configuration for discovery processes. It converts various input formats for 'include' into a consistent dictionary structure, ensuring it's properly handled by the discovery class.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/config_models/defaults.py",
            "description": "This file defines default configuration values for the Cloudera integration, providing base settings for various instance parameters. It is an autogenerated file, with changes managed through a `spec.yaml`.",
            "spof": false
          },
          {
            "path": "cloudera/datadog_checks/cloudera/config_models/instance.py",
            "description": "This file defines the Pydantic models for the Cloudera integration's instance-level configuration, automatically generated from a specification file.",
            "spof": false
          },
          {
            "path": "cloudera/datadog_checks/cloudera/config_models/validators.py",
            "description": "This file is intended for defining custom configuration validators and transformers for the Datadog Cloudera integration, allowing for additional logic beyond the base schema.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/config_models/shared.py",
            "description": "This file defines a Pydantic model (`SharedConfig`) for common configuration settings used by the Datadog Cloudera integration. It is automatically generated from a `spec.yaml` file.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class, providing structured access to instance-specific and shared configuration models for the Cloudera integration. It is an autogenerated component of Datadog's configuration management system.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/data",
            "description": "This directory is designated to store static data or configuration files pertinent to the Datadog Cloudera integration. Although currently empty, it serves as a placeholder for potential future assets, default settings, or supporting data.",
            "spof": false
          },
          {
            "path": "cloudera/assets/monitors",
            "description": "This directory is intended to store assets related to monitors for the Cloudera integration within the Datadog Agent. It would typically contain configuration files, definitions, or templates used to configure Datadog monitors for Cloudera services.",
            "spof": false
          },
          {
            "path": "cloudera/assets/configuration",
            "description": "This directory is designated to store configuration files and assets for the Datadog Cloudera integration. It would typically contain templates, default settings, or schema definitions. Currently, it appears to be empty.",
            "spof": false
          },
          {
            "path": "cloudera/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions or configurations specific to the Cloudera integration within the Datadog integrations-core repository. Its primary role is to provide pre-built visualizations and monitoring layouts for Cloudera services. These dashboards would typically be imported into Datadog to offer immediate insights.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 17
          },
          {
            "name": "Ofek Lev",
            "percent": 14
          },
          {
            "name": "jose-manuel-almaza",
            "percent": 13
          }
        ]
      },
      "Cloudera Data Collection and Processing": {
        "files": [
          {
            "path": "cloudera/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Cloudera integration. It verifies that the integration correctly collects and tags various Cloudera metrics and service checks.",
            "spof": false
          },
          {
            "path": "cloudera/tests/test_unit_hosts.py",
            "description": "This file contains unit tests for the Cloudera integration, specifically verifying the collection and reporting of host-related service checks, health statuses, and metrics under various configurations and host conditions.",
            "spof": true
          },
          {
            "path": "cloudera/tests/test_unit_clusters.py",
            "description": "This file contains unit tests for the Cloudera integration, specifically verifying the handling of cluster information, service checks, and metrics based on different cluster health statuses and exception scenarios.",
            "spof": true
          },
          {
            "path": "cloudera/tests/test_unit_events.py",
            "description": "This file contains unit tests for the Cloudera integration's event collection functionality, verifying how it handles different `read_events` API responses, including exceptions and various event payloads. It tests the generation of service checks and events based on these responses.",
            "spof": true
          },
          {
            "path": "cloudera/tests/test_unit_autodiscover.py",
            "description": "This file contains unit tests for the Cloudera integration's cluster autodiscovery feature. It verifies that various configuration settings for including, excluding, and limiting clusters are handled correctly, and that corresponding service checks and metrics are reported as expected.",
            "spof": false
          },
          {
            "path": "cloudera/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Cloudera check. It verifies the check's ability to connect to the Cloudera API, collect metrics, service checks, events, and metadata under various configurations, including custom queries and error scenarios.",
            "spof": false
          },
          {
            "path": "cloudera/tests/test_unit_custom_queries.py",
            "description": "This file contains unit tests for the custom query functionality of the Datadog Cloudera integration. It verifies how the integration handles custom queries, including successful execution and error scenarios, by asserting metrics and service checks.",
            "spof": true
          },
          {
            "path": "cloudera/tests/test_unit_disks.py",
            "description": "This file contains unit tests for the Cloudera integration, specifically verifying the collection of disk-related metrics and host health service checks under various conditions, including API connectivity issues, different host health statuses, and custom tagging.",
            "spof": true
          },
          {
            "path": "cloudera/tests/test_unit_roles.py",
            "description": "This file contains unit tests for the Datadog Cloudera integration, specifically verifying the generation of service checks and metrics related to Cloudera host health and connectivity under various simulated API responses.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/__init__.py",
            "description": "This file serves as the package initializer for the Cloudera integration, exposing its version and the main check class `ClouderaCheck`.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/entity_status.py",
            "description": "This file maps Cloudera entity status values to corresponding Datadog service check statuses. It defines a dictionary to translate various health statuses into Datadog's `ServiceCheck` enumeration values.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/check.py",
            "description": "This file defines the ClouderaCheck class, which is the main implementation of the Datadog Agent integration for Cloudera. It handles connecting to the Cloudera API, collecting metrics, and reporting service checks.",
            "spof": false
          },
          {
            "path": "cloudera/datadog_checks/cloudera/metrics.py",
            "description": "This file defines the timeseries and native metrics collected by the Datadog Cloudera integration, categorized by entity type such as cluster, host, role, and disk.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 69
          },
          {
            "name": "jose-manuel-almaza",
            "percent": 27
          },
          {
            "name": "Andrew Zhang",
            "percent": 3
          }
        ]
      },
      "Cloudera API Client": {
        "files": [
          {
            "path": "cloudera/tests/test_unit_client.py",
            "description": "This file contains unit tests for the Cloudera integration client, verifying its initialization, configuration parsing (including SSL settings), and error handling based on different instance parameters.",
            "spof": false
          },
          {
            "path": "cloudera/tests/test_unit_version.py",
            "description": "This file contains unit tests for the Datadog Cloudera integration, specifically verifying how the check handles various Cloudera Manager versions and API connection issues to report the `cloudera.can_connect` service check.",
            "spof": true
          },
          {
            "path": "cloudera/tests/docker/fixtures/api/v48/events",
            "description": "This directory is designated to store test fixtures specifically for API events related to Cloudera's API version 48. These fixtures would be utilized within Docker-based test environments for the Datadog Cloudera integration.",
            "spof": false
          },
          {
            "path": "cloudera/tests/docker/fixtures/api/v48/cm/version",
            "description": "This directory is intended to store test fixture data for the Cloudera integration, specifically for API version 48 of the Cloudera Manager's '/version' endpoint. These fixtures would be utilized within Docker-based integration tests to simulate specific API responses.",
            "spof": false
          },
          {
            "path": "cloudera/tests/docker/fixtures/api/v48/timeseries",
            "description": "This directory is intended to house Docker-based test fixtures for the Cloudera integration. Specifically, it would contain fixtures related to timeseries data from version 48 of the Cloudera API, used within the testing environment.",
            "spof": false
          },
          {
            "path": "cloudera/tests/docker/fixtures/api/v48/clusters/cluster_1/hosts",
            "description": "This directory is part of the test fixtures for the Datadog Cloudera integration, specifically for Docker-based tests. It is intended to contain simulated data or configurations related to host information within 'cluster_1' for version 48 of the Cloudera API. These fixtures would be used to mock API responses or states during integration testing.",
            "spof": false
          },
          {
            "path": "cloudera/datadog_checks/cloudera/client/factory.py",
            "description": "This file provides a factory function (`make_client`) to create different types of client objects for interacting with Cloudera, specifically a `CmClient` based on the provided type string.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/client/__init__.py",
            "description": "This empty '__init__.py' file signifies that the 'client' directory is a Python package within the Cloudera integration, allowing its modules to be imported and used.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/client/cm_client.py",
            "description": "This file defines the `CmClient` class, which acts as a wrapper around the Cloudera Manager API client to facilitate interactions such as retrieving clusters, hosts, events, metrics, and version information.",
            "spof": false
          },
          {
            "path": "cloudera/datadog_checks/cloudera/client/client.py",
            "description": "This file defines an abstract base class for a Cloudera API client, outlining the interface for collecting metrics, clusters, hosts, and events from Cloudera services.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/api/factory.py",
            "description": "This file provides a factory function (`make_api`) to instantiate the appropriate Cloudera API client based on the detected Cloudera Manager version (e.g., ApiV7). It configures the client and handles version-specific API object creation.",
            "spof": false
          },
          {
            "path": "cloudera/datadog_checks/cloudera/api/__init__.py",
            "description": "This is an empty `__init__.py` file, serving to mark the 'api' directory as a Python package within the Cloudera integration.",
            "spof": true
          },
          {
            "path": "cloudera/datadog_checks/cloudera/api/api_v7.py",
            "description": "This file implements the Cloudera API v7 client, responsible for collecting metrics and events from Cloudera clusters, hosts, roles, and disks.",
            "spof": false
          },
          {
            "path": "cloudera/datadog_checks/cloudera/api/api.py",
            "description": "This file defines an abstract base class for interacting with the Cloudera API to collect metrics and service checks. It outlines the `collect_data` method that concrete API implementations must provide.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 42
          },
          {
            "name": "jose-manuel-almaza",
            "percent": 29
          },
          {
            "name": "Jos Manuel Almaza Ramiro",
            "percent": 14
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 43,
      "spofCount": 19
    },
    "busFactor": 2,
    "authorCount": 9
  },
  "Cilium Network Observability": {
    "description": "Provides deep visibility into eBPF-based networking, security, and observability by collecting metrics from Cilium agents and operators.",
    "functions": {
      "Integration & E2E Testing": {
        "files": [
          {
            "path": "cilium/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Cilium integration, detailing all the changes, fixes, and new features added in each version release.",
            "spof": false
          },
          {
            "path": "cilium/tests/README.md",
            "description": "This file provides instructions for setting up and interacting with an End-to-End (E2E) testing environment for the Cilium integration using `kind` and `helm`. It details the setup process, requirements, and commands for cluster interaction.",
            "spof": true
          },
          {
            "path": "cilium/tests/conftest.py",
            "description": "This file provides pytest fixtures and helper functions for setting up a test environment (a Kubernetes Kind cluster with Cilium) and mocking data for the Datadog Cilium integration tests.",
            "spof": true
          },
          {
            "path": "cilium/tests/test_cilium.py",
            "description": "This file contains unit tests for the Datadog Cilium integration, verifying that the Cilium agent and operator components correctly collect and report their expected metrics across different configurations and versions.",
            "spof": false
          },
          {
            "path": "cilium/tests/common.py",
            "description": "This file defines common variables, pytest markers, and lists of expected metrics for testing the Datadog Cilium integration. It differentiates metrics based on Cilium agent versions (V1/V2) and specific Cilium releases (e.g., 1.14+).",
            "spof": false
          },
          {
            "path": "cilium/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Cilium integration. It verifies that the integration correctly collects all expected agent and operator metrics from a live Cilium environment.",
            "spof": true
          },
          {
            "path": "cilium/tests/legacy/legacy_common.py",
            "description": "This file defines lists of expected metric names for the Cilium integration, categorized by agent, operator, and cloud-specific metrics (AWS, Azure), often used for testing or monitoring purposes across different Cilium versions.",
            "spof": true
          },
          {
            "path": "cilium/tests/legacy/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Cilium integration in a legacy environment. It verifies that the agent successfully collects default and operator metrics.",
            "spof": true
          },
          {
            "path": "cilium/tests/legacy/__init__.py",
            "description": "This `__init__.py` file defines the `legacy` directory as a Python package within the `Cilium` integration's tests, allowing modules inside it to be imported. It contains no specific initialization logic beyond making the directory importable.",
            "spof": true
          },
          {
            "path": "cilium/tests/legacy/test_cilium.py",
            "description": "This file contains legacy integration tests for the Datadog Cilium check, verifying metric collection from both the Cilium agent and operator, and asserting correct version metadata reporting.",
            "spof": true
          },
          {
            "path": "cilium/tests/fixtures",
            "description": "This directory is intended to store test fixtures for the Cilium integration. These fixtures provide static data or mock configurations necessary for running automated tests for the Datadog Cilium integration.",
            "spof": false
          },
          {
            "path": "cilium/tests/kind",
            "description": "This directory is intended to contain configurations or utilities for running integration tests for the Cilium integration using `kind` (Kubernetes in Docker). As it is currently empty, it likely serves as a placeholder for future `kind`-specific testing resources.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Hadrien Patte",
            "percent": 72
          },
          {
            "name": "Jared Ledvina",
            "percent": 3
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 3
          }
        ]
      },
      "Cilium Metric Collection": {
        "files": [
          {
            "path": "cilium/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent's Cilium integration to collect metrics and logs from Cilium agents and operators. It covers installation, configuration details for host and containerized environments, and data collected.",
            "spof": true
          },
          {
            "path": "cilium/datadog_checks/cilium/__init__.py",
            "description": "This file initializes the Cilium integration package, exposing its version and the main CiliumCheck class for use by the Datadog Agent.",
            "spof": true
          },
          {
            "path": "cilium/datadog_checks/cilium/check.py",
            "description": "This file defines the Datadog check for collecting metrics from Cilium, supporting both agent and operator endpoints. It extends `OpenMetricsBaseCheckV2` to gather metrics via OpenMetrics endpoints based on the provided configuration.",
            "spof": true
          },
          {
            "path": "cilium/datadog_checks/cilium/metrics.py",
            "description": "This file defines dictionaries that map Cilium Agent and Operator Prometheus metric names to their corresponding Datadog metric names for the Datadog Cilium integration.",
            "spof": true
          },
          {
            "path": "cilium/datadog_checks/cilium/cilium.py",
            "description": "This file provides a legacy implementation for the Datadog Cilium integration, collecting metrics from either the Cilium agent or operator. It also acts as a dispatch mechanism to a newer OpenMetrics-based check when configured.",
            "spof": true
          },
          {
            "path": "cilium/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions or templates for the Datadog Cilium integration. It would typically contain files used to visualize metrics and provide operational insights for Cilium within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Hadrien Patte",
            "percent": 86
          },
          {
            "name": "domalessi",
            "percent": 7
          },
          {
            "name": "Jared Ledvina",
            "percent": 2
          }
        ]
      },
      "Configuration Model Management": {
        "files": [
          {
            "path": "cilium/datadog_checks/cilium/config_models/validators.py",
            "description": "This file is a placeholder for defining custom validation or transformation logic for the Cilium integration's configuration models, as indicated by the commented-out examples.",
            "spof": true
          },
          {
            "path": "cilium/datadog_checks/cilium/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options across the Cilium integration, including proxy settings, service names, and timeouts. It also incorporates validation and default value logic, and is automatically generated from a configuration specification.",
            "spof": true
          },
          {
            "path": "cilium/datadog_checks/cilium/config_models/defaults.py",
            "description": "This autogenerated file defines default configuration values for the Datadog Cilium integration, extracted from its specification file. It provides functions returning default settings for various shared and instance-level parameters.",
            "spof": true
          },
          {
            "path": "cilium/datadog_checks/cilium/config_models/instance.py",
            "description": "This file defines Pydantic models for the Cilium integration's instance configuration, including schema definition and validation logic. It is autogenerated from a specification file to ensure type safety and structure for configuration parameters.",
            "spof": false
          },
          {
            "path": "cilium/datadog_checks/cilium/config_models/__init__.py",
            "description": "This autogenerated file serves as an entry point for configuration models within the Cilium integration. It defines a `ConfigMixin` class to provide structured access to instance-specific and shared configuration objects.",
            "spof": true
          },
          {
            "path": "cilium/datadog_checks/cilium/data",
            "description": "This directory is intended to store static data, configuration templates, or other non-code assets specifically required by the Datadog Cilium integration check. While currently empty, it serves as a placeholder for such resources.",
            "spof": false
          },
          {
            "path": "cilium/assets/configuration",
            "description": "This directory is designated for storing configuration assets and examples specific to the Datadog Cilium integration. Its primary role is to centralize configuration files needed for the integration's setup and operation, even if currently empty.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 66
          },
          {
            "name": "Yann Armelin",
            "percent": 27
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 25,
      "spofCount": 16
    },
    "busFactor": 1,
    "authorCount": 7
  },
  "Container Monitoring": {
    "description": "Collects metrics on resource usage and performance for running containers across various supported container runtimes.",
    "functions": {
      "Container Monitoring Dashboards and Documentation": {
        "files": [
          {
            "path": "container/CHANGELOG.md",
            "description": "This file is a changelog for the Datadog Container integration, detailing its version history and updates.",
            "spof": true
          },
          {
            "path": "container/README.md",
            "description": "This README provides documentation for the Datadog Agent's `container` check, outlining its functionality, setup, configuration, and the metrics it collects for monitoring running containers across different runtimes. It also clarifies its distinction from the `containerd` check.",
            "spof": true
          },
          {
            "path": "container/assets/dashboards",
            "description": "This directory is designated to store Datadog dashboard definitions specifically for container-related integrations. It serves as a central location for visualizing metrics and logs from containerized environments within the Datadog platform.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Anthonin Bonnefoy",
            "percent": 63
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 30
          },
          {
            "name": "Vincent Boulineau",
            "percent": 4
          }
        ]
      },
      "Kubelet Integration and Pod Discovery": {
        "files": [
          {
            "path": "datadog_checks_base/tests/base/checks/test_kubelet_base.py",
            "description": "This file contains unit tests for the KubeletBase class and its utility functions, specifically verifying pod list retrieval, pod expiration datetime computation, and URL joining logic.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/fixtures/kubelet_base",
            "description": "This directory is designated to hold common test fixtures specifically for the Kubelet base integration within `datadog_checks_base`. It serves as a placeholder for shared test data used across various Kubelet-related tests, ensuring consistent testing environments.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/kubelet_base/base.py",
            "description": "This file provides a base class for Datadog Agent checks to interact with the Kubernetes Kubelet API, including methods for secure communication, retrieving pod lists, and filtering out expired pods.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 65
          },
          {
            "name": "Steven Yuen",
            "percent": 31
          },
          {
            "name": "Celene",
            "percent": 4
          }
        ]
      },
      "ECS Fargate Metric Collection": {
        "files": [
          {
            "path": "ecs_fargate/tests/test_unit.py",
            "description": "This file contains unit and integration tests for the Datadog ECS Fargate integration. It validates the FargateCheck's behavior in various scenarios, including successful metric collection on Linux and Windows, and error handling for metadata endpoint issues.",
            "spof": true
          },
          {
            "path": "ecs_fargate/datadog_checks/ecs_fargate/__init__.py",
            "description": "This is the initialization file for the 'ecs_fargate' package, exposing the package version and the FargateCheck class for external use.",
            "spof": true
          },
          {
            "path": "ecs_fargate/datadog_checks/ecs_fargate/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators and transformers for the ECS Fargate integration. It provides an optional place to add logic for processing or validating integration configuration settings before use.",
            "spof": true
          },
          {
            "path": "ecs_fargate/datadog_checks/ecs_fargate/data",
            "description": "This directory is intended to store static data files or configuration templates specific to the `ecs_fargate` Datadog integration. Although currently empty, its purpose is to house non-code resources required by the check.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 83
          },
          {
            "name": "Vincent Boulineau",
            "percent": 5
          },
          {
            "name": "Andrew Zhang",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 10,
      "spofCount": 6
    },
    "busFactor": 4,
    "authorCount": 7
  },
  "Cisco Secure Client (AnyConnect) Monitoring": {
    "description": "Collects logs from Cisco Secure Client (formerly AnyConnect) to monitor VPN connections and endpoint security events.",
    "functions": {
      "Integration Configuration and Assets": {
        "files": [
          {
            "path": "cisco_secure_client/CHANGELOG.md",
            "description": "This file documents all notable changes, new features, and bug fixes for the Cisco Secure Client integration. It serves as a historical record of updates made to the integration.",
            "spof": true
          },
          {
            "path": "cisco_secure_client/README.md",
            "description": "This README provides instructions for integrating Cisco Secure Client (formerly AnyConnect) logs with Datadog. It details the steps to configure log collection on the Datadog Agent and how to set up syslog forwarding on various Cisco firewall platforms.",
            "spof": true
          },
          {
            "path": "cisco_secure_client/images",
            "description": "This directory is intended to store images pertinent to the `cisco_secure_client` Datadog integration. These images would typically include icons, diagrams, or screenshots used in its documentation or UI. Although currently empty, its purpose is to house visual assets for the integration.",
            "spof": false
          },
          {
            "path": "cisco_secure_client/changelog.d",
            "description": "This directory is intended to store individual changelog fragments for the `cisco_secure_client` integration. These fragments are typically aggregated by a tool or script to generate a complete `CHANGELOG.md` file for the integration.",
            "spof": false
          },
          {
            "path": "cisco_secure_client/datadog_checks/cisco_secure_client/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the `cisco_secure_client` integration, primarily exposing the package version imported from `__about__.py`.",
            "spof": true
          },
          {
            "path": "cisco_secure_client/datadog_checks/cisco_secure_client/data",
            "description": "This directory is intended to store static data, default configurations, or other non-code assets specific to the `cisco_secure_client` Datadog integration. As it is currently empty, it may serve as a placeholder or indicates that data is managed dynamically or elsewhere.",
            "spof": false
          },
          {
            "path": "cisco_secure_client/assets/dashboards",
            "description": "This directory stores pre-built dashboards tailored for the Cisco Secure Client integration. These dashboards provide visualizations and metrics for monitoring the integration's performance and data within Datadog.",
            "spof": false
          },
          {
            "path": "cisco_secure_client/assets/configuration",
            "description": "This directory is designated to hold configuration-related assets for the Datadog `cisco_secure_client` integration. Its primary role is to provide any necessary configuration files, templates, or examples required for setting up and customizing the integration.",
            "spof": false
          },
          {
            "path": "cisco_secure_client/assets/monitors",
            "description": "This directory is intended to house Datadog monitor configurations specifically for the Cisco Secure Client integration. It would define alerts and checks to ensure the integrated system's health and performance. Although currently empty, its purpose is to centralize these monitor definitions.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "manan-crest",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 9,
      "spofCount": 3
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "HashiCorp Consul Connect Monitoring": {
    "description": "Provides observability into the Consul Connect service mesh by monitoring its Envoy sidecar proxies.",
    "functions": {
      "Integration Packaging and Documentation": {
        "files": [
          {
            "path": "consul_connect/CHANGELOG.md",
            "description": "This file is the changelog for the Consul Connect integration, documenting all changes and version releases over time.",
            "spof": true
          },
          {
            "path": "consul_connect/README.md",
            "description": "This file provides instructions on how to monitor Consul Connect Envoy sidecar proxies using the Datadog Agent. It details the setup for metric and log collection, leveraging the existing Datadog Envoy integration.",
            "spof": false
          },
          {
            "path": "consul_connect/assets",
            "description": "This directory is designated for storing static assets or resources pertinent to the `consul_connect` integration. Although currently empty, it serves as a placeholder for any images, icons, or other non-code files that might be required.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 44
          },
          {
            "name": "davidfeng-datadog",
            "percent": 32
          },
          {
            "name": "Andrew Zhang",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 1
    },
    "busFactor": 5,
    "authorCount": 5
  },
  "Confluent Platform Monitoring": {
    "description": "Monitors the Confluent Platform and its components, including Kafka brokers and Schema Registry, by collecting JMX metrics.",
    "functions": {
      "Confluent_Platform_JMX_Monitoring": {
        "files": [
          {
            "path": "confluent_platform/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor Confluent Platform and its various Kafka components. It details how to collect JMX metrics and logs, along with validation and troubleshooting steps.",
            "spof": false
          },
          {
            "path": "confluent_platform/CHANGELOG.md",
            "description": "This file is the changelog for the Confluent Platform integration, detailing all version updates, new features, bug fixes, and other modifications.",
            "spof": false
          },
          {
            "path": "confluent_platform/tests/conftest.py",
            "description": "This file contains pytest fixtures to set up and tear down a Dockerized Confluent Platform environment, including Kafka, Schema Registry, and Kafka Connect, for integration testing of the Confluent Platform check.",
            "spof": false
          },
          {
            "path": "confluent_platform/tests/__init__.py",
            "description": "This file marks the 'tests' directory as a Python package, allowing its test modules to be imported and organized within the `confluent_platform` integration.",
            "spof": true
          },
          {
            "path": "confluent_platform/tests/metrics.py",
            "description": "This file defines lists of expected metric names for testing the Confluent Platform integration, covering Kafka broker, Connect worker, and Connect task metrics.",
            "spof": false
          },
          {
            "path": "confluent_platform/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Confluent Platform integration, verifying that the expected metrics and service checks are collected by the Datadog Agent.",
            "spof": false
          },
          {
            "path": "confluent_platform/tests/common.py",
            "description": "This file defines common test configurations for the Confluent Platform integration, including JMX instance settings for various Confluent services like Zookeeper, Kafka, and Schema Registry.",
            "spof": true
          },
          {
            "path": "confluent_platform/tests/compose",
            "description": "This directory is intended to contain Docker Compose configurations and related files specifically for setting up and tearing down testing environments for the `confluent_platform` integration. It facilitates integration tests by orchestrating external services required for the integration to function and be tested effectively.",
            "spof": false
          },
          {
            "path": "confluent_platform/datadog_checks/confluent_platform/__init__.py",
            "description": "This file initializes the `confluent_platform` package and exposes its version number, which is imported from `__about__.py`.",
            "spof": true
          },
          {
            "path": "confluent_platform/datadog_checks/confluent_platform/config_models/validators.py",
            "description": "This file is intended for defining custom configuration validators or transformers for the Confluent Platform integration. It includes commented-out examples illustrating how to implement such logic.",
            "spof": true
          },
          {
            "path": "confluent_platform/datadog_checks/confluent_platform/config_models/defaults.py",
            "description": "This file defines default values for configuration options used by the Confluent Platform integration's configuration models, and it is automatically generated.",
            "spof": true
          },
          {
            "path": "confluent_platform/datadog_checks/confluent_platform/config_models/__init__.py",
            "description": "This file serves as the package initializer for configuration models, defining a `ConfigMixin` that provides access to instance-specific and shared configuration objects. It is an autogenerated file derived from a `spec.yaml`.",
            "spof": false
          },
          {
            "path": "confluent_platform/datadog_checks/confluent_platform/config_models/instance.py",
            "description": "This file defines the Pydantic model for validating the configuration schema of an instance of the Confluent Platform integration. It is an autogenerated file based on a specification.",
            "spof": true
          },
          {
            "path": "confluent_platform/datadog_checks/confluent_platform/config_models/shared.py",
            "description": "This file defines the shared Pydantic configuration model for the Confluent Platform integration, automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "confluent_platform/datadog_checks/confluent_platform/data",
            "description": "This `data` directory is part of the `confluent_platform` integration check. It is typically intended to store any static data files, configuration templates, or other resources required by the integration for its operation. While currently empty, its purpose is to centralize such auxiliary data.",
            "spof": false
          },
          {
            "path": "confluent_platform/assets/monitors",
            "description": "This directory is intended to store assets related to monitoring configurations for the Datadog Confluent Platform integration. It would typically contain monitor definitions, alerts, or related metadata. Though currently empty, its purpose is to house these monitoring resources.",
            "spof": false
          },
          {
            "path": "confluent_platform/assets/configuration",
            "description": "This directory is intended to store configuration assets or templates specifically for the Confluent Platform integration. Although currently empty, its purpose is to provide examples or default configurations for setting up and monitoring Confluent Platform services with Datadog.",
            "spof": false
          },
          {
            "path": "confluent_platform/assets/dashboards",
            "description": "This directory is designated to store dashboard assets specifically for the `confluent_platform` integration. These assets would typically include JSON definitions for Datadog dashboards, enabling visualization of Confluent Platform metrics.",
            "spof": false
          },
          {
            "path": "flink/datadog_checks/flink/data",
            "description": "This directory serves as a conventional location for static data files and configuration assets specific to the Datadog Flink integration check. It is intended to house non-code resources like default configurations or metric definitions that support the check's functionality.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 27
          },
          {
            "name": "Kyle Neale",
            "percent": 18
          },
          {
            "name": "HadhemiDD",
            "percent": 17
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 19,
      "spofCount": 7
    },
    "busFactor": 2,
    "authorCount": 8
  },
  "Citrix Hypervisor Monitoring": {
    "description": "Monitors Citrix Hypervisor (formerly XenServer) hosts and virtual machines for performance and resource utilization.",
    "functions": {
      "Hypervisor Metric and Metadata Collection": {
        "files": [
          {
            "path": "citrix_hypervisor/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Citrix Hypervisor integration, detailing all version updates, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "citrix_hypervisor/README.md",
            "description": "This file is the README for the Datadog Agent check for Citrix Hypervisor, detailing its overview, setup instructions, configuration, and data collected. It explains how to monitor Citrix Hypervisor through the Datadog Agent.",
            "spof": false
          },
          {
            "path": "citrix_hypervisor/tests/test_metrics.py",
            "description": "This file contains unit tests for the `metrics` module of the Citrix Hypervisor integration, specifically verifying the `build_metric` function's ability to parse raw metric strings into a standardized format with appropriate tags, and its error handling for invalid inputs.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/tests/test_citrix_hypervisor.py",
            "description": "Unit tests for the Citrix Hypervisor integration, covering connection handling, metric collection, and service checks using various mock scenarios.",
            "spof": false
          },
          {
            "path": "citrix_hypervisor/tests/test_metadata.py",
            "description": "This file contains unit tests for the Datadog Citrix Hypervisor integration, specifically verifying the collection and reporting of metadata, such as software version, from a mocked Citrix Hypervisor instance.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/__init__.py",
            "description": "This file serves as the package initializer for the `citrix_hypervisor` integration. It imports and exposes the package version and the main check class, `CitrixHypervisorCheck`, making them accessible when the package is imported.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/check.py",
            "description": "This file implements the Datadog Agent check for Citrix Hypervisor, collecting metrics and metadata from instances and handling session management, including master/slave detection.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/metrics.py",
            "description": "This file defines how to parse and transform raw Citrix Hypervisor metric strings into Datadog-compatible metric names and tags. It contains mappings for simple metrics and regular expressions for more complex, dynamic metrics.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/data",
            "description": "This directory is intended to store data-related files for the `citrix_hypervisor` Datadog integration. These files might include configuration templates, static lookup tables, or other non-code assets required by the check. As it is currently empty, it serves as a designated placeholder for such future content.",
            "spof": false
          },
          {
            "path": "citrix_hypervisor/assets/monitors",
            "description": "This directory is intended to house monitoring-specific assets or configuration files for the Datadog Citrix Hypervisor integration. Its purpose is to centralize resources related to data collection and visualization for this particular integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "NouemanKHAL",
            "percent": 24
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 15
          },
          {
            "name": "Kyle Neale",
            "percent": 14
          }
        ]
      },
      "Emulated Test Environment and E2E Validation": {
        "files": [
          {
            "path": "citrix_hypervisor/tests/__init__.py",
            "description": "This is an empty `__init__.py` file, which signifies that the `tests` directory is a Python package. Its purpose is to allow test modules within this directory to be imported and discovered by test runners.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/tests/test_lab.py",
            "description": "This file contains a manual test suite for the Citrix Hypervisor integration, designed to connect to and validate metrics from real Citrix Hypervisor instances.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Citrix Hypervisor integration. It verifies that the integration collects metrics correctly from various Citrix Hypervisor configurations.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/tests/conftest.py",
            "description": "This file defines pytest fixtures for the `citrix_hypervisor` integration's tests, including setting up a Docker environment and mocking HTTP requests to serve local fixture data.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/tests/common.py",
            "description": "This file contains common utilities, mock data, and configurations for testing the Citrix Hypervisor integration. It includes definitions for mocked instances, E2E test setups with Docker, mock session responses, and helper functions for asserting metrics.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/tests/compose/server.py",
            "description": "This Flask application serves as a mock Citrix Hypervisor API server for testing purposes. It provides predefined responses for RRD updates, host RRD data, and various XML-RPC calls based on request content.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/tests/fixtures/standalone",
            "description": "This directory is designated to store test fixtures for the `citrix_hypervisor` integration. These fixtures are intended for standalone test scenarios, providing isolated data or configurations for specific test cases. Although currently empty, it serves as a placeholder for future test data that operates independently.",
            "spof": false
          },
          {
            "path": "citrix_hypervisor/tests/fixtures/slave",
            "description": "This directory is intended to store test fixtures or data specifically related to a 'slave' component within the Citrix Hypervisor integration tests. It would provide mock data or configurations to simulate a slave environment for testing purposes.",
            "spof": false
          },
          {
            "path": "citrix_hypervisor/tests/fixtures/master",
            "description": "This directory is intended to house the primary or 'master' set of test fixtures specifically for the Datadog Citrix Hypervisor integration tests. These fixtures would provide consistent, pre-defined data to ensure reliable testing. Currently, it serves as an empty placeholder awaiting content.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "NouemanKHAL",
            "percent": 93
          },
          {
            "name": "Juanpe Araque",
            "percent": 3
          },
          {
            "name": "dkirov-dd",
            "percent": 2
          }
        ]
      },
      "Integration Configuration Schema": {
        "files": [
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators and transformers for the Citrix Hypervisor integration, allowing for additional checks and modifications of user-provided settings.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient accessors for integration instance and shared configuration models, which are autogenerated from a specification file.",
            "spof": false
          },
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/config_models/instance.py",
            "description": "This file defines the Pydantic data model for the configuration schema of a single instance of the Citrix Hypervisor Datadog integration. It includes various settings for connection, authentication, and metric collection.",
            "spof": false
          },
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/config_models/defaults.py",
            "description": "This file defines the default values for the configuration options of the Citrix Hypervisor integration, automatically generated from the integration's specification (spec.yaml).",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/datadog_checks/citrix_hypervisor/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options, such as proxy settings and timeouts, used across Datadog integrations. It is autogenerated from a specification file and includes validation logic for these common parameters.",
            "spof": true
          },
          {
            "path": "citrix_hypervisor/assets/configuration",
            "description": "This directory is designated to store configuration assets or templates specific to the Datadog Citrix Hypervisor integration. Although currently empty, its purpose is to centralize any configuration-related files needed for the integration's setup or deployment.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 79
          },
          {
            "name": "Yann Armelin",
            "percent": 13
          },
          {
            "name": "Paul",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 25,
      "spofCount": 14
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Cloud Foundry API Monitoring": {
    "description": "Collects audit events from the Cloud Foundry API to track administrative actions and user activity.",
    "functions": {
      "Cloud Foundry Event & Resource Polling": {
        "files": [
          {
            "path": "cloud_foundry_api/CHANGELOG.md",
            "description": "This file is the changelog for the Cloud Foundry API integration, detailing all the changes, fixes, and updates across different versions.",
            "spof": false
          },
          {
            "path": "cloud_foundry_api/tests/__init__.py",
            "description": "This is an empty `__init__.py` file, serving to mark the `tests` directory as a Python package.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/tests/test_utils.py",
            "description": "This file contains unit tests for the utility functions `date_to_ts`, `get_next_url`, and `join_url` used by the Cloud Foundry API integration.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/tests/test_cloud_foundry_api.py",
            "description": "This file contains unit tests for the `CloudFoundryApiCheck` integration, covering its initialization, event collection logic, and error handling for API interactions. It uses mocking to simulate API responses and verify correct check behavior.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/tests/conftest.py",
            "description": "This file defines pytest fixtures used for testing the Cloud Foundry API integration, including mock API responses and test configurations. It provides various data sets for Cloud Foundry API v2 and v3 events, organizations, spaces, and authentication tokens.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/tests/constants.py",
            "description": "This file defines constants used in the Cloud Foundry API integration tests, such as the current directory and a specific timestamp for time-based test scenarios.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/tests/fixtures",
            "description": "This directory is intended to store test fixtures for the `cloud_foundry_api` integration's tests. Although currently empty, it serves as the designated location for mock data, configuration files, or other static resources needed to set up specific test scenarios for the integration.",
            "spof": false
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/cloud_foundry_api.py",
            "description": "This file implements a Datadog agent check for monitoring Cloud Foundry. It handles API version discovery, authentication with UAA, and fetching organizational and space data from the Cloud Foundry API.",
            "spof": false
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/__init__.py",
            "description": "This `__init__.py` file serves as the entry point for the `cloud_foundry_api` package, exposing the `CloudFoundryApiCheck` class and the package version for external use.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/utils.py",
            "description": "This file provides utility functions for Cloud Foundry API interactions, including extracting pagination URLs, converting ISO dates to timestamps, and safely joining URL components.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 29
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 13
          },
          {
            "name": "HadhemiDD",
            "percent": 13
          }
        ]
      },
      "Integration Configuration Management": {
        "files": [
          {
            "path": "cloud_foundry_api/README.md",
            "description": "This README file provides instructions for setting up and configuring the Datadog Agent's Cloud Foundry API integration to collect audit events. It details installation, configuration, validation, and data collection specifics for the check.",
            "spof": false
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/constants.py",
            "description": "This file defines various constants used by the Cloud Foundry API integration, including default values for pagination, lookback periods, service check names, and event filters. It also specifies the minimum required Cloud Foundry API V3 version.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/config_models/defaults.py",
            "description": "This file defines default configuration values for the Cloud Foundry API integration, with each function returning a specific default setting. It is autogenerated from the integration's specification file.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that combines autogenerated instance-specific and shared configuration models for the Cloud Foundry API integration, providing access to them via `config` and `shared_config` properties.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators and transformers for the Cloud Foundry API integration, allowing for additional logic to process or validate instance settings beyond schema definitions.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/config_models/instance.py",
            "description": "This file defines Pydantic models for the configuration schema of the Datadog Cloud Foundry API integration, including structures for instance settings, authentication tokens, metric patterns, and proxy settings. It is an autogenerated file from the integration's `spec.yaml`.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options like proxy settings and timeouts, which are utilized across various integrations. It includes custom validation logic for these shared configurations.",
            "spof": true
          },
          {
            "path": "cloud_foundry_api/datadog_checks/cloud_foundry_api/data",
            "description": "This directory is intended to store static data files or assets used by the Cloud Foundry API Datadog integration. Examples could include default configuration templates, schema definitions, or lookup tables.",
            "spof": false
          },
          {
            "path": "cloud_foundry_api/assets/configuration",
            "description": "This directory is designated to store configuration-related assets for the `cloud_foundry_api` integration. While currently empty, it serves as the intended location for default or example configuration files, contributing to the integration's setup and operation.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 75
          },
          {
            "name": "Yann Armelin",
            "percent": 11
          },
          {
            "name": "dkirov-dd",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 19,
      "spofCount": 12
    },
    "busFactor": 1,
    "authorCount": 5
  },
  "BentoML Model Serving Monitoring": {
    "description": "Collects performance metrics from BentoML model serving deployments to ensure the reliability of machine learning services.",
    "functions": {
      "Pre-built Monitoring Assets and Documentation": {
        "files": [
          {
            "path": "bentoml/README.md",
            "description": "This file is the README for the Datadog Agent's BentoML integration, providing instructions on how to monitor BentoML deployments by collecting metrics, logs, and service checks.",
            "spof": true
          },
          {
            "path": "bentoml/CHANGELOG.md",
            "description": "This file documents the version history of the BentoML integration, detailing changes, new features, and fixes for each release.",
            "spof": false
          },
          {
            "path": "bentoml/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions or configurations specific to the Bentoml integration. It holds assets used for visualizing Bentoml-related metrics and logs within Datadog.",
            "spof": false
          },
          {
            "path": "bentoml/assets/monitors",
            "description": "This directory is intended to store monitor configurations or definitions specifically for the BentoML integration. It would house the necessary assets to set up monitoring within Datadog for BentoML services. Currently, the directory is empty.",
            "spof": false
          },
          {
            "path": "bentoml/assets/saved_views",
            "description": "This directory is designated to store definitions or configurations for 'saved views' specifically related to the Datadog BentoML integration. These views likely represent pre-defined dashboards, monitoring configurations, or visualization setups. Its purpose is to provide ready-to-use observability assets for BentoML services.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 79
          },
          {
            "name": "NouemanKHAL",
            "percent": 7
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 6
          }
        ]
      },
      "Integration Testing and Validation": {
        "files": [
          {
            "path": "bentoml/tests/__init__.py",
            "description": "This `__init__.py` file marks the 'tests' directory as a Python package, allowing its contents to be imported as modules.",
            "spof": true
          },
          {
            "path": "bentoml/tests/common.py",
            "description": "This file defines common constants, utility functions, and expected metric names used across tests for the Datadog Bentoml integration.",
            "spof": true
          },
          {
            "path": "bentoml/tests/test_unit.py",
            "description": "Unit tests for the Datadog Bentoml integration, verifying metric collection and service check functionality under various mocked HTTP response scenarios.",
            "spof": true
          },
          {
            "path": "bentoml/tests/fixtures",
            "description": "This directory is intended to store test fixtures for the BentoML integration. These fixtures would provide stable, predefined data, configurations, or mock objects necessary for running automated tests effectively. Although currently empty, its purpose is to house essential setup elements for reliable testing.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 100
          }
        ]
      },
      "BentoML Metric Collection and Health Checking": {
        "files": [
          {
            "path": "bentoml/datadog_checks/bentoml/__init__.py",
            "description": "This `__init__.py` file initializes the Datadog Bentoml integration package, exposing its version and the main BentomlCheck class for external use.",
            "spof": true
          },
          {
            "path": "bentoml/datadog_checks/bentoml/metrics.py",
            "description": "This file defines metric mappings and transformations for the Bentoml integration, translating Bentoml's internal metrics and labels into a Datadog-compatible format.",
            "spof": true
          },
          {
            "path": "bentoml/datadog_checks/bentoml/check.py",
            "description": "This file implements a Datadog integration check for Bentoml, collecting metrics from its OpenMetrics endpoint and monitoring the health of specific service endpoints.",
            "spof": true
          },
          {
            "path": "bentoml/datadog_checks/bentoml/data",
            "description": "This directory is part of the Datadog BentoML integration. It is designated for storing static data or configuration files that support the BentoML check, such as default metrics or service check definitions.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 100
          }
        ]
      },
      "Integration Configuration and Schema": {
        "files": [
          {
            "path": "bentoml/datadog_checks/bentoml/config_models/defaults.py",
            "description": "This file defines default configuration values for the Datadog Bentoml integration. It contains functions that return standard default settings for various integration parameters.",
            "spof": true
          },
          {
            "path": "bentoml/datadog_checks/bentoml/config_models/__init__.py",
            "description": "This file provides a mixin (`ConfigMixin`) that allows access to the `InstanceConfig` and `SharedConfig` models for the Bentoml integration, serving as a central point for configuration access. It is an autogenerated file based on the integration's `spec.yaml`.",
            "spof": true
          },
          {
            "path": "bentoml/datadog_checks/bentoml/config_models/validators.py",
            "description": "This file provides a location for defining additional validators and transformers for the Datadog Bentoml integration's configuration, allowing for custom logic to process or validate configuration settings.",
            "spof": true
          },
          {
            "path": "bentoml/datadog_checks/bentoml/config_models/shared.py",
            "description": "This autogenerated file defines shared Pydantic configuration models, including `Proxy` and `SharedConfig`, used across Datadog integrations. It implements a structured validation process for these common configuration settings.",
            "spof": true
          },
          {
            "path": "bentoml/datadog_checks/bentoml/config_models/instance.py",
            "description": "This file defines the Pydantic models for the configuration schema of a Datadog Agent `bentoml` integration instance, including various parameters for metric collection, networking, and authentication. It is an autogenerated file based on a YAML specification.",
            "spof": true
          },
          {
            "path": "bentoml/assets/configuration",
            "description": "This directory is designated to hold configuration assets for the Datadog BentoML integration. It would typically contain static configuration files that define the integration's behavior or settings.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 99
          },
          {
            "name": "Yann Armelin",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 19,
      "spofCount": 12
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "containerd Monitoring": {
    "description": "Monitors the `containerd` container runtime, collecting metrics, events, and service checks for container lifecycle management.",
    "functions": {
      "Integration Packaging and Documentation": {
        "files": [
          {
            "path": "containerd/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Containerd integration, documenting its versions and updates.",
            "spof": true
          },
          {
            "path": "containerd/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent's integration with Containerd. It details installation steps, configuration options, data collected (metrics, events, service checks), and troubleshooting information.",
            "spof": false
          },
          {
            "path": "containerd/assets",
            "description": "This directory is intended to store static assets for the Datadog Containerd integration. These typically include configuration files, dashboards, or other non-code resources necessary for the integration's deployment or functionality. Currently, it appears to be empty, suggesting no specific assets are required here at present.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 48
          },
          {
            "name": "davidfeng-datadog",
            "percent": 34
          },
          {
            "name": "cswatt",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 1
    },
    "busFactor": 4,
    "authorCount": 4
  },
  "Cisco Secure Web Appliance Log Analysis": {
    "description": "Ingests Access and L4TM logs from Cisco Secure Web Appliance to monitor web traffic and security policies.",
    "functions": {
      "Integration Assets and Configuration": {
        "files": [
          {
            "path": "cisco_secure_web_appliance/CHANGELOG.md",
            "description": "This file is a changelog documenting all release versions, new features, and updates for the Cisco Secure Web Appliance integration.",
            "spof": false
          },
          {
            "path": "cisco_secure_web_appliance/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent integration for Cisco Secure Web Appliance. It details how to collect Access Logs and L4TM Logs via Syslog Push or SCP on Remote Server, along with validation and troubleshooting steps.",
            "spof": true
          },
          {
            "path": "cisco_secure_web_appliance/images",
            "description": "This directory is intended to store images, such as screenshots or diagrams, that are relevant to the Cisco Secure Web Appliance integration. Although currently empty, its purpose is to house visual assets for documentation or UI elements related to this specific integration.",
            "spof": false
          },
          {
            "path": "cisco_secure_web_appliance/datadog_checks/cisco_secure_web_appliance/__init__.py",
            "description": "This file serves as the package initializer for the Cisco Secure Web Appliance integration, defining the package version by importing it from `__about__.py`.",
            "spof": true
          },
          {
            "path": "cisco_secure_web_appliance/datadog_checks/cisco_secure_web_appliance/data",
            "description": "This `data` directory is part of the `cisco_secure_web_appliance` integration. It is typically intended to store static data, default configurations, or other non-code assets required by the Datadog check.",
            "spof": false
          },
          {
            "path": "cisco_secure_web_appliance/assets/dashboards",
            "description": "This directory is designated to store JSON definitions for Datadog dashboards specifically tailored for the Cisco Secure Web Appliance integration. These dashboards would provide visualizations of metrics and logs collected, offering insights into the appliance's performance. Although currently empty, it serves as the intended location for these visualization assets.",
            "spof": false
          },
          {
            "path": "cisco_secure_web_appliance/assets/configuration",
            "description": "This directory is intended to store configuration-related assets for the Datadog integration with Cisco Secure Web Appliance. It would typically house files defining how the integration should be configured or examples of configuration settings.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "madhavpandya-crest",
            "percent": 77
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 6
          },
          {
            "name": "Kyle Neale",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 7,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "CrowdStrike Falcon Data Replicator Integration": {
    "description": "Ingests comprehensive endpoint security data from CrowdStrike Falcon Data Replicator (FDR) for advanced threat hunting and analysis.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "crowdstrike_fdr/CHANGELOG.md",
            "description": "This file is the changelog for the `crowdstrike_fdr` integration, documenting its release history and updates, starting with its initial release.",
            "spof": true
          },
          {
            "path": "crowdstrike_fdr/README.md",
            "description": "This README provides instructions for integrating CrowdStrike Falcon Data Replicator (FDR) with Datadog, covering setup of an AWS S3 bucket for data replication and configuration of the Datadog Forwarder.",
            "spof": true
          },
          {
            "path": "crowdstrike_fdr/images",
            "description": "This directory is designated to store images and visual assets specifically associated with the `crowdstrike_fdr` integration. These assets could include icons, screenshots, or diagrams used for documentation or UI purposes. Although currently empty, it serves as the dedicated location for such content.",
            "spof": false
          },
          {
            "path": "crowdstrike_fdr/assets/dashboards",
            "description": "This directory is intended to store dashboard assets and configurations specifically designed for the CrowdStrike FDR Datadog integration. It would contain files defining dashboards that visualize data collected by this integration, providing operational insights.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Tirthraj Chaudhari",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "CrewAI Observability": {
    "description": "Provides automatic tracing and monitoring for autonomous AI agent applications built with the CrewAI framework.",
    "functions": {
      "Integration Documentation and Assets": {
        "files": [
          {
            "path": "crewai/README.md",
            "description": "This README provides instructions for setting up and using the Datadog integration to monitor, troubleshoot, and evaluate applications built with the CrewAI framework, including details on automatic tracing for CrewAI methods.",
            "spof": true
          },
          {
            "path": "crewai/CHANGELOG.md",
            "description": "This file documents all releases and changes for the Datadog CrewAI integration. It provides a historical record of updates, new features, and bug fixes.",
            "spof": true
          },
          {
            "path": "crewai/assets",
            "description": "This directory is intended to house various assets or static files that support the Datadog CrewAI integration. While currently empty, it serves as a designated location for resources such as images, configuration templates, or other supplementary content relevant to the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Yun Kim",
            "percent": 98
          },
          {
            "name": "dkirov-dd",
            "percent": 2
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Contentful Audit Trail Integration": {
    "description": "Ingests event logs from Contentful via webhooks to monitor content updates, publications, and user activity.",
    "functions": {
      "Contentful Integration Assets and Configuration": {
        "files": [
          {
            "path": "contentful/CHANGELOG.md",
            "description": "This file documents all notable changes and version history for the Datadog Contentful integration, starting from its initial release.",
            "spof": true
          },
          {
            "path": "contentful/README.md",
            "description": "This README provides instructions for setting up the Datadog-Contentful integration, detailing how to configure Contentful webhooks to forward event logs to Datadog. It outlines the types of Contentful events collected as logs.",
            "spof": false
          },
          {
            "path": "contentful/images",
            "description": "This directory is designated to store image assets and visual resources specifically related to the Contentful integration within the Datadog integrations-core repository. Although currently empty, its purpose is to house any relevant images for documentation, UI, or other integration-specific needs.",
            "spof": false
          },
          {
            "path": "contentful/assets/dashboards",
            "description": "This directory is intended to store pre-configured Datadog dashboards specifically for the Contentful integration. It would typically contain JSON definitions of dashboards designed to visualize metrics collected from Contentful.",
            "spof": false
          },
          {
            "path": "contentful/assets/monitors",
            "description": "This directory is intended to store definitions or configurations for Datadog monitors specifically designed for the Contentful integration. These monitors would likely track metrics, events, or service checks related to Contentful, triggering alerts when predefined conditions are met.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Mauneel Sorathia",
            "percent": 69
          },
          {
            "name": "dkirov-dd",
            "percent": 19
          },
          {
            "name": "davidfeng-datadog",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 1
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "Integrations Core Library": {
    "description": "Provides the foundational components, base classes, utilities, and standardized APIs for developing all Datadog Agent integrations.",
    "functions": {
      "Secure Artifact Downloader": {
        "files": [
          {
            "path": "datadog_checks_dependency_provider/README.md",
            "description": "This file describes a component whose sole purpose is to define dependencies for integrations that are not part of `integrations-core`.",
            "spof": true
          },
          {
            "path": "datadog_checks_dependency_provider/CHANGELOG.md",
            "description": "This file is a changelog for the `datadog_checks_dependency_provider` component, documenting all version releases and the changes included in each, such as additions, fixes, and removals.",
            "spof": false
          },
          {
            "path": "datadog_checks_dependency_provider/datadog_checks/datadog_checks_dependency_provider/__init__.py",
            "description": "This is the package initialization file for `datadog_checks_dependency_provider`, primarily used to expose the package's version number.",
            "spof": true
          },
          {
            "path": "datadog_checks_dependency_provider/datadog_checks/datadog_checks_dependency_provider/data",
            "description": "This directory is designated to store static data files or configuration assets for the `datadog_checks_dependency_provider` module. Although currently empty, it serves as a placeholder for any non-code resources required to provision dependencies for other Datadog checks.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Checks Downloader, documenting all version releases, new features, bug fixes, security updates, and other changes over time.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/tests/test_unit.py",
            "description": "This file contains unit tests for the `TUFDownloader` class, specifically verifying its ability to filter non-official (pre-release) wheel versions when determining the correct download path.",
            "spof": true
          },
          {
            "path": "datadog_checks_downloader/tests/test_downloader.py",
            "description": "This file contains unit and integration tests for the `datadog_checks_downloader` module. It verifies the downloader's functionality, including package download, metadata verification (TUF), and error handling for various scenarios.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/datadog_checks/downloader/parameters.py",
            "description": "This module provides a `substitute` function that parses a Python package's relative path (likely a wheel filename) to extract and return key parameters, such as package version and distribution names, for use in in-toto inspections.",
            "spof": true
          },
          {
            "path": "datadog_checks_downloader/datadog_checks/downloader/download.py",
            "description": "This file implements a `TUFDownloader` class responsible for securely downloading software artifacts using The Update Framework (TUF) and in-toto for supply chain integrity verification. It handles fetching targets, metadata, and performing cryptographic checks.",
            "spof": false
          },
          {
            "path": "datadog_checks_downloader/datadog_checks/downloader/data/repo/metadata",
            "description": "This directory is intended to store metadata pertaining to external repositories used by the Datadog checks downloader. It likely serves as a cache or storage location for information required to manage and retrieve integration source data.",
            "spof": false
          },
          {
            "path": "docs/proposals/checks_as_wheels.md",
            "description": "This document is a proposal outlining a change in how Datadog Agent checks are packaged and distributed. It suggests migrating from system packages to Python wheels to address issues with building, versioning, dependencies, and user experience for both core and custom checks.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 15
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 14
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 13
          }
        ]
      },
      "Configuration Management & Modeling": {
        "files": [
          {
            "path": "crio/datadog_checks/crio/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options, such as proxy settings and timeouts, used across Datadog integrations. It includes validation and default value handling for these common configuration parameters.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/__init__.py",
            "description": "This `__init__.py` file serves as the entry point for the configuration tooling module, exposing core configuration specifications.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/configuration/core.py",
            "description": "This file defines the `ConfigSpec` class, responsible for parsing, validating, and resolving configuration specifications from raw text, including handling YAML loading, templating, and error collection.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/test_config.py",
            "description": "This file contains unit tests for the `config` module within `datadog_checks_base`, specifically testing the `is_affirmative` function and its backward-compatible alias for handling boolean-like configuration values.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/test_ast_config.py",
            "description": "This file contains unit tests for the `_config_ast` utility, which safely parses string representations of configuration values, including special float values like `inf` and `nan`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_config.py",
            "description": "This file contains tests for the configuration schema of the Windows performance counter check, ensuring that invalid or malformed configuration options raise appropriate exceptions. It validates types, presence, and structure of various settings like server, username, password, metrics, and counters.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/models/test_interface.py",
            "description": "Tests the configuration loading, validation, and deprecation warning mechanisms for AgentCheck instances using the `ConfigMixin` and its associated models. It covers default values, error handling, boolean parsing, and name normalization.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/models/config_models/validators.py",
            "description": "This file is intended to define custom configuration validators and transformers for Datadog check models, as demonstrated by the example functions.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/models/config_models/deprecations.py",
            "description": "This file defines models for deprecation configurations, specifically providing `shared` and `instance` level deprecation details including agent versions and migration instructions. It likely serves as test data or examples for handling deprecations within Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/models/config_models/defaults.py",
            "description": "This autogenerated file defines default values for configuration models, likely for testing purposes within the Datadog check base library. It provides a default `instance_flag` value and is generated from `spec.yaml`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/models/config_models/shared.py",
            "description": "This autogenerated file defines the `SharedConfig` Pydantic model, which provides a base structure and validation logic for common configuration parameters across integration checks. It includes handling for deprecations and applies custom validators defined elsewhere.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/models/config_models/__init__.py",
            "description": "This is an autogenerated file that defines the `ConfigMixin` class. It provides properties to access `InstanceConfig` and `SharedConfig` for Datadog check configurations, typically generated from a `spec.yaml`.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/models/config_models/instance.py",
            "description": "This file defines Pydantic models for the `instance` configuration of a Datadog integration, including validation logic and handling of defaults and deprecations. It is an autogenerated file based on a `spec.yaml`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/models/data",
            "description": "This directory is intended to store data files used by tests for data models within the `datadog_checks_base` package. Although currently empty, it serves as the designated location for mock or sample data required to validate model functionality.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/config.py",
            "description": "This file serves as a public interface for configuration utilities within `datadog_checks_base`. It re-exports all essential configuration components and the `_is_affirmative` function from the `base.config` module.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/config.py",
            "description": "This file provides a utility function `is_affirmative` for converting various input values (e.g., strings, numbers) into a meaningful boolean representation, useful for configuration parsing. It also includes a deprecated compatibility alias.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/models/types.py",
            "description": "Provides a utility function `copy_raw` for creating a deep copy of basic Python data structures (lists, dictionaries), treating strings and other primitive types as atomic.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/models/__init__.py",
            "description": "This file marks the 'models' directory as a Python package. It likely serves as a container for data models or schemas used across Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/models/validation/utils.py",
            "description": "This file provides utility functions for model validation, including making data structures immutable and handling deprecated configuration options by generating warning messages.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/models/validation/core.py",
            "description": "This file provides core utility functions, `initialize_config` and `check_model`, which act as placeholder or default validators for configuration models within Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/models/validation/__init__.py",
            "description": "This file initializes the `validation` package, making core validation logic and utility functions available for model validation within Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/_config_ast.py",
            "description": "This module parses string representations of Python objects, specifically handling and converting special float values (infinity, negative infinity, and NaN) into their proper float types by using AST transformation and placeholders.",
            "spof": true
          },
          {
            "path": "dcgm/datadog_checks/dcgm/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration settings, such as proxy and timeout, used by Datadog integrations. It is autogenerated from a `spec.yaml` and includes logic for validation and applying default values.",
            "spof": false
          },
          {
            "path": "directory/datadog_checks/directory/config_models/shared.py",
            "description": "This autogenerated file defines the `SharedConfig` Pydantic model, which serves as a base schema for common configuration parameters within Datadog integrations, including validation logic.",
            "spof": true
          },
          {
            "path": "directory/assets/configuration",
            "description": "This directory is intended to house configuration assets for a specific Datadog integration within the `integrations-core` repository. It likely serves as a designated location for examples, templates, or schema definitions related to the integration's setup, even though it currently contains no files.",
            "spof": false
          },
          {
            "path": "druid/datadog_checks/druid/config_models/instance.py",
            "description": "This file defines Pydantic models for the configuration of a Druid integration instance. It is automatically generated from a `spec.yaml` file.",
            "spof": true
          },
          {
            "path": "druid/datadog_checks/druid/config_models/__init__.py",
            "description": "This file initializes the configuration models for the Druid integration, providing a mixin (`ConfigMixin`) to access both instance-specific and shared configuration settings. It is an autogenerated file derived from a `spec.yaml`.",
            "spof": false
          },
          {
            "path": "druid/datadog_checks/druid/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options, such as proxy settings, within the Druid integration, including validation and default value handling.",
            "spof": true
          },
          {
            "path": "druid/datadog_checks/druid/config_models/validators.py",
            "description": "This file is a placeholder for custom configuration validators and transformers specific to the Datadog Druid integration, enabling advanced config logic and validation.",
            "spof": true
          },
          {
            "path": "druid/assets/configuration",
            "description": "This directory is intended to house configuration assets or example configuration files specific to the Datadog Druid integration. Its purpose is to provide users with guidance or boilerplate for setting up the integration.",
            "spof": false
          },
          {
            "path": "elastic/datadog_checks/elastic/config_models/shared.py",
            "description": "This autogenerated file defines Pydantic models for shared configuration options, such as proxy settings, used across multiple integrations, including associated validation logic.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Enrico Donnici",
            "percent": 58
          },
          {
            "name": "Ofek Lev",
            "percent": 35
          },
          {
            "name": "Yann Armelin",
            "percent": 2
          }
        ]
      },
      "Integration Development & Validation Tooling (ddev)": {
        "files": [
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/manifest_validator/common/validator.py",
            "description": "This file defines common base classes and specific validators for checking and potentially fixing issues within integration manifest files, supporting different manifest versions (V1 and V2).",
            "spof": false
          },
          {
            "path": "ddev/tests/event_bus/test_event_bus.py",
            "description": "This file contains unit tests for the ddev event bus orchestrator, simulating a realistic communication system with various message types and processors to test message handling, processor logic, error handling, and timing.",
            "spof": true
          },
          {
            "path": "ddev/tests/event_bus/__init__.py",
            "description": "This file defines the `event_bus` Python package within the `ddev` testing suite. It serves as a package marker for test-related modules concerning an event bus implementation.",
            "spof": true
          },
          {
            "path": "ddev/tests/validation/test_tracker.py",
            "description": "This file contains unit tests for the `ValidationTracker` class, ensuring it correctly records and renders validation successes, errors, and warnings using a rich console tree structure.",
            "spof": true
          },
          {
            "path": "ddev/tests/size/__init__.py",
            "description": "This empty `__init__.py` file marks the `size` directory as a Python package, enabling it to contain and organize size-related tests for the `ddev` tool.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/repo/__init__.py",
            "description": "This `__init__.py` file marks the `repo` directory as a Python package, allowing its modules to be imported. It currently contains no code, serving only to define the package structure.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/repo/core.py",
            "description": "This file defines the `Repository` and `IntegrationRegistry` classes, which provide programmatic access and management for a source code repository and its contained Datadog integrations.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/event_bus/orchestrator.py",
            "description": "This file defines an `EventBusOrchestrator` responsible for managing message queues, registering processors for specific message types, and orchestrating the asynchronous processing of these messages through their lifecycle.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/event_bus/__init__.py",
            "description": "This file marks the 'event_bus' directory as a Python package within the 'ddev' project. As an empty `__init__.py`, it primarily serves to enable module imports from this directory.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/plugin/specs.py",
            "description": "This file defines the `pluggy` hook specification for `ddev` plugins to register new commands with the CLI.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/integration/core.py",
            "description": "This file defines the `Integration` class, which represents a single integration within a repository, providing properties and methods to access its metadata, files, and various characteristics.",
            "spof": false
          },
          {
            "path": "ddev/src/ddev/integration/metrics.py",
            "description": "This file defines the Pydantic `Metric` model, which specifies the structure and properties for a metric within the `ddev` integration development tool. It serves as a data schema for validating and managing metric definitions for Datadog integrations.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/integration/__init__.py",
            "description": "This `__init__.py` file marks the `integration` directory as a Python package within the `ddev` module. It currently contains no functional code, serving primarily for package structure.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 97
          },
          {
            "name": "Ofek Lev",
            "percent": 1
          },
          {
            "name": "Steven Yuen",
            "percent": 1
          }
        ]
      },
      "Agent Check Base & Core Services": {
        "files": [
          {
            "path": "datadog_checks_base/README.md",
            "description": "This README describes the `datadog_checks_base` Python package, which provides the necessary components for Datadog Agent integrations (checks) to run, and also supports standalone testing and development.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/CHANGELOG.md",
            "description": "This file is the changelog for the `datadog_checks_base` component, detailing version updates, bug fixes, new features, and security enhancements.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/test_serialization.py",
            "description": "This file contains unit tests for the serialization utility within `datadog_checks_base`, specifically verifying that it utilizes `orjson` for fast JSON operations.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/test_zzz_run_last.py",
            "description": "This test file, designed to run last, verifies the `use_boringssl` configuration option by ensuring it correctly patches `urllib3` to use BoringSSL when enabled. It reloads the `datadog_checks.base` module to apply the configuration change.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/test_log.py",
            "description": "This file contains unit tests for the logging utilities in `datadog_checks.base.log`, covering functionalities like log level conversion, warning capture, logger instantiation, and Datadog trace context injection into log messages.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/test_metadata.py",
            "description": "This file contains unit tests for the metadata collection functionality within the `datadog_checks.base` module, particularly focusing on the `set_metadata` method of `AgentCheck`. It validates how metadata, especially version information with different schemes (e.g., semantic versioning, regex), is processed and reported to the agent.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/__init__.py",
            "description": "Marks the `base` directory as a Python package, specifically for shared test utilities or base test classes within `datadog_checks_base`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/test_constants.py",
            "description": "This file contains tests to verify that the constant integer values for service check statuses (OK, WARNING, CRITICAL, UNKNOWN) are consistent between `ServiceCheck` and `AgentCheck` classes.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_aws.py",
            "description": "This file contains unit tests for the `rds_parse_tags_from_endpoint` utility function, ensuring it correctly extracts relevant tags from various AWS RDS endpoint strings.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_diagnose.py",
            "description": "This file contains unit tests for the `Diagnosis` utility, verifying its functionality for recording, retrieving, and running diagnostic results within Datadog Agent checks. It also tests error handling and secret sanitization for diagnostic outputs.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_tls.py",
            "description": "This file contains unit tests for the `TlsContextWrapper` class and the TLS context handling within `AgentCheck`, verifying various TLS configuration options and their effects on the `ssl.SSLContext`.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_fips.py",
            "description": "This file contains unit tests for the `is_enabled` utility function, verifying its ability to detect FIPS mode status on both Linux and Windows systems under various configurations.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_tracking.py",
            "description": "Tests the `tracked_method` utility to ensure it correctly tracks method execution time, result length, and exceptions as metrics within the Datadog AgentCheck context.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_hashing.py",
            "description": "This file contains unit tests for the `HashMethod` utility, verifying its functionality, singleton behavior, architecture-specific hash algorithm selection (SHA256, BLAKE2b/s), and internal caching mechanisms.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_tracing.py",
            "description": "This file contains unit tests for the `traced_class` utility, which automatically instruments `AgentCheck` methods for Datadog tracing. It verifies that methods are correctly traced or not traced based on `integration_tracing` and `integration_tracing_exhaustive` configuration flags.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/concurrency/__init__.py",
            "description": "This file marks the 'concurrency' directory as a Python package within the test utilities for datadog_checks_base.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/concurrency/test_limiter.py",
            "description": "This file contains unit tests for the `ConditionLimiter` class, verifying its functionality, including default and custom limits, item removal, argument handling, and thread-safety under concurrent access.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/discovery/test_discovery.py",
            "description": "Tests the `Discovery` utility class, verifying its functionality for filtering, limiting, and caching discovered items based on include/exclude patterns, limits, and time intervals.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/format/test_json.py",
            "description": "Tests the JSON encoding and decoding utility functions provided by `datadog_checks_base`, including string and bytes encoding, and key sorting.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/replay/__init__.py",
            "description": "This file marks the 'replay' directory as a Python package. It is part of the testing utilities for `datadog_checks_base`, likely intended for replaying test scenarios.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/replay/test_check.py",
            "description": "This file contains a pytest test for the `AgentCheck` base class, demonstrating and verifying how configuration (initialization and instance-level) affects a check's behavior, emitted metrics, service checks, and logging, particularly concerning `process_isolation` and tags.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/utils.py",
            "description": "This file defines utility Pydantic models, such as `BaseModelTest`, intended for use in testing scenarios within the `datadog_checks_base` module.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/test_load_config.py",
            "description": "This file contains unit tests for the `AgentCheck.load_config` method, verifying its ability to correctly parse various YAML configurations, including different data types, error handling, and Unicode characters.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/models/test_types.py",
            "description": "This file contains unit tests for the `make_immutable` utility function, verifying its ability to convert mutable Python data structures into immutable ones using `MappingProxyType` and tuples.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/models/__init__.py",
            "description": "This empty `__init__.py` file marks the `models` directory as a Python package, allowing its contents to be imported and used within tests for `datadog_checks_base`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/stubs/test_assert_metric.py",
            "description": "This file contains a stub test for the `assert_metric` method, specifically verifying its behavior when asserting metrics with and without a specified hostname.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/stubs/test_aggregator_metric_has_tag.py",
            "description": "This file contains unit tests for the aggregator's tag assertion functionality, specifically `assert_metric_has_tags`. It verifies that metrics are correctly identified with or without specified tags under various conditions.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/fixtures/dcos",
            "description": "This directory serves as a placeholder for test fixtures related to DCOS (Datacenter Operating System) within the `datadog_checks_base` component. It is intended to store data or configurations necessary for testing DCOS-specific integrations or functionalities.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/log.py",
            "description": "This file re-exports logging functionalities from `datadog_checks.base.log`, serving as an import point for other parts of the Datadog Agent, particularly for configuration-related logging.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/__init__.py",
            "description": "This `__init__.py` file marks `datadog_checks` as a Python namespace package. It uses `pkgutil.extend_path` to allow the `datadog_checks` package to be spread across multiple directories or installations.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/errors.py",
            "description": "This file serves as a re-export of common error classes defined in `datadog_checks_base.base.errors`, making them easily accessible within the `datadog_checks` package.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/__init__.py",
            "description": "This `__init__.py` file serves as an aggregation point, exposing core check functionalities like `AgentCheck`, base check classes, and `CheckException` directly when importing from `datadog_checks.checks`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/network_checks.py",
            "description": "This file defines core components and utilities, including `NetworkCheck`, `EventType`, and `Status`, for implementing network-related checks within the Datadog Agent's base integration library.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/base.py",
            "description": "This file re-exports all components from the core `base.checks.base` module, simplifying access to fundamental check functionalities within the `datadog_checks` package.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/libs/__init__.py",
            "description": "This `__init__.py` file marks the 'libs' directory as a Python package within the `datadog_checks.checks` module. While currently empty of code, its presence allows Python to recognize and import modules from this directory.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/errors.py",
            "description": "This file defines custom exception classes used by Datadog checks, primarily for handling configuration errors and issues that might prevent an instance from being loaded or run.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/constants.py",
            "description": "This file defines or re-exports the `ServiceCheck` type for compatibility and simplified access within Datadog checks base components.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/types.py",
            "description": "This file defines common type aliases, TypedDicts, and custom type-checking enums used across Datadog Agent checks for configuration, events, and service check statuses.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/log.py",
            "description": "This file defines custom logging classes and utilities for Datadog Agent checks, enabling Python logs to be formatted, sanitized, and forwarded to the Datadog Agent's Go backend with support for tracing.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/__init__.py",
            "description": "This file initializes the `datadog_checks.base` package, enabling lazy loading for its contents. It also conditionally configures `urllib3` to use PyOpenSSL if the `use_boringssl` agent configuration is enabled, for specific SSL/TLS handling.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/aws.py",
            "description": "Provides utility functions for parsing AWS RDS/Aurora endpoint strings to extract relevant tags like instance/cluster identifiers and region.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/constants.py",
            "description": "This file defines common time unit constants (second, millisecond, microsecond, nanosecond) and provides a dictionary mapping these units to their corresponding values, intended for use across Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/secrets.py",
            "description": "This file provides a `SecretsSanitizer` utility class to redact sensitive information (secrets, passwords, keys) from text by replacing registered patterns with a placeholder.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/limiter.py",
            "description": "This file defines a `Limiter` class that provides a simple object count capping logic. It is used by Agent checks to limit the number of specific objects, such as tag sets, to prevent excessive resource usage.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/tagging.py",
            "description": "This file provides utilities for tagging in Datadog checks, including importing the `tagger` module and defining a set of generic, commonly used tag keys.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/tracking.py",
            "description": "This file provides a decorator (`tracked_method`) for agent check methods to automatically track execution time, errors, and result length, and to log debug information for troubleshooting. It helps in standardizing the collection of performance metrics for integration methods.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/diagnose.py",
            "description": "This file defines a `Diagnosis` class used to register explicit diagnostic routines and record structured diagnostic results (success, failure, warnings, errors) for Datadog integrations.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/common.py",
            "description": "This file provides a collection of common utility functions for Datadog checks, including helpers for string encoding/decoding, numerical calculations (like percentages and rounding), and pattern-based list filtering.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/tracing.py",
            "description": "This file provides utilities for integrating Datadog tracing into Agent checks, allowing automatic instrumentation of check methods with options for default or exhaustive tracing.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/format/__init__.py",
            "description": "Initializes the `format` utility package within `datadog_checks_base`. This package is intended to house various formatting utilities for Datadog agent checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/discovery/__init__.py",
            "description": "This `__init__.py` file uses `lazy_loader` to enable lazy loading for modules within the `discovery` package, improving import performance by deferring imports until needed.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/discovery/filter.py",
            "description": "This file defines a `Filter` class used to discover and filter items based on include/exclude regular expression patterns, with support for item key extraction and a discovery limit.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/health.py",
            "description": "This file provides the base implementation for the Datadog Agent's health reporting system, defining enums for health events and statuses, and a utility class to submit these events with optional cooldowns.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/metadata/core.py",
            "description": "This file defines the `MetadataManager` class, which handles collecting and transforming metadata from checks before it is submitted to the Datadog Agent. It supports custom metadata transformers and provides a default transformer for version strings.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/metadata/utils.py",
            "description": "This file provides utility functions for metadata processing. It includes a function to determine if an object is a primitive type, useful for serialization contexts like JSON.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/metadata/__init__.py",
            "description": "This `__init__.py` file uses `lazy_loader` to efficiently manage imports within the `metadata` utility module. It defers the loading of submodules until they are explicitly accessed, optimizing performance.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/metadata/constants.py",
            "description": "This file defines a constant blacklist of sensitive keywords used for data scrubbing, preventing the exposure of credentials or private information in metadata and logs.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/metadata/version.py",
            "description": "This file provides utility functions for parsing version strings based on different schemes, such as semantic versioning, custom regular expressions, or predefined parts, to extract their components.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/concurrency/__init__.py",
            "description": "This file serves as the package initializer for the `concurrency` utility module within `datadog_checks_base`, intended to house utilities related to concurrent operations or threading for Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/concurrency/limiter.py",
            "description": "This file provides the `ConditionLimiter` class, which is used to limit the number of concurrently satisfied conditions, ensuring that a predefined maximum is not exceeded by preventing new evaluations once the limit is reached.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/replay/constants.py",
            "description": "This file defines constants, including known Datadog Agent setter methods and environment variable names, primarily used within the replay utility for testing and debugging.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/replay/__init__.py",
            "description": "This file serves as the initialization file for the 'replay' utility package within the Datadog checks base library. It is intended to contain or enable functionality related to replaying data or events for testing or debugging purposes.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/replay/redirect.py",
            "description": "This module provides 'replay' versions of Datadog Agent core functionalities (aggregator, datadog_agent, logger) to capture and serialize their interactions for testing or debugging purposes by printing structured JSON messages to stdout.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/__init__.py",
            "description": "This file implements lazy loading for the 'checks' package, deferring the import of its submodules until they are explicitly accessed. This improves startup performance for applications using the Datadog Agent.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/base.py",
            "description": "This file defines the base `AgentCheck` class, providing the foundational structure and common utilities for all Datadog Agent integrations. It handles core functionalities like logging, configuration parsing, metric submission, and HTTP client setup for checks.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/network.py",
            "description": "This file defines the deprecated `NetworkCheck` base class for Datadog agents, providing a structure for network-related checks and service status reporting. It advises inheriting directly from `AgentCheck` instead.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/libs/thread_pool.py",
            "description": "This file provides a custom thread pool implementation similar to Python's `multiprocessing.Pool`, offering methods for parallel task execution with additional asynchronous and unordered processing capabilities.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/stubs/common.py",
            "description": "This file defines stub data structures using namedtuples for metrics, service checks, and histogram buckets, primarily used for testing and internal representation within the Datadog Agent's check base.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/stubs/log.py",
            "description": "This file customizes Python's logging module for Datadog checks by introducing a `TRACE` log level and restricting the use of the `critical` log level to agent shutdowns.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/stubs/tagging.py",
            "description": "This file provides a stub for the Datadog Agent's tagging functionality, enabling unit tests for checks to run without a live agent. It simulates tag retrieval and allows for asserting tagger calls.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/stubs/__init__.py",
            "description": "This file serves as the `__init__.py` for the `stubs` package, providing mock or placeholder objects for core Datadog Agent components such as the aggregator, agent API, and tagger, primarily for testing or development purposes.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/stubs/_util.py",
            "description": "This file provides a stub for executing subprocess commands, specifically designed to allow Datadog Agent checks to run during testing or development without a full agent. It captures stdout and stderr and handles cases of empty output.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/stubs/similar.py",
            "description": "This file provides utilities for comparing expected and received data structures (metrics, service checks, histogram buckets) in tests, calculating similarity scores, and generating detailed difference messages to improve assertion failure diagnostics.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/containers.py",
            "description": "This file re-exports container-related utility functions and classes from a base module, serving as an alias or proxy for easier access within the `datadog_checks_base` package.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/common.py",
            "description": "This file re-exports common utility functions and constants from the base `datadog_checks_base` module, providing them under an alternative or legacy import path within the `datadog_checks` namespace.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/stubs/__init__.py",
            "description": "This file re-exports common stub definitions from `datadog_checks_base.base.stubs`, making them accessible directly under the `datadog_checks_base.datadog_checks.stubs` module for convenience.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/stubs/_util.py",
            "description": "This file serves as a re-export of utilities from the base stub module, likely for compatibility or consolidated access within the `datadog_checks_base` package.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/stubs/aggregator.py",
            "description": "This file re-exports aggregator stubs from the `datadog_checks_base.base.stubs` module, providing them under a more direct import path within the `datadog_checks_base.stubs` namespace.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/changelog.d",
            "description": "This directory contains individual changelog fragments for the `datadog_checks_base` package. These fragments are typically aggregated by a build process to generate the comprehensive changelog for the base library.",
            "spof": false
          },
          {
            "path": "druid/datadog_checks/druid/__init__.py",
            "description": "This `__init__.py` file defines the `druid` package, exposing the `DruidCheck` class and the package's version for external use.",
            "spof": false
          },
          {
            "path": "docs/developer/architecture/snmp.md",
            "description": "This document explains the architecture and implementation details of the Datadog SNMP integration for developers. It covers the Python check, Agent auto-discovery, and Cluster Agent support for SNMP monitoring.",
            "spof": false
          },
          {
            "path": "docs/developer/base/basics.md",
            "description": "This document provides a developer's guide to creating Datadog Agent integrations (checks). It covers the `AgentCheck` base class, metric types, service checks, events, namespacing, and check initialization.",
            "spof": true
          },
          {
            "path": "docs/developer/base/tls.md",
            "description": "This document provides guidelines for Datadog Agent developers on implementing TLS/SSL connections within their checks, specifically recommending the use of `AgentCheck.get_tls_context()` for obtaining an SSL context.",
            "spof": true
          },
          {
            "path": "docs/developer/base/metadata.md",
            "description": "This document describes how to collect and set metadata within Datadog Agent checks using the `set_metadata` method. It details the method's interface, arguments, and the use of transformers for processing metadata.",
            "spof": true
          },
          {
            "path": "docs/developer/base/api.md",
            "description": "This file documents the API methods available for developing Datadog Agent checks, including core metric/event reporting functions and testing utilities provided by `AggregatorStub` and `DatadogAgentStub`.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 17
          },
          {
            "name": "Juanpe Araque",
            "percent": 13
          },
          {
            "name": "Seth Samuel",
            "percent": 12
          }
        ]
      },
      "HTTP Client & Network Utilities": {
        "files": [
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_auth.py",
            "description": "This file contains unit tests for the authentication methods supported by the RequestsWrapper utility, covering basic, digest, NTLM, and AWS authentication types to ensure correct configuration and behavior.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_proxy.py",
            "description": "This file contains unit tests for the `RequestsWrapper` utility, specifically testing its handling of proxy configurations including agent-level settings, instance/init_config overrides, `no_proxy` rules, `skip_proxy` behavior, and environment variables.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_config.py",
            "description": "This file contains unit tests for the `RequestsWrapper` utility, verifying how it handles various HTTP configuration options such as timeouts, request size, TLS verification, proxy settings, and redirects.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_kerberos_unit.py",
            "description": "Unit tests for the Kerberos authentication configuration and behavior within the `RequestsWrapper` utility. It verifies how different Kerberos settings are processed and applied, including legacy options, mutual authentication levels, and environment variable handling for keytab files and caches.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_api.py",
            "description": "This file contains unit tests for the `RequestsWrapper` utility, verifying its functionality across various HTTP methods (GET, POST, HEAD, PUT, PATCH, DELETE, OPTIONS). It specifically checks how the wrapper handles session persistence, default options, and method-specific option overrides when making HTTP requests.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_kerberos_int.py",
            "description": "This file contains integration tests for the `RequestsWrapper` utility's Kerberos authentication capabilities, covering various scenarios like missing configuration, nonexistent principals, and different cache/keytab setups. It also includes a dedicated test for Agent QA to verify Kerberos authorization from within an Agent container.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_authtoken.py",
            "description": "This file contains unit tests for the creation and configuration of authentication token handlers within the `RequestsWrapper`, covering validation for different reader (file, OAuth, DCOS) and writer types.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_tls_and_certs.py",
            "description": "This file contains unit tests for the RequestsWrapper's TLS/SSL certificate handling, including loading certificates and private keys, and its functionality for ignoring TLS warnings.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_socks5_proxy_integration.py",
            "description": "Integration tests for the `RequestsWrapper` HTTP client, specifically verifying SOCKS5 proxy functionality and `no_proxy` rules for domains and IP addresses (including CIDR notation).",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_http.py",
            "description": "This file contains unit and integration tests for the `RequestsWrapper` utility, which handles HTTP requests for Datadog Agent checks, covering features like TLS ciphers, Unix Domain Sockets, session management, and request logging.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/fixtures/bearer_tokens",
            "description": "This directory is intended to store test fixtures related to bearer tokens for the `datadog_checks_base` module. It serves as a designated, albeit currently empty, location for mock or sample bearer tokens used during testing authentication flows.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/fixtures/kerberos",
            "description": "This directory is designated to store test fixtures or mock data specifically for testing Kerberos-related functionalities within the `datadog_checks_base` library. Its purpose is to provide controlled data or configurations required for verifying Kerberos integration and authentication during tests.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/compose/kerberos/kerberos-nginx",
            "description": "This directory is part of the test infrastructure for `datadog_checks_base`, specifically for Docker Compose-based tests involving Kerberos and Nginx. Although currently empty, it is intended to house configuration and setup files for simulating environments where Nginx integrates with Kerberos, within the context of the Datadog Agent's base checks.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/network.py",
            "description": "This file serves as a compatibility layer or alias, re-exporting network-related check utilities and classes from `datadog_checks_base.base.checks.network` to make them accessible under `datadog_checks.checks.network`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/tls.py",
            "description": "This file provides utilities for creating and managing SSL/TLS contexts, handling certificate loading, cipher configuration, and hostname verification for secure communication.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/http.py",
            "description": "This file provides a robust and configurable HTTP client for Datadog checks, extending the `requests` library with features like various authentication methods, TLS configurations, proxy settings, and connection management specific to agent integrations.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/headers.py",
            "description": "This file re-exports header utility functions from the `datadog_checks_base.base.utils.headers` module, simplifying access for `datadog_checks`.",
            "spof": true
          },
          {
            "path": "docs/developer/base/http.md",
            "description": "This document explains how to use the base HTTP wrapper in Datadog integrations, which provides a 'requests'-like interface, handles configuration automatically, and supports features like HTTP config remapping and Unix sockets.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 67
          },
          {
            "name": "Juanpe Araque",
            "percent": 13
          },
          {
            "name": "Kyle Neale",
            "percent": 8
          }
        ]
      },
      "Database Monitoring (DBM) Framework": {
        "files": [
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_db_sql.py",
            "description": "This file contains unit tests for SQL utility functions, specifically verifying the consistency of SQL query signature computation (hashing) and the normalization of query tags.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/common.py",
            "description": "This file provides utility functions for testing the `QueryManager` in `datadog_checks_base`, including a mock executor and a helper to create `QueryManager` instances for tests.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_transformers.py",
            "description": "This file contains unit tests for various column transformers used in database query managers, ensuring they correctly process and transform query results into metrics and tags.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_db_statements.py",
            "description": "This file contains unit tests for the `StatementMetrics` class and its helper functions, specifically `compute_derivative_rows` and `_merge_duplicate_rows`, ensuring they correctly process and aggregate database statement metrics.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_query_manager.py",
            "description": "This file contains unit tests for the `QueryManager`'s query compilation and validation logic, ensuring that query configurations (including queries, columns, and extras) adhere to expected formats and constraints.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_sql_commenter.py",
            "description": "This file contains unit tests for the `generate_sql_comment` and `add_sql_comment` utility functions, which are used to create and inject SQL comments into database queries.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_query_result.py",
            "description": "This file contains unit tests for the `query_manager`'s ability to execute queries and handle their results, including empty results, exceptions during execution, and iterating over expected data from various mock executors.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_query_executor.py",
            "description": "This file contains unit tests for the `QueryExecutor` utility, which is responsible for executing database queries and emitting metrics with various types, tags, and configuration options. It verifies the correct handling of different metric types, multiple executors, query intervals, and metric prefixes.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_schemas.py",
            "description": "This file contains unit tests for the `SchemaCollector` utility, using mock `DatabaseCheck` and `SchemaCollector` implementations to verify that database schema metadata is correctly collected and reported.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_util.py",
            "description": "Tests various utility functions used in Datadog database monitoring (DBM) and other base checks, including host resolution, rate limiting, caching, asynchronous job management, and SQL obfuscation.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/db/test_custom_queries.py",
            "description": "This file contains unit tests for the custom query functionality within Datadog Agent checks. It verifies various aspects of custom query configuration, compilation, execution, and metric emission, including interactions between global and instance-level query definitions.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/sql_commenter.py",
            "description": "This file provides utility functions for generating SQL comments from key-value pairs and prepending or appending them to SQL statements.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/core.py",
            "description": "This file provides core utilities for executing database queries and submitting their results as telemetry in Datadog Agent checks. It defines `QueryExecutor` for low-level query management and `QueryManager` for integrating with AgentCheck instances, including handling custom queries.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/statement_metrics.py",
            "description": "This file defines a utility class, `StatementMetrics`, for calculating derivative-based, normalized statement-level metrics from database statistics tables. It manages state between check runs to compute the difference in metric values over time, handling duplicates and potential stats resets.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/schemas.py",
            "description": "This file defines an abstract base class (`SchemaCollector`) and related data structures for collecting and submitting database schema metadata to the Datadog agent. It provides a common framework for integrating various database management systems (DBMS) to report their schema information.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/query.py",
            "description": "This file defines the `Query` class, which represents and compiles configurations for database queries, including custom queries, within the Datadog Agent's integration framework.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/transform.py",
            "description": "This file provides utility functions for transforming data obtained from database queries into various Datadog metric types (tags, gauges, rates, service checks) and formats. It defines a set of 'transformers' that convert raw column values based on specified modifiers and column names.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/types.py",
            "description": "This file defines common type aliases for database-related operations, including callable types for data transformation and query execution. It provides consistent type hints for functions and objects involved in database interactions within the Datadog checks base library.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for database-related utilities, using `lazy_loader` to defer the loading of its submodules until they are accessed. This improves import performance for Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/utils.py",
            "description": "This file provides a collection of utility functions and classes primarily used for database monitoring (DBM) within Datadog checks. It includes functionalities like data submission transformers, rate limiting, database host resolution, SQL obfuscation, and tracing for DBM-related async jobs.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/db.py",
            "description": "This file defines the abstract base class `DatabaseCheck` for database monitoring (DBM) integrations. It provides common methods for reporting DBM events and abstract properties that concrete database check implementations must define.",
            "spof": false
          },
          {
            "path": "docs/developer/base/databases.md",
            "description": "This document describes how to use the Datadog base package to monitor databases, detailing the `Query` and `QueryManager` classes for defining and collecting data from queries, along with various data transformation utilities.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Seth Samuel",
            "percent": 37
          },
          {
            "name": "Zhengda Lu",
            "percent": 33
          },
          {
            "name": "Eric Weaver",
            "percent": 18
          }
        ]
      },
      "Kubernetes Leader Election Check Base": {
        "files": [
          {
            "path": "datadog_checks_base/tests/base/checks/test_kube_leader.py",
            "description": "This file contains unit and integration tests for the `KubeLeaderElectionBaseCheck` in `datadog_checks_base`. It verifies the check's ability to parse Kubernetes leader election records (from annotations and leases) and accurately report metrics and service check statuses.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/kube_leader/mixins.py",
            "description": "This file defines a mixin class (`KubeLeaderElectionMixin`) for AgentCheck, providing utilities to check Kubernetes leader election status by retrieving election records from K8s objects (leases, endpoints, configmaps) and reporting metrics and service checks.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/kube_leader/base_check.py",
            "description": "This file defines a base class for Datadog Agent checks that monitors Kubernetes leader election status. It integrates a leader election mixin, allowing configuration through YAML to track the leader election for specific resources.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/kubelet_base/__init__.py",
            "description": "This `__init__.py` file defines the `kubelet_base` module, utilizing `lazy_loader` for efficient and on-demand loading of its contents.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 53
          },
          {
            "name": "Ofek Lev",
            "percent": 20
          },
          {
            "name": "Steven Yuen",
            "percent": 19
          }
        ]
      },
      "Windows Performance Monitoring (PDH & WMI)": {
        "files": [
          {
            "path": "datadog_checks_base/tests/base/checks/win/test_wmicheck.py",
            "description": "This file contains unit tests for the `WinWMICheck` base class, specifically verifying that the WMI sampler instance is correctly managed and does not leak resources or create multiple instances unnecessarily.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/win/test_pdhbasecheck.py",
            "description": "This file contains unit tests for the `PDHBaseCheck` class, which is responsible for collecting Windows Performance Data Helper (PDH) counters. It verifies various scenarios for metric collection and configuration of admin shares.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/win/test_wmisampler.py",
            "description": "Tests the `WMISampler` class's functionality for formatting WMI filters into WQL queries and also tests the `CaseInsensitiveDict` utility, specifically for Windows-based checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/win/test_winpdh.py",
            "description": "This file contains unit tests for the `WinPDHCounter` class, verifying its functionality and robustness with various inputs, including invalid performance strings and different language settings, specifically on Windows platforms.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/__init__.py",
            "description": "This is an empty `__init__.py` file, serving to define the `windows` directory as a Python package within the `tests/base/checks` structure for the `datadog_checks_base` component.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_health.py",
            "description": "This file contains unit tests for the health service check functionality of Windows performance counters. It verifies the behavior of the health check under various conditions, including successful collection, disabled state, and error scenarios during query, refresh, or collect operations.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_filter.py",
            "description": "This file contains unit tests for the filtering logic applied to Windows performance counter instances. It verifies that `include` and `exclude` regular expressions correctly select or discard performance counter instances, including tests for case sensitivity.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_refresh.py",
            "description": "This file contains tests for the Windows performance counter collection logic, specifically verifying how metric values are aggregated and refreshed across multiple instances and check runs.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_aggregation.py",
            "description": "Tests various aggregation strategies for Windows Performance Counters, including summing, averaging, and different aggregation behaviors like 'aggregate' and 'aggregate only'.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/utils.py",
            "description": "This file provides utility functions for testing `PerfCountersBaseCheck` instances, including a helper to create and configure a test check object for Windows performance counters.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_localization.py",
            "description": "This file contains unit tests for the Windows performance counter collection logic, specifically focusing on how the system handles localized and unlocalized (English) counter names based on configuration settings.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/__init__.py",
            "description": "This file acts as the package initializer for the `perf_counters` test directory, allowing Python to recognize it as a package for organizing tests related to Windows performance counters.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_subclass.py",
            "description": "This file contains tests for subclassing the `PerfCountersBaseCheck` and `PerfObject` classes to add custom logic, specifically demonstrating how to implement custom metric transformers and service check conditions for Windows performance counters.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_legacy_support.py",
            "description": "This file contains unit tests for the `PerfCountersBaseCheckWithLegacySupport` class, verifying its functionality for collecting Windows performance counter metrics defined through the 'additional_metrics' configuration, including instance handling and warning logs.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/transformers/test_monotonic_count.py",
            "description": "Tests the `monotonic_count` transformer for Windows performance counters. It verifies that performance counter values configured as monotonic counts are correctly collected and tagged.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/transformers/test_service_check.py",
            "description": "Tests the `service_check` transformer for Windows performance counters, verifying that service checks are correctly reported as OK or UNKNOWN based on the configured `status_map`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/transformers/test_rate.py",
            "description": "This file contains a test case for the 'rate' transformer used with Windows performance counters. It verifies that a performance counter configured as a 'rate' metric is correctly processed and reported by the Datadog Agent.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/transformers/test_count.py",
            "description": "This file contains a unit test for the 'count' type transformer within the Windows performance counters collection system, verifying that metrics configured as 'count' are correctly processed and reported.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/transformers/__init__.py",
            "description": "This file marks the `transformers` directory as a Python package, intended for testing utilities related to Windows performance counter data transformations.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/transformers/test_time_elapsed.py",
            "description": "This file contains a unit test for the `time_elapsed` transformer used with Windows performance counters. It verifies that the transformer correctly calculates the elapsed time between two counter readings.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/transformers/test_gauge.py",
            "description": "This file contains unit tests to verify that Windows performance counters are correctly collected and reported as Datadog gauge metrics, covering both explicit and default type definitions.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/windows/perf_counters/test_integration.py",
            "description": "This file contains integration tests for the Windows Performance Counters check in the Datadog Agent, validating metric collection for single and multi-instance counters, tagging, and error handling for invalid data or misspelled counter names.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/winwmi_check.py",
            "description": "This file provides the base `WinWMICheck` class and related utilities for implementing Windows WMI-based checks within the Datadog Agent.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/libs/wmi/sampler.py",
            "description": "This file provides a lightweight Python WMI module wrapper, built on `pywin32` and `win32com`, for sampling WMI data efficiently. It re-exports or is a compatibility layer for the `WMISampler` class.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/win/__init__.py",
            "description": "This `__init__.py` file re-exports Windows-specific check functionalities from the base module, simplifying imports for other modules within the `datadog_checks_base` package.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/win/winpdh.py",
            "description": "This file re-exports all symbols from the `datadog_checks.base.checks.win.winpdh` module, providing a compatibility layer or simplified import path.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/win/winpdh_base.py",
            "description": "This file re-exports all contents from `datadog_checks_base.base.checks.win.winpdh_base`, likely for backward compatibility or to maintain a specific import path within the `datadog_checks` namespace.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/win/winpdh_stub.py",
            "description": "This file acts as a re-exporting module, providing an alternative import path for the core Windows Performance Data Helper (PDH) stub located in the `datadog_checks_base/base/checks/win` directory.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/win/wmi/__init__.py",
            "description": "This `__init__.py` file re-exports the contents of the base WMI check module. It provides direct access to core Windows WMI functionalities under this package.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/win/wmi/sampler.py",
            "description": "This file re-exports all contents from the `sampler` module located in the `datadog_checks_base.base.checks.win.wmi` package. It acts as an alias or compatibility layer to expose the WMI sampler functionality at a different path within the `datadog_checks_base` structure.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/win/wmi/counter_type.py",
            "description": "This file re-exports the contents of the `counter_type` module from the base Windows WMI checks, making it accessible at this specific package path. It serves as an alias or an exposure point for core WMI counter type definitions.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/__init__.py",
            "description": "This file serves as the package initializer for Windows-specific base checks, designating the `windows` directory as a Python package within the `datadog_checks_base` library.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/__init__.py",
            "description": "This file serves as the package initializer for `perf_counters`, making `PerfCountersBaseCheck` available when the package is imported. It exports the base class for Windows performance counter checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/counter.py",
            "description": "This file defines the `PerfObject` class, which is responsible for configuring, filtering, and collecting Windows performance counter data for a specific object, handling instances and metric prefixes.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/base.py",
            "description": "Provides base classes for Datadog Agent checks to collect metrics from Windows Performance Counters. It handles connection management, querying performance data, and submitting metrics, with support for both current and legacy configuration formats.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/constants.py",
            "description": "This file defines constants used for Windows Performance Counter (PDH) operations, including the format for retrieving counter values and various PDH status and error codes.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/utils.py",
            "description": "This file provides utility functions for interacting with Windows Performance Data Helper (PDH) API, including constructing counter paths, retrieving counter values, and validating paths, with considerations for localized counter names.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/transform.py",
            "description": "This file defines and aggregates various metric transformation functions (e.g., count, gauge, service check) and exposes them as attributes of a `Transformers` class for programmatic access and documentation.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/utils_win32pdh_fix.py",
            "description": "This file provides a corrected implementation of `win32pdh.GetFormattedCounterArray` using `ctypes` to properly handle Windows performance counter instances with non-unique names, addressing a limitation in the `pywin32` library.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/connection.py",
            "description": "This file provides utilities for managing connections to Windows systems, specifically for querying performance counters (PDH), including handling network resource connections for remote servers.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/transformers/count.py",
            "description": "This file defines a utility function `get_count` that creates and returns a callable (a closure) designed to submit a count metric using the provided check instance and metric name. It acts as a wrapper to simplify count metric submission within the Datadog Agent's check framework.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/transformers/rate.py",
            "description": "This file defines a factory function to create a callable that submits a performance counter value as a rate metric using the Datadog Agent's check object.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/transformers/__init__.py",
            "description": "This file serves as the package initializer for Windows performance counter transformers, making various metric transformation utility functions accessible from a single entry point.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/transformers/monotonic_count.py",
            "description": "This file provides a transformer function that creates a closure to wrap `check.monotonic_count`, allowing easy application of monotonic counter logic to a specific metric name with a given value and tags.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/transformers/gauge.py",
            "description": "This file defines a factory function `get_gauge` that returns a specialized gauge reporting function for a given metric name. This allows for simplified reporting of gauge metrics by pre-binding the metric name.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/transformers/time_elapsed.py",
            "description": "This file defines a transformer for Windows performance counters that calculates the time elapsed since a given timestamp and reports it as a gauge metric.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/windows/perf_counters/transformers/service_check.py",
            "description": "This file provides utilities for transforming Windows performance counter values into Datadog service checks. It includes functions to compile and validate the mapping of integer values to service check statuses for submission.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/winpdh_base.py",
            "description": "Provides a base class (PDHBaseCheck) for Datadog Agent checks on Windows that utilize the Performance Data Helper (PDH) API to collect system performance counters. It handles counter initialization, remote host connections, data type precision, and metric submission.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/winpdh_stub.py",
            "description": "This file provides a stub implementation of the `WinPDHCounter` class, likely used as a placeholder or mock for Windows Performance Data Helper (PDH) functionality on non-Windows systems or during testing.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/__init__.py",
            "description": "This file initializes the Windows-specific checks subpackage within `datadog_checks_base` and configures lazy loading for its modules. It uses `lazy_loader` to defer the import of actual Windows check implementations until they are explicitly accessed.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/winpdh.py",
            "description": "This file defines the `WinPDHCounter` class, which interacts with the Windows Performance Data Helper (PDH) API to collect system performance metrics. It handles localized counter names and provides methods to query and retrieve counter values.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/wmi/types.py",
            "description": "This file defines custom type aliases and data structures for WMI (Windows Management Instrumentation) related operations within the Datadog Agent, such as WMIMetric, WMIProperties, WMIObject, and WMIFilter.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/wmi/base.py",
            "description": "This file provides a base class, `WinWMICheck`, for Datadog Agent checks to interact with Windows Management Instrumentation (WMI). It handles WMI queries, extracts metrics, and applies dynamic tagging based on WMI properties for Windows-specific monitoring.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/wmi/counter_type.py",
            "description": "This file implements calculators for various Windows Management Instrumentation (WMI) performance counter types, mapping WMI CounterType identifiers to specific calculation logic for metric collection.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/wmi/sampler.py",
            "description": "This file provides a lightweight Python WMI module wrapper, `WMISampler`, built on `pywin32` and `win32com` to efficiently sample and format Windows Management Instrumentation performance data.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/win/wmi/__init__.py",
            "description": "This `__init__.py` file uses `lazy_loader` to enable lazy loading for the `wmi` subpackage, optimizing import performance by deferring module loading until attributes are accessed.",
            "spof": true
          },
          {
            "path": "datadog_checks_tests_helper/datadog_test_libs/win/fixtures/README.md",
            "description": "This README describes Windows performance counter fixtures used for testing, explaining their generation from `typeperf -qx` output and the parsing logic involved. It also includes an old Python script snippet demonstrating how these counter strings were processed.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 62
          },
          {
            "name": "Mohammad Rafi",
            "percent": 13
          },
          {
            "name": "Jack Phillips",
            "percent": 7
          }
        ]
      },
      "OpenMetrics & Prometheus Integration Framework": {
        "files": [
          {
            "path": "datadog_checks_base/tests/base/checks/prometheus/test_prometheus_base_check.py",
            "description": "This file contains unit tests for the `GenericPrometheusCheck` class, verifying how configuration overrides like metric types, timeouts, and label-to-hostname mappings are processed and applied.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/prometheus/test_prometheus.py",
            "description": "This file contains unit tests for the `PrometheusCheck` class, verifying its functionality in parsing Prometheus metrics from protobuf and text formats, handling type overrides, and processing collected metrics.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_legacy/utils.py",
            "description": "This file provides utility classes and functions for testing compatibility with legacy OpenMetrics checks using the v2 base check structure.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_legacy/test_bench.py",
            "description": "This file contains benchmark tests for the OpenMetricsBaseCheck, measuring its performance when processing different OpenMetrics exposition formats (KSM, Amazon MSK JMX) and configurations, including label joins. These benchmarks appear to target a legacy implementation of the check.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_legacy/test_openmetrics_base_check.py",
            "description": "This file contains unit tests for the `OpenMetricsBaseCheck` class, verifying its initialization, configuration parsing, and behavior regarding instance overrides, metric type overrides, timeouts, label to hostname mapping, and bearer token handling for Prometheus scraping.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_legacy/test_compat_scraper.py",
            "description": "This file contains unit tests for the configuration validation and data processing of legacy OpenMetrics checks. It verifies that various settings like metric prefixes, label handling, and exclusion rules correctly raise exceptions for invalid input and process valid configurations.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_legacy/test_openmetrics.py",
            "description": "This file contains unit tests for the OpenMetricsBaseCheck, validating its functionality in parsing, processing, and submitting metrics from OpenMetrics/Prometheus endpoints. It covers various scenarios including configuration, metric processing, polling different content types, and handling labels for tag and hostname generation.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_interface.py",
            "description": "Tests for the OpenMetricsBaseCheckV2 interface, covering functionalities like default configuration, tagging, dynamic service checks, and custom metric transformers.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_config.py",
            "description": "This file contains unit tests for the configuration validation logic of OpenMetrics checks (v2). It verifies that various invalid configurations raise appropriate exceptions, ensuring robust handling of user-provided settings.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_bench.py",
            "description": "This file contains benchmark tests for the OpenMetricsBaseCheckV2 class, evaluating its performance when processing OpenMetrics exposition formats with various configurations, including metrics collection and label joining.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_options.py",
            "description": "This file contains unit tests for various configuration options related to OpenMetricsV2-based checks in the Datadog Agent, such as namespace, labels, metric exclusions, and service checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/utils.py",
            "description": "This file provides utility functions for creating and configuring `OpenMetricsBaseCheckV2` instances for testing purposes. It helps set up default instance and init configurations, including a test OpenMetrics endpoint and namespace.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_time_elapsed.py",
            "description": "Tests the OpenMetrics `time_elapsed` transformer, ensuring it correctly calculates the time elapsed from a given timestamp and applies appropriate tags.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_counter_gauge.py",
            "description": "Tests the `counter_gauge` metric transformer for OpenMetrics V2, ensuring Prometheus counters are correctly converted into both Datadog monotonic counts and gauges.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_service_check.py",
            "description": "Tests the OpenMetrics V2 transformer's ability to process and map metric values to Datadog service checks based on a `status_map` configuration. It verifies both successful mapping and handling of unknown values.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_gauge.py",
            "description": "Tests the OpenMetrics V2 transformer's ability to correctly parse and collect gauge metrics, including those with labels that are converted to tags.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_type_override.py",
            "description": "This file contains a test suite for validating the OpenMetrics V2 integration's ability to override metric types, specifically for untyped or mis-typed metrics, forcing them to be collected as counters or gauges.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_rate.py",
            "description": "This file tests the OpenMetrics v2 integration's ability to transform a raw counter metric from an OpenMetrics endpoint into a Datadog rate metric. It verifies the correct conversion and reporting of the rate type.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_summary.py",
            "description": "Tests the OpenMetrics V2 transformer's ability to process and transform Prometheus 'summary' type metrics into Datadog metrics, including quantiles, sums, and counts, and handles metric remapping.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_histogram.py",
            "description": "This file contains unit tests for the OpenMetrics v2 transformer's handling of histogram metrics. It verifies the correct collection and tagging of histogram buckets, sums, and counts, as well as the functionality to disable histogram bucket collection.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_counter.py",
            "description": "This file contains unit tests for the OpenMetrics V2 transformer's handling of 'counter' type metrics. It verifies correct metric collection, suffix dropping (e.g., '_total'), and tag extraction for counters.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_metadata.py",
            "description": "This file contains unit tests for the OpenMetrics V2 metadata transformer, verifying its ability to extract and standardize version information from metric labels like 'gitVersion' into structured metadata.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/test_transformers/test_native_dynamic.py",
            "description": "This test file verifies the OpenMetrics v2 transformer's ability to dynamically infer metric types (like gauge or monotonic count) based on metric names, specifically handling metrics with a `_total` suffix. It ensures that `native_dynamic` type metrics are correctly processed and asserted.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/scraper/test_first_scrape_handler.py",
            "description": "This file contains unit tests for the `first_scrape_handler` functionality within the OpenMetrics V2 scraper, specifically testing how it handles the initial flush of metrics, particularly when `process_start_time` is involved.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/checks/openmetrics/test_v2/scraper/test_http_status_class_scraper.py",
            "description": "This file contains unit tests for the `WithHttpCodeClass` decorator within the OpenMetricsV2 scraper, ensuring it correctly adds HTTP status code class tags (e.g., '2xx', '4xx') to metrics based on the provided status label and code.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/openmetrics/mixins.py",
            "description": "This file re-exports all content from the base OpenMetrics mixins module, serving as a shim or alias for backward compatibility or internal restructuring.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/openmetrics/base_check.py",
            "description": "This file re-exports the OpenMetrics base check from a lower-level module, making it available at this location within the `datadog_checks_base` package for consumption.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/openmetrics/__init__.py",
            "description": "This `__init__.py` file serves as a package entry point, re-exporting all contents from the `datadog_checks_base.base.checks.openmetrics` module. It likely acts as an alias or a way to expose components from a deeper internal structure at a higher level.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/prometheus/base_check.py",
            "description": "This file re-exports all symbols from the core Prometheus base check, serving as an alias or a forwarding mechanism to `datadog_checks_base.base.checks.prometheus.base_check`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/prometheus/__init__.py",
            "description": "This `__init__.py` file re-exports all contents from the Prometheus base check module, making them accessible directly under `datadog_checks.checks.prometheus`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/prometheus/prometheus_base.py",
            "description": "This file acts as a re-export for the Prometheus base check functionalities from a lower-level module within the `datadog_checks_base` package, simplifying import paths.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/prometheus/mixins.py",
            "description": "This file re-exports Prometheus check mixins from the `datadog_checks_base` package, providing a consistent interface for integrations to utilize common Prometheus-related functionalities.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/prometheus_check/__init__.py",
            "description": "This `__init__.py` file re-exports core Prometheus-related classes and exceptions, including `PrometheusCheck`, `PrometheusFormat`, and `UnknownFormatError`, from a parent module. It makes these symbols directly accessible when the `prometheus_check` package is imported.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/prometheus/functions.py",
            "description": "This file contains a deprecated utility function for parsing Prometheus `MetricFamily` messages from a binary buffer, primarily used for processing Prometheus metrics data.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/prometheus/__init__.py",
            "description": "This `__init__.py` file initializes the `prometheus` utility package for `datadog_checks_base`, primarily using `lazy_loader` to manage the loading of its sub-modules efficiently.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/prometheus/metrics_pb2.py",
            "description": "This file is a generated Python Protobuf file defining the data structures (messages and enums) for Prometheus metrics, based on the `metrics.proto` schema. It enables Python applications to serialize and deserialize Prometheus metric data.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/__init__.py",
            "description": "This file uses `lazy_loader` to enable lazy loading for the `openmetrics` module, deferring imports until its contents are explicitly accessed to improve startup performance.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/mixins.py",
            "description": "This file defines a mixin class, `OpenMetricsScraperMixin`, that provides common scraping and processing logic for OpenMetrics/Prometheus endpoints. It handles configuration, metric filtering, label enrichment, and various options for submitting metrics to Datadog.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/base_check.py",
            "description": "This file defines the `OpenMetricsBaseCheck` class, a base class for Datadog Agent integrations designed to scrape Prometheus/OpenMetrics endpoints using YAML configurations. It provides common functionalities for metric collection, configuration validation, and HTTP request handling for such integrations.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/base.py",
            "description": "This file defines `OpenMetricsBaseCheckV2`, a base class for Datadog integrations designed to scrape Prometheus/OpenMetrics endpoints. It provides core logic for configuring, initializing, and executing OpenMetrics scrapers for metric collection.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/metrics.py",
            "description": "This file defines a dictionary of default Go metrics, mapping their OpenMetrics names to Datadog metric names, often including specific metric types for accurate reporting.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transform.py",
            "description": "This file defines a `MetricTransformer` class responsible for parsing and applying metric transformations based on configuration, converting OpenMetrics data into Datadog-compatible metrics. It handles various metric types like counters, gauges, histograms, and provides mechanisms for custom and native transformations.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/utils.py",
            "description": "This file provides utility functions for processing OpenMetrics/Prometheus histogram samples, primarily to decumulate buckets and add lower bound labels for easier analysis.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/__init__.py",
            "description": "This file serves as the package initializer for the OpenMetrics V2 base checks within the Datadog integration library. It allows the `v2` directory to be recognized as a Python package.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/labels.py",
            "description": "This file defines a `LabelAggregator` class that processes and applies shared labels and target information labels to OpenMetrics metrics based on configured rules. It also provides utilities for normalizing specific label types like histogram and summary quantiles.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/first_scrape_handler.py",
            "description": "This file defines a handler for processing metrics during the first scrape of an OpenMetrics V2 endpoint. It identifies the process start time and buffers certain metric types to potentially manage initial values or counter resets.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/__init__.py",
            "description": "This `__init__.py` file uses `lazy_loader` to enable lazy loading of submodules within the `transformers` package, optimizing import performance.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/counter.py",
            "description": "This file defines a transformer function for OpenMetrics 'counter' type metrics. It processes raw counter samples and submits them as Datadog monotonic counts, appending '.count' to the metric name.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/counter_gauge.py",
            "description": "Provides a transformer that submits a single metric value as both a `monotonic_count` (suffixed with `.count`) and a `gauge` (suffixed with `.total`). This is used for OpenMetrics metrics that need to be represented as both a cumulative total and an incrementally increasing count.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/metadata.py",
            "description": "This file provides a transformer function to extract instance metadata from OpenMetrics metric labels. It allows submitting a specific label's value as metadata for a given metric name.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/time_elapsed.py",
            "description": "This file defines a transformer function for OpenMetrics checks that calculates and reports the time elapsed since a given timestamp as a gauge metric.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/gauge.py",
            "description": "This file provides a transformer function specifically designed to process OpenMetrics gauge type metrics, converting them into Datadog gauge metrics using the check's gauge method.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/service_check.py",
            "description": "This file contains functions to transform OpenMetrics metrics into Datadog service checks, mapping specific metric values to service check statuses like OK, WARNING, CRITICAL, or UNKNOWN.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/rate.py",
            "description": "This file defines a transformer function for OpenMetrics v2 checks that uses the Datadog Agent's `rate` method to send metrics as rates. It processes raw metric samples and converts them into rate-based metrics.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/summary.py",
            "description": "This file defines a transformer for OpenMetrics v2 'summary' type metrics, converting them into Datadog `monotonic_count` for sum/count and `gauge` for quantiles.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/transformers/histogram.py",
            "description": "This module provides a transformer function for OpenMetrics v2 histograms. It processes histogram samples, converting them into Datadog metrics (monotonic counts or histogram buckets) based on different configuration settings for bucket collection and distribution handling.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/scraper/decorators.py",
            "description": "This file defines a scraper decorator that adds a `code_class` tag to metrics, categorizing HTTP status codes (e.g., 2xx, 4xx) parsed from an existing tag.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/scraper/base_scraper.py",
            "description": "This file defines the `OpenMetricsScraper` class, which is responsible for configuring and executing metric scraping from OpenMetrics/Prometheus endpoints, including advanced processing of metrics, labels, and service checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/openmetrics/v2/scraper/__init__.py",
            "description": "This `__init__.py` file defines the public API for the OpenMetrics V2 scraper package. It exposes the core scraper classes (`OpenMetricsScraper`, `OpenMetricsCompatibilityScraper`) and related decorators for use in Datadog checks.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/prometheus/__init__.py",
            "description": "This file acts as an entry point for the Prometheus check utilities, using lazy loading to defer the import of actual implementations until they are explicitly accessed, which helps improve import performance.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/prometheus/prometheus_base.py",
            "description": "This file defines the `PrometheusCheck` base class, providing a structure and helpers for Datadog Agent checks to collect metrics, events, and service checks from Prometheus endpoints.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/prometheus/base_check.py",
            "description": "This file provides base classes for collecting and submitting metrics from Prometheus endpoints to Datadog. It includes a `PrometheusScraper` for handling the scraping logic and a `GenericPrometheusCheck` for configuring and managing multiple Prometheus scrapers via YAML.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/prometheus/mixins.py",
            "description": "This file defines the `PrometheusScraperMixin` class, which provides core functionality for Datadog checks to scrape, parse, and process Prometheus-style metrics from endpoints, supporting both Protobuf and text formats.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/prometheus/functions.py",
            "description": "This file re-exports common Prometheus utility functions from a base module and imports Protocol Buffer definitions for metrics. It serves as an aggregation point for Prometheus-related utilities within the Datadog checks base library.",
            "spof": true
          },
          {
            "path": "docs/developer/base/openmetrics.md",
            "description": "This document describes Datadog's OpenMetrics v2 implementation, outlining the base check, scraper, and transformer components. It serves as a reference for integrating OpenMetrics checks within the Datadog agent, highlighting its Python 3 compatibility and its role as the default version for new checks.",
            "spof": true
          },
          {
            "path": "docs/developer/legacy/prometheus.md",
            "description": "This document describes how Datadog integrations collect Prometheus/OpenMetrics V1 metrics, detailing the underlying classes, configuration options, and the mapping of various Prometheus metric types (gauge, counter, histogram, summary) to Datadog metrics.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 79
          },
          {
            "name": "Juanpe Araque",
            "percent": 6
          },
          {
            "name": "Florent Clarret",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 307,
      "spofCount": 211
    },
    "busFactor": 2,
    "authorCount": 57
  },
  "CoreDNS Monitoring": {
    "description": "Monitors the CoreDNS server in Kubernetes and other environments, collecting metrics on DNS requests, latency, and errors.",
    "functions": {
      "Bundled Assets and Packaging": {
        "files": [
          {
            "path": "coredns/CHANGELOG.md",
            "description": "This file is the changelog for the CoreDNS integration, detailing new features, bug fixes, changes, and removals across different versions.",
            "spof": false
          },
          {
            "path": "coredns/README.md",
            "description": "This file provides documentation for the Datadog CoreDNS integration, detailing setup, configuration for metric and log collection across various platforms (Docker, Kubernetes, ECS), and troubleshooting.",
            "spof": false
          },
          {
            "path": "coredns/datadog_checks/coredns/__init__.py",
            "description": "This file marks the `coredns` directory as a Python package, exposing its version and the main `CoreDNSCheck` class for external use.",
            "spof": true
          },
          {
            "path": "coredns/datadog_checks/coredns/data",
            "description": "This directory is intended to store auxiliary data files, such as configuration templates, default settings, or other static assets, specific to the Datadog CoreDNS integration check. Although currently empty, its purpose is to house any supplementary data required by the check.",
            "spof": false
          },
          {
            "path": "coredns/assets/configuration",
            "description": "This directory is designated to store configuration assets or example configuration files specifically for the Datadog CoreDNS integration. Although currently empty, its intended role is to provide users with reference configurations.",
            "spof": false
          },
          {
            "path": "coredns/assets/dashboards",
            "description": "This directory is designated to store pre-built dashboard definitions for the Datadog CoreDNS integration. These assets provide out-of-the-box visualizations and metric displays to facilitate monitoring of CoreDNS services within the Datadog platform.",
            "spof": false
          },
          {
            "path": "coredns/assets/monitors",
            "description": "This directory is designated to hold JSON definitions for Datadog monitors specific to the CoreDNS integration. While currently empty, its purpose is to provide custom alerting and monitoring configurations.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "HadhemiDD",
            "percent": 17
          },
          {
            "name": "Kyle Neale",
            "percent": 14
          },
          {
            "name": "Sarah Wang",
            "percent": 14
          }
        ]
      },
      "Integration Testing Framework": {
        "files": [
          {
            "path": "coredns/tests/__init__.py",
            "description": "This empty __init__.py file marks the 'tests' directory as a Python package, enabling test discovery and organization for the coredns integration.",
            "spof": true
          },
          {
            "path": "coredns/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog CoreDNS integration. It verifies that the integration correctly collects metrics from CoreDNS, including a specific test for OpenMetrics V2.",
            "spof": true
          },
          {
            "path": "coredns/tests/common.py",
            "description": "This file defines common constants and metric lists used in tests for the Datadog CoreDNS integration, accommodating different CoreDNS versions and metric output formats.",
            "spof": true
          },
          {
            "path": "coredns/tests/test_check.py",
            "description": "This file contains unit and integration tests for the Datadog CoreDNS check, verifying its metric collection capabilities under various configurations, including OpenMetrics V2 and Docker environments.",
            "spof": false
          },
          {
            "path": "coredns/tests/conftest.py",
            "description": "This file provides pytest fixtures for setting up and tearing down the CoreDNS test environment using Docker, including version-specific metric mocks, for the Datadog Agent integration tests.",
            "spof": false
          },
          {
            "path": "coredns/tests/fixtures",
            "description": "This directory is designated to store test fixtures for the `coredns` integration. It provides predefined data or configurations used to set up consistent environments for running automated tests.",
            "spof": false
          },
          {
            "path": "coredns/tests/docker/coredns",
            "description": "This directory is designated to store Docker-related files for testing the Datadog CoreDNS integration. It would typically contain Dockerfiles, compose configurations, or other resources needed to set up a containerized test environment for CoreDNS. Currently empty, it serves as a placeholder for these integration testing artifacts.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Fanny Jiang",
            "percent": 52
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 35
          },
          {
            "name": "Ofek Lev",
            "percent": 6
          }
        ]
      },
      "CoreDNS Metric Collection": {
        "files": [
          {
            "path": "coredns/datadog_checks/coredns/check.py",
            "description": "This file defines the Datadog integration check for CoreDNS, inheriting from OpenMetricsBaseCheckV2 to collect metrics via the OpenMetrics V2 scraper.",
            "spof": true
          },
          {
            "path": "coredns/datadog_checks/coredns/coredns.py",
            "description": "This file contains a legacy implementation for collecting CoreDNS metrics from its Prometheus endpoint. It handles configuration transformation for `OpenMetricsBaseCheck` and can delegate to a newer implementation if specified.",
            "spof": false
          },
          {
            "path": "coredns/datadog_checks/coredns/metrics.py",
            "description": "This file defines mappings for CoreDNS and Go runtime Prometheus metrics to Datadog metric names, accommodating different CoreDNS versions to ensure proper data collection and naming within Datadog.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 52
          },
          {
            "name": "Fanny Jiang",
            "percent": 33
          },
          {
            "name": "Juanpe Araque",
            "percent": 13
          }
        ]
      },
      "Configuration Modeling and Validation": {
        "files": [
          {
            "path": "coredns/datadog_checks/coredns/config_models/defaults.py",
            "description": "This file defines default configuration values for the CoreDNS integration. It is an autogenerated file, mapping configuration options to their default settings.",
            "spof": true
          },
          {
            "path": "coredns/datadog_checks/coredns/config_models/validators.py",
            "description": "This file defines a configuration validator for CoreDNS checks, ensuring that either `prometheus_url` or `openmetrics_endpoint` is present in the instance configuration.",
            "spof": false
          },
          {
            "path": "coredns/datadog_checks/coredns/config_models/instance.py",
            "description": "This file defines the Pydantic models for the CoreDNS integration's instance configuration, automatically generated from a specification file.",
            "spof": false
          },
          {
            "path": "coredns/datadog_checks/coredns/config_models/shared.py",
            "description": "This file defines shared Pydantic models, `Proxy` and `SharedConfig`, used for configuration across different integrations. It is autogenerated from a spec.yaml file.",
            "spof": true
          },
          {
            "path": "coredns/datadog_checks/coredns/config_models/__init__.py",
            "description": "This `__init__.py` file serves as the entry point for the `config_models` package, autogenerating classes for instance and shared configurations and providing a `ConfigMixin` to easily access them.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 66
          },
          {
            "name": "Yann Armelin",
            "percent": 28
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 22,
      "spofCount": 8
    },
    "busFactor": 3,
    "authorCount": 13
  },
  "CouchDB Monitoring": {
    "description": "Monitors Apache CouchDB databases, collecting metrics on performance, replication, and resource usage.",
    "functions": {
      "CouchDB Metric Collection and Configuration": {
        "files": [
          {
            "path": "couch/README.md",
            "description": "This file is the README for the Datadog CouchDB integration, providing instructions on how to set up metric and log collection for CouchDB instances using the Datadog Agent.",
            "spof": false
          },
          {
            "path": "couch/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog CouchDB integration. It documents all the changes, additions, fixes, and removals across different versions of the integration.",
            "spof": false
          },
          {
            "path": "couch/images",
            "description": "This directory is designated for storing image assets pertinent to the Datadog CouchDB integration. It would typically contain visuals such as icons, diagrams, or screenshots used in documentation or UI for the CouchDB integration.",
            "spof": false
          },
          {
            "path": "couch/datadog_checks/couch/errors.py",
            "description": "This file defines custom exception classes, `ConnectionError` and `BadVersionError`, used within the CouchDB integration. These exceptions inherit from `CheckException` to provide specific error handling for the check.",
            "spof": true
          },
          {
            "path": "couch/datadog_checks/couch/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the `couch` integration. It exposes the `CouchDb` check class, `__version__` information, and custom `errors` for the package.",
            "spof": false
          },
          {
            "path": "couch/datadog_checks/couch/couch.py",
            "description": "This file implements the Datadog Agent check for CouchDB, collecting metrics and performing service checks for CouchDB instances. It supports different CouchDB versions (1.x and 2.x+) by adapting its metric collection methods.",
            "spof": false
          },
          {
            "path": "couch/datadog_checks/couch/config_models/defaults.py",
            "description": "This file contains autogenerated default values for configuration parameters of the CouchDB integration. These defaults are used when specific settings are not provided in the integration's configuration.",
            "spof": true
          },
          {
            "path": "couch/datadog_checks/couch/config_models/validators.py",
            "description": "This file provides custom configuration validation and transformation logic for the CouchDB integration, allowing for handling of legacy options or enforcing specific value constraints.",
            "spof": true
          },
          {
            "path": "couch/datadog_checks/couch/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration settings, including proxy and general connection parameters, for the Datadog CouchDB integration. It is an autogenerated file from a specification.",
            "spof": true
          },
          {
            "path": "couch/datadog_checks/couch/config_models/instance.py",
            "description": "This file defines autogenerated Pydantic models for the CouchDB integration's instance-level configuration, specifying the data structure and validation rules for various settings such as authentication, connection details, and metric patterns.",
            "spof": true
          },
          {
            "path": "couch/datadog_checks/couch/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient access to autogenerated instance and shared configuration models for the CouchDB integration.",
            "spof": true
          },
          {
            "path": "couch/datadog_checks/couch/data",
            "description": "This directory is intended to store static data files, configurations, or examples specific to the Datadog CouchDB integration. Although currently empty, it serves as a placeholder for such assets.",
            "spof": false
          },
          {
            "path": "couch/assets/dashboards",
            "description": "This directory is responsible for storing pre-built dashboard configurations or templates specifically for the Datadog CouchDB integration. These dashboards provide out-of-the-box visualizations for monitoring CouchDB metrics within the Datadog platform.",
            "spof": false
          },
          {
            "path": "couch/assets/configuration",
            "description": "This directory is designated to store configuration-related assets specifically for the Datadog integration with CouchDB. It defines the expected location for configuration files used by the CouchDB integration, even if currently empty.",
            "spof": false
          },
          {
            "path": "couch/assets/saved_views",
            "description": "This directory is intended to store pre-defined saved views for the Datadog CouchDB integration. These views would typically be used for monitoring or data collection purposes. Although currently empty, it serves as a placeholder for such assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 21
          },
          {
            "name": "Sarah Wang",
            "percent": 11
          },
          {
            "name": "Kyle Neale",
            "percent": 11
          }
        ]
      },
      "CouchDB Integration Test Suite": {
        "files": [
          {
            "path": "couch/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the 'tests' directory as a Python package, allowing its modules to be imported. It serves as a placeholder as there are no package-specific initializations needed.",
            "spof": true
          },
          {
            "path": "couch/tests/test_couchv2.py",
            "description": "This file contains integration tests for the Datadog CouchDB check, specifically designed to verify metric collection and service checks for CouchDB version 2 and above.",
            "spof": false
          },
          {
            "path": "couch/tests/conftest.py",
            "description": "This file provides Pytest fixtures for the CouchDB integration tests, including setting up a Dockerized CouchDB environment (v1 or v2) and preparing test data.",
            "spof": true
          },
          {
            "path": "couch/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog CouchDB integration. It verifies configuration parsing, including authentication and timeout settings, and ensures correct handling of system metrics for different CouchDB versions.",
            "spof": true
          },
          {
            "path": "couch/tests/test_couch.py",
            "description": "This file contains unit and integration tests for the Datadog CouchDB integration, covering scenarios like metadata collection, configuration validation, connection errors, and unsupported server versions.",
            "spof": true
          },
          {
            "path": "couch/tests/common.py",
            "description": "This file defines common variables, constants, and test configurations for the CouchDB integration's test suite. It includes CouchDB connection details, expected metric names, and various test configurations for different scenarios.",
            "spof": false
          },
          {
            "path": "couch/tests/test_couchv1.py",
            "description": "This file contains integration and end-to-end tests for the Datadog CouchDB integration, specifically designed for CouchDB version 1. It verifies metric collection, database filtering, configuration options, and service checks.",
            "spof": true
          },
          {
            "path": "couch/tests/fixtures",
            "description": "This directory is intended to store test fixtures, such as mock data or configuration files, specifically for the CouchDB integration tests. Although currently empty, its purpose is to provide static resources needed to set up or validate test scenarios.",
            "spof": false
          },
          {
            "path": "couch/tests/compose",
            "description": "This directory is intended to store Docker Compose configurations for setting up the testing environment for the Datadog CouchDB integration. Its purpose is to define services, such as a CouchDB instance, required to execute integration tests.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 58
          },
          {
            "name": "Sam Rose",
            "percent": 16
          },
          {
            "name": "dkirov-dd",
            "percent": 12
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 24,
      "spofCount": 11
    },
    "busFactor": 4,
    "authorCount": 12
  },
  "Couchbase Monitoring": {
    "description": "Monitors Couchbase clusters, including data nodes, indexers, and Sync Gateway, for performance and health.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "couchbase/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor Couchbase, detailing metric, log, and event collection.",
            "spof": false
          },
          {
            "path": "couchbase/CHANGELOG.md",
            "description": "This file documents all changes, new features, and fixes across different versions of the Datadog Couchbase integration, serving as a release history for the project.",
            "spof": false
          },
          {
            "path": "couchbase/images",
            "description": "This directory is intended to store image assets specifically for the Couchbase integration within the Datadog integrations-core repository. These images might be used for documentation, UI elements, or other visual resources related to the integration.",
            "spof": false
          },
          {
            "path": "couchbase/assets/configuration",
            "description": "This directory is intended to house configuration files or templates specific to the Datadog integration for Couchbase. It serves as a dedicated location for assets related to configuring the Couchbase integration within the Datadog ecosystem.",
            "spof": false
          },
          {
            "path": "couchbase/assets/dashboards",
            "description": "This directory is designated to store Datadog dashboard definitions specifically for the Couchbase integration. It would typically contain pre-built JSON or YAML files that users can import to visualize Couchbase metrics. Although currently empty, its role is to house these essential visualization assets for the integration.",
            "spof": false
          },
          {
            "path": "couchbase/assets/saved_views",
            "description": "This directory is intended to store definitions or configurations for saved views specific to the Datadog Couchbase integration. It likely holds pre-defined queries or views that can be deployed or utilized within a Couchbase environment for monitoring purposes.",
            "spof": false
          },
          {
            "path": "couchbase/datadog_checks/couchbase/data",
            "description": "This directory is intended to store static data files or configuration assets specific to the Datadog Couchbase integration. Although currently empty, its name suggests it would house any required non-code resources for the check.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Wang",
            "percent": 17
          },
          {
            "name": "Kyle Neale",
            "percent": 15
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 14
          }
        ]
      },
      "Integration Testing and Environment Management": {
        "files": [
          {
            "path": "couchbase/tests/test_unit.py",
            "description": "This file contains unit tests for the Couchbase integration, verifying utility functions, configuration parsing, metric collection, and service checks using mocked data.",
            "spof": true
          },
          {
            "path": "couchbase/tests/test_e2e.py",
            "description": "This file contains an end-to-end test for the Datadog Couchbase integration, verifying all collected metrics except for query-related ones. It asserts bucket and node statistics to ensure proper data collection.",
            "spof": true
          },
          {
            "path": "couchbase/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Couchbase check, verifying metrics collection, service checks, and metadata reporting for various Couchbase features like buckets, nodes, queries, Sync Gateway, and index statistics.",
            "spof": true
          },
          {
            "path": "couchbase/tests/conftest.py",
            "description": "This file defines pytest fixtures and helper functions for setting up and managing a Couchbase Docker test environment for integration tests.",
            "spof": true
          },
          {
            "path": "couchbase/tests/__init__.py",
            "description": "This file marks the 'tests' directory as a Python package, enabling the discovery and execution of test modules within it.",
            "spof": true
          },
          {
            "path": "couchbase/tests/common.py",
            "description": "This file defines common constants, configurations, and expected metric lists used for testing the Datadog Couchbase integration, including specific metrics for different Couchbase Sync Gateway versions.",
            "spof": false
          },
          {
            "path": "couchbase/tests/compose",
            "description": "This directory is intended to house Docker Compose configurations for setting up test environments specific to the Couchbase integration. It facilitates the creation of isolated service dependencies required for integration testing.",
            "spof": false
          },
          {
            "path": "couchbase/tests/fixtures/admin",
            "description": "This directory is designated for storing test fixtures specific to the administrative functionalities of the Datadog Couchbase integration. These fixtures would provide controlled data or mock environments for testing administrative scenarios. Although currently empty, its role is to support robust testing of Couchbase administration.",
            "spof": false
          },
          {
            "path": "couchbase/tests/fixtures/pools/default/buckets/cb_buckets",
            "description": "This directory serves as a placeholder or container for test fixtures related to Couchbase buckets. It is part of the test setup for the Couchbase integration, specifically within the default pool configuration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sven Ulland",
            "percent": 73
          },
          {
            "name": "Florent Clarret",
            "percent": 15
          },
          {
            "name": "dkirov-dd",
            "percent": 11
          }
        ]
      },
      "Couchbase Data Collection and Configuration": {
        "files": [
          {
            "path": "couchbase/datadog_checks/couchbase/__init__.py",
            "description": "This file serves as the main entry point for the `couchbase` integration package, exposing its version information and the primary Couchbase check class.",
            "spof": false
          },
          {
            "path": "couchbase/datadog_checks/couchbase/couchbase.py",
            "description": "This file implements a Datadog Agent check for Couchbase, collecting metrics, service checks, and events from Couchbase clusters, Sync Gateways, and indexers via their respective REST APIs.",
            "spof": false
          },
          {
            "path": "couchbase/datadog_checks/couchbase/couchbase_consts.py",
            "description": "This file defines constants, service check names, API paths, and lists of metrics specifically for the Datadog Couchbase integration.",
            "spof": true
          },
          {
            "path": "couchbase/datadog_checks/couchbase/config_models/validators.py",
            "description": "This file is a placeholder for custom configuration validators and transformers for the Couchbase integration, allowing for advanced validation and data manipulation of integration settings.",
            "spof": true
          },
          {
            "path": "couchbase/datadog_checks/couchbase/config_models/defaults.py",
            "description": "This autogenerated file defines default configuration values for various settings within the Datadog Couchbase integration. These defaults are used when specific configurations are not provided by the user.",
            "spof": true
          },
          {
            "path": "couchbase/datadog_checks/couchbase/config_models/shared.py",
            "description": "This file defines shared Pydantic models for configuration, such as proxy settings, used by the Couchbase integration. It includes validation logic and default value handling for these shared configuration options.",
            "spof": true
          },
          {
            "path": "couchbase/datadog_checks/couchbase/config_models/__init__.py",
            "description": "This file defines a mixin for accessing autogenerated configuration models (instance-specific and shared) for the Couchbase integration, serving as an entry point for its configuration types.",
            "spof": false
          },
          {
            "path": "couchbase/datadog_checks/couchbase/config_models/instance.py",
            "description": "This file defines the Pydantic models for the Couchbase integration's instance configuration. It is autogenerated from the integration's `spec.yaml` file to enforce configuration schema and validation.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Sven Ulland",
            "percent": 53
          },
          {
            "name": "Ofek Lev",
            "percent": 35
          },
          {
            "name": "Yann Armelin",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 24,
      "spofCount": 10
    },
    "busFactor": 3,
    "authorCount": 9
  },
  "Btrfs Filesystem Monitoring": {
    "description": "Collects usage and performance metrics from Btrfs filesystems to monitor disk space, allocation, and health.",
    "functions": {
      "Btrfs Metric Collection and Integration": {
        "files": [
          {
            "path": "btrfs/README.md",
            "description": "This README.md file provides documentation for the Datadog Agent's Btrfs integration. It details how to set up, configure, and validate the integration, as well as the types of data collected (metrics, no events or service checks).",
            "spof": false
          },
          {
            "path": "btrfs/tests/__init__.py",
            "description": "This is an empty `__init__.py` file that marks the `tests` directory as a Python package, allowing test modules within it to be imported and organized.",
            "spof": true
          },
          {
            "path": "btrfs/tests/test_btrfs.py",
            "description": "This file contains unit and integration tests for the Datadog Btrfs check, verifying its ability to collect disk usage metrics from Btrfs filesystems using mocked system calls and data.",
            "spof": true
          },
          {
            "path": "btrfs/CHANGELOG.md",
            "description": "This file documents all the changes, new features, bug fixes, and version updates for the DataDog Btrfs integration over time.",
            "spof": false
          },
          {
            "path": "btrfs/images",
            "description": "This directory is designated for storing image assets specifically for the Datadog Btrfs integration. Its purpose is to house visual content such as screenshots, icons, or dashboard graphics used in documentation or monitoring interfaces.",
            "spof": false
          },
          {
            "path": "btrfs/datadog_checks/btrfs/__init__.py",
            "description": "This file serves as the main entry point for the BTRFS integration package. It imports and exposes the package version and the core BTRFS check class.",
            "spof": true
          },
          {
            "path": "btrfs/datadog_checks/btrfs/btrfs.py",
            "description": "This file implements a Datadog Agent check for monitoring Btrfs file systems. It collects metrics on disk usage, space allocation, and replication types by interacting with the Btrfs kernel module via ioctl calls.",
            "spof": false
          },
          {
            "path": "btrfs/datadog_checks/btrfs/config_models/shared.py",
            "description": "This file defines the `SharedConfig` Pydantic model for Btrfs integration, handling common configuration options and applying validation rules. It is an autogenerated file from a specification, providing a standardized structure for shared settings.",
            "spof": true
          },
          {
            "path": "btrfs/datadog_checks/btrfs/config_models/validators.py",
            "description": "This file is intended to house custom validation and transformation logic for the Btrfs integration's configuration, as demonstrated by the provided commented examples.",
            "spof": true
          },
          {
            "path": "btrfs/datadog_checks/btrfs/config_models/__init__.py",
            "description": "This file serves as the entry point for Btrfs integration's configuration models, providing a `ConfigMixin` to access both instance-specific and shared configuration settings.",
            "spof": false
          },
          {
            "path": "btrfs/datadog_checks/btrfs/config_models/defaults.py",
            "description": "This file defines default configuration values for the Btrfs integration, specifically for instance-level settings like tag disabling, hostname, and collection interval. It is an autogenerated file based on a configuration specification.",
            "spof": true
          },
          {
            "path": "btrfs/datadog_checks/btrfs/config_models/instance.py",
            "description": "This file defines the Pydantic models for validating and parsing the configuration of a single instance of the Datadog Btrfs integration. It is an autogenerated file based on a specification.",
            "spof": true
          },
          {
            "path": "btrfs/datadog_checks/btrfs/data",
            "description": "This `data` directory within the Datadog Btrfs integration is designated for storing static files, configuration, or auxiliary data. Although currently empty, it serves as a placeholder for resources specific to the Btrfs check's operation or testing.",
            "spof": false
          },
          {
            "path": "btrfs/assets/dashboards",
            "description": "This directory is designated to store dashboard definitions or configurations for the `btrfs` integration. As an `assets/dashboards` folder, it would typically contain JSON or YAML files defining visualizations and metrics for monitoring Btrfs. Currently, it is empty, indicating no dashboards are provided with this integration.",
            "spof": false
          },
          {
            "path": "btrfs/assets/configuration",
            "description": "This directory is intended to store configuration-related assets for the Datadog Btrfs integration. It would typically contain example configuration files or default settings needed for the integration to function, though it is currently empty.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 21
          },
          {
            "name": "HadhemiDD",
            "percent": 18
          },
          {
            "name": "Kyle Neale",
            "percent": 18
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 15,
      "spofCount": 7
    },
    "busFactor": 2,
    "authorCount": 9
  },
  "Databricks Unified Analytics Monitoring": {
    "description": "Provides observability into Databricks workspaces, monitoring jobs, cluster performance, costs, and data pipelines.",
    "functions": {
      "Integration Asset Management and Documentation": {
        "files": [
          {
            "path": "databricks/CHANGELOG.md",
            "description": "This file is the CHANGELOG for the Databricks integration, documenting all changes and releases. It currently indicates the initial release of the integration.",
            "spof": true
          },
          {
            "path": "databricks/README.md",
            "description": "This document provides an overview of Datadog's Databricks integration capabilities, including monitoring for jobs, costs, logs, and data observability. It also offers detailed instructions for setting up and configuring the integration within Datadog.",
            "spof": true
          },
          {
            "path": "databricks/images",
            "description": "This directory is designated to store images pertinent to the Databricks integration within the Datadog integrations-core repository. It would typically contain icons, diagrams, or screenshots used for documentation or UI elements related to the Databricks integration.",
            "spof": false
          },
          {
            "path": "databricks/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions or related assets specific to the Databricks integration within Datadog. Although currently empty, its purpose is to house visualizations and metrics configurations for monitoring Databricks environments.",
            "spof": false
          },
          {
            "path": "databricks/assets/monitors",
            "description": "This directory is intended to house Datadog monitor definitions or configuration assets specifically for the Databricks integration. These monitors would be used to observe and alert on the health and performance of Databricks environments.",
            "spof": false
          },
          {
            "path": "flink/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor Flink, covering both metric and log collection.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "rkaneriya",
            "percent": 79
          },
          {
            "name": "Rosa Trieu",
            "percent": 5
          },
          {
            "name": "Florent Clarret",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 6,
      "spofCount": 3
    },
    "busFactor": 2,
    "authorCount": 4
  },
  "CRI-O Monitoring": {
    "description": "Monitors the CRI-O container runtime, collecting metrics on performance and operational health.",
    "functions": {
      "CRI-O Metric Collection": {
        "files": [
          {
            "path": "crio/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog Agent's CRI-O integration, detailing how to monitor CRI-O metrics and service checks.",
            "spof": true
          },
          {
            "path": "crio/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Crio integration, detailing version updates, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "crio/tests/conftest.py",
            "description": "This file defines pytest fixtures `dd_environment` and `instance` for the CRIO integration tests. These fixtures provide a base configuration, including a Prometheus URL, for testing purposes.",
            "spof": false
          },
          {
            "path": "crio/tests/__init__.py",
            "description": "This empty __init__.py file marks the 'tests' directory as a Python package, allowing test modules for the CRIO integration to be organized and imported.",
            "spof": true
          },
          {
            "path": "crio/tests/test_crio.py",
            "description": "This file contains unit and end-to-end tests for the Datadog Crio integration. It verifies that the integration correctly collects metrics and service checks from a Crio endpoint.",
            "spof": true
          },
          {
            "path": "crio/tests/fixtures",
            "description": "This directory is intended to store supplementary data, mock objects, or configurations used as 'fixtures' for testing the 'crio' integration. These fixtures provide consistent and isolated environments for running integration tests.",
            "spof": false
          },
          {
            "path": "crio/assets/configuration",
            "description": "This directory is intended to store configuration assets specific to the Datadog Crio integration. Although currently empty, its purpose is to house configuration files or templates that define how the Crio integration should be set up or customized.",
            "spof": false
          },
          {
            "path": "crio/assets/dashboards",
            "description": "This directory is intended to store JSON definitions or templates for Datadog dashboards specifically designed for monitoring the CRI-O container runtime. These assets would allow users to visualize metrics and logs collected by the CRI-O integration.",
            "spof": false
          },
          {
            "path": "crio/datadog_checks/crio/__init__.py",
            "description": "This `__init__.py` file initializes the `crio` package, making the `CrioCheck` class and the package `__version__` accessible upon import.",
            "spof": false
          },
          {
            "path": "crio/datadog_checks/crio/crio.py",
            "description": "This file implements a Datadog check to collect CRI-O runtime metrics using the OpenMetrics format. It gathers metrics like operations, latency, CPU time, and memory usage from a configured CRI-O endpoint.",
            "spof": false
          },
          {
            "path": "crio/datadog_checks/crio/config_models/defaults.py",
            "description": "This file contains autogenerated default configuration values for the CRIO integration. It defines default settings for various parameters, such as timeouts, authentication types, and metric collection behaviors.",
            "spof": true
          },
          {
            "path": "crio/datadog_checks/crio/config_models/instance.py",
            "description": "This file defines Pydantic models for the CRIO integration's instance configuration, including schema for various configuration options and validation logic. It is autogenerated from the integration's `spec.yaml`.",
            "spof": false
          },
          {
            "path": "crio/datadog_checks/crio/config_models/__init__.py",
            "description": "This file initializes the configuration models for the CRIO integration, defining a mixin to access instance-specific and shared configuration settings. It is an autogenerated file based on a configuration specification.",
            "spof": false
          },
          {
            "path": "crio/datadog_checks/crio/config_models/validators.py",
            "description": "This file is intended for custom configuration validation and transformation logic for the CRIO integration. It provides a place to define functions that can modify or validate configuration values before they are used.",
            "spof": true
          },
          {
            "path": "crio/datadog_checks/crio/data",
            "description": "This directory is designated to store static data files, configuration templates, or other auxiliary assets specific to the Datadog CRIO integration. Although currently empty, its typical role within `datadog_checks` is to provide a location for non-code resources required by the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 25
          },
          {
            "name": "Yann Armelin",
            "percent": 13
          },
          {
            "name": "Kyle Neale",
            "percent": 11
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 15,
      "spofCount": 5
    },
    "busFactor": 2,
    "authorCount": 8
  },
  "HashiCorp Consul Monitoring": {
    "description": "Monitors HashiCorp Consul clusters for service discovery health, leadership status, and key-value store performance.",
    "functions": {
      "Declarative Assets and Documentation": {
        "files": [
          {
            "path": "consul/README.md",
            "description": "This README provides documentation for the Datadog Agent's integration with Consul, detailing how to set up metric collection, log collection, and validate the integration for monitoring Consul nodes.",
            "spof": false
          },
          {
            "path": "consul/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Agent's Consul integration, documenting all releases, new features, bug fixes, and other changes for each version.",
            "spof": false
          },
          {
            "path": "consul/images",
            "description": "This directory is designated for storing image assets relevant to the Datadog Consul integration. While currently empty, it serves as a placeholder for any visual content, such as diagrams or screenshots, that might be used for documentation or UI purposes related to the integration.",
            "spof": false
          },
          {
            "path": "consul/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions and related assets specifically for the Datadog Consul integration. Although currently empty, its purpose is to house visualizations and monitoring layouts for Consul.",
            "spof": false
          },
          {
            "path": "consul/assets/saved_views",
            "description": "This directory is designated to store pre-configured saved views or dashboard configurations specifically for the Datadog Consul integration. Although currently empty, it serves as the intended location for these analytical assets.",
            "spof": false
          },
          {
            "path": "consul/assets/monitors",
            "description": "This directory is intended to store Datadog monitor definitions or configurations specific to the Consul integration. It serves as a dedicated location for assets that define monitoring checks and alerts for the Consul service.",
            "spof": false
          },
          {
            "path": "consul/assets/configuration",
            "description": "This directory is intended to house configuration assets or examples specifically for the Datadog Consul integration. As part of the `assets/configuration` path, it would typically contain default or sample configuration files relevant to setting up and using the Consul integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Wang",
            "percent": 17
          },
          {
            "name": "HadhemiDD",
            "percent": 15
          },
          {
            "name": "Kyle Neale",
            "percent": 14
          }
        ]
      },
      "Integration Testing and Quality Assurance": {
        "files": [
          {
            "path": "consul/tests/test_bench.py",
            "description": "This file contains a benchmark test for the Consul integration's network latency check, simulating different numbers of nodes to measure performance.",
            "spof": true
          },
          {
            "path": "consul/tests/__init__.py",
            "description": "This empty `__init__.py` file designates the `tests` directory within the Consul integration as a Python package. This allows test modules inside to be properly imported and discovered.",
            "spof": true
          },
          {
            "path": "consul/tests/consul_mocks.py",
            "description": "Provides mock configurations and functions for testing the Datadog Consul integration, simulating Consul API responses and agent configurations.",
            "spof": true
          },
          {
            "path": "consul/tests/conftest.py",
            "description": "This file provides pytest fixtures for setting up and tearing down a Docker-based Consul test environment and defining various test configurations for the Datadog Consul integration.",
            "spof": false
          },
          {
            "path": "consul/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Consul integration, verifying the correct collection of metrics and service checks from a Consul cluster under various conditions, such as different health statuses and cluster configurations.",
            "spof": true
          },
          {
            "path": "consul/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Agent's Consul integration, verifying metric collection and service checks against a running Consul instance.",
            "spof": true
          },
          {
            "path": "consul/tests/common.py",
            "description": "This file defines common variables, configurations, and expected Prometheus metrics used by the Consul integration's test suite. It includes environment setup details and version-specific metric lists.",
            "spof": false
          },
          {
            "path": "consul/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Consul integration, verifying metric collection, service checks, error handling, Prometheus endpoint functionality, and version metadata reporting across different Consul setups.",
            "spof": true
          },
          {
            "path": "consul/tests/compose",
            "description": "This directory is intended to house Docker Compose configurations for setting up test environments. Specifically, it would contain the necessary service definitions to spin up a Consul instance for integration testing the Datadog Consul agent check.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Witt",
            "percent": 76
          },
          {
            "name": "Ian Bucad",
            "percent": 11
          },
          {
            "name": "dkirov-dd",
            "percent": 7
          }
        ]
      },
      "Core Metric and Health Collection": {
        "files": [
          {
            "path": "consul/datadog_checks/consul/metrics.py",
            "description": "This file defines a mapping between raw Consul metric names and their corresponding standardized Datadog metric names. It's used to normalize metric data collected from Consul.",
            "spof": true
          },
          {
            "path": "consul/datadog_checks/consul/__init__.py",
            "description": "This `__init__.py` file defines the `consul` Python package, importing the package version and the main `ConsulCheck` class to make them accessible when the package is imported.",
            "spof": true
          },
          {
            "path": "consul/datadog_checks/consul/common.py",
            "description": "This file defines constants and utility functions used across the Datadog Consul integration, including metric names, status mappings, and logic for calculating network distances between Consul nodes.",
            "spof": true
          },
          {
            "path": "consul/datadog_checks/consul/consul.py",
            "description": "This file defines the Datadog integration check for Consul, responsible for collecting metrics, performing service checks, and monitoring the health and leadership status of a Consul cluster.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Sarah Witt",
            "percent": 78
          },
          {
            "name": "Kyle Neale",
            "percent": 6
          },
          {
            "name": "Juanpe Araque",
            "percent": 6
          }
        ]
      },
      "Configuration Handling and Validation": {
        "files": [
          {
            "path": "consul/datadog_checks/consul/config_models/__init__.py",
            "description": "This file defines the `ConfigMixin` class, which provides convenient access to autogenerated instance and shared configuration models for the Consul integration. It serves as an interface to the structured configuration settings defined in `spec.yaml`.",
            "spof": false
          },
          {
            "path": "consul/datadog_checks/consul/config_models/validators.py",
            "description": "This file is intended to define custom configuration validators and transformers for the Datadog Consul integration, as indicated by its name and example code comments.",
            "spof": true
          },
          {
            "path": "consul/datadog_checks/consul/config_models/defaults.py",
            "description": "This file is autogenerated and provides default configuration values for the Consul integration. These defaults are generated from the `spec.yaml` file in the assets directory.",
            "spof": true
          },
          {
            "path": "consul/datadog_checks/consul/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration parameters used by the Datadog Consul integration. It handles parsing, validation, and default values for common configuration options, and is automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "consul/datadog_checks/consul/config_models/instance.py",
            "description": "This file defines the Pydantic model for the Consul integration's instance configuration, including its structure, data types, and validation rules. It is auto-generated from a YAML specification.",
            "spof": false
          },
          {
            "path": "consul/datadog_checks/consul/data",
            "description": "This `data` directory is reserved for static data files or configuration templates specific to the Datadog Consul integration. Although currently empty, its purpose is to house any auxiliary resources that the Consul check might require, such as default configurations or YAML templates.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 74
          },
          {
            "name": "Sarah Witt",
            "percent": 12
          },
          {
            "name": "Yann Armelin",
            "percent": 11
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 26,
      "spofCount": 13
    },
    "busFactor": 2,
    "authorCount": 8
  },
  "Utility": {
    "description": "",
    "functions": {
      "General Utility": {
        "files": [
          {
            "path": "datadog_checks_dev/tests/test_structures.py",
            "description": "This file contains unit tests for the `EnvVars` and `TempDir` utility structures, verifying their functionality for managing environment variables and temporary directories respectively.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/test_subprocess.py",
            "description": "Tests the `run_command` utility from `datadog_checks.dev.subprocess`, verifying its ability to capture command output and correctly handle environment variables.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/tests/test_utils.py",
            "description": "This file contains unit tests for utility functions (`find_free_port`, `find_free_ports`) used to discover available network ports on a given IP address. It verifies that these functions correctly return valid and unbound ports.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/ssh_tunnel.py",
            "description": "This file provides utilities for creating and managing SSH SOCKS proxies and TCP tunnels programmatically, primarily for use within testing environments. It handles background execution of SSH commands and process cleanup.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/http.py",
            "description": "This file defines a `MockResponse` class that extends `requests.Response`. Its purpose is to create customizable mock HTTP responses for testing, allowing content to be set from strings, files, or JSON data, along with status codes, headers, and cookies.",
            "spof": true
          },
          {
            "path": "datadog_checks_dev/datadog_checks/dev/tooling/datastructures.py",
            "description": "This file defines a `JSONDict` class, extending the built-in dictionary with methods to access and modify nested elements using JSONPointer-like string paths.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_time.py",
            "description": "This file contains unit tests for the time utility functions and constants provided by `datadog_checks.base.utils.time`, ensuring their correct behavior for datetime normalization, current time retrieval, timestamp generation, and precise timing.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/test_utils.py",
            "description": "This file contains unit tests for various utility functions and classes provided by the `datadog_checks_base.utils` module, covering functionalities like pattern filtering, rate limiting, rounding, container manipulation (hashing, unique iteration), string encoding/decoding, and secret sanitization.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/common.py",
            "description": "This file defines default HTTP request options and the path to common test fixtures used by the `datadog_checks_base` module.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/tests/base/utils/http/test_headers.py",
            "description": "This file contains unit tests for the HTTP header handling functionality within Datadog's `RequestsWrapper` utility and the `agent_headers` helper, covering default, custom, extra, and dynamically provided headers, including type conversion.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/tests/base/utils/format/__init__.py",
            "description": "Marks the `format` directory as a Python package for testing utilities related to formatting within `datadog_checks_base`.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/libs/thread_pool.py",
            "description": "This file re-exports the thread pool utilities from the `datadog_checks_base` package. It serves as an alias or an entry point to the shared thread pool implementation.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/libs/timer.py",
            "description": "This file re-exports the timer utilities from the base `datadog_checks_base.base.checks.libs.timer` module. It serves as a compatibility layer or alternative import path for timer functionalities.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/libs/wmi/__init__.py",
            "description": "This is the initialization file for the WMI (Windows Management Instrumentation) library package within Datadog agent checks. It likely defines the package or imports necessary modules to make WMI functionalities available.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/_http_utils.py",
            "description": "This file implements a lazy loading mechanism for various external dependencies, such as `requests-toolbelt`, `aws-requests-auth`, `oauthlib`, and `cryptography`, making them available only when accessed.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/functions.py",
            "description": "This file provides a collection of basic, generic utility functions, including identity, no-op, predicate, and exception-raising functions, often useful as placeholders or default behaviors in other modules.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/time.py",
            "description": "This file provides utility functions for time-related operations, including high-precision time measurements, retrieving Unix timestamps, getting current timezone-aware datetimes, and ensuring datetime objects are timezone-aware.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/headers.py",
            "description": "This file provides utility functions for constructing and managing HTTP headers, primarily for use by the Datadog Agent, including default headers, user agent, and common HTTP specifications.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/hashing.py",
            "description": "This file defines a utility class, `HashMethod`, which provides access to secure (SHA256) and fast (Blake2b/Blake2s) hashing algorithms, dynamically choosing the appropriate algorithm based on system architecture or security requirements.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/date.py",
            "description": "This file provides utilities for parsing and formatting date and time strings according to the RFC3339 standard, including custom timezone handling. It was originally sourced from the Kubernetes Python client library.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/fips.py",
            "description": "This file provides utilities to enable and check the status of Federal Information Processing Standards (FIPS) compliance, particularly for configuring OpenSSL and verifying FIPS mode across different operating systems.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/platform.py",
            "description": "This file provides utility functions and a `Platform` class to identify the operating system, its architecture, and the execution environment (e.g., containerized, Kubernetes, ECS).",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/containers.py",
            "description": "Provides utilities for stably hashing and identifying unique mutable data structures, such as lists and dictionaries, by converting them into immutable and sortable representations.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/tailfile.py",
            "description": "This file implements a `TailFile` class that continuously reads new lines from a file, similar to the `tail -f` command, and invokes a callback for each new line, while also handling log rotation events like file truncation or replacement.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/serialization.py",
            "description": "This module provides utility functions for JSON serialization and deserialization, prioritizing `orjson` for performance but falling back to the standard `json` library. It is deprecated and scheduled for removal.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/__init__.py",
            "description": "This `__init__.py` file designates the `utils` directory as a Python package within `datadog_checks_base`, enabling the import of utility modules defined in this directory. As an empty `__init__.py` file, its primary purpose is to mark the directory as a package.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/format/_json.py",
            "description": "This module provides functions for encoding and decoding JSON, preferring `orjson` for performance and falling back to the standard `json` library if `orjson` is not available.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/format/json.py",
            "description": "Provides a lazy-loaded public interface for JSON encoding and decoding utilities, delegating to an internal `_json` module.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/discovery/discovery.py",
            "description": "This module defines a `Discovery` class that provides a mechanism for discovering, caching, and filtering items. It uses internal `Cache` and `Filter` components to manage item retrieval and selection.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/utils/db/sql.py",
            "description": "This file provides utility functions for processing and normalizing SQL queries and execution plans, including generating 64-bit hex signatures and normalizing query strings for use as metric tags.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/libs/prometheus.py",
            "description": "This file provides a custom parser for Prometheus text format metrics, adapted from the official `prometheus_client` library. It specifically modifies the parsing behavior to not automatically add a `_total` suffix to counter metrics, preserving their original names.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/libs/timer.py",
            "description": "This file defines a `Timer` class that provides utilities for measuring elapsed time, including total duration and step-by-step intervals, often used for profiling or performance monitoring.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/proxy.py",
            "description": "This file re-exports all functionalities from the core proxy utility module, serving as an alias or compatibility layer within the `datadog_checks` namespace.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/tailfile.py",
            "description": "This file re-exports utilities related to tailing files from a base module, providing a compatibility layer or module restructuring.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/platform.py",
            "description": "This file re-exports all platform utility functions from the `datadog_checks_base.base.utils.platform` module, likely serving as a public interface or compatibility layer.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/tracing.py",
            "description": "This file re-exports all tracing utilities from the underlying `datadog_checks_base.base.utils.tracing` module, serving as an alias or re-export point for these functionalities.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/limiter.py",
            "description": "This file re-exports all components from `datadog_checks_base.base.utils.limiter`. It serves as an alias or a compatibility layer, making the limiter utilities available via this import path.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/prometheus/__init__.py",
            "description": "This file re-exports Prometheus-related utilities from the base Datadog checks module, providing a unified import path for these functionalities.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/utils/prometheus/metrics_pb2.py",
            "description": "This file re-exports the `metrics_pb2` definitions from a base utility module, making them accessible from a different import path within the `datadog_checks_base` package. It serves as an alias for Prometheus metrics protobuf definitions.",
            "spof": true
          },
          {
            "path": "ddev/tests/utils/test_platform.py",
            "description": "This file contains unit tests for the `Platform` utility class, verifying its ability to detect the operating system (Windows, macOS, Linux) and correctly format commands for subprocess execution across different platforms.",
            "spof": true
          },
          {
            "path": "ddev/tests/utils/test_json.py",
            "description": "This file contains unit tests for the `JSONPointerFile` utility, which allows reading, modifying, and saving JSON data within a file using JSON Pointers.",
            "spof": true
          },
          {
            "path": "ddev/tests/utils/__init__.py",
            "description": "Marks the `utils` directory as a Python package. This file serves as a placeholder for shared utility functions or modules used across `ddev` tests.",
            "spof": true
          },
          {
            "path": "ddev/tests/utils/test_structures.py",
            "description": "This file contains unit tests for the `EnvVars` utility, which provides a context manager for temporarily manipulating and restoring environment variables.",
            "spof": false
          },
          {
            "path": "ddev/tests/utils/test_git.py",
            "description": "This file contains unit tests for the Git utility functions and repository operations within the `ddev` project, covering functionalities like branch management, commit history, file status, and worktree handling.",
            "spof": false
          },
          {
            "path": "ddev/tests/utils/test_fs.py",
            "description": "This file contains unit tests for the filesystem utility functions and the custom `Path` class in `ddev.utils.fs`, verifying their behavior for managing files, directories, and temporary environments.",
            "spof": true
          },
          {
            "path": "ddev/tests/utils/test_metadata.py",
            "description": "This file contains unit tests for the `pyproject_metadata` utility function, which extracts and validates project metadata, particularly the `[tool.ddev]` configuration, from a `pyproject.toml` file. It covers various scenarios including missing files, invalid configurations, and correct metadata extraction.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/cli/meta/scripts/scripts/serve.py",
            "description": "This script implements a simple HTTP server that serves one or more files over HTTP, rotating through them for each GET request, primarily for Prometheus or OpenMetrics metrics.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/toml.py",
            "description": "This file provides utility functions for loading and dumping TOML data, abstracting away differences in TOML parsing libraries across Python versions (tomllib/tomli) and using tomli_w for writing.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/network.py",
            "description": "This file provides utility functions for network operations, specifically for downloading files from a URL and saving them to a local path using `httpx`.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/structures.py",
            "description": "This file defines the `EnvVars` context manager, which allows for temporary manipulation of environment variables by filtering, updating, and restoring them around a block of code.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/json.py",
            "description": "This file provides utility classes, `JSONPointer` and `JSONPointerFile`, for manipulating JSON data using JSON Pointers. `JSONPointerFile` specifically handles reading, modifying, and saving JSON data from/to files.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/github.py",
            "description": "This file provides utilities for interacting with the GitHub API, including classes for representing pull requests and a manager for making authenticated API calls, handling rate limits, and retrieving various repository and pull request data.",
            "spof": true
          },
          {
            "path": "ddev/src/ddev/utils/fs.py",
            "description": "This file provides an enhanced `Path` class extending `pathlib.Path` with utility methods for robust file system operations, including atomic writes, directory management, and context managers for temporary file system states.",
            "spof": false
          },
          {
            "path": "elastic/datadog_checks/elastic/utils.py",
            "description": "This file provides utility functions for common unit conversions, such as milliseconds to seconds and bytes to mebibytes, for the Elastic integration.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Juanpe Araque",
            "percent": 50
          },
          {
            "name": "Luca",
            "percent": 14
          },
          {
            "name": "Ofek Lev",
            "percent": 13
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 54,
      "spofCount": 46
    },
    "busFactor": 2,
    "authorCount": 17
  },
  "TokuMX Monitoring": {
    "description": "Monitors TokuMX, a high-performance distribution of MongoDB, for database performance and health.",
    "functions": {
      "Integration Testing and Validation": {
        "files": [
          {
            "path": "datadog_checks_dev/tests/tooling/commands/validate/data/tokumx/assets/configuration",
            "description": "This directory is intended to house configuration files and assets specifically used for validating the 'tokumx' integration. It serves as part of the test data for the `validate` command within the `datadog_checks_dev` tooling, ensuring proper setup and functionality of integration configurations.",
            "spof": false
          },
          {
            "path": "datadog_checks_dev/tests/tooling/commands/validate/data/tokumx/datadog_checks/tokumx/config_models",
            "description": "This directory contains test data for `config_models` specific to the `tokumx` integration. This data is utilized by the `validate` command's tests within the `datadog_checks_dev` tooling. Its role is to provide samples for validating the structure and content of `tokumx` integration configuration models.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/tokumx/linux",
            "description": "This directory is intended to house Continuous Integration (CI) scripts specifically designed for TokuMX database integrations, targeted for execution on Linux systems. It likely contains platform-specific automation scripts used within the `.ddev` development environment for testing purposes.",
            "spof": false
          }
        ],
        "contributors": []
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 0
    }
  },
  "VMware vSphere Monitoring": {
    "description": "Provides comprehensive monitoring of VMware vSphere environments, including vCenter, ESXi hosts, and virtual machines.",
    "functions": {
      "vSphere Metric and Integration Definitions": {
        "files": [
          {
            "path": "datadog_checks_base/datadog_checks/checks/libs/vmware/all_metrics.py",
            "description": "This file re-exports all metrics definitions from the base VMware library module, likely to maintain compatibility or provide an alternative import path.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/checks/libs/vmware/basic_metrics.py",
            "description": "This file re-exports basic VMware metric definitions and utilities from another internal module within the `datadog_checks_base` package, likely for organizational or compatibility purposes.",
            "spof": true
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/libs/vmware/all_metrics.py",
            "description": "This file defines a comprehensive list of CPU and datastore performance metrics collected from VMware environments, including their types, units, rollup methods, and associated entities.",
            "spof": false
          },
          {
            "path": "datadog_checks_base/datadog_checks/base/checks/libs/vmware/basic_metrics.py",
            "description": "This file defines a dictionary of basic VMware performance metrics, specifying their type, unit, aggregation method, and applicable entities for Datadog integrations.",
            "spof": true
          },
          {
            "path": "docs/developer/architecture/vsphere.md",
            "description": "This document provides an overview of the Datadog vSphere integration, explaining vSphere concepts, the integration's setup, data collection mechanisms (realtime vs. historical), and advanced filtering options.",
            "spof": false
          },
          {
            "path": ".stubs/pyVmomi/vim",
            "description": "This directory serves as a placeholder to complete the Python package structure for type stub files related to the `pyVmomi.vim` module. It ensures that type checkers correctly recognize the module hierarchy within the `datadog/integrations-core` repository's stub definitions.",
            "spof": false
          },
          {
            "path": ".stubs/pyVmomi/vmodl",
            "description": "This directory is designated to store type stub files for the `vmodl` module within the `pyVmomi` library. These stubs would provide static type information, enhancing development and type checking for the Datadog `integrations-core` project. Currently, it is empty, suggesting no specific stubs for this module are present or required at this time.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Nicholas Muesch",
            "percent": 35
          },
          {
            "name": "Ofek Lev",
            "percent": 29
          },
          {
            "name": "Steven Yuen",
            "percent": 21
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 7,
      "spofCount": 3
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "CRI Monitoring": {
    "description": "Monitors any container runtime that implements the Kubernetes Container Runtime Interface (CRI) for lifecycle events and performance.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "cri/CHANGELOG.md",
            "description": "This file is the changelog for the CRI integration, documenting version updates and changes made over time.",
            "spof": true
          },
          {
            "path": "cri/README.md",
            "description": "This file is a README for the Datadog Agent's CRI (Container Runtime Interface) integration, providing instructions on its setup, configuration, and the metrics it collects.",
            "spof": true
          },
          {
            "path": "cri/assets/dashboards",
            "description": "This directory is intended to store Datadog dashboard definitions specifically for the Container Runtime Interface (CRI) integration. It serves as a placeholder for visualizations and metrics dashboards related to CRI monitoring. Currently, it is empty, indicating no dashboards are defined here yet.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 50
          },
          {
            "name": "davidfeng-datadog",
            "percent": 36
          },
          {
            "name": "Pierre Guceski",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 2
    },
    "busFactor": 6,
    "authorCount": 6
  },
  "ClickHouse Monitoring": {
    "description": "Collects performance metrics and system health data from ClickHouse analytical databases.",
    "functions": {
      "Integration Configuration and Assets": {
        "files": [
          {
            "path": "clickhouse/CHANGELOG.md",
            "description": "This file documents the release history, including new features, bug fixes, and breaking changes, for the Datadog ClickHouse integration.",
            "spof": false
          },
          {
            "path": "clickhouse/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent's ClickHouse integration, covering both host and containerized environments. It details how to collect metrics and logs, and lists the data collected by the integration.",
            "spof": false
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators or transformers for the ClickHouse integration, allowing for advanced logic to manipulate or validate configuration settings before they are used.",
            "spof": true
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/config_models/instance.py",
            "description": "This file defines Pydantic models for the ClickHouse integration's instance configuration, including custom queries and metric patterns, and includes validation logic for these configurations. It is an autogenerated file based on the integration's specification.",
            "spof": true
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/config_models/defaults.py",
            "description": "This file defines default configuration values for the ClickHouse integration, such as connection timeouts, database name, port, and username. It is an autogenerated file from the integration's specification.",
            "spof": false
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/config_models/shared.py",
            "description": "Defines the autogenerated Pydantic model for shared configuration settings of the ClickHouse integration, including validation logic.",
            "spof": true
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/config_models/__init__.py",
            "description": "This autogenerated file defines a `ConfigMixin` class, providing structured access to instance-specific and shared configuration models for the ClickHouse integration. It serves as an interface to configuration data generated from a `spec.yaml` file.",
            "spof": false
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/data",
            "description": "This directory is intended to store static data files or assets specific to the ClickHouse integration. While currently empty, it serves as the designated location for any such supporting data required by the `datadog_checks.clickhouse` module.",
            "spof": false
          },
          {
            "path": "clickhouse/assets/dashboards",
            "description": "This directory is intended to store dashboard assets for the Datadog ClickHouse integration. It would typically contain JSON definitions or other configuration files related to pre-built dashboards.",
            "spof": false
          },
          {
            "path": "clickhouse/assets/configuration",
            "description": "This directory is intended to house configuration assets specific to the Datadog ClickHouse integration. It would typically contain files defining how the integration should be configured, such as default settings or examples.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 15
          },
          {
            "name": "Ofek Lev",
            "percent": 15
          },
          {
            "name": "Kyle Neale",
            "percent": 14
          }
        ]
      },
      "ClickHouse Metric Collection": {
        "files": [
          {
            "path": "clickhouse/tests/common.py",
            "description": "This file defines common configuration variables and settings for testing the ClickHouse integration, including connection details, Docker setup paths, and environment-specific parameters.",
            "spof": true
          },
          {
            "path": "clickhouse/tests/__init__.py",
            "description": "This empty __init__.py file marks the 'tests' directory as a Python package, enabling test discovery within the ClickHouse integration.",
            "spof": true
          },
          {
            "path": "clickhouse/tests/test_utils.py",
            "description": "This file contains unit tests for the `ErrorSanitizer` utility class within the ClickHouse integration. It verifies the functionality of methods that clean and scrub sensitive information from error messages.",
            "spof": true
          },
          {
            "path": "clickhouse/tests/conftest.py",
            "description": "This file defines pytest fixtures for setting up and tearing down a ClickHouse test environment using Docker, including conditions to ensure the service is ready for testing.",
            "spof": true
          },
          {
            "path": "clickhouse/tests/metrics.py",
            "description": "This file defines comprehensive lists of metrics collected from ClickHouse, categorized into base metrics (always available) and optional metrics (not always available), likely used for testing or configuring the Datadog ClickHouse integration.",
            "spof": false
          },
          {
            "path": "clickhouse/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog ClickHouse integration, covering configuration validation, connection handling, error scenarios, and verification of system metrics against upstream documentation.",
            "spof": true
          },
          {
            "path": "clickhouse/tests/test_clickhouse.py",
            "description": "This file contains integration tests for the Datadog ClickHouse check, verifying metric collection, custom query execution, and version metadata reporting.",
            "spof": true
          },
          {
            "path": "clickhouse/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog ClickHouse integration, verifying that various metrics are collected correctly with the expected tags.",
            "spof": false
          },
          {
            "path": "clickhouse/tests/utils.py",
            "description": "This file contains utility functions for the ClickHouse integration, primarily used for parsing metrics from a given URL and handling CSV safe strings.",
            "spof": true
          },
          {
            "path": "clickhouse/tests/docker/override_configs",
            "description": "This directory is intended to store configuration files used to override default settings for ClickHouse integration tests run within Docker containers. These overrides ensure specific testing scenarios or custom environments can be established for the integration.",
            "spof": false
          },
          {
            "path": "clickhouse/tests/docker/macros",
            "description": "This directory is designated for storing macros, which are reusable code snippets or configurations. These macros would be specifically utilized within the Docker-based testing environment for the ClickHouse integration, streamlining test setup and execution.",
            "spof": false
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/__init__.py",
            "description": "This file serves as the package initializer for the ClickHouse integration, making its version and the main ClickhouseCheck class directly accessible when the package is imported.",
            "spof": true
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/clickhouse.py",
            "description": "This file implements the Datadog Agent check for ClickHouse, responsible for connecting to a ClickHouse database, collecting various metrics, and reporting service health.",
            "spof": true
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/queries.py",
            "description": "This file defines SQL queries and their corresponding metric mappings for collecting system metrics from ClickHouse to be reported to Datadog.",
            "spof": true
          },
          {
            "path": "clickhouse/datadog_checks/clickhouse/utils.py",
            "description": "This file provides utility functions for sanitizing error messages, specifically removing stack trace indicators and scrubbing sensitive data like passwords, and for compacting SQL queries.",
            "spof": true
          },
          {
            "path": "druid/datadog_checks/druid/druid.py",
            "description": "This file implements a Datadog Agent check for monitoring a Druid database service. It gathers health status and process properties by making HTTP requests to the Druid API and submits them as metrics and service checks.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Patryk",
            "percent": 62
          },
          {
            "name": "Steven Yuen",
            "percent": 24
          },
          {
            "name": "Oliver Harrison",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 26,
      "spofCount": 14
    },
    "busFactor": 1,
    "authorCount": 8
  },
  "Datadog Operator for Kubernetes": {
    "description": "Automates the deployment and lifecycle management of the Datadog Agent and its components on Kubernetes clusters.",
    "functions": {
      "Operator Documentation and Monitoring Assets": {
        "files": [
          {
            "path": "datadog_operator/CHANGELOG.md",
            "description": "This file serves as the changelog for the Datadog Operator, detailing new features, improvements, and bug fixes across different versions. It tracks the evolution and updates made to the operator.",
            "spof": false
          },
          {
            "path": "datadog_operator/README.md",
            "description": "This README provides an overview of the Datadog Operator integration for the Datadog Agent, detailing its purpose, setup instructions, and the types of data it collects.",
            "spof": false
          },
          {
            "path": "datadog_operator/assets/dashboards",
            "description": "This directory is intended to house Datadog dashboard definitions specifically related to the Datadog Operator. It serves as a designated location for any pre-built or example dashboards that might be included as assets for monitoring the operator's performance or status.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "dkirov-dd",
            "percent": 49
          },
          {
            "name": "levan-m",
            "percent": 28
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 14
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 3,
      "spofCount": 0
    },
    "busFactor": 3,
    "authorCount": 3
  },
  "Datadog CSI Driver Monitoring": {
    "description": "Monitors the Datadog Container Storage Interface (CSI) driver to ensure reliable log collection from persistent volumes in Kubernetes.",
    "functions": {
      "CSI Driver Metrics Polling": {
        "files": [
          {
            "path": "datadog_csi_driver/CHANGELOG.md",
            "description": "This file documents the version history, new features, and bug fixes for the Datadog CSI Driver integration, providing a chronological log of changes across different releases.",
            "spof": false
          },
          {
            "path": "datadog_csi_driver/README.md",
            "description": "This README documents the Datadog Agent integration for monitoring the Datadog CSI Driver, providing setup instructions and details on collected metrics.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog CSI Driver integration, verifying that the check collects and asserts expected metrics from a mocked HTTP response.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/tests/__init__.py",
            "description": "This is an empty `__init__.py` file, serving to mark the `tests` directory as a Python package. It allows test modules within this directory to be imported and executed.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/tests/common.py",
            "description": "Defines common constants, utility functions, and mock data for testing the Datadog CSI driver integration.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/tests/fixtures",
            "description": "This directory is intended to store test fixtures or static data used by the unit or integration tests for the Datadog CSI Driver. It ensures consistent and reproducible test environments, even though it currently contains no files.",
            "spof": false
          },
          {
            "path": "datadog_csi_driver/tests/docker",
            "description": "This directory is designated to house Docker-related test configurations or environments for the Datadog CSI driver integration. It would contain files necessary for setting up Docker-based test infrastructure to validate the CSI driver.",
            "spof": false
          },
          {
            "path": "datadog_csi_driver/datadog_checks/datadog_csi_driver/__init__.py",
            "description": "This file serves as the package initializer for the `datadog_csi_driver` integration, exposing its version and the main `DatadogCSIDriverCheck` class for external use.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/datadog_checks/datadog_csi_driver/check.py",
            "description": "This file defines the Datadog check for the Datadog CSI Driver, collecting OpenMetrics related to node volume operations from its `/metrics` endpoint. It leverages the OpenMetricsBaseCheckV2 to monitor metrics like publish and unpublish volume attempts.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/assets/dashboards",
            "description": "This directory is intended to store pre-built dashboard definitions specifically for the Datadog CSI Driver integration. These dashboards would provide visualizations and monitoring insights for the CSI driver's performance and status, enhancing the integration's observability features.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Adel Haj Hassan",
            "percent": 71
          },
          {
            "name": "Steven Yuen",
            "percent": 7
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 7
          }
        ]
      },
      "Integration Configuration Handling": {
        "files": [
          {
            "path": "datadog_csi_driver/images/IMAGES_README.md",
            "description": "This file provides guidelines and requirements for images and videos to be used in the Datadog Marketplace media carousel, detailing specifications for file type, size, dimensions, and naming conventions.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/datadog_checks/datadog_csi_driver/config_models/validators.py",
            "description": "This file is intended to house custom validation and transformation logic for configuration models within the Datadog CSI driver integration, including examples for handling legacy options or enforcing value constraints.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/datadog_checks/datadog_csi_driver/config_models/instance.py",
            "description": "This file defines Pydantic models for the Datadog CSI Driver integration's instance configuration, including various settings for metrics collection, authentication, network, and other operational parameters. It is an autogenerated file from a `spec.yaml`.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/datadog_checks/datadog_csi_driver/config_models/defaults.py",
            "description": "This file defines default configuration values for the Datadog CSI Driver integration, auto-generated from a specification file. It provides default settings for various instance-level parameters like timeouts, authentication, and metric collection behavior.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/datadog_checks/datadog_csi_driver/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient access to autogenerated instance and shared configuration models for the Datadog CSI Driver integration.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/datadog_checks/datadog_csi_driver/config_models/shared.py",
            "description": "This autogenerated file defines the `SharedConfig` Pydantic model for the `datadog_csi_driver` integration, encapsulating common configuration parameters. It includes automated validation logic using base utilities and a dedicated validators module.",
            "spof": true
          },
          {
            "path": "datadog_csi_driver/datadog_checks/datadog_csi_driver/data",
            "description": "This directory is intended to hold static data, configuration templates, or other ancillary files required by the `datadog_csi_driver` integration check. While currently empty, it serves as a designated location for such resources.",
            "spof": false
          },
          {
            "path": "datadog_csi_driver/assets/configuration",
            "description": "This directory is designated to store configuration files and examples specific to the Datadog CSI driver integration. Its role is to provide the necessary setup and operational parameters for the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Adel Haj Hassan",
            "percent": 99
          },
          {
            "name": "Yann Armelin",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 18,
      "spofCount": 12
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Delinea Secret Server Audit": {
    "description": "Collects audit logs from Delinea Secret Server to monitor access to privileged credentials and secrets.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "delinea_secret_server/README.md",
            "description": "This file is the README for the Delinea Secret Server integration, detailing how to set up log collection from Delinea Secret Server to Datadog, including installation, configuration, and troubleshooting steps.",
            "spof": true
          },
          {
            "path": "delinea_secret_server/CHANGELOG.md",
            "description": "This file is the changelog for the `delinea_secret_server` integration, documenting changes across different versions, including new features and updates.",
            "spof": false
          },
          {
            "path": "delinea_secret_server/datadog_checks/__init__.py",
            "description": "This `__init__.py` file is part of a Python namespace package (`datadog_checks`). It allows multiple directories, such as `delinea_secret_server`, to contribute modules to the `datadog_checks` package.",
            "spof": true
          },
          {
            "path": "delinea_secret_server/datadog_checks/delinea_secret_server/__init__.py",
            "description": "This `__init__.py` file serves as the package entry point for the Delinea Secret Server integration, primarily exposing the package version information.",
            "spof": true
          },
          {
            "path": "delinea_secret_server/datadog_checks/delinea_secret_server/data",
            "description": "This directory is intended to store various data files relevant to the Delinea Secret Server Datadog integration. This could include configuration examples, metric definitions, or other static assets necessary for the check's operation.",
            "spof": false
          },
          {
            "path": "delinea_secret_server/images",
            "description": "This directory is intended to store image assets, such as icons, logos, or screenshots, specifically used to support the Delinea Secret Server integration within Datadog. Its purpose is to house visual resources relevant to the integration's documentation or user interface.",
            "spof": false
          },
          {
            "path": "delinea_secret_server/assets/dashboards",
            "description": "This directory stores dashboard configuration files specifically for the Delinea Secret Server integration. These assets define the dashboards used to visualize metrics and logs collected by the integration within Datadog.",
            "spof": false
          },
          {
            "path": "delinea_secret_server/assets/configuration",
            "description": "This directory is intended to store configuration-related assets for the Delinea Secret Server integration. It would typically contain files like `conf.yaml.example` that serve as templates or examples for users setting up the integration. Although currently empty, its purpose is to provide essential configuration guidance.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "surabhipatel-crest",
            "percent": 72
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 7
          },
          {
            "name": "HadhemiDD",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 8,
      "spofCount": 3
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "DNSFilter Security Integration": {
    "description": "Collects DNS traffic logs from DNSFilter to monitor for security threats and analyze web filtering policies.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "dnsfilter/CHANGELOG.md",
            "description": "This file is the changelog for the DNSFilter integration, documenting its versions and updates, starting with the initial release.",
            "spof": true
          },
          {
            "path": "dnsfilter/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog DNSFilter integration, detailing the DNS traffic logs it collects and how to connect DNSFilter to Datadog.",
            "spof": false
          },
          {
            "path": "dnsfilter/images",
            "description": "This directory is intended to store image assets for the `dnsfilter` integration. These images could include icons, diagrams, or screenshots used in documentation, UI, or other visual representations specific to this integration.",
            "spof": false
          },
          {
            "path": "dnsfilter/assets/dashboards",
            "description": "This directory is designated to store dashboard configurations or related assets specifically for the `dnsfilter` integration within the Datadog `integrations-core` repository. It centralizes visualization resources for monitoring the `dnsfilter` service, allowing users to analyze its metrics and logs effectively.",
            "spof": false
          },
          {
            "path": "dnsfilter/assets/monitors",
            "description": "This directory is intended to store monitor definitions and configurations specific to the Datadog `dnsfilter` integration. It serves as an `assets` subdirectory for maintaining monitoring-related files that would enable alerting and observation for the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "manan-crest",
            "percent": 56
          },
          {
            "name": "Akshit Vaid",
            "percent": 39
          },
          {
            "name": "dkirov-dd",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 1
    },
    "busFactor": 2,
    "authorCount": 2
  },
  "DNS Resolution Monitoring": {
    "description": "Performs DNS lookups to verify that hostnames resolve correctly and measures DNS response time for performance tracking.",
    "functions": {
      "DNS Query Execution and Reporting": {
        "files": [
          {
            "path": "dns_check/CHANGELOG.md",
            "description": "This file is a changelog that documents all notable changes, additions, and fixes for the `dns_check` integration across various versions.",
            "spof": false
          },
          {
            "path": "dns_check/README.md",
            "description": "This file is the README for the Datadog DNS Integration, providing an overview and instructions for monitoring DNS record resolvability and lookup times. It details installation, configuration, validation, and collected data.",
            "spof": false
          },
          {
            "path": "dns_check/tests/test_dns_check.py",
            "description": "This file contains unit tests for the Datadog DNSCheck integration, verifying its behavior across various scenarios like successful DNS queries, NXDOMAIN responses, and different timeout configurations.",
            "spof": true
          },
          {
            "path": "dns_check/tests/conftest.py",
            "description": "This `conftest.py` file provides pytest fixtures for testing the Datadog `dns_check` integration, including environment setup and an instantiated check object.",
            "spof": false
          },
          {
            "path": "dns_check/tests/test_integration.py",
            "description": "This file contains integration tests for the `dns_check` integration, verifying its functionality against a live environment.",
            "spof": false
          },
          {
            "path": "dns_check/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog DNS Check integration. It verifies the integration's functionality by running a check against a common test instance.",
            "spof": true
          },
          {
            "path": "dns_check/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the `tests` directory as a Python package, enabling test modules within it to be imported and run.",
            "spof": true
          },
          {
            "path": "dns_check/tests/common.py",
            "description": "This file provides common configurations and helper functions used in the tests for the `dns_check` integration, including various DNS check instance configurations and utility functions for metric assertions.",
            "spof": true
          },
          {
            "path": "dns_check/tests/mocks.py",
            "description": "Provides mock objects and functions for simulating DNS query responses (success and NXDOMAIN) and time-related operations, primarily for testing the DNS check integration.",
            "spof": false
          },
          {
            "path": "dns_check/datadog_checks/dns_check/__init__.py",
            "description": "This file initializes the `dns_check` Python package, exposing the package version and the `DNSCheck` class for external use. It acts as the package's entry point, defining what is publicly available upon import.",
            "spof": true
          },
          {
            "path": "dns_check/datadog_checks/dns_check/dns_check.py",
            "description": "This file implements a Datadog Agent check that performs DNS lookups for a specified hostname and record type. It measures the response time and reports the resolution status and timing as metrics and service checks.",
            "spof": false
          },
          {
            "path": "dns_check/datadog_checks/dns_check/config_models/validators.py",
            "description": "This file is intended to contain custom validators or transformers for the configuration of the Datadog DNS check integration, as demonstrated by the commented-out examples.",
            "spof": true
          },
          {
            "path": "dns_check/datadog_checks/dns_check/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` that provides convenient access to autogenerated configuration models, specifically `InstanceConfig` and `SharedConfig`, for the DNS check integration.",
            "spof": true
          },
          {
            "path": "dns_check/datadog_checks/dns_check/config_models/defaults.py",
            "description": "This file defines the default configuration values for the `dns_check` integration. It is an autogenerated file, with its content derived from a `spec.yaml` configuration.",
            "spof": true
          },
          {
            "path": "dns_check/datadog_checks/dns_check/config_models/shared.py",
            "description": "This file defines a shared Pydantic configuration model for the DNS Check integration, automatically generated from a YAML specification, and includes validation and default value handling logic.",
            "spof": true
          },
          {
            "path": "dns_check/datadog_checks/dns_check/config_models/instance.py",
            "description": "This file defines Pydantic models for the `dns_check` integration's instance configuration, including schema and validation logic for its settings.",
            "spof": true
          },
          {
            "path": "dns_check/datadog_checks/dns_check/data",
            "description": "This directory is intended to store auxiliary data, configuration files, or other static assets specifically used by the DNS Check integration. While currently empty, it serves as a designated location for any data resources that the check may require.",
            "spof": false
          },
          {
            "path": "dns_check/assets/configuration",
            "description": "This directory is designated for storing configuration-related assets for the Datadog DNS Check integration. Although presently empty, its intended role is to house any specific configuration files or templates associated with the integration's assets.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 18
          },
          {
            "name": "Kyle Neale",
            "percent": 14
          },
          {
            "name": "HadhemiDD",
            "percent": 13
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 18,
      "spofCount": 10
    },
    "busFactor": 4,
    "authorCount": 13
  },
  "NVIDIA DCGM Monitoring": {
    "description": "Collects detailed GPU performance and health metrics from the NVIDIA Data Center GPU Manager (DCGM) exporter.",
    "functions": {
      "Default Assets and Documentation": {
        "files": [
          {
            "path": "dcgm/CHANGELOG.md",
            "description": "This file is a changelog for the Datadog DCGM Exporter integration, documenting its version history including new features, bug fixes, and general changes over time.",
            "spof": false
          },
          {
            "path": "dcgm/README.md",
            "description": "This file is the README for the Datadog Agent DCGM (NVIDIA Data Center GPU Manager) Exporter integration, detailing how to set up and configure the agent to collect GPU metrics from the NVIDIA DCGM Exporter.",
            "spof": false
          },
          {
            "path": "dcgm/datadog_checks/dcgm/config_models/defaults.py",
            "description": "This file defines default configuration values for the DCGM integration. It is an autogenerated file, with values derived from the integration's `spec.yaml`.",
            "spof": false
          },
          {
            "path": "dcgm/datadog_checks/dcgm/data",
            "description": "This directory is intended to house static data, configuration templates, or other auxiliary files specific to the DCGM Datadog integration. While currently empty, it serves as a placeholder for any necessary supporting assets for the check.",
            "spof": false
          },
          {
            "path": "dcgm/assets/configuration",
            "description": "This directory is designated to store configuration files or templates specific to the DCGM (NVIDIA Data Center GPU Manager) integration. It serves as the intended location for settings and parameters required for the integration's operation within Datadog.",
            "spof": false
          },
          {
            "path": "dcgm/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions or templates for visualizing metrics collected by the DCGM integration within Datadog. It would contain the JSON configurations necessary to display relevant data for the NVIDIA Data Center GPU Manager.",
            "spof": false
          },
          {
            "path": "dcgm/assets/monitors",
            "description": "This directory is designated to hold monitor configurations for the Datadog DCGM integration. Its role is to define default alerting and monitoring rules to be deployed with the integration. Currently, no specific monitor configurations are present here.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Florent Clarret",
            "percent": 19
          },
          {
            "name": "tbavelier",
            "percent": 11
          },
          {
            "name": "Kyle Neale",
            "percent": 10
          }
        ]
      },
      "Integration Testing and Validation": {
        "files": [
          {
            "path": "dcgm/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the DCGM integration, ensuring that expected metrics are collected by the Datadog Agent.",
            "spof": false
          },
          {
            "path": "dcgm/tests/common.py",
            "description": "This file defines common constants and expected metrics used for testing the DCGM (Datacenter GPU Manager) integration. It includes configuration for Docker host, OpenMetrics endpoint, Docker Compose file path, and a comprehensive list of metrics to be asserted during integration tests.",
            "spof": false
          },
          {
            "path": "dcgm/tests/__init__.py",
            "description": "This `__init__.py` file marks the `tests` directory as a Python package. It allows Python to recognize and import test modules located within this directory.",
            "spof": true
          },
          {
            "path": "dcgm/tests/conftest.py",
            "description": "This file defines pytest fixtures for testing the Datadog DCGM integration, including setting up a Docker environment, providing test instances and check objects, and mocking HTTP requests for metric data.",
            "spof": false
          },
          {
            "path": "dcgm/tests/test_unit.py",
            "description": "This file contains unit tests for the DCGM (NVIDIA Data Center GPU Manager) integration, verifying its functionality including error handling, label remapping, metric collection, and configuration validation.",
            "spof": false
          },
          {
            "path": "dcgm/tests/fixtures",
            "description": "This directory is designated to store test fixtures for the `dcgm` integration within the `integrations-core` repository. It would typically contain predefined data, configurations, or mock objects required to set up consistent testing environments. Although currently empty, its purpose is to support the testing suite for the `dcgm` integration.",
            "spof": false
          },
          {
            "path": "dcgm/tests/docker/serve",
            "description": "This directory is intended to house Docker-based serving components for the DCGM integration's tests. It would typically contain configurations or scripts to set up a test server, such as a mock DCGM environment, within a Docker container for testing purposes.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 41
          },
          {
            "name": "Florent Clarret",
            "percent": 32
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 14
          }
        ]
      },
      "DCGM Metric Collection and Processing": {
        "files": [
          {
            "path": "dcgm/datadog_checks/dcgm/__init__.py",
            "description": "This file serves as the package entry point for the Datadog DCGM integration, exposing its version and the main check class.",
            "spof": true
          },
          {
            "path": "dcgm/datadog_checks/dcgm/check.py",
            "description": "This file implements the Datadog check for DCGM (NVIDIA Data Center GPU Manager), extending the OpenMetricsBaseCheckV2 to collect and process DCGM metrics and extract build version information.",
            "spof": false
          },
          {
            "path": "dcgm/datadog_checks/dcgm/metrics.py",
            "description": "This file defines the mapping of raw DCGM metrics to Datadog metric names and specifies how certain labels and tags should be processed or ignored for the Datadog DCGM integration.",
            "spof": true
          },
          {
            "path": "dcgm/datadog_checks/dcgm/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators and transformers for the Datadog DCGM integration, enabling additional logic for processing or validating instance-specific configurations.",
            "spof": true
          },
          {
            "path": "dcgm/datadog_checks/dcgm/config_models/instance.py",
            "description": "This file defines Pydantic models for the `dcgm` integration's instance configuration, including various settings for metrics, authentication, proxy, and other common integration parameters. It is an autogenerated file used for structuring and validating integration configurations.",
            "spof": false
          },
          {
            "path": "dcgm/datadog_checks/dcgm/config_models/__init__.py",
            "description": "This autogenerated file serves as the entry point for the DCGM integration's configuration models, providing a mixin to access instance and shared configuration settings derived from `spec.yaml`.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Steven Yuen",
            "percent": 37
          },
          {
            "name": "Ofek Lev",
            "percent": 28
          },
          {
            "name": "Florent Clarret",
            "percent": 23
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 20,
      "spofCount": 5
    },
    "busFactor": 2,
    "authorCount": 5
  },
  "Amazon EKS on Fargate Monitoring": {
    "description": "Monitors Kubernetes pods running on Amazon Elastic Kubernetes Service (EKS) using the AWS Fargate serverless compute engine.",
    "functions": {
      "ECS Fargate Task Monitoring": {
        "files": [
          {
            "path": "ecs_fargate/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor containers running in AWS ECS Fargate. It covers various deployment methods, including Web UI, AWS CLI, CloudFormation, CDK, and Terraform.",
            "spof": false
          },
          {
            "path": "ecs_fargate/CHANGELOG.md",
            "description": "This file is the CHANGELOG for the Datadog ECS Fargate integration, documenting all changes, new features, and bug fixes across different versions.",
            "spof": false
          },
          {
            "path": "ecs_fargate/tests/conftest.py",
            "description": "This file provides pytest fixtures, mock functions, and expected metric lists for testing the `ecs_fargate` integration, simulating different Fargate metadata and stats API responses.",
            "spof": false
          },
          {
            "path": "ecs_fargate/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog ECS Fargate integration, specifically checking the `fargate_check` service check status.",
            "spof": true
          },
          {
            "path": "ecs_fargate/tests/test_unit_v4.py",
            "description": "This file contains unit and integration tests for the ECS Fargate check, specifically verifying its functionality with the ECS Fargate metadata API v4 on Linux environments.",
            "spof": false
          },
          {
            "path": "ecs_fargate/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the `tests` directory as a Python package. It allows Python to recognize and import test modules for the `ecs_fargate` integration.",
            "spof": true
          },
          {
            "path": "ecs_fargate/tests/fixtures",
            "description": "This directory is intended to store test fixtures, which are predefined sets of data or configurations used as a consistent baseline for running automated tests for the `ecs_fargate` integration. These fixtures ensure repeatable and isolated test execution by providing controlled inputs.",
            "spof": false
          },
          {
            "path": "ecs_fargate/datadog_checks/ecs_fargate/ecs_fargate.py",
            "description": "This file implements a Datadog Agent check to collect metrics from AWS ECS Fargate tasks and containers. It fetches data from the Fargate metadata and stats endpoints (v2 and v4) to report CPU, memory, network, I/O, and ephemeral storage metrics, along with relevant tags.",
            "spof": false
          },
          {
            "path": "ecs_fargate/datadog_checks/ecs_fargate/config_models/defaults.py",
            "description": "This auto-generated file defines default configuration values for the ECS Fargate integration. It specifies default settings for various parameters such as timeouts, proxy behavior, and authentication options.",
            "spof": true
          },
          {
            "path": "ecs_fargate/datadog_checks/ecs_fargate/config_models/__init__.py",
            "description": "This autogenerated file defines a `ConfigMixin` class that provides convenient accessors for instance-specific and shared configuration models. It serves as an entry point for the ECS Fargate integration's configuration schema.",
            "spof": false
          },
          {
            "path": "ecs_fargate/datadog_checks/ecs_fargate/config_models/shared.py",
            "description": "This file defines Pydantic models for common configuration parameters, such as proxy settings, timeout, and service, that are shared across various Datadog integrations. It includes validation logic and default value handling for these shared configuration options.",
            "spof": true
          },
          {
            "path": "ecs_fargate/datadog_checks/ecs_fargate/config_models/instance.py",
            "description": "This file defines Pydantic models for the `ecs_fargate` integration's instance configuration, including schema for authentication, network settings, and general parameters. It is an autogenerated file based on a configuration specification.",
            "spof": true
          },
          {
            "path": "ecs_fargate/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions or configurations specifically for the ECS Fargate integration. While currently empty, it serves as a placeholder for any visualizations or monitoring dashboards related to this integration.",
            "spof": false
          },
          {
            "path": "ecs_fargate/assets/monitors",
            "description": "This directory is designated for storing monitoring configurations or assets specifically tailored for the Datadog ECS Fargate integration. While currently empty, it serves as the intended location for defining alerts, dashboards, or other monitoring-related files for Fargate service health and performance.",
            "spof": false
          },
          {
            "path": "ecs_fargate/assets/configuration",
            "description": "This directory is designated to store configuration-related assets for the `ecs_fargate` integration within the Datadog Agent. It serves as a placeholder for files that define or assist in configuring this specific integration. Although currently empty, its purpose is to centralize configuration materials.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Bryce Eadie",
            "percent": 29
          },
          {
            "name": "Gabriel Dos Santos",
            "percent": 20
          },
          {
            "name": "Ida Adjivon",
            "percent": 15
          }
        ]
      },
      "EKS Fargate Pod Monitoring": {
        "files": [
          {
            "path": "eks_fargate/CHANGELOG.md",
            "description": "This file documents the release history, including new features, bug fixes, and changes for the Datadog EKS Fargate integration.",
            "spof": false
          },
          {
            "path": "eks_fargate/conftest.py",
            "description": "This `conftest.py` file sets up a mock `kubeutil` module and its `get_connection_info` function for testing the `eks_fargate` integration. It provides a dummy local URL for connection information during tests.",
            "spof": true
          },
          {
            "path": "eks_fargate/README.md",
            "description": "This README provides instructions for integrating Datadog with Amazon EKS Fargate to monitor pods, detailing the necessary setup, prerequisites like RBAC and secrets, and installation methods for the Datadog Agent as a sidecar.",
            "spof": true
          },
          {
            "path": "eks_fargate/tests/__init__.py",
            "description": "This file marks the 'tests' directory as a Python package, allowing test modules within it to be imported.",
            "spof": true
          },
          {
            "path": "eks_fargate/tests/test_eks_fargate.py",
            "description": "This file contains unit and integration tests for the `EksFargateCheck` and its helper functions, verifying correct metric collection and resource parsing in AWS EKS Fargate environments.",
            "spof": true
          },
          {
            "path": "eks_fargate/tests/fixtures",
            "description": "This directory is designated to store test fixtures for the EKS Fargate integration tests. It would typically contain pre-configured data or setup files required to run these tests. Currently, the directory is empty, indicating that specific fixtures might not be needed or are managed implicitly for the existing tests.",
            "spof": false
          },
          {
            "path": "eks_fargate/datadog_checks/eks_fargate/__init__.py",
            "description": "This `__init__.py` file acts as the package initializer for the `eks_fargate` integration. It exposes the package version and the main `EksFargateCheck` class for external use.",
            "spof": true
          },
          {
            "path": "eks_fargate/datadog_checks/eks_fargate/eks_fargate.py",
            "description": "This file implements a Datadog check for Amazon EKS on AWS Fargate, collecting and submitting metrics such as pod heartbeats and provisioned CPU and memory capacity for Fargate workloads.",
            "spof": true
          },
          {
            "path": "eks_fargate/datadog_checks/eks_fargate/config_models/validators.py",
            "description": "This file is intended for defining additional configuration validators or transformers for the EKS Fargate integration, allowing for custom logic to process or validate configuration values.",
            "spof": true
          },
          {
            "path": "eks_fargate/datadog_checks/eks_fargate/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration settings (like proxy details and timeouts) used by the `eks_fargate` integration, including validation and default value handling. It is autogenerated from a configuration specification.",
            "spof": true
          },
          {
            "path": "eks_fargate/datadog_checks/eks_fargate/config_models/__init__.py",
            "description": "This file defines the configuration models for the EKS Fargate integration, providing a `ConfigMixin` to access instance-specific and shared configuration properties. It is an autogenerated file based on `spec.yaml`.",
            "spof": false
          },
          {
            "path": "eks_fargate/datadog_checks/eks_fargate/config_models/instance.py",
            "description": "This file defines Pydantic models for the configuration of a Datadog integration instance, automatically generated from a specification file. It ensures the structure and validation of various configuration parameters for the 'eks_fargate' integration.",
            "spof": true
          },
          {
            "path": "eks_fargate/datadog_checks/eks_fargate/config_models/defaults.py",
            "description": "This file defines auto-generated default values for configuration parameters used by the Datadog EKS Fargate integration. It provides fallback settings for various options like timeouts, proxy behavior, and authentication.",
            "spof": true
          },
          {
            "path": "eks_fargate/datadog_checks/eks_fargate/data",
            "description": "This directory is designated for storing static data files, configuration templates, or other non-code assets for the Datadog EKS Fargate integration. Its current emptiness suggests that no such dedicated data is presently required or it could be a placeholder for future needs.",
            "spof": false
          },
          {
            "path": "eks_fargate/assets/configuration",
            "description": "This directory is intended to store configuration assets for the `eks_fargate` Datadog integration. Although currently empty, it serves as the designated location for any configuration files required by this specific integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "JacksonDavenport",
            "percent": 67
          },
          {
            "name": "Justin Lesko",
            "percent": 10
          },
          {
            "name": "Jackson Davenport",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 30,
      "spofCount": 15
    },
    "busFactor": 3,
    "authorCount": 16
  },
  "Delinea Privilege Manager Audit": {
    "description": "Ingests logs from Delinea Privilege Manager to monitor privileged access and endpoint privilege management activities.",
    "functions": {
      "Integration Packaging and Assets": {
        "files": [
          {
            "path": "delinea_privilege_manager/CHANGELOG.md",
            "description": "This file documents the version history and changes made to the Delinea Privilege Manager integration. It lists new features, bug fixes, and other updates for each release.",
            "spof": false
          },
          {
            "path": "delinea_privilege_manager/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent integration for Delinea Privilege Manager, focusing on log collection and syslog forwarding.",
            "spof": true
          },
          {
            "path": "delinea_privilege_manager/images",
            "description": "This directory is designated to store image assets, such as icons or screenshots, specifically for the Delinea Privilege Manager Datadog integration. Although currently empty, it serves as the intended location for visual resources related to this integration.",
            "spof": false
          },
          {
            "path": "delinea_privilege_manager/datadog_checks/delinea_privilege_manager/__init__.py",
            "description": "This `__init__.py` file primarily serves to define the package version for the Delinea Privilege Manager integration, making it accessible when the package is imported.",
            "spof": true
          },
          {
            "path": "delinea_privilege_manager/datadog_checks/delinea_privilege_manager/data",
            "description": "This directory is designated to store static data, configuration templates, or other auxiliary non-code assets for the Delinea Privilege Manager integration. While currently empty, it follows the standard convention for housing essential data files required by the check.",
            "spof": false
          },
          {
            "path": "delinea_privilege_manager/assets/configuration",
            "description": "This directory is designated to store configuration assets for the Delinea Privilege Manager integration. Although currently empty, its intended role is to house default or example configuration files required for the integration's setup and operation.",
            "spof": false
          },
          {
            "path": "delinea_privilege_manager/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions or templates specifically for the Delinea Privilege Manager integration. These dashboards would visualize metrics and logs collected by the integration within the Datadog platform, offering insights into its performance and monitored systems.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "manan-crest",
            "percent": 75
          },
          {
            "name": "HadhemiDD",
            "percent": 8
          },
          {
            "name": "Kyle Neale",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 7,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "Disk Performance and Usage Monitoring": {
    "description": "Collects metrics on disk usage, free space, inodes, and I/O statistics for all mounted filesystems.",
    "functions": {
      "Filesystem Metric Collection": {
        "files": [
          {
            "path": "disk/README.md",
            "description": "This README provides an overview, setup instructions, configuration details, and troubleshooting information for the Datadog Agent's Disk Check integration, which collects metrics related to disk usage and I/O.",
            "spof": false
          },
          {
            "path": "disk/CHANGELOG.md",
            "description": "This file is a changelog documenting the historical changes, new features, and bug fixes for the Datadog disk integration across different versions.",
            "spof": false
          },
          {
            "path": "disk/tests/__init__.py",
            "description": "This empty __init__.py file marks the 'tests' directory as a Python package, enabling test discovery within the Datadog Disk integration.",
            "spof": true
          },
          {
            "path": "disk/tests/metrics.py",
            "description": "This file defines dictionaries of expected metric names and their corresponding values. It is used to provide test data for the `disk` integration tests.",
            "spof": true
          },
          {
            "path": "disk/tests/mocks.py",
            "description": "This file provides various mock objects and functions to simulate disk-related data and system outputs for testing the Datadog Disk integration.",
            "spof": true
          },
          {
            "path": "disk/tests/test_check.py",
            "description": "This file contains unit tests for the Datadog Disk integration. It verifies that the integration correctly collects and reports expected metrics.",
            "spof": false
          },
          {
            "path": "disk/tests/conftest.py",
            "description": "This file provides pytest fixtures to configure the test environment and define expected metrics for the Datadog Disk integration, including platform-specific considerations for gauges.",
            "spof": true
          },
          {
            "path": "disk/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Disk integration, verifying that the agent collects and reports expected disk and filesystem metrics across different operating systems.",
            "spof": true
          },
          {
            "path": "disk/tests/test_unit.py",
            "description": "Unit tests for the Datadog Disk integration, verifying its core functionality, configuration options, and metric collection under various mocked system conditions.",
            "spof": true
          },
          {
            "path": "disk/tests/fixtures",
            "description": "This directory is intended to store test fixtures and auxiliary data specifically for the 'disk' integration's test suite. Although currently empty, its purpose is to provide stable, reproducible data for testing scenarios.",
            "spof": false
          },
          {
            "path": "disk/datadog_checks/disk/disk.py",
            "description": "This file implements the Datadog Agent's Disk check, which collects metrics related to disk usage, inodes, and other disk-specific statistics on a machine.",
            "spof": false
          },
          {
            "path": "disk/datadog_checks/disk/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the Datadog disk check, exposing the `Disk` class and the package version (`__version__`) as its public interface.",
            "spof": false
          },
          {
            "path": "disk/datadog_checks/disk/config_models/validators.py",
            "description": "This file is intended for defining custom configuration validators and transformers for the Datadog disk integration, allowing for logic to modify or validate configuration values before use.",
            "spof": true
          },
          {
            "path": "disk/datadog_checks/disk/config_models/defaults.py",
            "description": "This file defines default configuration values for the `disk` integration's instances, automatically generated from its specification file.",
            "spof": false
          },
          {
            "path": "disk/datadog_checks/disk/config_models/shared.py",
            "description": "This autogenerated file defines the `SharedConfig` Pydantic model, providing common configuration options and validation logic for the `disk` integration.",
            "spof": true
          },
          {
            "path": "disk/datadog_checks/disk/config_models/__init__.py",
            "description": "This autogenerated file serves as the entry point for the 'disk' integration's configuration models, providing a mixin class to access parsed instance and shared configuration objects.",
            "spof": false
          },
          {
            "path": "disk/datadog_checks/disk/config_models/instance.py",
            "description": "This file defines the Pydantic models for the `disk` integration's instance-level configuration, automatically generated from a specification to enable structured validation and default value handling.",
            "spof": true
          },
          {
            "path": "disk/datadog_checks/disk/data",
            "description": "This directory is designated for storing static data, configuration examples, or other assets specific to the Datadog Disk integration. Although currently empty, it follows a common pattern within `datadog_checks` for holding supplementary files required by the check.",
            "spof": false
          },
          {
            "path": "disk/assets/configuration",
            "description": "This directory is designated to store configuration-related assets for the 'disk' integration within the Datadog integrations-core project. It would typically contain configuration templates, examples, or schemas for this specific integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 69
          },
          {
            "name": "Juanpe Araque",
            "percent": 9
          },
          {
            "name": "Ofek Lev",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 19,
      "spofCount": 9
    },
    "busFactor": 1,
    "authorCount": 7
  },
  "Hadoop MapReduce Monitoring": {
    "description": "Monitors Hadoop MapReduce jobs, collecting metrics on job status, performance, and resource usage.",
    "functions": {
      "Integration Configuration and Packaging": {
        "files": [
          {
            "path": "flink/datadog_checks/flink/__init__.py",
            "description": "This is the package initialization file for the Flink integration, primarily exposing the package's version number.",
            "spof": true
          },
          {
            "path": "flink/assets/configuration",
            "description": "This directory is designated to store configuration assets or templates specifically for the Datadog Flink integration. While currently empty, its path indicates it would house example configuration files, schema definitions, or default settings for the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Witt",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 2,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Directory and File Monitoring": {
    "description": "Monitors specified directories and files for changes, collecting metrics such as file count, size, age, and modification time.",
    "functions": {
      "Directory Monitoring and Metric Collection": {
        "files": [
          {
            "path": "directory/CHANGELOG.md",
            "description": "This file is a changelog documenting the version history, new features, and bug fixes for the 'directory' integration within the Datadog integrations-core repository.",
            "spof": false
          },
          {
            "path": "directory/README.md",
            "description": "This file provides an overview and setup instructions for the Datadog Directory integration, detailing how to monitor file and directory metrics. It explains installation, configuration, and troubleshooting for the Directory check.",
            "spof": false
          },
          {
            "path": "directory/tests/__init__.py",
            "description": "This `__init__.py` file makes the 'tests' directory a Python package, allowing test modules within it to be imported and discovered by testing frameworks.",
            "spof": true
          },
          {
            "path": "directory/tests/test_directory.py",
            "description": "This file contains unit tests for the Datadog Directory integration, verifying its ability to correctly count files and folders and collect file-level metrics under various configurations and directory structures, including recursive scans, pattern matching, and directory exclusions.",
            "spof": false
          },
          {
            "path": "directory/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog DirectoryCheck, verifying its functionality with common configurations and expected metrics.",
            "spof": false
          },
          {
            "path": "directory/tests/test_e2e.py",
            "description": "This file contains an end-to-end test for a Datadog agent integration, verifying that directory and file metrics are correctly collected and reported.",
            "spof": false
          },
          {
            "path": "directory/tests/test_bench.py",
            "description": "This file contains a benchmark test for the Datadog `DirectoryCheck` integration. It measures the performance of the `check` method by creating a temporary directory and running the check against it.",
            "spof": true
          },
          {
            "path": "directory/tests/conftest.py",
            "description": "This file defines pytest fixtures for the integration's tests. It provides a `dd_environment` fixture to supply configuration stubs for test environments.",
            "spof": false
          },
          {
            "path": "directory/datadog_checks/directory/config.py",
            "description": "This file defines the `DirectoryConfig` class, responsible for parsing and validating configuration parameters for the Datadog directory check. It handles settings like directory path, file patterns, exclusions, recursion, and various tagging and metric submission options.",
            "spof": true
          },
          {
            "path": "directory/datadog_checks/directory/__init__.py",
            "description": "This `__init__.py` file defines the `directory` package for Datadog checks, exposing the package version and the main `DirectoryCheck` class for external use.",
            "spof": true
          },
          {
            "path": "directory/datadog_checks/directory/directory.py",
            "description": "This file implements the Datadog Agent's Directory Check, which monitors and reports metrics about files and folders within a specified directory, including counts, sizes, and modification times.",
            "spof": false
          },
          {
            "path": "directory/datadog_checks/directory/traverse.py",
            "description": "This file provides a custom `walk` function for efficiently traversing directory trees, similar to `os.walk`, but yielding `os.DirEntry` objects for optimized access to file metadata.",
            "spof": true
          },
          {
            "path": "directory/datadog_checks/directory/config_models/defaults.py",
            "description": "This file defines default configuration values for the Datadog 'directory' integration. It is automatically generated from the integration's `spec.yaml` file.",
            "spof": false
          },
          {
            "path": "directory/datadog_checks/directory/config_models/__init__.py",
            "description": "This file provides a `ConfigMixin` for the `directory` integration, allowing access to autogenerated instance and shared configuration models.",
            "spof": false
          },
          {
            "path": "directory/datadog_checks/directory/config_models/validators.py",
            "description": "This file is intended to hold custom configuration validators and transformers for the Datadog Agent, allowing for modification or validation of configuration values during initialization.",
            "spof": true
          },
          {
            "path": "directory/datadog_checks/directory/config_models/instance.py",
            "description": "This file defines the Pydantic model for the configuration schema of a Datadog 'directory' integration instance, including field validation and default values. It is an autogenerated file based on a specification.",
            "spof": true
          },
          {
            "path": "directory/datadog_checks/directory/data",
            "description": "This directory is intended to store static data files or configuration assets specific to the 'directory' Datadog check. Although currently empty, its typical purpose would be to house non-code resources required by the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 14
          },
          {
            "name": "Sarah Wang",
            "percent": 12
          },
          {
            "name": "Kyle Neale",
            "percent": 11
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 17,
      "spofCount": 7
    },
    "busFactor": 4,
    "authorCount": 11
  },
  "DuckDB Monitoring": {
    "description": "Monitors DuckDB in-process analytical databases, collecting performance metrics and query statistics.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "duckdb/CHANGELOG.md",
            "description": "This file is the changelog for the DuckDB integration, detailing version updates, new features, and changes over time.",
            "spof": false
          },
          {
            "path": "duckdb/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent integration for DuckDB, detailing installation steps, configuration options, and collected data.",
            "spof": true
          },
          {
            "path": "duckdb/datadog_checks/duckdb/data",
            "description": "This directory is designated for storing data files pertinent to the Datadog DuckDB integration. Typically, it would contain static assets, configuration templates, or other non-code resources required by the check. Currently, it is empty, suggesting it might be a placeholder for future data.",
            "spof": false
          },
          {
            "path": "duckdb/assets/monitors",
            "description": "This directory is designated to store monitor definitions or configurations specifically for the Datadog DuckDB integration. Although currently empty, it serves as the intended location for files related to monitoring DuckDB instances within the Datadog ecosystem.",
            "spof": false
          },
          {
            "path": "duckdb/assets/dashboards",
            "description": "This directory is designated to store Datadog dashboard definitions specific to the DuckDB integration. These dashboards provide out-of-the-box visualizations for monitoring DuckDB metrics and logs, enhancing observability for users. Its primary role is to house pre-configured dashboard assets for the DuckDB integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "HadhemiDD",
            "percent": 72
          },
          {
            "name": "Kyle Neale",
            "percent": 14
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 9
          }
        ]
      },
      "Integration Testing and Validation": {
        "files": [
          {
            "path": "duckdb/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog DuckDB integration, verifying metric collection, connection handling, and version metadata reporting.",
            "spof": true
          },
          {
            "path": "duckdb/tests/test_unit.py",
            "description": "This file contains unit tests for the DuckDB integration, specifically verifying the behavior of the `DuckdbCheck` class and its instance configuration validation.",
            "spof": true
          },
          {
            "path": "duckdb/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog DuckDB integration. It verifies that the integration correctly collects all expected metrics from a DuckDB instance.",
            "spof": true
          },
          {
            "path": "duckdb/tests/common.py",
            "description": "This file defines common constants and configurations used across tests for the DuckDB integration, such as database paths, test instances, and expected metric names.",
            "spof": true
          },
          {
            "path": "duckdb/tests/conftest.py",
            "description": "This file defines pytest fixtures for the DuckDB integration tests, providing common test configurations and environment setup, including installation commands for DuckDB.",
            "spof": true
          },
          {
            "path": "duckdb/tests/data",
            "description": "This directory is designated to store data files and fixtures specifically used by the tests for the DuckDB integration. It provides necessary external data for test cases, ensuring robust validation of the integration's functionality.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "HadhemiDD",
            "percent": 100
          }
        ]
      },
      "DuckDB Metric Collection": {
        "files": [
          {
            "path": "duckdb/datadog_checks/duckdb/__init__.py",
            "description": "This `__init__.py` file serves as the package initializer for the `duckdb` integration, exposing its version information and the main `DuckdbCheck` class.",
            "spof": true
          },
          {
            "path": "duckdb/datadog_checks/duckdb/check.py",
            "description": "This file implements the Datadog integration check for DuckDB, connecting to a DuckDB database, executing predefined queries, and collecting metrics and metadata.",
            "spof": true
          },
          {
            "path": "duckdb/datadog_checks/duckdb/queries.py",
            "description": "This file defines a collection of standard queries used to collect metrics and configuration settings from a DuckDB database.",
            "spof": true
          },
          {
            "path": "duckdb/datadog_checks/duckdb/config_models/defaults.py",
            "description": "This file defines default configuration values for the DuckDB integration, automatically generated from its specification file. It provides fallback settings for various integration parameters.",
            "spof": true
          },
          {
            "path": "duckdb/datadog_checks/duckdb/config_models/validators.py",
            "description": "This file is intended to define custom validation and transformation logic for configuration values specific to the DuckDB integration. It includes examples for modifying configuration options or raising errors based on specific conditions.",
            "spof": true
          },
          {
            "path": "duckdb/datadog_checks/duckdb/config_models/instance.py",
            "description": "This file defines Pydantic models for the Datadog DuckDB integration's instance configuration, including data structure and validation logic. It is an autogenerated file used to parse and validate configuration settings.",
            "spof": true
          },
          {
            "path": "duckdb/datadog_checks/duckdb/config_models/__init__.py",
            "description": "This autogenerated file defines `ConfigMixin`, providing convenient access to the `InstanceConfig` and `SharedConfig` models for the DuckDB integration. It acts as an interface to the integration's autogenerated configuration schema.",
            "spof": true
          },
          {
            "path": "duckdb/datadog_checks/duckdb/config_models/shared.py",
            "description": "This file defines a Pydantic model, `SharedConfig`, which represents common configuration settings for the DuckDB integration. It is an autogenerated file that handles validation and immutability of these shared configuration parameters based on a YAML specification.",
            "spof": true
          },
          {
            "path": "duckdb/assets/configuration",
            "description": "This directory is designated to hold configuration-related assets for the Datadog DuckDB integration. While currently empty, its purpose is to store configuration files, templates, or example settings necessary for the integration's setup and operation.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "HadhemiDD",
            "percent": 100
          },
          {
            "name": "Juanpe Araque",
            "percent": 0
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 20,
      "spofCount": 14
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "Elasticsearch Monitoring": {
    "description": "Monitors Elasticsearch clusters for health, performance, search and indexing rates, and resource utilization.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "druid/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor Apache Druid, including collecting metrics via DogStatsD, service checks, and logs.",
            "spof": false
          },
          {
            "path": "druid/images",
            "description": "This directory is designated for storing image assets specifically associated with the Datadog integration for Druid. These images likely support documentation, dashboards, or other visual elements of the integration.",
            "spof": false
          },
          {
            "path": "druid/datadog_checks/druid/data",
            "description": "This `data` directory is designated for storing static data or configuration files that support the Datadog Druid integration. Its role is to house non-code assets such as metric metadata, default dashboards, or other auxiliary files required for the check's functionality.",
            "spof": false
          },
          {
            "path": "elastic/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog 'elastic' integration, documenting all version releases, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "elastic/README.md",
            "description": "This file provides comprehensive documentation for setting up and configuring the Datadog Agent's Elasticsearch integration, including instructions for metric, trace, and log collection in various environments.",
            "spof": false
          },
          {
            "path": "elastic/images",
            "description": "This directory is designated to store image assets, such as icons or screenshots, specifically for the Datadog integration with Elastic. These images would typically be used in documentation or within the Datadog UI to represent the Elastic integration.",
            "spof": false
          },
          {
            "path": "elastic/datadog_checks/elastic/data",
            "description": "This directory is intended to store static data files or resources specifically used by the Datadog Elastic integration. Although currently empty, it serves as a placeholder for potential configuration templates, predefined dashboards, or other non-code assets required for the integration's operation.",
            "spof": false
          },
          {
            "path": "elastic/assets/dashboards",
            "description": "This directory is designated to store dashboard configurations or templates specifically for the Datadog integration with Elasticsearch. These assets would provide pre-built visualizations for monitoring Elasticsearch performance and health within Datadog.",
            "spof": false
          },
          {
            "path": "elastic/assets/monitors",
            "description": "This directory is designated to store assets specifically for Datadog monitors related to the Elastic integration. It would typically contain configurations or definitions for monitoring the Elastic Stack services.",
            "spof": false
          },
          {
            "path": "elastic/assets/saved_views",
            "description": "This directory is intended to store definitions or configurations for pre-configured dashboards or visualizations (saved views) specifically tailored for the Datadog integration with Elasticsearch. These assets would provide out-of-the-box monitoring views for users leveraging the Elastic integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Wang",
            "percent": 19
          },
          {
            "name": "Kyle Neale",
            "percent": 13
          },
          {
            "name": "HadhemiDD",
            "percent": 12
          }
        ]
      },
      "Elasticsearch Metric Collection": {
        "files": [
          {
            "path": "elastic/tests/__init__.py",
            "description": "This file marks the 'tests' directory as a Python package. It is empty, indicating no specific initialization logic is needed for the package.",
            "spof": true
          },
          {
            "path": "elastic/tests/test_bench.py",
            "description": "This file contains benchmark tests for the Datadog Elastic integration, measuring the performance of various check methods including general, primary shard, and index statistics collection.",
            "spof": false
          },
          {
            "path": "elastic/tests/test_metrics.py",
            "description": "This file contains unit tests for functions that define Elasticsearch metrics collected by the Datadog integration, verifying the number of metrics returned for various Elasticsearch versions and configurations.",
            "spof": false
          },
          {
            "path": "elastic/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Elastic integration. It uses `pytest` to verify the integration's functionality in an e2e environment.",
            "spof": true
          },
          {
            "path": "elastic/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Elasticsearch check, verifying its ability to collect metrics, handle custom queries, and apply various configurations under different Elasticsearch versions.",
            "spof": false
          },
          {
            "path": "elastic/tests/test_unit.py",
            "description": "This file contains unit tests for the Elasticsearch integration's check class, covering various internal methods, configuration options, and data processing logic.",
            "spof": false
          },
          {
            "path": "elastic/datadog_checks/elastic/__init__.py",
            "description": "This `__init__.py` file defines the version for the Datadog Elastic integration and exposes the `ESCheck` class as the main entry point for the integration.",
            "spof": false
          },
          {
            "path": "elastic/datadog_checks/elastic/metrics.py",
            "description": "This file defines mappings for various Elasticsearch metrics to Datadog metric names, types, and optional conversion functions. It organizes these definitions into dictionaries, often grouped by Elasticsearch version compatibility.",
            "spof": true
          },
          {
            "path": "elastic/datadog_checks/elastic/elastic.py",
            "description": "This file implements the Datadog Agent check for Elasticsearch, collecting various metrics and performing service checks for Elasticsearch clusters. It gathers data related to cluster health, nodes, shards, indices, SLM policies, and custom queries, adapting to different Elasticsearch versions.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 52
          },
          {
            "name": "Steven Yuen",
            "percent": 12
          },
          {
            "name": "Florent Clarret",
            "percent": 10
          }
        ]
      },
      "Configuration and Test Environment Management": {
        "files": [
          {
            "path": "elastic/tests/test_config.py",
            "description": "This file contains unit tests for the configuration parsing logic of the Datadog Elastic integration. It verifies the correct processing of instance configurations, URL sanitization, and error handling for invalid custom query configurations.",
            "spof": true
          },
          {
            "path": "elastic/tests/conftest.py",
            "description": "This file provides pytest fixtures and environment setup for testing the Datadog Elasticsearch integration, including Dockerized environments and pre-configured check instances.",
            "spof": false
          },
          {
            "path": "elastic/tests/compose",
            "description": "This directory is intended to contain Docker Compose configurations for setting up test environments specific to the Datadog Elastic integration. It would typically house `docker-compose.yml` files used to spin up instances of Elasticsearch for integration testing purposes.",
            "spof": false
          },
          {
            "path": "elastic/datadog_checks/elastic/config.py",
            "description": "This file defines the configuration structure and parsing logic for an Elasticsearch integration instance, extracting various parameters, sanitizing URLs, and handling custom tags and queries from an instance dictionary.",
            "spof": true
          },
          {
            "path": "elastic/datadog_checks/elastic/config_models/validators.py",
            "description": "This file provides configuration validators and transformers for the Elastic integration, specifically ensuring that custom queries and their columns are properly structured with required fields and valid metric types.",
            "spof": false
          },
          {
            "path": "elastic/datadog_checks/elastic/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` for the Elastic integration, allowing access to autogenerated instance-specific and shared configuration models. It serves as an entry point for configuration models within the package.",
            "spof": false
          },
          {
            "path": "elastic/datadog_checks/elastic/config_models/defaults.py",
            "description": "This file defines default configuration values for the Elastic integration, automatically generated from a specification file. It contains functions that return default settings for various integration parameters.",
            "spof": true
          },
          {
            "path": "elastic/datadog_checks/elastic/config_models/instance.py",
            "description": "This file defines Pydantic models for the Elastic integration's configuration, automatically generated from a specification. It includes models for the main instance configuration and its various sub-components.",
            "spof": true
          },
          {
            "path": "elastic/assets/configuration",
            "description": "This directory is intended to house configuration-related assets for the Datadog Elastic integration. It serves as a dedicated location for configuration templates, examples, or schemas that define how the integration should be set up.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 55
          },
          {
            "name": "Ofek Lev",
            "percent": 30
          },
          {
            "name": "Yann Armelin",
            "percent": 5
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 28,
      "spofCount": 7
    },
    "busFactor": 3,
    "authorCount": 15
  },
  "Falco Security Monitoring": {
    "description": "Collects and analyzes real-time security events from Falco to detect anomalous activity in containers and cloud infrastructure.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "falco/README.md",
            "description": "This file is the README for the Falco integration, detailing how to set up metric and log collection from Falco into Datadog.",
            "spof": false
          },
          {
            "path": "falco/CHANGELOG.md",
            "description": "This file is the changelog for the Falco integration, documenting all changes, additions, fixes, and removals across different versions.",
            "spof": false
          },
          {
            "path": "falco/datadog_checks/__init__.py",
            "description": "This file establishes `datadog_checks` as a Python namespace package for the Falco integration, ensuring its modules are correctly included and discoverable.",
            "spof": true
          },
          {
            "path": "falco/datadog_checks/falco/data",
            "description": "This directory is intended to store data files, configuration templates, or other static assets specifically required by the Falco Datadog integration. It serves as a dedicated location for non-code resources that support the integration's functionality.",
            "spof": false
          },
          {
            "path": "falco/images",
            "description": "This directory is designated to store images associated with the Falco integration. These images would typically include visual assets for documentation, UI elements, or other graphical resources relevant to the integration.",
            "spof": false
          },
          {
            "path": "falco/assets/monitors",
            "description": "This directory is designated to store monitor definitions and configurations specific to the Datadog Falco integration. These monitors are used to alert on and visualize metrics or logs generated by Falco within the Datadog platform. Currently, the directory is empty, indicating no custom monitors are defined here yet.",
            "spof": false
          },
          {
            "path": "falco/assets/configuration",
            "description": "This directory is designated to store configuration assets specifically for the Falco integration. It would typically contain default configuration files, examples, or templates required for its setup and operation within Datadog.",
            "spof": false
          },
          {
            "path": "falco/assets/dashboards",
            "description": "This directory contains dashboard definitions specifically designed for the Datadog Falco integration. These assets provide pre-configured visualizations to monitor metrics and logs collected from Falco, aiding in the analysis and understanding of security events.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 51
          },
          {
            "name": "surabhipatel-crest",
            "percent": 16
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 6
          }
        ]
      },
      "Integration Testing": {
        "files": [
          {
            "path": "falco/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Falco integration, covering metric collection, service checks, and metadata version reporting.",
            "spof": true
          },
          {
            "path": "falco/tests/conftest.py",
            "description": "This file defines pytest fixtures for the Falco integration's tests, including setting up a Dockerized test environment and providing a deep copy of the integration instance configuration.",
            "spof": true
          },
          {
            "path": "falco/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Falco integration, specifically verifying its service check health using `datadog_checks.dev` utilities.",
            "spof": true
          },
          {
            "path": "falco/tests/__init__.py",
            "description": "This `__init__.py` file marks the `tests` directory as a Python package for the Falco integration, enabling Python to recognize and import modules from within this directory.",
            "spof": true
          },
          {
            "path": "falco/tests/common.py",
            "description": "This file defines common constants, helper functions, and expected metric names used for testing the Falco integration. It includes paths for Docker Compose, host/port information, and a list of Falco-related metrics.",
            "spof": true
          },
          {
            "path": "falco/tests/compose",
            "description": "This directory is intended to house Docker Compose configurations used for setting up test environments specific to the Falco integration. Although currently empty, its role is to define the services and networking necessary for integration testing.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 99
          },
          {
            "name": "dkirov-dd",
            "percent": 1
          }
        ]
      },
      "Falco Metric Collection": {
        "files": [
          {
            "path": "falco/datadog_checks/falco/check.py",
            "description": "This file defines the Datadog Falco integration check, inheriting from OpenMetricsBaseCheckV2 to collect metrics. It sets the default namespace and configures metric collection using predefined mappings and label renames.",
            "spof": true
          },
          {
            "path": "falco/datadog_checks/falco/metrics.py",
            "description": "This file defines the mapping between Falco's Prometheus-style metric names and their corresponding Datadog metric names, including special handling for version metadata and label renaming.",
            "spof": true
          },
          {
            "path": "falco/datadog_checks/falco/__init__.py",
            "description": "This `__init__.py` file defines the Falco integration package. It imports and exposes the package version and the `FalcoCheck` class, making them available when the `falco` package is imported.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 99
          },
          {
            "name": "Juanpe Araque",
            "percent": 1
          }
        ]
      },
      "Configuration Management": {
        "files": [
          {
            "path": "falco/datadog_checks/falco/config_models/validators.py",
            "description": "This file is intended for defining custom validation and transformation logic for the Falco integration's configuration, allowing for advanced processing of user-provided settings.",
            "spof": true
          },
          {
            "path": "falco/datadog_checks/falco/config_models/__init__.py",
            "description": "This file defines `ConfigMixin` to expose both instance-specific and shared configuration models for the Falco integration, acting as an entry point for its autogenerated configuration models.",
            "spof": true
          },
          {
            "path": "falco/datadog_checks/falco/config_models/shared.py",
            "description": "This file defines shared configuration models, such as Proxy settings and common integration parameters, for the Falco integration. It is an autogenerated file used for pydantic-based configuration validation and default value handling.",
            "spof": true
          },
          {
            "path": "falco/datadog_checks/falco/config_models/defaults.py",
            "description": "This file defines default configuration values for the Datadog Falco integration, automatically generated from its specification file. It provides default settings for shared and instance-specific parameters.",
            "spof": true
          },
          {
            "path": "falco/datadog_checks/falco/config_models/instance.py",
            "description": "This file defines the Pydantic data model for the Falco integration's instance configuration, automatically generated from a specification file.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Kyle Neale",
            "percent": 99
          },
          {
            "name": "Yann Armelin",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 22,
      "spofCount": 14
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "ESET PROTECT Security Integration": {
    "description": "Collects and analyzes security logs from ESET PROTECT (formerly ESET Security Management Center) for threat monitoring and endpoint security.",
    "functions": {
      "Integration Asset and Configuration Management": {
        "files": [
          {
            "path": "eset_protect/README.md",
            "description": "This file is the README for the Datadog ESET Protect integration. It describes how to set up the integration to collect, parse, and analyze ESET Protect logs in Datadog, providing insights through dashboards and SIEM rules.",
            "spof": true
          },
          {
            "path": "eset_protect/CHANGELOG.md",
            "description": "This file documents all the changes, new features, and version updates for the `eset-protect` integration. It serves as a historical record of releases and their corresponding modifications.",
            "spof": false
          },
          {
            "path": "eset_protect/datadog_checks/__init__.py",
            "description": "This file is part of a Python namespace package, allowing modules for Datadog checks to be distributed across multiple locations while appearing under a single `datadog_checks` package. It extends the package's search path dynamically.",
            "spof": true
          },
          {
            "path": "eset_protect/datadog_checks/eset_protect/__init__.py",
            "description": "This file is the package initialization for the `eset_protect` integration, primarily exposing its version information.",
            "spof": true
          },
          {
            "path": "eset_protect/datadog_checks/eset_protect/data",
            "description": "This directory is intended to store static data files or configuration templates specifically utilized by the ESET Protect Datadog integration. As it is currently empty, it likely serves as a placeholder for future data assets required by the check.",
            "spof": false
          },
          {
            "path": "eset_protect/images",
            "description": "This directory is reserved for storing images associated with the `eset_protect` Datadog integration. It would typically house visual assets like icons, logos, or screenshots used for documentation or UI purposes.",
            "spof": false
          },
          {
            "path": "eset_protect/assets/dashboards",
            "description": "This directory is designated to store dashboard assets for the ESET Protect integration within Datadog. It would typically contain JSON or YAML definitions for pre-built dashboards that visualize metrics and logs collected by the integration.",
            "spof": false
          },
          {
            "path": "eset_protect/assets/configuration",
            "description": "This directory is intended to store configuration assets specifically for the `eset_protect` Datadog integration. It serves as a dedicated location for any configuration files or templates required by the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "savandalasaniya-crest",
            "percent": 79
          },
          {
            "name": "HadhemiDD",
            "percent": 6
          },
          {
            "name": "Kyle Neale",
            "percent": 6
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 8,
      "spofCount": 3
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "Docker Daemon Monitoring": {
    "description": "Collects metrics on the performance and resource usage of the Docker daemon itself, providing insights into the health of the container engine.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "docker_daemon/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog `docker_daemon` integration, documenting version updates, new features, and bug fixes over time.",
            "spof": false
          },
          {
            "path": "docker_daemon/README.md",
            "description": "This file documents the Datadog Docker Daemon integration, providing instructions for installation, configuration, and migration between Agent versions to monitor Docker metrics.",
            "spof": false
          },
          {
            "path": "docker_daemon/images",
            "description": "This directory is designated to store Docker images or related artifacts specifically for the `docker_daemon` integration within the Datadog integrations-core repository. It serves as a dedicated location for image-related assets necessary for testing, building, or deploying the integration.",
            "spof": false
          },
          {
            "path": "docker_daemon/assets/dashboards",
            "description": "This directory is designated to store pre-built dashboard assets specifically for the Datadog Docker Daemon integration. These dashboards provide visualizations for metrics collected from Docker Daemon, offering immediate insights into its performance and health.",
            "spof": false
          },
          {
            "path": "docker_daemon/datadog_checks/docker_daemon/data",
            "description": "This directory is intended to house static data files, configuration templates, or other persistent assets for the `docker_daemon` Datadog integration check. While currently empty, it serves as a designated location for such essential data.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Wang",
            "percent": 41
          },
          {
            "name": "Ofek Lev",
            "percent": 22
          },
          {
            "name": "davidfeng-datadog",
            "percent": 15
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 0
    },
    "busFactor": 3,
    "authorCount": 3
  },
  "Amazon EKS Anywhere Monitoring": {
    "description": "Provides monitoring for Kubernetes clusters deployed on-premises or in hybrid environments using Amazon EKS Anywhere.",
    "functions": {
      "EKS Anywhere Integration Management": {
        "files": [
          {
            "path": "eks_anywhere/README.md",
            "description": "This README provides instructions for monitoring Amazon EKS Anywhere environments using Datadog. It covers setup details for the Datadog Agent, including Helm chart configurations for metric and log collection.",
            "spof": true
          },
          {
            "path": "eks_anywhere/CHANGELOG.md",
            "description": "This file documents all changes and releases for the Amazon EKS Anywhere integration. It provides a historical record of updates, fixes, and new features introduced in each version.",
            "spof": true
          },
          {
            "path": "eks_anywhere/assets",
            "description": "This directory is intended to store static assets or supporting files for the Datadog EKS Anywhere integration. Although currently empty, its purpose is to host non-code resources such as images, templates, or configuration examples that complement the integration's functionality.",
            "spof": false
          },
          {
            "path": "eks_anywhere/images",
            "description": "This directory is designated for storing container images, build artifacts, or other image-related assets essential for the Datadog EKS Anywhere integration. Its purpose is to centralize resources required for deploying or documenting the integration's components.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 72
          },
          {
            "name": "Cedric Lamoriniere",
            "percent": 21
          },
          {
            "name": "Sarah Wang",
            "percent": 4
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 3,
    "authorCount": 3
  },
  "DocuSign Audit Trail Integration": {
    "description": "Ingests audit logs from DocuSign to monitor envelope status, user actions, and security events related to e-signatures.",
    "functions": {
      "Integration Assets and Configuration": {
        "files": [
          {
            "path": "docusign/CHANGELOG.md",
            "description": "This file is the changelog for the docusign integration, documenting all version updates and changes made to it.",
            "spof": true
          },
          {
            "path": "docusign/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Docusign integration, detailing prerequisites, API credential generation, and the data collected (logs) by the integration.",
            "spof": true
          },
          {
            "path": "docusign/images",
            "description": "This directory is designated to store images specifically for the Datadog Docusign integration. Although currently empty, its purpose is to house any visual assets or icons associated with the integration's documentation or UI elements.",
            "spof": false
          },
          {
            "path": "docusign/assets/monitors",
            "description": "This empty directory is designated to store monitoring-related assets or configurations specific to the Datadog Docusign integration. It likely serves as a placeholder for future monitor definitions or related files.",
            "spof": false
          },
          {
            "path": "docusign/assets/dashboards",
            "description": "This directory is intended to store definition files for Datadog dashboards related to the Docusign integration. These dashboards would typically visualize metrics and logs collected from Docusign, providing operational insights.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "narendranandaniya-crest",
            "percent": 96
          },
          {
            "name": "dkirov-dd",
            "percent": 4
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 5,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "Fly.io Application Platform Monitoring": {
    "description": "Monitors applications, machines, and volumes on the Fly.io platform, collecting performance and health metrics.",
    "functions": {
      "Integration Configuration and Asset Management": {
        "files": [
          {
            "path": "fly_io/CHANGELOG.md",
            "description": "This file documents the version history and changes made to the Datadog Fly.io integration, including new features, bug fixes, and dependency updates.",
            "spof": false
          },
          {
            "path": "fly_io/README.md",
            "description": "This document describes how to set up and configure the Datadog Agent to monitor Fly.io metrics, traces, and logs. It provides instructions for deploying the Agent as a Fly.io application and integrating various Fly.io services with Datadog.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/constants.py",
            "description": "This file defines constants, primarily metric names and state indicators, for the Datadog Fly.io integration, categorizing them by machines, volumes, and applications.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/metrics.py",
            "description": "This file defines and maps metrics collected from Fly.io applications, instances, and PostgreSQL databases to standardized Datadog metric names and types. It serves as a central repository for metric definitions used by the Fly.io integration.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/config_models/validators.py",
            "description": "This file is intended to define custom configuration validators and transformers for the Fly.io integration. It provides a placeholder for functions like `initialize_instance` to modify or validate configuration values.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/config_models/defaults.py",
            "description": "This file defines functions that return default configuration values for the Datadog Fly.io integration. It is an autogenerated file based on the integration's specification.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/config_models/instance.py",
            "description": "This file defines Pydantic models for the configuration of a Fly.io integration instance, including various settings for metrics, authentication, and network proxies. It is an autogenerated file based on a YAML specification.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration parameters of the Datadog Agent's `fly_io` integration, including proxy settings and general connection options. It is an autogenerated file responsible for handling config validation and defaults.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/config_models/__init__.py",
            "description": "This autogenerated file serves as the package initializer for configuration models, providing a mixin class to access typed `InstanceConfig` and `SharedConfig` objects for the `fly_io` integration.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/data",
            "description": "This directory is designated for storing static data files or non-code assets specific to the Datadog integration for Fly.io. It would typically hold configuration templates, default values, or other supplementary resources necessary for the check's operation.",
            "spof": false
          },
          {
            "path": "fly_io/assets/monitors",
            "description": "This directory contains definitions for monitors related to the Fly.io integration. These monitors are assets used to track and alert on the health and performance of Fly.io resources within Datadog.",
            "spof": false
          },
          {
            "path": "fly_io/assets/dashboards",
            "description": "This directory is designated to hold dashboard configurations or templates for the Datadog Fly.io integration. If present, these assets would provide pre-built visualizations and metrics for monitoring Fly.io services within Datadog. Its current emptiness indicates that no specific dashboards are currently defined or bundled.",
            "spof": false
          },
          {
            "path": "fly_io/assets/configuration",
            "description": "This directory is designated to hold configuration-related assets or templates for the Datadog Fly.io integration. Its role is to centralize files that define how this specific integration can be configured by users.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Witt",
            "percent": 72
          },
          {
            "name": "Kyle Neale",
            "percent": 5
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 5
          }
        ]
      },
      "Fly.io Metric and Health Data Collection": {
        "files": [
          {
            "path": "fly_io/tests/__init__.py",
            "description": "This `__init__.py` file marks the `fly_io/tests` directory as a Python package, enabling Python to recognize and import modules within it.",
            "spof": true
          },
          {
            "path": "fly_io/tests/common.py",
            "description": "This file defines common test configurations and utility variables for the Fly.io integration, including API endpoints, authentication tokens, and Docker Compose file paths, often sourced from environment variables for testing purposes.",
            "spof": true
          },
          {
            "path": "fly_io/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Fly.io integration, verifying that the Datadog Agent collects all expected metrics and service checks.",
            "spof": true
          },
          {
            "path": "fly_io/tests/metrics.py",
            "description": "This file defines lists of expected metric names and mock metric data used for testing the Datadog Fly.io integration. It includes Prometheus metrics, REST API metrics, and detailed metric payloads for various Fly.io resources like applications, machines, and volumes.",
            "spof": true
          },
          {
            "path": "fly_io/tests/conftest.py",
            "description": "This file provides Pytest fixtures for the Fly.io integration tests, including setting up a Docker-based test environment and mocking HTTP requests to simulate API responses from the Fly.io Machines API and OpenMetrics endpoints.",
            "spof": true
          },
          {
            "path": "fly_io/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog Fly.io integration, verifying its metric collection, service checks, external host tag emission, and error handling for various scenarios with both Prometheus and REST API data sources.",
            "spof": true
          },
          {
            "path": "fly_io/tests/docker/machines-api",
            "description": "This directory is intended to house tests for the Fly.io integration within Datadog's `integrations-core`. Specifically, it focuses on Docker-based tests related to the Fly.io Machines API. Its purpose is to ensure the integration correctly monitors and interacts with the Fly.io Machines API under Dockerized testing environments.",
            "spof": false
          },
          {
            "path": "fly_io/tests/docker/prometheus",
            "description": "This directory is intended to contain Docker-related test configurations and resources for the `fly_io` integration. Its specific role is to support the validation of Prometheus metric collection within a Dockerized test environment.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/example-app-2/volumes",
            "description": "This directory stores fixture data for testing the Fly.io integration, specifically mimicking the JSON response from the Fly.io Machines API for a GET request to retrieve volumes associated with the 'example-app-2' application.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/example-app-2/machines",
            "description": "This directory contains test fixture data representing the expected JSON response from the Fly.io Machines API for a GET request to '/v1/apps/example-app-2/machines'. It provides mock data for testing the Datadog Fly.io integration's ability to process machine listings for a specific application.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/example-app-3/volumes",
            "description": "This directory serves as a test fixture for the Datadog `fly_io` integration. It specifically contains data simulating the response from a GET request to the Fly.io Machines API endpoint for listing volumes associated with a particular application, `example-app-3`.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/example-app-3/machines",
            "description": "This directory serves as a test fixture, specifically designed to store mock API responses for `GET /v1/apps/example-app-3/machines` requests. It provides simulated data for testing the Datadog Fly.io integration's ability to retrieve machine information for a particular application.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/example-app-4/volumes",
            "description": "This directory contains test fixtures, specifically mock API responses for the Fly.io Machines API endpoint to retrieve volumes associated with the 'example-app-4' application. These fixtures are used by tests for the Datadog Fly.io integration to simulate API calls and ensure proper data parsing and handling.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/example-app-4/machines",
            "description": "This directory serves as a fixture location for mock API responses related to the Fly.io Machines API. Specifically, it's designed to contain data simulating a GET request for machines associated with the 'example-app-4' application. This allows tests to run reliably without external API dependencies.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/org_slug=test",
            "description": "This directory serves as a fixture for testing the `fly_io` integration, specifically for mocking responses from the Machines API's `GET /v1/apps` endpoint. It simulates API responses when querying applications associated with an organization identified by the slug 'test'.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/example-app-1/volumes",
            "description": "This directory serves as a test fixture location for the Datadog Fly.io integration, specifically for mocking the API response of `GET /v1/apps/example-app-1/volumes` from the Fly.io Machines API. It provides mock data to simulate the retrieval of volumes for a specific application during integration tests.",
            "spof": false
          },
          {
            "path": "fly_io/tests/fixtures/machines-api/GET/v1/apps/example-app-1/machines",
            "description": "This directory serves as a test fixture for the `fly_io` integration. It is designed to hold mock API responses for the `GET /v1/apps/example-app-1/machines` endpoint of the Fly.io API, used during testing.",
            "spof": false
          },
          {
            "path": "fly_io/datadog_checks/fly_io/__init__.py",
            "description": "This file serves as the package entry point for the `fly_io` Datadog integration, exposing the package version and the main `FlyIoCheck` class.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/errors.py",
            "description": "This file defines a decorator `handle_error` used for robust error handling in Datadog checks. It catches and logs `requests.exceptions.RequestException` and general `Exception` types, returning `None` if an error occurs.",
            "spof": true
          },
          {
            "path": "fly_io/datadog_checks/fly_io/check.py",
            "description": "This file implements the Datadog integration for Fly.io, collecting metrics related to Fly.io applications, machines, and volumes through both OpenMetrics endpoints and the Fly.io API.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Sarah Witt",
            "percent": 97
          },
          {
            "name": "Juanpe Araque",
            "percent": 2
          },
          {
            "name": "dkirov-dd",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 33,
      "spofCount": 17
    },
    "busFactor": 1,
    "authorCount": 3
  },
  "Fluentd Log Collector Monitoring": {
    "description": "Monitors Fluentd instances, collecting metrics on log pipeline performance, buffer queues, and plugin status.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "fluentd/README.md",
            "description": "This README.md file provides instructions on how to integrate Fluentd with Datadog for collecting metrics and logs, including configuration steps for both host and containerized environments. It details how to set up Fluentd, configure the Datadog Agent, and enable log collection with metadata and tagging.",
            "spof": false
          },
          {
            "path": "fluentd/CHANGELOG.md",
            "description": "This file is the changelog for the Datadog Fluentd integration, detailing version updates, new features, fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "fluentd/assets/configuration",
            "description": "This directory is intended to store configuration assets or example configuration files specifically for the Datadog Fluentd integration. It defines how the Fluentd integration can be set up and customized.",
            "spof": false
          },
          {
            "path": "fluentd/assets/dashboards",
            "description": "This directory is intended to house dashboard configurations for the Datadog Fluentd integration. It serves as a placeholder for visualization assets related to monitoring Fluentd metrics within the Datadog platform.",
            "spof": false
          },
          {
            "path": "fluentd/assets/saved_views",
            "description": "This directory, located within the `assets` for the Datadog Fluentd integration, stores definitions for pre-configured saved views. These views likely encompass dashboard layouts, log exploration queries, or other visual configurations for monitoring Fluentd data within Datadog.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 16
          },
          {
            "name": "Sarah Wang",
            "percent": 15
          },
          {
            "name": "HadhemiDD",
            "percent": 15
          }
        ]
      },
      "Integration Test Suite": {
        "files": [
          {
            "path": "fluentd/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the `tests` directory as a Python package, enabling test modules within it to be imported and run.",
            "spof": true
          },
          {
            "path": "fluentd/tests/conftest.py",
            "description": "This file defines pytest fixtures for the Fluentd integration tests, primarily setting up and tearing down a Fluentd Docker environment using `dd_environment`.",
            "spof": true
          },
          {
            "path": "fluentd/tests/test_integration_and_e2e.py",
            "description": "This file contains integration and end-to-end tests for the Datadog Fluentd integration, verifying basic metric and service check collection.",
            "spof": false
          },
          {
            "path": "fluentd/tests/test_metadata.py",
            "description": "This file contains integration tests for the Fluentd check's metadata collection, ensuring accurate version reporting and handling of missing or invalid Fluentd binaries.",
            "spof": false
          },
          {
            "path": "fluentd/tests/common.py",
            "description": "This file defines common constants, configurations, and expected metrics for testing the Datadog Fluentd integration.",
            "spof": false
          },
          {
            "path": "fluentd/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Fluentd check, verifying its metric collection, service checks, tagging capabilities, and HTTP timeout configuration under various scenarios.",
            "spof": true
          },
          {
            "path": "fluentd/tests/util.py",
            "description": "This file provides utility functions and pytest markers for Fluentd integration tests. It helps in conditionally executing tests and determining expected metrics based on the Fluentd version being tested.",
            "spof": false
          },
          {
            "path": "fluentd/tests/mock/fluentd_version.py",
            "description": "This mock script simulates the output of a Fluentd version command, printing 'fluentd' followed by a version string provided as a command-line argument. It is used for testing purposes within the Datadog Agent Fluentd integration.",
            "spof": true
          },
          {
            "path": "fluentd/tests/compose",
            "description": "This directory is intended to house Docker Compose configurations for integration tests of the Fluentd integration. It would define multi-service environments necessary for comprehensive testing, even if currently empty.",
            "spof": false
          },
          {
            "path": "fluentd/images",
            "description": "This directory is designated to store Docker images or related build artifacts specifically for the Datadog Fluentd integration. It serves as the location for container images used for testing, deployment, or dependencies of the Fluentd integration within the `integrations-core` repository.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 97
          },
          {
            "name": "Alex Lopez",
            "percent": 1
          },
          {
            "name": "Sarah Witt",
            "percent": 1
          }
        ]
      },
      "Fluentd Metric Collection and Configuration": {
        "files": [
          {
            "path": "fluentd/datadog_checks/fluentd/fluentd.py",
            "description": "This file implements the Datadog Agent check for Fluentd, collecting metrics and metadata from Fluentd instances via their monitoring agent API.",
            "spof": true
          },
          {
            "path": "fluentd/datadog_checks/fluentd/__init__.py",
            "description": "This file initializes the Fluentd integration package for the Datadog Agent, exposing its version and the main Fluentd check class.",
            "spof": true
          },
          {
            "path": "fluentd/datadog_checks/fluentd/config_models/instance.py",
            "description": "This file defines Pydantic models for validating and parsing the Fluentd integration's instance configuration, automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "fluentd/datadog_checks/fluentd/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators and transformers for the Datadog Fluentd integration, as demonstrated by the commented-out examples.",
            "spof": true
          },
          {
            "path": "fluentd/datadog_checks/fluentd/config_models/__init__.py",
            "description": "This autogenerated file serves as the entry point for the Fluentd integration's configuration models, providing `ConfigMixin` to access `InstanceConfig` and `SharedConfig`.",
            "spof": true
          },
          {
            "path": "fluentd/datadog_checks/fluentd/config_models/defaults.py",
            "description": "This autogenerated file defines default configuration values for the Fluentd integration, derived from the integration's specification file.",
            "spof": true
          },
          {
            "path": "fluentd/datadog_checks/fluentd/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration options within the Fluentd integration. It is an autogenerated file, providing structured validation for common configuration settings.",
            "spof": true
          },
          {
            "path": "fluentd/datadog_checks/fluentd/data",
            "description": "This directory is intended to store static data files or configuration templates specific to the Fluentd integration. Although currently empty, it serves as a designated location for non-code resources that support the integration's functionality.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 82
          },
          {
            "name": "Yann Armelin",
            "percent": 12
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 23,
      "spofCount": 11
    },
    "busFactor": 5,
    "authorCount": 13
  },
  "ExtraHop Reveal(x) Integration": {
    "description": "Ingests security detection and investigation data from the ExtraHop Reveal(x) Network Detection and Response (NDR) platform.",
    "functions": {
      "Integration Assets and Dashboards": {
        "files": [
          {
            "path": "extrahop/README.md",
            "description": "This README details the Datadog ExtraHop integration, explaining how it collects detection and investigation logs from ExtraHop and provides setup instructions for connecting ExtraHop to Datadog.",
            "spof": true
          },
          {
            "path": "extrahop/CHANGELOG.md",
            "description": "This file documents the release history and changes for the Datadog extrahop integration. It serves as a changelog for the integration, detailing new features, bug fixes, and other updates.",
            "spof": true
          },
          {
            "path": "extrahop/images",
            "description": "This directory is intended to store images or graphical assets specifically associated with the 'extrahop' integration. These assets could include icons, screenshots, or diagrams used in documentation or UI elements for the integration.",
            "spof": false
          },
          {
            "path": "extrahop/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions or configurations specifically for the ExtraHop integration. It would typically contain files that describe how ExtraHop-related data should be visualized within monitoring dashboards.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "surabhipatel-crest",
            "percent": 91
          },
          {
            "name": "dkirov-dd",
            "percent": 9
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "VMware ESXi Monitoring": {
    "description": "Monitors VMware ESXi hosts and their virtual machines, collecting performance metrics on CPU, memory, disk, and network usage.",
    "functions": {
      "ESXi Data Collection and Processing": {
        "files": [
          {
            "path": "esxi/CHANGELOG.md",
            "description": "This file is a changelog for the ESXi integration, detailing version updates, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "esxi/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog Agent ESXi integration, detailing how to monitor ESXi hosts and virtual machines, including configuration for per-instance metrics collection.",
            "spof": true
          },
          {
            "path": "esxi/tests/test_e2e.py",
            "description": "This file contains an end-to-end test for the Datadog ESXi integration, verifying that the agent can connect to an ESXi host and report the 'can_connect' metric successfully.",
            "spof": true
          },
          {
            "path": "esxi/tests/__init__.py",
            "description": "This file marks the 'tests' directory as a Python package for the ESXi integration tests, allowing Python to import modules from it.",
            "spof": true
          },
          {
            "path": "esxi/tests/conftest.py",
            "description": "This file provides pytest fixtures for the ESXi integration tests, including environment setup for a vCenter simulator (VCSIM) or a vSphere lab, and mocks for various vSphere API calls.",
            "spof": true
          },
          {
            "path": "esxi/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog ESXi integration, verifying metric collection, external host tags, and SSL handling using a vCenter simulator.",
            "spof": true
          },
          {
            "path": "esxi/tests/common.py",
            "description": "This file defines common variables, mock data, and configurations using `pyVmomi` objects for testing the Datadog ESXi integration, simulating a vSphere environment's inventory and performance metrics.",
            "spof": true
          },
          {
            "path": "esxi/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog ESXi integration. It verifies the check's ability to connect to ESXi hosts, collect metrics, handle various data scenarios, and correctly assign external host tags for ESXi entities and their hierarchical relationships.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/constants.py",
            "description": "This file defines various constants used for ESXi monitoring, including mappings for metric rollups, resource types, instance tags, and filtering options.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/check.py",
            "description": "This file implements the Datadog Agent check for monitoring ESXi hosts, handling connection to vSphere/ESXi API, configuration parsing, and resource/metric filtering.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/__init__.py",
            "description": "This `__init__.py` file defines the `esxi` Python package for the Datadog ESXi integration. It exposes the package's version and the main `EsxiCheck` class, making them importable when the package is used.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/resource_filters.py",
            "description": "This file defines a system for filtering ESXi resources based on properties like name, hostname, or guest hostname using regular expressions. It provides a base filter class and specific implementations to match against different resource attributes.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/metrics.py",
            "description": "This file defines the specific metrics collected from ESXi hosts and virtual machines by the Datadog ESXi integration.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/utils.py",
            "description": "This file provides utility functions for the ESXi integration, including tag generation, resource filtering, and metric collection logic based on vSphere Managed Object References (MORs).",
            "spof": true
          },
          {
            "path": "esxi/assets/dashboards",
            "description": "This directory is intended to store dashboard definitions or configurations specifically for the Datadog ESXi integration. It serves as a placeholder for assets used to visualize ESXi metrics.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Witt",
            "percent": 86
          },
          {
            "name": "Juanpe Araque",
            "percent": 7
          },
          {
            "name": "Kyle Neale",
            "percent": 2
          }
        ]
      },
      "Configuration Modeling and Validation": {
        "files": [
          {
            "path": "esxi/datadog_checks/esxi/config_models/validators.py",
            "description": "This file is intended to define custom configuration validation and transformation logic for the ESXi integration's configuration models.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/config_models/defaults.py",
            "description": "This file contains autogenerated default configuration values for the ESXi integration. These defaults are derived from the integration's specification (spec.yaml) and are used for various instance-level settings.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/config_models/shared.py",
            "description": "This autogenerated file defines the Pydantic `SharedConfig` model for the ESXi integration, encapsulating common configuration parameters and their associated validation and default value logic.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` that provides typed access to the autogenerated `InstanceConfig` and `SharedConfig` models for the ESXi integration. It serves as the entry point for configuration models within the `esxi.config_models` package.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/config_models/instance.py",
            "description": "This file defines the Pydantic data models for the ESXi integration's instance configuration, including nested models for filters and metric patterns. It is an autogenerated file used for structuring and validating the integration's configuration.",
            "spof": true
          },
          {
            "path": "esxi/datadog_checks/esxi/data",
            "description": "This directory is intended to store data files for the ESXi integration. These data files could include configuration templates, static assets, or other non-code resources required by the Datadog Agent's ESXi check. Its current emptiness suggests that no such files are presently needed or defined.",
            "spof": false
          },
          {
            "path": "esxi/assets/configuration",
            "description": "This directory is intended to store configuration-related assets for the Datadog ESXi integration. While currently empty, it serves as a designated location for default configuration examples, schemas, or templates.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Witt",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 22,
      "spofCount": 18
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "etcd Monitoring": {
    "description": "Monitors etcd, the distributed key-value store for Kubernetes, collecting metrics on cluster health, leadership, and performance.",
    "functions": {
      "Packaged Assets and Documentation": {
        "files": [
          {
            "path": "etcd/CHANGELOG.md",
            "description": "This file is the changelog for the etcd integration, documenting all version releases, new features, bug fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "etcd/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog Etcd integration, detailing how to collect metrics and logs to monitor Etcd cluster health and performance.",
            "spof": false
          },
          {
            "path": "etcd/images",
            "description": "This directory is intended to store images and other visual assets specifically for the `etcd` integration within the Datadog `integrations-core` repository. Its purpose is to centralize visual elements like icons, logos, or diagrams associated with the `etcd` monitoring solution, despite currently being empty.",
            "spof": false
          },
          {
            "path": "etcd/datadog_checks/etcd/data",
            "description": "This directory is intended to house static data, default configurations, or other ancillary non-code assets specifically for the Datadog etcd integration. Although currently empty, its purpose is to store any necessary data files that the integration might require for its operation.",
            "spof": false
          },
          {
            "path": "etcd/assets/configuration",
            "description": "This directory is intended to store configuration assets specific to the Datadog etcd integration. It serves as a placeholder for any configuration files required by the integration, although it is currently empty.",
            "spof": false
          },
          {
            "path": "etcd/assets/saved_views",
            "description": "This directory is intended to store predefined views or configurations, such as dashboards or monitors, specific to the Datadog etcd integration. It currently serves as a placeholder for these assets.",
            "spof": false
          },
          {
            "path": "etcd/assets/dashboards",
            "description": "This directory is intended to contain Datadog dashboard configurations specifically for the `etcd` integration within the `integrations-core` repository. These dashboards would provide out-of-the-box visualizations for `etcd` metrics.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Sarah Wang",
            "percent": 18
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 14
          },
          {
            "name": "Kyle Neale",
            "percent": 14
          }
        ]
      },
      "Integration Testing": {
        "files": [
          {
            "path": "etcd/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog etcd integration, verifying that metrics and service checks are collected correctly from an etcd instance using OpenMetrics.",
            "spof": true
          },
          {
            "path": "etcd/tests/utils.py",
            "description": "Provides utility functions for etcd tests, including a function to determine if a given etcd instance is the leader.",
            "spof": true
          },
          {
            "path": "etcd/tests/__init__.py",
            "description": "This empty `__init__.py` file marks the `etcd/tests` directory as a Python package, allowing test discovery by Python's testing frameworks.",
            "spof": true
          },
          {
            "path": "etcd/tests/common.py",
            "description": "This file defines common constants, configurations, and expected metric lists for testing the `etcd` integration, primarily for use in a Dockerized test environment.",
            "spof": false
          },
          {
            "path": "etcd/tests/test_integration.py",
            "description": "This file contains integration tests for the Datadog Etcd check, verifying its metric collection, service checks, and configuration handling in an integrated environment.",
            "spof": false
          },
          {
            "path": "etcd/tests/conftest.py",
            "description": "This file provides pytest fixtures for the etcd integration's E2E tests, including setting up a Dockerized etcd environment and defining expected metrics.",
            "spof": true
          },
          {
            "path": "etcd/tests/docker",
            "description": "This directory contains Docker-related configurations and setups specifically designed for running integration tests for the etcd integration. It provides the necessary environment to simulate an etcd cluster within a Dockerized context for testing purposes.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Alex Lopez",
            "percent": 65
          },
          {
            "name": "dkirov-dd",
            "percent": 18
          },
          {
            "name": "Steven Yuen",
            "percent": 10
          }
        ]
      },
      "Etcd Integration Core": {
        "files": [
          {
            "path": "etcd/datadog_checks/etcd/__init__.py",
            "description": "This `__init__.py` file defines the `etcd` Python package for the Datadog Agent, making its version and the main `Etcd` check class directly importable.",
            "spof": true
          },
          {
            "path": "etcd/datadog_checks/etcd/metrics.py",
            "description": "This file defines `METRIC_MAP`, a dictionary that maps raw Etcd metric names (typically from Prometheus) to standardized Datadog metric names for consistent reporting.",
            "spof": true
          },
          {
            "path": "etcd/datadog_checks/etcd/etcd.py",
            "description": "This file implements the Datadog integration check for Etcd, collecting metrics from its Prometheus endpoint and reporting on the cluster's health and leader status.",
            "spof": true
          },
          {
            "path": "etcd/datadog_checks/etcd/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides convenient accessors for `InstanceConfig` and `SharedConfig` objects, which represent the configuration models for the integration. It is an autogenerated file from a specification.",
            "spof": false
          },
          {
            "path": "etcd/datadog_checks/etcd/config_models/validators.py",
            "description": "This file is a placeholder for custom configuration validators and transformers, providing examples of how to modify or validate configuration options before use.",
            "spof": true
          },
          {
            "path": "etcd/datadog_checks/etcd/config_models/defaults.py",
            "description": "This file defines default configuration values for the Datadog etcd integration. These values are used when specific configuration parameters are not provided by the user.",
            "spof": true
          },
          {
            "path": "etcd/datadog_checks/etcd/config_models/instance.py",
            "description": "This file defines the Pydantic data model for the Datadog etcd integration's instance configuration, including schema and validation rules for various parameters like connection details, metric collection, and authentication. It is an autogenerated file from a YAML specification.",
            "spof": false
          },
          {
            "path": "etcd/datadog_checks/etcd/config_models/shared.py",
            "description": "This autogenerated file defines Pydantic models for shared configuration parameters within the Datadog etcd integration, including proxy settings and general configuration options, along with associated validation and default value handling.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 52
          },
          {
            "name": "Yann Armelin",
            "percent": 27
          },
          {
            "name": "Alex Lopez",
            "percent": 17
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 22,
      "spofCount": 10
    },
    "busFactor": 1,
    "authorCount": 9
  },
  "Forcepoint Secure Web Gateway Integration": {
    "description": "Ingests web traffic and Data Loss Prevention (DLP) logs from Forcepoint SWG for security and compliance analysis.",
    "functions": {
      "Integration Assets and Dashboards": {
        "files": [
          {
            "path": "forcepoint_secure_web_gateway/CHANGELOG.md",
            "description": "This file is a changelog documenting the version history and updates for the Forcepoint Secure Web Gateway integration. It records the initial release of the integration.",
            "spof": true
          },
          {
            "path": "forcepoint_secure_web_gateway/README.md",
            "description": "This file describes the Datadog integration for Forcepoint Secure Web Gateway. It details how to set up the integration to ingest web and web DLP logs into Datadog for analysis, monitoring, and security.",
            "spof": true
          },
          {
            "path": "forcepoint_secure_web_gateway/images",
            "description": "This directory is designated to store images pertinent to the Forcepoint Secure Web Gateway integration. These images could include screenshots for documentation, diagrams, or icons used within the integration's associated materials.",
            "spof": false
          },
          {
            "path": "forcepoint_secure_web_gateway/assets/dashboards",
            "description": "This directory is intended to store JSON definitions or configuration files for Datadog dashboards specific to the Forcepoint Secure Web Gateway integration. These dashboards provide visualizations for metrics and logs collected from the integration.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "madhavpandya-crest",
            "percent": 90
          },
          {
            "name": "dkirov-dd",
            "percent": 7
          },
          {
            "name": "manan-crest",
            "percent": 3
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "FluxCD GitOps Monitoring": {
    "description": "Provides observability into FluxCD, monitoring the health and synchronization status of Kubernetes resources managed via GitOps.",
    "functions": {
      "FluxCD Metric Collection": {
        "files": [
          {
            "path": "fluxcd/CHANGELOG.md",
            "description": "This file serves as the changelog for the Datadog FluxCD integration, documenting all changes, additions, and fixes across different versions and agent releases.",
            "spof": false
          },
          {
            "path": "fluxcd/README.md",
            "description": "This file is the README for the Datadog Agent `fluxcd` integration. It provides instructions on how to install, configure, and use the check to monitor Flux services, including collecting metrics and logs.",
            "spof": true
          },
          {
            "path": "fluxcd/tests/common.py",
            "description": "This file defines common expected metrics for testing the FluxCD integration, categorized by different versions (v1 and v2).",
            "spof": true
          },
          {
            "path": "fluxcd/tests/__init__.py",
            "description": "This is an empty `__init__.py` file, serving to mark the `tests` directory as a Python package. It enables the Python interpreter to discover and import test modules within the `fluxcd` integration.",
            "spof": true
          },
          {
            "path": "fluxcd/tests/test_e2e.py",
            "description": "This file contains an end-to-end test for the Datadog FluxCD integration, specifically verifying the collection and accuracy of metrics for FluxCD version 2. It asserts expected metrics and ensures all collected metrics are covered.",
            "spof": true
          },
          {
            "path": "fluxcd/tests/test_unit.py",
            "description": "This file contains unit tests for the Datadog FluxCD integration, verifying metric collection across different FluxCD versions and ensuring proper configuration validation and error handling.",
            "spof": true
          },
          {
            "path": "fluxcd/tests/conftest.py",
            "description": "This file defines pytest fixtures for the Datadog FluxCD integration. It sets up a Kind Kubernetes cluster with FluxCD, port-forwards to its metrics endpoints, and provides mock metric data for testing.",
            "spof": true
          },
          {
            "path": "fluxcd/tests/fixtures",
            "description": "This directory is intended to store static test data or pre-configured environments (fixtures) used by the automated tests for the FluxCD integration. These fixtures help ensure consistent and reliable testing by providing known input states.",
            "spof": false
          },
          {
            "path": "fluxcd/tests/kind",
            "description": "This directory is dedicated to testing the Datadog FluxCD integration using a KinD (Kubernetes in Docker) cluster. It likely contains setup files, configurations, or test scripts designed to deploy and validate the integration within a local Kubernetes environment.",
            "spof": false
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/__init__.py",
            "description": "This file serves as the package initializer for the `fluxcd` integration, exposing its version and the main `FluxcdCheck` class for external use.",
            "spof": true
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/check.py",
            "description": "This file defines the `FluxcdCheck` class, which serves as the core check for the Datadog FluxCD integration. It collects metrics from FluxCD using the OpenMetricsBaseCheckV2 framework and applies configuration settings.",
            "spof": true
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/metrics.py",
            "description": "This file defines dictionaries that map raw metric names to standardized metric names for Flux v1 and Flux v2. It consolidates these mappings into a single `METRIC_MAP` for use in collecting and reporting metrics.",
            "spof": true
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/config_models/defaults.py",
            "description": "This file contains autogenerated functions that return default values for various configuration options used by the FluxCD integration. These defaults are generated from the integration's `spec.yaml`.",
            "spof": true
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/config_models/shared.py",
            "description": "This file defines Pydantic models for shared configuration parameters, such as proxy settings, within the FluxCD integration. It includes validation logic and defaults for these models, and is automatically generated from a specification file.",
            "spof": true
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/config_models/validators.py",
            "description": "This file is intended for defining custom validation and transformation logic for the FluxCD integration's configuration. It provides a placeholder for functions that can modify or validate configuration parameters before use.",
            "spof": true
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/config_models/instance.py",
            "description": "This file defines the Pydantic data model for the FluxCD integration's instance configuration. It is an autogenerated file based on a specification, containing various configuration fields and validation logic.",
            "spof": true
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/config_models/__init__.py",
            "description": "This file defines a `ConfigMixin` class that provides access to the autogenerated instance and shared configuration models for the FluxCD integration.",
            "spof": true
          },
          {
            "path": "fluxcd/datadog_checks/fluxcd/data",
            "description": "This directory is intended to store supplementary data files for the 'fluxcd' Datadog integration check. While currently empty, it serves as a designated location for configuration templates, default values, or static assets needed by the check.",
            "spof": false
          },
          {
            "path": "fluxcd/assets/saved_views",
            "description": "This directory is intended to store configurations for pre-defined saved views or dashboard templates specifically related to the Flux CD integration. These assets would typically be used within the Datadog platform to provide out-of-the-box monitoring perspectives.",
            "spof": false
          },
          {
            "path": "fluxcd/assets/monitors",
            "description": "This directory is designated to store Datadog monitor definitions specifically tailored for the FluxCD integration. These monitors would be used to observe the health and performance of FluxCD deployments within a Datadog environment.",
            "spof": false
          },
          {
            "path": "fluxcd/assets/dashboards",
            "description": "This directory is designated to store Datadog dashboard definitions specifically for the FluxCD integration. It serves as a placeholder for pre-configured visualizations and metrics that users can deploy to monitor FluxCD components within Datadog. Currently, no dashboard assets are provided here.",
            "spof": false
          },
          {
            "path": "fluxcd/assets/configuration",
            "description": "This directory is designated for storing configuration-related assets or examples pertinent to the FluxCD integration for Datadog. Currently, no such assets are present, suggesting it serves as a placeholder or that configuration examples are provided elsewhere.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ilia Kurenkov",
            "percent": 55
          },
          {
            "name": "Kyle Neale",
            "percent": 9
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 8
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 22,
      "spofCount": 14
    },
    "busFactor": 1,
    "authorCount": 2
  },
  "Forcepoint SSE Integration": {
    "description": "Collects logs from Forcepoint Security Service Edge (SSE) to monitor cloud-native security services.",
    "functions": {
      "Integration Assets and Documentation": {
        "files": [
          {
            "path": "forcepoint_security_service_edge/README.md",
            "description": "This README provides an overview and setup instructions for the Datadog integration with Forcepoint Security Service Edge, detailing the types of logs collected and how to configure the connection.",
            "spof": true
          },
          {
            "path": "forcepoint_security_service_edge/CHANGELOG.md",
            "description": "This file documents all changes, new features, and bug fixes for the Forcepoint Security Service Edge integration across its various releases. It serves as a historical record of updates made to the integration.",
            "spof": true
          },
          {
            "path": "forcepoint_security_service_edge/images",
            "description": "This directory is intended to store image assets associated with the `forcepoint_security_service_edge` Datadog integration. Such assets might include icons, diagrams, or screenshots used for documentation or UI within the integration.",
            "spof": false
          },
          {
            "path": "forcepoint_security_service_edge/assets/dashboards",
            "description": "This directory is intended to store JSON definitions for Datadog dashboards specific to the Forcepoint Security Service Edge integration. While currently empty, its purpose is to house pre-built visualization and monitoring dashboards for this service.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "manan-crest",
            "percent": 92
          },
          {
            "name": "dkirov-dd",
            "percent": 6
          },
          {
            "name": "davidfeng-datadog",
            "percent": 2
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 4,
      "spofCount": 2
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "FoundationDB Monitoring": {
    "description": "Monitors FoundationDB distributed databases, collecting metrics on cluster health, transaction performance, and resource usage.",
    "functions": {
      "FoundationDB Metric Collection and Integration Packaging": {
        "files": [
          {
            "path": "foundationdb/README.md",
            "description": "This README provides instructions for setting up and configuring the Datadog Agent to monitor FoundationDB, including collecting metrics and logs, and details about the data collected.",
            "spof": false
          },
          {
            "path": "foundationdb/CHANGELOG.md",
            "description": "This file is the changelog for the FoundationDB integration, detailing version updates, new features, bug fixes, and other modifications over time.",
            "spof": false
          },
          {
            "path": "foundationdb/images",
            "description": "This directory is designated for storing images pertinent to the Datadog FoundationDB integration. Although currently empty, it is the intended location for documentation screenshots, UI assets, or other visual components related to the integration.",
            "spof": false
          },
          {
            "path": "foundationdb/datadog_checks/foundationdb/__init__.py",
            "description": "This file defines the `foundationdb` package for Datadog integrations, exposing its version and the main FoundationDB check class for external use.",
            "spof": true
          },
          {
            "path": "foundationdb/datadog_checks/foundationdb/check.py",
            "description": "This file implements the Datadog Agent integration for FoundationDB, collecting metrics and service checks by parsing the database's status JSON.",
            "spof": true
          },
          {
            "path": "foundationdb/datadog_checks/foundationdb/config_models/instance.py",
            "description": "This file defines Pydantic models for the FoundationDB integration's instance configuration, including schema, default values, and validation logic. It is autogenerated from a specification file.",
            "spof": true
          },
          {
            "path": "foundationdb/datadog_checks/foundationdb/config_models/validators.py",
            "description": "This file provides a placeholder for custom configuration validators and transformers for the FoundationDB integration. It includes commented-out examples demonstrating how to modify configuration values or raise validation errors.",
            "spof": true
          },
          {
            "path": "foundationdb/datadog_checks/foundationdb/config_models/__init__.py",
            "description": "This autogenerated file defines configuration models for the FoundationDB integration, providing `ConfigMixin` to access instance-specific and shared configurations.",
            "spof": true
          },
          {
            "path": "foundationdb/datadog_checks/foundationdb/config_models/defaults.py",
            "description": "This file defines the default configuration values for the Datadog FoundationDB integration. It is automatically generated from the integration's `spec.yaml`.",
            "spof": true
          },
          {
            "path": "foundationdb/datadog_checks/foundationdb/config_models/shared.py",
            "description": "This file defines the `SharedConfig` Pydantic model for the FoundationDB integration, which handles shared configuration options and their validation. It is an autogenerated file based on a `spec.yaml`.",
            "spof": true
          },
          {
            "path": "foundationdb/datadog_checks/foundationdb/data",
            "description": "This directory serves as a placeholder for data files, configuration templates, or other static assets specific to the FoundationDB integration. Although currently empty, it is reserved for resources that support the Datadog check for FoundationDB.",
            "spof": false
          },
          {
            "path": "foundationdb/assets/dashboards",
            "description": "This directory is designated to store Datadog dashboard assets specifically for the FoundationDB integration. It would contain pre-configured dashboard definitions, typically in JSON format, for monitoring FoundationDB instances. Currently, it is empty, indicating no dashboard assets have been provided yet.",
            "spof": false
          },
          {
            "path": "foundationdb/assets/saved_views",
            "description": "This directory is designated to store pre-configured or 'saved views' specifically for the FoundationDB integration within the Datadog ecosystem. These views typically offer ready-to-use dashboards or query configurations for monitoring FoundationDB instances. Currently, it serves as an empty placeholder for such assets.",
            "spof": false
          },
          {
            "path": "foundationdb/assets/monitors",
            "description": "This directory is designated to store monitoring assets for the Datadog FoundationDB integration. Its purpose is to house monitor definitions, alerts, or related configurations that ensure the health and performance of FoundationDB, even if currently empty. It serves as a placeholder for future monitoring-specific resources.",
            "spof": false
          },
          {
            "path": "foundationdb/assets/configuration",
            "description": "This directory is designated to store configuration assets and examples for the Datadog FoundationDB integration. Its purpose is to provide users with the necessary files to configure the integration, even if it is currently empty.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Jon Chambers",
            "percent": 68
          },
          {
            "name": "Kyle Neale",
            "percent": 7
          },
          {
            "name": "Ofek Lev",
            "percent": 4
          }
        ]
      },
      "Integration Test Suite and Environment Provisioning": {
        "files": [
          {
            "path": "foundationdb/tests/README.md",
            "description": "Provides instructions for setting up FoundationDB client libraries on macOS for end-to-end testing, addressing a common shared library error.",
            "spof": true
          },
          {
            "path": "foundationdb/tests/__init__.py",
            "description": "This empty __init__.py file marks the 'tests' directory as a Python package, allowing test modules within it to be imported and run as part of the FoundationDB integration tests.",
            "spof": true
          },
          {
            "path": "foundationdb/tests/conftest.py",
            "description": "This file provides pytest fixtures for setting up a Dockerized FoundationDB environment (standard or TLS) and initializing the database for integration tests.",
            "spof": false
          },
          {
            "path": "foundationdb/tests/common.py",
            "description": "This file defines common constants, configurations, and metric names used for testing the FoundationDB integration, including setup for end-to-end test environments with and without TLS.",
            "spof": false
          },
          {
            "path": "foundationdb/tests/test_foundationdb.py",
            "description": "This file contains unit and integration tests for the Datadog FoundationDB integration, verifying metric collection, service checks, and custom query functionality against both mock data and live environments (including TLS and non-TLS setups).",
            "spof": true
          },
          {
            "path": "foundationdb/tests/docker/tls",
            "description": "This directory is intended to contain resources or configurations specifically for testing the FoundationDB integration within Docker environments, focusing on Transport Layer Security (TLS) setups. It would typically hold TLS certificates, keys, or configuration files necessary for these tests.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/foundationdb/linux",
            "description": "This directory is designated for Continuous Integration (CI) scripts related to FoundationDB specifically for Linux environments. It likely holds setup or testing scripts used within the `.ddev` development environment to support Datadog integrations.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Jon Chambers",
            "percent": 75
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 8
          },
          {
            "name": "Fanny Jiang",
            "percent": 7
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 22,
      "spofCount": 10
    },
    "busFactor": 2,
    "authorCount": 8
  },
  "Microsoft Exchange Server Monitoring": {
    "description": "Collects performance counters from Microsoft Exchange Server to monitor mail flow, database health, and client access.",
    "functions": {
      "Integration Testing and Assets": {
        "files": [
          {
            "path": "exchange_server/CHANGELOG.md",
            "description": "This file is the changelog for the 'exchange_server' integration, documenting all version releases, features, fixes, and other changes over time.",
            "spof": false
          },
          {
            "path": "exchange_server/README.md",
            "description": "This file is the README for the Datadog Agent's integration with Microsoft Exchange Server, providing instructions for setup, configuration, and data collection (metrics and logs).",
            "spof": false
          },
          {
            "path": "exchange_server/images",
            "description": "This directory is intended to store image files specifically associated with the `exchange_server` integration within the Datadog integrations-core repository. These images might include icons, diagrams, or screenshots used for documentation or UI elements related to the integration.",
            "spof": false
          },
          {
            "path": "exchange_server/tests/__init__.py",
            "description": "This empty file serves to mark the 'tests' directory as a Python package, allowing test modules within it to be imported and discovered for the 'exchange_server' integration.",
            "spof": true
          },
          {
            "path": "exchange_server/tests/conftest.py",
            "description": "This file defines pytest fixtures for the `exchange_server` integration tests. It sets up a Datadog test environment using a Windows Docker platform and provides a deep-copied instance configuration for tests.",
            "spof": true
          },
          {
            "path": "exchange_server/tests/test_unit.py",
            "description": "This file contains unit tests for the `exchange_server` integration. It verifies that the check correctly collects and reports various performance metrics and service checks using mocked Windows performance objects.",
            "spof": true
          },
          {
            "path": "exchange_server/tests/common.py",
            "description": "This file defines common constants, instance names, and expected metric configurations used across the tests for the Datadog Exchange Server integration, facilitating consistent testing environments.",
            "spof": false
          },
          {
            "path": "exchange_server/tests/test_e2e.py",
            "description": "This file contains end-to-end tests for the Datadog Exchange Server integration. It verifies the integration's service checks and the reporting of specific Exchange Server performance metrics.",
            "spof": false
          },
          {
            "path": "exchange_server/assets/dashboards",
            "description": "This directory is intended to store JSON definitions or configurations for dashboards specifically designed for monitoring the Microsoft Exchange Server integration. As part of the 'assets' for the integration, these dashboards provide visual representations of metrics and logs collected from Exchange Server instances.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "HadhemiDD",
            "percent": 16
          },
          {
            "name": "Kyle Neale",
            "percent": 16
          },
          {
            "name": "datadog-agent-integrations-bot[bot]",
            "percent": 16
          }
        ]
      },
      "Metric Collection and Configuration": {
        "files": [
          {
            "path": "exchange_server/assets/configuration",
            "description": "This directory is intended to store configuration assets specific to the Datadog `exchange_server` integration. While currently empty, its purpose is to house configuration files, templates, or example configurations required for setting up and running the integration.",
            "spof": false
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/__init__.py",
            "description": "This `__init__.py` file defines the public interface for the `exchange_server` Datadog check package, exposing its version and the main `ExchangeCheck` class.",
            "spof": false
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/exchange_server.py",
            "description": "This file implements the Exchange Server check, acting as a dispatcher to select between a legacy and a new version of the check based on configuration, and initializes performance counter collection.",
            "spof": false
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/metrics.py",
            "description": "This file defines the Windows Performance Monitor counter mappings for collecting metrics from Exchange Server. It specifies the categories, counter names, and how they should be transformed into Datadog metric names and types.",
            "spof": true
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/check.py",
            "description": "This file implements the Datadog check for Exchange Server, collecting Windows performance counters and providing custom aggregation for specific metrics. It defines `ExchangeCheckV2` to handle metric collection and `CompatibilityPerfObject` for customized counter processing.",
            "spof": true
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/config_models/defaults.py",
            "description": "This file defines default configuration values for the `exchange_server` integration, automatically generated from its specification file.",
            "spof": true
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/config_models/shared.py",
            "description": "This file defines the Pydantic `SharedConfig` model for the Exchange Server integration, handling shared configuration options with validation logic. It is an autogenerated file based on a spec.yaml.",
            "spof": true
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/config_models/validators.py",
            "description": "This file is intended to house custom configuration validators and transformers for the Exchange Server integration, allowing for additional logic to process or validate integration configurations.",
            "spof": true
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/config_models/__init__.py",
            "description": "This `__init__.py` file acts as the entry point for the Exchange Server integration's configuration models, providing a `ConfigMixin` to access autogenerated instance and shared configuration settings.",
            "spof": false
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/config_models/instance.py",
            "description": "This file defines Pydantic models for the configuration schema of an Exchange Server integration instance. It is an autogenerated file used for validating and parsing instance-specific configuration settings.",
            "spof": true
          },
          {
            "path": "exchange_server/datadog_checks/exchange_server/data",
            "description": "This directory is intended to store static data files or configuration templates specifically for the Exchange Server integration. Although currently empty, it serves as a placeholder for any necessary data resources required by the check.",
            "spof": false
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 87
          },
          {
            "name": "Ilia Kurenkov",
            "percent": 11
          },
          {
            "name": "Julia",
            "percent": 1
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 20,
      "spofCount": 9
    },
    "busFactor": 3,
    "authorCount": 12
  },
  "Windows Event Log Collection": {
    "description": "Collects and forwards events from the Windows Event Log for monitoring, troubleshooting, and security analysis.",
    "functions": {
      "Windows Event Log Acquisition": {
        "files": [
          {
            "path": "docs/developer/architecture/win32_event_log.md",
            "description": "This document describes the architecture and various methods for collecting Windows Event Logs within Datadog, detailing filtering options, subscription models, and how events can be processed as logs.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Ofek Lev",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 1,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "IBM i (AS/400) Monitoring": {
    "description": "Collects system performance and health metrics from IBM i operating systems via ODBC connections.",
    "functions": {
      "Metric Collection via ODBC": {
        "files": [
          {
            "path": "docs/developer/architecture/ibm_i.md",
            "description": "This document describes the architecture and internal workings of the IBM i integration, focusing on its use of ODBC and the workarounds implemented to address limitations of the IBM i ODBC driver, such as query timeouts.",
            "spof": true
          }
        ],
        "contributors": [
          {
            "name": "Pablo Baeyens",
            "percent": 100
          }
        ]
      }
    },
    "stats": {
      "totalFiles": 1,
      "spofCount": 1
    },
    "busFactor": 1,
    "authorCount": 1
  },
  "IBM MQ Monitoring": {
    "description": "Monitors IBM MQ queue managers, channels, and queues to ensure the reliability of enterprise messaging.",
    "functions": {
      "CI/CD": {
        "files": [
          {
            "path": ".ddev/ci/scripts/ibm_mq/linux",
            "description": "This directory is designated for continuous integration (CI) scripts related to the IBM MQ integration, specifically tailored for Linux environments within the Datadog integrations-core repository. While currently empty, it serves as a placeholder for platform-specific CI automation.",
            "spof": false
          }
        ],
        "contributors": []
      }
    },
    "stats": {
      "totalFiles": 1,
      "spofCount": 0
    }
  },
  "IBM App Connect Enterprise (ACE) Monitoring": {
    "description": "Monitors IBM App Connect Enterprise integration servers, collecting metrics on message flows and application performance.",
    "functions": {
      "Environment Setup and CI": {
        "files": [
          {
            "path": ".ddev/ci/scripts/ibm_ace/windows/55_install_ibm_mq_client.py",
            "description": "This script downloads a specific version of the IBM MQ redistributable client for Windows and extracts it to a designated installation directory.",
            "spof": false
          },
          {
            "path": ".ddev/ci/scripts/ibm_ace/linux",
            "description": "This directory is designated for continuous integration (CI) scripts specifically tailored for IBM App Connect Enterprise (ACE) integrations running on a Linux environment, as part of the repository's DDEV-managed CI processes.",
            "spof": false
          }
        ],
        "contributors": []
      }
    },
    "stats": {
      "totalFiles": 2,
      "spofCount": 0
    }
  },
  "Microsoft SQL Server Monitoring": {
    "description": "Monitors Microsoft SQL Server instances for performance metrics, query execution statistics, and database health.",
    "functions": {
      "SqlServerMonitoring": {
        "files": [
          {
            "path": ".ddev/ci/scripts/sqlserver/windows",
            "description": "This directory is intended to house Continuous Integration (CI) scripts specifically designed for testing Datadog's SQL Server integration on Windows environments. It ensures the integration functions correctly on Windows as part of the automated testing pipeline.",
            "spof": false
          }
        ],
        "contributors": []
      }
    },
    "stats": {
      "totalFiles": 1,
      "spofCount": 0
    }
  },
  "Oracle WebLogic Monitoring": {
    "description": "Monitors Oracle WebLogic servers, collecting JMX metrics on application performance, server health, and resource utilization.",
    "functions": {},
    "stats": {
      "totalFiles": 0,
      "spofCount": 0
    }
  },
  "SAP HANA Monitoring": {
    "description": "Monitors SAP HANA databases for performance, resource usage, and system health.",
    "functions": {},
    "stats": {
      "totalFiles": 0,
      "spofCount": 0
    }
  }
}