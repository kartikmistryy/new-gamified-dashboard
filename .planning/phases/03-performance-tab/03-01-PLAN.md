---
phase: 03-performance-tab
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/teamDashboard/types.ts
  - lib/teamDashboard/performanceTypes.ts
  - lib/teamDashboard/performanceMockData.ts
  - lib/teamDashboard/performanceHelpers.ts
autonomous: true

must_haves:
  truths:
    - "Performance time-series data exists for each team member with daily data points over ~90 days"
    - "Smart sampling reduces any data set to ~40 points while preserving first and last points"
    - "Time range filtering correctly clips data to 1 month, 3 months, 1 year, or max"
    - "Visible member calculation respects all 6 filter tab types"
    - "Performance insights generate 3-4 contextual insights based on member data and time range"
  artifacts:
    - path: "lib/teamDashboard/performanceTypes.ts"
      provides: "ViewMode, PerformanceFilter, MemberPerformanceDataPoint types"
      exports: ["ViewMode", "PerformanceFilter", "MemberPerformanceDataPoint"]
    - path: "lib/teamDashboard/performanceMockData.ts"
      provides: "Time-series mock data generator"
      exports: ["generateMemberPerformanceTimeSeries"]
    - path: "lib/teamDashboard/performanceHelpers.ts"
      provides: "Smart sampling, time range filtering, visibility, sufficiency, insights"
      exports: ["smartSample", "filterByTimeRange", "isTimeRangeSufficient", "getVisibleMembersForFilter", "getPerformanceInsights"]
    - path: "lib/teamDashboard/types.ts"
      provides: "Extended MemberPerformanceRow with change and churnRate fields"
      contains: "change"
  key_links:
    - from: "lib/teamDashboard/performanceMockData.ts"
      to: "lib/teamDashboard/performanceTypes.ts"
      via: "imports MemberPerformanceDataPoint type"
      pattern: "import.*MemberPerformanceDataPoint.*performanceTypes"
    - from: "lib/teamDashboard/performanceHelpers.ts"
      to: "lib/teamDashboard/performanceTypes.ts"
      via: "imports all performance types"
      pattern: "import.*performanceTypes"
    - from: "lib/teamDashboard/performanceMockData.ts"
      to: "lib/teamDashboard/types.ts"
      via: "imports MemberPerformanceRow"
      pattern: "import.*MemberPerformanceRow"
---

<objective>
Create the performance data layer: types, time-series mock data generator, and helper functions for smart sampling, time range filtering, member visibility, data sufficiency, and insight generation.

Purpose: All data transformations and business logic must exist before the chart component and page can consume them. This plan establishes the complete data pipeline from mock generation through sampling and filtering to insight generation.
Output: Four files providing types, mock data, and helper utilities that Plan 02 will wire into the UI.
</objective>

<execution_context>
@/Users/kartikmistry/.claude/get-shit-done/workflows/execute-plan.md
@/Users/kartikmistry/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-performance-tab/03-RESEARCH.md

@lib/teamDashboard/types.ts
@lib/teamDashboard/overviewMockData.ts
@lib/orgDashboard/timeRangeTypes.ts
@lib/orgDashboard/colors.ts
@lib/orgDashboard/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create performance types and extend MemberPerformanceRow</name>
  <files>
    lib/teamDashboard/performanceTypes.ts
    lib/teamDashboard/types.ts
  </files>
  <action>
    1. Create `lib/teamDashboard/performanceTypes.ts` with these type definitions:

    ```typescript
    export type ViewMode = "aggregate" | "individual";

    export type PerformanceFilter =
      | "mostProductive"
      | "leastProductive"
      | "mostImproved"
      | "mostRegressed"
      | "highestChurn"
      | "lowestChurn";

    export type MemberPerformanceDataPoint = {
      date: string;           // ISO date string YYYY-MM-DD
      value: number;          // Team average performance at this point
      memberValues: Record<string, number>; // Individual member values keyed by memberName
    };
    ```

    2. Extend `lib/teamDashboard/types.ts` to add optional `change` and `churnRate` fields to MemberPerformanceRow:
    - Add `change?: number;` (performance change in points, positive = improved, negative = regressed)
    - Add `churnRate?: number;` (code churn rate 0-100)
    - Keep all existing fields untouched. These are optional fields so they do NOT break existing Overview tab usage.

    Per user decision: use performanceValue as the metric (matches Overview gauge). Use average (not median) for aggregate calculation, matching Phase 2's `teamGaugeValue = Math.round(sum / members.length)` pattern.
  </action>
  <verify>Run `npx tsc --noEmit` to confirm no type errors across the project. The new optional fields must not break existing MemberPerformanceRow usages in MemberTable or overviewMockData.</verify>
  <done>performanceTypes.ts exports ViewMode, PerformanceFilter, MemberPerformanceDataPoint. types.ts has change and churnRate optional fields on MemberPerformanceRow. Zero type errors.</done>
</task>

<task type="auto">
  <name>Task 2: Create mock data generator and performance helper functions</name>
  <files>
    lib/teamDashboard/performanceMockData.ts
    lib/teamDashboard/performanceHelpers.ts
  </files>
  <action>
    1. Create `lib/teamDashboard/performanceMockData.ts`:
    - Export `generateMemberPerformanceTimeSeries(members: MemberPerformanceRow[]): MemberPerformanceDataPoint[]`
    - Generate daily data points over ~90 days (enough for 3-month range, partial 1-year)
    - For each day, calculate each member's value as: `member.performanceValue + random_walk_variation`
    - Use deterministic noise based on member name + day index (so data is stable across renders)
    - Reuse the `noise()` function pattern from overviewMockData.ts for deterministic randomness
    - Clamp all values to 0-100
    - Calculate `value` field as average of all memberValues (matches Overview gauge calculation)
    - Data points sorted chronologically (oldest first)

    2. Create `lib/teamDashboard/performanceHelpers.ts` with these exports:

    **smartSample<T extends { date: string }>(data: T[], targetPoints = 40): T[]**
    - If data.length <= targetPoints, return data unchanged
    - Always include first and last point
    - Evenly distribute remaining points between first and last
    - Use step = (data.length - 1) / (targetPoints - 1), pick Math.round(i * step)

    **filterByTimeRange<T extends { date: string }>(data: T[], timeRange: TimeRangeKey): T[]**
    - "max" returns all data
    - "1m" / "3m" / "1y": calculate startDate from last data point, filter data where date >= startDate
    - Import TimeRangeKey from `@/lib/orgDashboard/timeRangeTypes`

    **isTimeRangeSufficient<T extends { date: string }>(data: T[], timeRange: TimeRangeKey): boolean**
    - Filter data by time range, return true if >= 2 points exist (minimum to draw a line)
    - Per user decision: >= 2 data points threshold for enabling range buttons

    **getVisibleMembersForFilter(members: MemberPerformanceRow[], filter: PerformanceFilter, viewMode: ViewMode): Set<string>**
    - If viewMode is "aggregate", return empty Set (not used)
    - "mostProductive": sort by performanceValue desc, take top 3
    - "leastProductive": sort by performanceValue asc, take top 3
    - "mostImproved": filter where (change ?? 0) > 0
    - "mostRegressed": filter where (change ?? 0) < 0
    - "highestChurn": sort by (churnRate ?? 0) desc, take top 3
    - "lowestChurn": sort by (churnRate ?? 0) asc, take top 3
    - Return Set of memberName strings
    - IMPORTANT: Always spread-copy arrays before sorting to avoid mutating input

    **getPerformanceInsights(members: MemberPerformanceRow[], data: MemberPerformanceDataPoint[], timeRange: TimeRangeKey): ChartInsight[]**
    - Import ChartInsight from `@/lib/orgDashboard/types`
    - Calculate trend from first to last data point value
    - If change > 5: "Team performance increased X points over the {period}" (positive insight)
    - If change < -5: "Team performance decreased X points" (concern insight)
    - Else: "Team performance remained stable" (neutral insight)
    - Add top performers insight (members with performanceValue >= 75)
    - Add improved members insight (members with change > 10)
    - Return up to 4 insights, each with unique id and text string
    - Personalize with member names (matches Phase 2 pattern from overviewHelpers.ts)

    Anti-patterns to avoid:
    - Do NOT sample before filtering time range (filter first, sample second)
    - Do NOT use median for aggregate (use average per user decision)
    - Do NOT mutate input arrays in sort operations (always spread-copy first)
  </action>
  <verify>Run `npx tsc --noEmit` to confirm no type errors. Verify exports by checking that all 5 helper functions and the mock generator are importable.</verify>
  <done>performanceMockData.ts generates 90+ daily data points with deterministic member values. performanceHelpers.ts exports all 5 functions: smartSample, filterByTimeRange, isTimeRangeSufficient, getVisibleMembersForFilter, getPerformanceInsights. All compile without errors.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes with zero errors
- lib/teamDashboard/performanceTypes.ts exists with ViewMode, PerformanceFilter, MemberPerformanceDataPoint exports
- lib/teamDashboard/performanceMockData.ts exists with generateMemberPerformanceTimeSeries export
- lib/teamDashboard/performanceHelpers.ts exists with all 5 helper function exports
- lib/teamDashboard/types.ts has change and churnRate optional fields
- Existing MemberTable and overview page still work (no breaking changes to MemberPerformanceRow)
</verification>

<success_criteria>
All performance data layer files compile cleanly, export correct types and functions, and do not break any existing code. The mock generator produces deterministic time-series data with ~90 daily points, and helpers correctly implement smart sampling, time range filtering, member visibility, data sufficiency, and insight generation.
</success_criteria>

<output>
After completion, create `.planning/phases/03-performance-tab/03-01-SUMMARY.md`
</output>
